#!/usr/bin/python

# to create an exe from .py , run below command: pyinstaller extractor.py
# if pyinstaller is not installed and you get SSL error, try: pip install pyinstaller --trusted-host pypi.org --trusted-host files.pythonhosted.org

# Import modules
import logging
from tkinter import *
from PIL import ImageTk, Image
from tksheet import Sheet
from tkinter import ttk
from functools import partial
from tkinter import messagebox
from tkinter.messagebox import askyesno
import pyodbc
import time
from time import gmtime, strftime
import datetime
from datetime import date
import os
import pathlib
from pathlib import Path
import pandas as pd
import numpy as np
import configparser
import xlwt  # write to xls
import xlrd  # read from xls
import warnings
import re
import ast
import gc
from tkinter import filedialog
import tkinter.scrolledtext as st
import win32com.client as win32  # for email
import subprocess, sys
import shutil
import csv
import sqlite3
import stat
import zipfile

log_filename = "python_costing_extractor_log.log"
logging.basicConfig(
    filename=log_filename,
    format="%(asctime)s - %(message)s",
    datefmt="%d-%b-%Y %H:%M:%S",
    filemode="w",
    level=logging.INFO,
)
logging.info("STARTING COSTING EXTRACTOR.")
warnings.filterwarnings("ignore")
logging.info("Import modules completed.")
# datetime object containing current date and time
now = datetime.datetime.now()
# To prevent ParsingError, set allow_no_value=True
config = configparser.ConfigParser(allow_no_value=True)
config.read("config.ini")
# checking if the directory  exist or not.
# if the directory is not present  then create it.
if not os.path.exists("./Costing"):
    os.makedirs("./Costing")
if not os.path.exists("./ExtractorDB"):
    os.makedirs("./ExtractorDB")
if not os.path.exists("./Output"):
    os.makedirs("./Output")
if not os.path.exists("./temp_transform"):
    os.makedirs("./temp_transform")
if not os.path.exists("./Staging"):
    os.makedirs("./Staging")
logging.info(
    "Created Costing, ExtractorDB, Output, temp_transform and Staging folders, if they did not exist before."
)
# Fetch list of 64 bit data sources
drivers_list = pyodbc.dataSources()
logging.info("List of 64 bit DSN  = %s", drivers_list)
# source list
source_list = ["HIE", "EDW"]
logging.info("Display splash screen.")
# Create object
splash_screen = Tk()
splash_screen_width = 300
splash_screen_height = 300
# get the screen dimension
screen_width = splash_screen.winfo_screenwidth()
screen_height = splash_screen.winfo_screenheight()
# find the center point
center_x = int(screen_width / 2 - splash_screen_width / 2)
center_y = int(screen_height / 2 - splash_screen_height / 2)
# set the position of the window to the center of the screen
splash_screen.geometry(
    f"{splash_screen_width}x{splash_screen_height}+{center_x}+{center_y}"
)
# SET WINDOW TITLE
splash_screen.title("Data Extraction Utility for PPM3 v1.17")
# set window color
splash_screen.configure(bg="white")
# add logo
# Open image
img = Image.open("hssg_logo.jpg")
# Resize the Image using resize method
resized_image = img.resize((181, 70), Image.LANCZOS)
# Create an object of tkinter ImageTk
new_image = ImageTk.PhotoImage(resized_image)
# Create a Label Widget to display the Image
logo_label = Label(splash_screen, image=new_image)
logo_label.place(relx=0.5, rely=0.5, anchor="center")
# Set Label
splash_label = Label(splash_screen, text="Starting...", font=1, bg="white")
# use place method to set the position of label to bottom left
splash_label.place(relx=0.1, rely=0.9, anchor="sw")
# Prevent window x and y to be rezizeable
splash_screen.resizable(False, False)
aecc_round_id_list_OLD = []
aecc_round_id_list = [
    "V26.25",
    "V26.50",
    "V26.75",
    "V26",
    "V27.25",
    "V27.50",
    "V27.75",
    "V27.4",
    "V27",
    "V28.25",
    "V28.50",
    "V28.75",
    "V28.4",
    "V28",
    "V29.25",
    "V29.50",
    "V29.75",
    "V29.4",
    "V29",
    "V30.25",
    "V30.50",
    "V30.75",
    "V30.4",
    "V30",
]


def cleanup_memory(df_1):
    if len(df_1) > 0:
        del [[df_1]]
        gc.collect()
        df_1 = pd.DataFrame()
    gc.collect()


def read_csv_file(file_path, encoding, dtype, keep_default_na, na_values):
    df = pd.read_csv(file_path, encoding="unicode_escape", keep_default_na=False)
    return df


def changeState(button, choose):
    pick = choose.get()
    if pick != "":
        button["state"] = ACTIVE
    else:
        button["state"] = DISABLED


def clear_output_dir(dir_path):
    if os.path.exists(dir_path):
        for f in os.listdir(dir_path):
            try:
                os.remove(os.path.join(dir_path, f))
            except OSError as e:
                logging.exception("Exception occurred")
                messagebox.showerror("Delete Files", str(e))
        messagebox.showinfo(
            "Delete Files",
            "Files generated from previous run have been deleted from " + dir_path,
        )


def clear_neg_one(df):
    df_upd = df.replace(-1, "")
    df_upd1 = df_upd.replace("-1", "")
    return df_upd1


def run_omen():
    directory_path = "./Output/"
    no_of_files = len(os.listdir(directory_path))
    if no_of_files == 0:
        messagebox.showinfo(
            "Omen",
            "There are no files in the Output folder to perform OMEN.\nCosting Extractor will now close.",
            parent=main_screen,
        )
        button_omen["state"] = DISABLED
        main_screen.destroy()
        logging.info(
            "There are no files in the Output folder to perform OMEN. COSTING EXTRACTOR COMPLETED SUCCESSFULLY."
        )
    else:
        logging.info("User initiated OMEN.")
        messagebox.showinfo(
            "Omen", "OMEN is now running. Please wait...", parent=main_screen
        )
        omen_round = config["previous_exractor_run"]["prev_roundid"]
        omen_round = omen_round.replace("V", "")
        split_round = omen_round.split(".")
        if len(split_round) == 1:
            omen_round = str(split_round[0])
            omen_round_hash = str(split_round[0])
            omen_round_und = str(split_round[0])
        else:
            if split_round[1] == "25":
                omen_round = str(split_round[0]) + ".25"
                omen_round_hash = str(split_round[0]) + "#25"
                omen_round_und = str(split_round[0]) + "_25"
            elif split_round[1] == "50":
                omen_round = str(split_round[0]) + ".50"
                omen_round_hash = str(split_round[0]) + "#50"
                omen_round_und = str(split_round[0]) + "_50"
            elif split_round[1] == "75":
                omen_round = str(split_round[0]) + ".75"
                omen_round_hash = str(split_round[0]) + "#75"
                omen_round_und = str(split_round[0]) + "_75"
        omen_start_dt = (
            str(config["previous_exractor_run"]["prev_start_dt"]) + " " + "00:00:00"
        )
        omen_end_dt = (
            str(config["previous_exractor_run"]["prev_end_dt"]) + " " + "23:59:59"
        )
        # create omen directories
        if not os.path.exists("./LoadingFiles"):
            os.makedirs("./LoadingFiles")
        if not os.path.exists("./QualityChecks"):
            os.makedirs("./QualityChecks")
        if not os.path.exists("./WorkingFiles"):
            os.makedirs("./WorkingFiles")
        if not os.path.exists("./SourceFiles/Output"):
            os.makedirs("./SourceFiles/Output")
        # Copy the Output Folder as is from the Extractor and paste it in the SourceFiles folder.
        logging.info("Copying files from Output folder to SourceFiles/Output folder.")
        shutil.copytree("./Output", "./SourceFiles/Output", dirs_exist_ok=True)
        logging.info(
            "Copying files from Output folder to SourceFiles/Output folder completed."
        )
        omen_result = subprocess.run(
            [
                "powershell.exe",
                "-ExecutionPolicy",
                "Bypass",
                "-File",
                os.path.abspath("OMEN.ps1"),
                "-round",
                omen_round,
                "-round_und",
                omen_round_und,
                "-round_hash",
                omen_round_hash,
                "-start_dt",
                omen_start_dt,
                "-end_dt",
                omen_end_dt,
            ],
            stdout=sys.stdout,
        )
        print(omen_result.stdout)
        logging.info("Stdout from OMEN:\n%s", omen_result.stdout)
        messagebox.showinfo(
            "Omen",
            "OMEN completed.\nPlease check python_costing_extractor_log to see if OMEN completed successfully.\nIf the OMEN was successful, the output will be present in./LoadingFile.\nCosting Extractor will now close.",
            parent=main_screen,
        )
        button_omen["state"] = DISABLED
        main_screen.destroy()
        logging.info("COSTING EXTRACTOR COMPLETED.")


def quote_output_files():
    for file_f in os.listdir("./Output"):
        prefixes = [
            "tbl_PPM_Patient",
            "tbl_PPM_Transfer",
            "tbl_PPM_Encounter",
            "tbl_ppm_ED_Encounter",
        ]
        if file_f.startswith(tuple(prefixes)):
            logging.info("Quoting %s STARTED", str(file_f))
            df_read = read_csv_file(
                "./Output/" + str(file_f),
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
            if len(df_read) > 0:
                try:
                    df_read.to_csv(
                        "./Output/" + str(file_f),
                        quoting=csv.QUOTE_ALL,
                        index=False,
                        na_rep="",
                        float_format=str,
                        decimal=str,
                        date_format=str,
                    )
                except Exception as e:
                    logging.exception("Exception occurred")
                    messagebox.showerror("Quote File", str(e))
                    return
                else:
                    logging.info("Quoting %s COMPLETED.", str(file_f))


def run_reconciliation():
    logging.info("reconciliationEdDataReport started")
    versionID = config["previous_exractor_run"]["prev_roundid"]
    x = versionID.split(".")
    if len(x) == 1:
        versionID_hash = x[0]
        versionID_underscore = x[0]
        versionID_dot = x[0]
    elif len(x) == 2:
        versionID_hash = x[0] + "#" + x[1]
        versionID_underscore = x[0] + "_" + x[1]
        versionID_dot = x[0] + "." + x[1]
    # import tbl_ppm_ED_Encounter_preclean
    file_tbl_ppm_ED_Encounter_preclean = "./ExtractorDB/PpmEdEncounterPreclean.csv"
    if os.path.isfile(file_tbl_ppm_ED_Encounter_preclean):
        try:
            tbl_ppm_ED_Encounter_preclean = read_csv_file(
                file_tbl_ppm_ED_Encounter_preclean,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_ppm_ED_Encounter_preclean from ./ExtractorDB/PpmEdEncounterPreclean.csv.\n"
                + str(e),
            )
            return
        else:
            tbl_ppm_ED_Encounter_preclean = tbl_ppm_ED_Encounter_preclean.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_ppm_ED_Encounter_preclean = tbl_ppm_ED_Encounter_preclean.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_ppm_ED_Encounter_preclean = tbl_ppm_ED_Encounter_preclean.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_ppm_ED_Encounter_preclean = tbl_ppm_ED_Encounter_preclean.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
    else:
        tbl_ppm_ED_Encounter_preclean = pd.DataFrame()
    ##############
    file_tbl_PPM_ED_Encounter = (
        "./ExtractorDB/tbl_PPM_ED_Encounter_" + versionID_underscore + "_OLD_FORMAT.csv"
    )
    if os.path.isfile(file_tbl_PPM_ED_Encounter):
        try:
            tbl_PPM_ED_Encounter = read_csv_file(
                file_tbl_PPM_ED_Encounter,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            label_9_status = 0
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_PPM_ED_Encounter from ./Output/tbl_PPM_ED_Encounter.csv.\n"
                + str(e),
            )
            label_9_sub.configure(text="Failed (tbl_PPM_ED_Encounter)...", fg="red")
            main_screen.update()
            return
        else:
            tbl_PPM_ED_Encounter = tbl_PPM_ED_Encounter.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_PPM_ED_Encounter = tbl_PPM_ED_Encounter.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_PPM_ED_Encounter = tbl_PPM_ED_Encounter.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_PPM_ED_Encounter = tbl_PPM_ED_Encounter.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
    else:
        tbl_PPM_ED_Encounter = pd.DataFrame()
    #################
    file_tbl_PPM_ED_Encounter_EVT13 = (
        "./ExtractorDB/tbl_PPM_ED_Encounter_EVT13_"
        + versionID_underscore
        + "_OLD_FORMAT2.csv"
    )
    if os.path.isfile(file_tbl_PPM_ED_Encounter_EVT13):
        try:
            tbl_PPM_ED_Encounter_EVT13 = read_csv_file(
                file_tbl_PPM_ED_Encounter_EVT13,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            label_9_status = 0
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_PPM_ED_Encounter_EVT13 from ./Output/tbl_PPM_ED_Encounter_EVT13.csv.\n"
                + str(e),
            )
            label_9_sub.configure(
                text="Failed (tbl_PPM_ED_Encounter_EVT13)...", fg="red"
            )
            main_screen.update()
            return
        else:
            tbl_PPM_ED_Encounter_EVT13 = tbl_PPM_ED_Encounter_EVT13.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_PPM_ED_Encounter_EVT13 = tbl_PPM_ED_Encounter_EVT13.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_PPM_ED_Encounter_EVT13 = tbl_PPM_ED_Encounter_EVT13.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_PPM_ED_Encounter_EVT13 = tbl_PPM_ED_Encounter_EVT13.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
    else:
        tbl_PPM_ED_Encounter_EVT13 = pd.DataFrame()
    ###############
    file_tbl_ExcludedEncounters = "./Output/tbl_ExcludedEncounters.csv"
    if os.path.isfile(file_tbl_ExcludedEncounters):
        try:
            tbl_ExcludedEncounters = read_csv_file(
                file_tbl_ExcludedEncounters,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            label_9_status = 0
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_ExcludedEncounters from ./Output/tbl_ExcludedEncounters.csv.\n"
                + str(e),
            )
            label_9_sub.configure(text="Failed (tbl_ExcludedEncounters)...", fg="red")
            main_screen.update()
            return
        else:
            tbl_ExcludedEncounters = tbl_ExcludedEncounters.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_ExcludedEncounters = tbl_ExcludedEncounters.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_ExcludedEncounters = tbl_ExcludedEncounters.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_ExcludedEncounters = tbl_ExcludedEncounters.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
    else:
        tbl_ExcludedEncounters = pd.DataFrame()
    ###############
    file_tbl_PPM_Encounter = (
        "./ExtractorDB/tbl_PPM_Encounter_" + versionID_underscore + "_OLD_FORMAT.csv"
    )
    if os.path.isfile(file_tbl_PPM_Encounter):
        try:
            tbl_PPM_Encounter = read_csv_file(
                file_tbl_PPM_Encounter,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            label_9_status = 0
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_PPM_Encounter from ./Output/tbl_PPM_Encounter.csv.\n"
                + str(e),
            )
            label_9_sub.configure(text="Failed (tbl_PPM_Encounter)...", fg="red")
            main_screen.update()
            return
        else:
            tbl_PPM_Encounter = tbl_PPM_Encounter.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_PPM_Encounter = tbl_PPM_Encounter.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_PPM_Encounter = tbl_PPM_Encounter.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_PPM_Encounter = tbl_PPM_Encounter.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
    else:
        tbl_PPM_Encounter = pd.DataFrame()
    ###############
    # import OutputEpisodeATS
    file_tbl_OutputEpisodeAts = "./ExtractorDB/OutputEpisodeAts.csv"
    if os.path.isfile(file_tbl_OutputEpisodeAts):
        try:
            tbl_dbo_episode_ats = read_csv_file(
                file_tbl_OutputEpisodeAts,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_dbo_episode_ats from ./ExtractorDB/OutputEpisodeAts.csv.\n"
                + str(e),
            )
            return
        else:
            tbl_dbo_episode_ats = tbl_dbo_episode_ats.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_dbo_episode_ats = tbl_dbo_episode_ats.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_dbo_episode_ats = tbl_dbo_episode_ats.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_episode_ats = tbl_dbo_episode_ats.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
    else:
        tbl_dbo_episode_ats = pd.DataFrame()
    ##############
    # import OutputEpisodeSrg
    file_tbl_OutputEpisodeSrg = "./ExtractorDB/OutputEpisodeSrg.csv"
    if os.path.isfile(file_tbl_OutputEpisodeSrg):
        try:
            tbl_dbo_episode_srg = read_csv_file(
                file_tbl_OutputEpisodeSrg,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_dbo_episode_srg from ./ExtractorDB/OutputEpisodeSrg.csv.\n"
                + str(e),
            )
            return
        else:
            tbl_dbo_episode_srg = tbl_dbo_episode_srg.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_dbo_episode_srg = tbl_dbo_episode_srg.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_dbo_episode_srg = tbl_dbo_episode_srg.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_episode_srg = tbl_dbo_episode_srg.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
    else:
        tbl_dbo_episode_srg = pd.DataFrame()
    ##############
    # import OutputEpisode
    file_tbl_dbo_episode = "./ExtractorDB/OutputEpisode.csv"
    if os.path.isfile(file_tbl_dbo_episode):
        try:
            tbl_dbo_episode = read_csv_file(
                file_tbl_dbo_episode,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_dbo_episode from ./ExtractorDB/OutputEpisode.csv.\n"
                + str(e),
            )
            return
        else:
            tbl_dbo_episode = tbl_dbo_episode.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_dbo_episode = tbl_dbo_episode.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_dbo_episode = tbl_dbo_episode.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_episode = tbl_dbo_episode.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
    else:
        tbl_dbo_episode = pd.DataFrame()
    #########################################
    tbl_dbo_episode_ats["stay_number"] = (
        tbl_dbo_episode_ats["stay_number"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0")
    )
    tbl_dbo_episode_ats["episode_sequence_number"] = (
        tbl_dbo_episode_ats["episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    tbl_dbo_episode["stay_number"] = (
        tbl_dbo_episode["stay_number"].astype(str).str.pad(8, side="left", fillchar="0")
    )
    tbl_dbo_episode["episode_sequence_number"] = (
        tbl_dbo_episode["episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    tbl_dbo_episode_srg["stay_number"] = (
        tbl_dbo_episode_srg["stay_number"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0")
    )
    tbl_dbo_episode_srg["episode_sequence_number"] = (
        tbl_dbo_episode_srg["episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    tbl_ExcludedEncounters["stay_number"] = (
        tbl_ExcludedEncounters["stay_number"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0")
    )
    tbl_ExcludedEncounters["episode_sequence_number"] = (
        tbl_ExcludedEncounters["episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    ############  ED ########################
    ### 1. ED PRECLEAN
    encounters_EDVisit_Table_13 = tbl_ppm_ED_Encounter_preclean[
        tbl_ppm_ED_Encounter_preclean["Extra:EDVisitType"] == "13"
    ]
    encounters_EDVisit_Table_13["Facility"] = encounters_EDVisit_Table_13["Hospital"]
    encounters_EDVisit_Table_13["ED Visit Type"] = np.where(
        encounters_EDVisit_Table_13["Extra:EDVisitType"] == "13",
        "ED Encounter 1EVT13",
        "ED Encounter",
    )
    encounters_EDVisit_Table_13 = encounters_EDVisit_Table_13[
        ["Facility", "ED Visit Type"]
    ]
    encounters_EDVisit_Table_13 = (
        encounters_EDVisit_Table_13.groupby(["Facility", "ED Visit Type"])
        .size()
        .reset_index(name="Encounters ED Visit Table")
    )
    encounters_EDVisit_Table_13 = encounters_EDVisit_Table_13[
        ["Facility", "ED Visit Type", "Encounters ED Visit Table"]
    ]
    encounters_EDVisit_Table_13["Encounters ED Visit Table"] = (
        encounters_EDVisit_Table_13["Encounters ED Visit Table"].fillna(0)
    )
    # Get sum of all rows as a new row in Dataframe
    encounters_EDVisit_Table_13.loc["Total"] = encounters_EDVisit_Table_13.sum()
    encounters_EDVisit_Table_13.at["Total", "Facility"] = "total"
    encounters_EDVisit_Table_13.at["Total", "ED Visit Type"] = "ED Encounter 1EVT13"
    encounters_EDVisit_Table_non_13 = tbl_ppm_ED_Encounter_preclean[
        tbl_ppm_ED_Encounter_preclean["Extra:EDVisitType"] != "13"
    ]
    encounters_EDVisit_Table_non_13["Facility"] = encounters_EDVisit_Table_non_13[
        "Hospital"
    ]
    encounters_EDVisit_Table_non_13["ED Visit Type"] = np.where(
        encounters_EDVisit_Table_non_13["Extra:EDVisitType"] == "13",
        "ED Encounter 1EVT13",
        "ED Encounter",
    )
    encounters_EDVisit_Table_non_13 = encounters_EDVisit_Table_non_13[
        ["Facility", "ED Visit Type"]
    ]
    encounters_EDVisit_Table_non_13 = (
        encounters_EDVisit_Table_non_13.groupby(["Facility", "ED Visit Type"])
        .size()
        .reset_index(name="Encounters ED Visit Table")
    )
    encounters_EDVisit_Table_non_13 = encounters_EDVisit_Table_non_13[
        ["Facility", "ED Visit Type", "Encounters ED Visit Table"]
    ]
    encounters_EDVisit_Table_non_13["Encounters ED Visit Table"] = (
        encounters_EDVisit_Table_non_13["Encounters ED Visit Table"].fillna(0)
    )
    # Get sum of all rows as a new row in Dataframe
    encounters_EDVisit_Table_non_13.loc["Total"] = encounters_EDVisit_Table_non_13.sum()
    encounters_EDVisit_Table_non_13.at["Total", "Facility"] = "total"
    encounters_EDVisit_Table_non_13.at["Total", "ED Visit Type"] = "ED Encounter"
    encounters_EDVisit_Table = pd.concat(
        [encounters_EDVisit_Table_non_13, encounters_EDVisit_Table_13], axis=0
    )
    ###############################
    ### 2.a) ED ENCOUNTER != 13
    encounters_tbl_ppm_ED_Encounter_table_non_evt13 = (
        tbl_PPM_ED_Encounter.groupby(["Hospital"])
        .size()
        .reset_index(name="Encounters tbl_ppm_ED_Encounter table")
    )
    encounters_tbl_ppm_ED_Encounter_table_non_evt13[
        "Encounters tbl_ppm_ED_Encounter table"
    ] = encounters_tbl_ppm_ED_Encounter_table_non_evt13[
        "Encounters tbl_ppm_ED_Encounter table"
    ].fillna(0)
    encounters_tbl_ppm_ED_Encounter_table_non_evt13["Facility"] = (
        encounters_tbl_ppm_ED_Encounter_table_non_evt13["Hospital"]
    )
    encounters_tbl_ppm_ED_Encounter_table_non_evt13["ED Visit Type"] = "ED Encounter"
    encounters_tbl_ppm_ED_Encounter_table_non_evt13 = (
        encounters_tbl_ppm_ED_Encounter_table_non_evt13[
            ["Facility", "ED Visit Type", "Encounters tbl_ppm_ED_Encounter table"]
        ]
    )
    encounters_tbl_ppm_ED_Encounter_table_non_evt13.sort_values(
        by=["Facility", "ED Visit Type"], inplace=True
    )
    # Get sum of all rows as a new row in Dataframe
    encounters_tbl_ppm_ED_Encounter_table_non_evt13.loc["Total"] = (
        encounters_tbl_ppm_ED_Encounter_table_non_evt13.sum()
    )
    encounters_tbl_ppm_ED_Encounter_table_non_evt13.at["Total", "Facility"] = "total"
    encounters_tbl_ppm_ED_Encounter_table_non_evt13.at["Total", "ED Visit Type"] = (
        "ED Encounter"
    )
    #### 2.b) ED ENCOUNTER = 13
    encounters_tbl_ppm_ED_Encounter_table_evt13 = (
        tbl_PPM_ED_Encounter_EVT13.groupby(["Hospital"])
        .size()
        .reset_index(name="Encounters tbl_ppm_ED_Encounter table")
    )
    encounters_tbl_ppm_ED_Encounter_table_evt13[
        "Encounters tbl_ppm_ED_Encounter table"
    ] = encounters_tbl_ppm_ED_Encounter_table_evt13[
        "Encounters tbl_ppm_ED_Encounter table"
    ].fillna(0)
    encounters_tbl_ppm_ED_Encounter_table_evt13["Facility"] = (
        encounters_tbl_ppm_ED_Encounter_table_evt13["Hospital"]
    )
    encounters_tbl_ppm_ED_Encounter_table_evt13["ED Visit Type"] = "ED Encounter 1EVT13"
    encounters_tbl_ppm_ED_Encounter_table_evt13 = (
        encounters_tbl_ppm_ED_Encounter_table_evt13[
            ["Facility", "ED Visit Type", "Encounters tbl_ppm_ED_Encounter table"]
        ]
    )
    encounters_tbl_ppm_ED_Encounter_table_evt13.sort_values(
        by=["Facility", "ED Visit Type"], inplace=True
    )
    # Get sum of all rows as a new row in Dataframe
    encounters_tbl_ppm_ED_Encounter_table_evt13.loc["Total"] = (
        encounters_tbl_ppm_ED_Encounter_table_evt13.sum()
    )
    encounters_tbl_ppm_ED_Encounter_table_evt13.at["Total", "Facility"] = "total"
    encounters_tbl_ppm_ED_Encounter_table_evt13.at["Total", "ED Visit Type"] = (
        "ED Encounter 1EVT13"
    )
    #### 2. CONCAT
    encounters_tbl_ppm_ED_Encounter_table = pd.concat(
        [
            encounters_tbl_ppm_ED_Encounter_table_non_evt13,
            encounters_tbl_ppm_ED_Encounter_table_evt13,
        ],
        axis=0,
    )
    ######################EXCLUDED ENCOUNTER
    ### 3.a) ED ENCOUNTER = 13
    tbl_ExcludedEncounters_13 = tbl_ExcludedEncounters[
        tbl_ExcludedEncounters["ReasonForExclusion"]
        == "ED Visit Type 13 - Admitted Patient"
    ]
    tbl_ExcludedEncounters_13["Facility"] = tbl_ExcludedEncounters_13[
        "facility_identifier"
    ]
    tbl_ExcludedEncounters_13["ED Visit Type"] = "ED Encounter 1EVT13"
    tbl_ExcludedEncounters_13 = tbl_ExcludedEncounters_13[["Facility", "ED Visit Type"]]
    tbl_ExcludedEncounters_13 = (
        tbl_ExcludedEncounters_13.groupby(["Facility", "ED Visit Type"])
        .size()
        .reset_index(name="Excluded Encounters")
    )
    tbl_ExcludedEncounters_13 = tbl_ExcludedEncounters_13[
        ["Facility", "ED Visit Type", "Excluded Encounters"]
    ]
    tbl_ExcludedEncounters_13["Excluded Encounters"] = tbl_ExcludedEncounters_13[
        "Excluded Encounters"
    ].fillna(0)
    # Get sum of all rows as a new row in Dataframe
    tbl_ExcludedEncounters_13.loc["Total"] = tbl_ExcludedEncounters_13.sum()
    tbl_ExcludedEncounters_13.at["Total", "Facility"] = "total"
    tbl_ExcludedEncounters_13.at["Total", "ED Visit Type"] = "ED Encounter 1EVT13"
    ### 3.b) ED ENCOUNTER != 13
    tbl_ExcludedEncounters_non_13 = tbl_ExcludedEncounters[
        tbl_ExcludedEncounters["ReasonForExclusion"]
        == "Duplicate ED Encounter with same patientnumber, Start and End Date Time as another Encounter"
    ]
    tbl_ExcludedEncounters_non_13["Facility"] = tbl_ExcludedEncounters_non_13[
        "facility_identifier"
    ]
    tbl_ExcludedEncounters_non_13["ED Visit Type"] = "ED Encounter"
    tbl_ExcludedEncounters_non_13 = tbl_ExcludedEncounters_non_13[
        ["Facility", "ED Visit Type"]
    ]
    tbl_ExcludedEncounters_non_13 = (
        tbl_ExcludedEncounters_non_13.groupby(["Facility", "ED Visit Type"])
        .size()
        .reset_index(name="Excluded Encounters")
    )
    tbl_ExcludedEncounters_non_13 = tbl_ExcludedEncounters_non_13[
        ["Facility", "ED Visit Type", "Excluded Encounters"]
    ]
    tbl_ExcludedEncounters_non_13["Excluded Encounters"] = (
        tbl_ExcludedEncounters_non_13["Excluded Encounters"].fillna(0)
    )
    # Get sum of all rows as a new row in Dataframe
    tbl_ExcludedEncounters_non_13.loc["Total"] = tbl_ExcludedEncounters_non_13.sum()
    tbl_ExcludedEncounters_non_13.at["Total", "Facility"] = "total"
    tbl_ExcludedEncounters_non_13.at["Total", "ED Visit Type"] = "ED Encounter"
    tbl_ExcludedEncounters_Table = pd.concat(
        [tbl_ExcludedEncounters_non_13, tbl_ExcludedEncounters_13], axis=0
    )
    ###############################################
    #### 4. MERGE 1, 2, 3
    reconciliationEdDataReport = pd.merge(
        encounters_tbl_ppm_ED_Encounter_table,
        encounters_EDVisit_Table,
        how="outer",
        on=["Facility", "ED Visit Type"],
        suffixes=("", "_drop"),
    ).merge(
        tbl_ExcludedEncounters_Table,
        how="outer",
        on=["Facility", "ED Visit Type"],
        suffixes=("", "_drop"),
    )
    reconciliationEdDataReport = reconciliationEdDataReport.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    reconciliationEdDataReport = reconciliationEdDataReport[
        [
            "Facility",
            "ED Visit Type",
            "Encounters ED Visit Table",
            "Excluded Encounters",
            "Encounters tbl_ppm_ED_Encounter table",
        ]
    ]
    reconciliationEdDataReport["Encounters ED Visit Table"] = np.where(
        (reconciliationEdDataReport["Encounters ED Visit Table"] == "")
        | (reconciliationEdDataReport["Encounters ED Visit Table"].isnull()),
        0,
        reconciliationEdDataReport["Encounters ED Visit Table"],
    )
    reconciliationEdDataReport["Excluded Encounters"] = np.where(
        (reconciliationEdDataReport["Excluded Encounters"] == "")
        | (reconciliationEdDataReport["Excluded Encounters"].isnull()),
        0,
        reconciliationEdDataReport["Excluded Encounters"],
    )
    reconciliationEdDataReport["Excluded Encounters"] = reconciliationEdDataReport[
        "Excluded Encounters"
    ].astype("Int64", errors="ignore")
    reconciliationEdDataReport["Encounters tbl_ppm_ED_Encounter table"] = np.where(
        (reconciliationEdDataReport["Encounters tbl_ppm_ED_Encounter table"] == "")
        | (
            reconciliationEdDataReport["Encounters tbl_ppm_ED_Encounter table"].isnull()
        ),
        0,
        reconciliationEdDataReport["Encounters tbl_ppm_ED_Encounter table"],
    )
    reconciliationEdDataReport.sort_values(
        by=["Facility", "ED Visit Type"], inplace=True
    )
    reconciliationEdDataReport.to_csv(
        "./Output/ReconcileEdPatientData.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    logging.info("reconciliationEdDataReport=%s", len(reconciliationEdDataReport))
    #########################################
    ############  IP ########################
    # PPMEncounterRec
    # 	SELECT tbl_PPM_Encounter.EncounterNumber, Replace([Extra:HospitalStayNumber],"SN","") AS Stay, tbl_PPM_Encounter.[Extra:EpisodeSequenceNumber], tbl_PPM_Encounter.Hospital
    # FROM tbl_PPM_Encounter;
    ppmEncounterRec = tbl_PPM_Encounter[
        [
            "EncounterNumber",
            "Extra:HospitalStayNumber",
            "Extra:EpisodeSequenceNumber",
            "Hospital",
        ]
    ]
    ppmEncounterRec.rename(columns={"Extra:HospitalStayNumber": "Stay"}, inplace=True)
    ppmEncounterRec["Stay"] = ppmEncounterRec["Stay"].astype(str).str.replace("SN", "")
    ppmEncounterRec["Stay"] = (
        ppmEncounterRec["Stay"].astype(str).str.pad(8, side="left", fillchar="0")
    )
    ppmEncounterRec["Extra:EpisodeSequenceNumber"] = (
        ppmEncounterRec["Extra:EpisodeSequenceNumber"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    # ##################
    # RecInpatient01
    # 	TRANSFORM Count(tbl_dbo_episode_ats.stay_number) AS CountOfstay_number1
    # 	SELECT IIf([tbl_dbo_episode_srg]![ed_status] In ("1","4"),"X",IIf([tbl_dbo_episode_ats]![episode_of_care_type]="5" And [tbl_dbo_episode_ats]![qualified_bed_time]=0,"x",IIf([tbl_dbo_episode_ats]![episode_of_care_type]="M","MH",IIf([tbl_dbo_episode_ats]![episode_of_care_type] In ("1","5","9"),"159",IIf([tbl_dbo_episode_ats]![episode_of_care_type] In ("0",""),"E",[tbl_dbo_episode_ats]![episode_of_care_type]))))) AS [Encounter Type], Count(tbl_dbo_episode_ats.stay_number) AS CountOfstay_number
    # 	FROM (tbl_dbo_episode_ats LEFT JOIN tbl_dbo_episode_srg ON (tbl_dbo_episode_ats.episode_sequence_number = tbl_dbo_episode_srg.episode_sequence_number) AND (tbl_dbo_episode_ats.stay_number = tbl_dbo_episode_srg.stay_number) AND (tbl_dbo_episode_ats.facility_identifier = tbl_dbo_episode_srg.facility_identifier)) LEFT JOIN tbl_dbo_episode ON (tbl_dbo_episode_ats.episode_sequence_number = tbl_dbo_episode.episode_sequence_number) AND (tbl_dbo_episode_ats.stay_number = tbl_dbo_episode.stay_number) AND (tbl_dbo_episode_ats.facility_identifier = tbl_dbo_episode.facility_identifier)
    # 	GROUP BY IIf([tbl_dbo_episode_srg]![ed_status] In ("1","4"),"X",IIf([tbl_dbo_episode_ats]![episode_of_care_type]="5" And [tbl_dbo_episode_ats]![qualified_bed_time]=0,"x",IIf([tbl_dbo_episode_ats]![episode_of_care_type]="M","MH",IIf([tbl_dbo_episode_ats]![episode_of_care_type] In ("1","5","9"),"159",IIf([tbl_dbo_episode_ats]![episode_of_care_type] In ("0",""),"E",[tbl_dbo_episode_ats]![episode_of_care_type])))))
    # 	PIVOT IIf([WIP] In ("1","4"),"14","23");
    tbl_dbo_episode_ats_dummy = tbl_dbo_episode_ats[
        [
            "episode_of_care_type",
            "qualified_bed_time",
            "episode_sequence_number",
            "stay_number",
            "facility_identifier",
            "WIP",
        ]
    ]
    tbl_dbo_episode_srg_dummy = tbl_dbo_episode_srg[
        ["ed_status", "episode_sequence_number", "stay_number", "facility_identifier"]
    ]
    tbl_dbo_episode_dummy = tbl_dbo_episode[
        ["episode_sequence_number", "stay_number", "facility_identifier"]
    ]
    recInpatient01 = pd.merge(
        tbl_dbo_episode_ats_dummy,
        tbl_dbo_episode_srg_dummy,
        how="left",
        on=["facility_identifier", "stay_number", "episode_sequence_number"],
        suffixes=("", "_drop"),
    ).merge(
        tbl_dbo_episode_dummy,
        how="left",
        on=["facility_identifier", "stay_number", "episode_sequence_number"],
        suffixes=("", "_drop"),
    )
    condlist = [
        recInpatient01["ed_status"].isin(["1", "4"]),
        ~(recInpatient01["ed_status"].isin(["1", "4"]))
        & (recInpatient01["episode_of_care_type"] == "5")
        & (recInpatient01["qualified_bed_time"] == "0"),
        ~(recInpatient01["ed_status"].isin(["1", "4"]))
        & (recInpatient01["episode_of_care_type"] == "M"),
        ~(recInpatient01["ed_status"].isin(["1", "4"]))
        & (recInpatient01["episode_of_care_type"].isin(["1", "5", "9"])),
        ~(recInpatient01["ed_status"].isin(["1", "4"]))
        & (recInpatient01["episode_of_care_type"].isin(["0", ""])),
    ]
    choicelist = ["X", "X", "MH", "159", "E"]
    recInpatient01["Encounter Type"] = np.select(
        condlist, choicelist, recInpatient01["episode_of_care_type"]
    )
    recInpatient01 = recInpatient01[
        ["facility_identifier", "Encounter Type", "stay_number", "WIP"]
    ]
    recInpatient01["WIP"] = np.where(recInpatient01["WIP"].isin(["1", "4"]), "14", "23")
    recInpatient01 = (
        recInpatient01.groupby(["facility_identifier", "Encounter Type", "WIP"])[
            "stay_number"
        ]
        .count()
        .unstack()
    )
    recInpatient01 = (
        recInpatient01.reset_index().rename_axis(None).rename_axis(None, axis=1)
    )
    # ##################
    # RecInpatient02
    # 	TRANSFORM Count(tbl_dbo_episode_ats.stay_number) AS CountOfstay_number1
    # 	SELECT IIf([tbl_dbo_episode_srg]![ed_status] In ("1","4"),"X",IIf([tbl_dbo_episode_ats]![episode_of_care_type]="5" And [tbl_dbo_episode_ats]![qualified_bed_time]=0,"x",IIf([tbl_dbo_episode_ats]![episode_of_care_type]="M","MH",IIf([tbl_dbo_episode_ats]![episode_of_care_type] In ("1","5","9"),"159",IIf([tbl_dbo_episode_ats]![episode_of_care_type] In ("0",""),"E",[tbl_dbo_episode_ats]![episode_of_care_type]))))) AS [Encounter Type], Count(tbl_dbo_episode_ats.stay_number) AS CountOfstay_number
    # 	FROM ((tbl_dbo_episode_ats LEFT JOIN tbl_dbo_episode_srg ON (tbl_dbo_episode_ats.episode_sequence_number = tbl_dbo_episode_srg.episode_sequence_number) AND (tbl_dbo_episode_ats.stay_number = tbl_dbo_episode_srg.stay_number) AND (tbl_dbo_episode_ats.facility_identifier = tbl_dbo_episode_srg.facility_identifier)) LEFT JOIN tbl_dbo_episode ON (tbl_dbo_episode_ats.episode_sequence_number = tbl_dbo_episode.episode_sequence_number) AND (tbl_dbo_episode_ats.stay_number = tbl_dbo_episode.stay_number) AND (tbl_dbo_episode_ats.facility_identifier = tbl_dbo_episode.facility_identifier)) INNER JOIN PPMEncounterRec ON (tbl_dbo_episode_ats.episode_sequence_number = PPMEncounterRec.[Extra:EpisodeSequenceNumber]) AND (tbl_dbo_episode_ats.stay_number = PPMEncounterRec.Stay)
    # 	GROUP BY IIf([tbl_dbo_episode_srg]![ed_status] In ("1","4"),"X",IIf([tbl_dbo_episode_ats]![episode_of_care_type]="5" And [tbl_dbo_episode_ats]![qualified_bed_time]=0,"x",IIf([tbl_dbo_episode_ats]![episode_of_care_type]="M","MH",IIf([tbl_dbo_episode_ats]![episode_of_care_type] In ("1","5","9"),"159",IIf([tbl_dbo_episode_ats]![episode_of_care_type] In ("0",""),"E",[tbl_dbo_episode_ats]![episode_of_care_type])))))
    # 	PIVOT IIf([WIP] In ("1","4"),"14","23");
    tbl_dbo_episode_ats_dummy = tbl_dbo_episode_ats[
        [
            "episode_of_care_type",
            "qualified_bed_time",
            "episode_sequence_number",
            "stay_number",
            "facility_identifier",
            "WIP",
        ]
    ]
    tbl_dbo_episode_srg_dummy = tbl_dbo_episode_srg[
        ["ed_status", "episode_sequence_number", "stay_number", "facility_identifier"]
    ]
    tbl_dbo_episode_dummy = tbl_dbo_episode[
        ["episode_sequence_number", "stay_number", "facility_identifier"]
    ]
    recInpatient02 = (
        pd.merge(
            tbl_dbo_episode_ats_dummy,
            tbl_dbo_episode_srg_dummy,
            how="left",
            on=["facility_identifier", "stay_number", "episode_sequence_number"],
            suffixes=("", "_drop"),
        )
        .merge(
            tbl_dbo_episode_dummy,
            how="left",
            on=["facility_identifier", "stay_number", "episode_sequence_number"],
            suffixes=("", "_drop"),
        )
        .merge(
            ppmEncounterRec[["Extra:EpisodeSequenceNumber", "Stay"]],
            how="inner",
            left_on=["stay_number", "episode_sequence_number"],
            right_on=["Stay", "Extra:EpisodeSequenceNumber"],
            suffixes=("", "_drop"),
        )
    )
    condlist = [
        recInpatient02["ed_status"].isin(["1", "4"]),
        ~(recInpatient02["ed_status"].isin(["1", "4"]))
        & (recInpatient02["episode_of_care_type"] == "5")
        & (recInpatient02["qualified_bed_time"] == "0"),
        ~(recInpatient02["ed_status"].isin(["1", "4"]))
        & (recInpatient02["episode_of_care_type"] == "M"),
        ~(recInpatient02["ed_status"].isin(["1", "4"]))
        & (recInpatient02["episode_of_care_type"].isin(["1", "5", "9"])),
        ~(recInpatient02["ed_status"].isin(["1", "4"]))
        & (recInpatient02["episode_of_care_type"].isin(["0", ""])),
    ]
    choicelist = ["X", "X", "MH", "159", "E"]
    recInpatient02["Encounter Type"] = np.select(
        condlist, choicelist, recInpatient02["episode_of_care_type"]
    )
    recInpatient02 = recInpatient02[
        ["facility_identifier", "Encounter Type", "stay_number", "WIP"]
    ]
    recInpatient02["WIP"] = np.where(recInpatient02["WIP"].isin(["1", "4"]), "14", "23")
    recInpatient02 = (
        recInpatient02.groupby(["facility_identifier", "Encounter Type", "WIP"])[
            "stay_number"
        ]
        .count()
        .unstack()
    )
    recInpatient02 = (
        recInpatient02.reset_index().rename_axis(None).rename_axis(None, axis=1)
    )
    # ##################
    # RecInpatient03
    # 	TRANSFORM Count(tbl_dbo_episode_ats.stay_number) AS CountOfstay_number1
    # 	SELECT IIf([tbl_dbo_episode_srg]![ed_status] In ("1","4"),"X",IIf([tbl_dbo_episode_ats]![episode_of_care_type]="5" And [tbl_dbo_episode_ats]![qualified_bed_time]=0,"x",IIf([tbl_dbo_episode_ats]![episode_of_care_type]="M","MH",IIf([tbl_dbo_episode_ats]![episode_of_care_type] In ("1","5","9"),"159",IIf([tbl_dbo_episode_ats]![episode_of_care_type] In ("0",""),"E",[tbl_dbo_episode_ats]![episode_of_care_type]))))) AS [Encounter Type], Count(tbl_dbo_episode_ats.stay_number) AS CountOfstay_number
    # 	FROM ((tbl_dbo_episode_ats LEFT JOIN tbl_dbo_episode_srg ON (tbl_dbo_episode_ats.episode_sequence_number = tbl_dbo_episode_srg.episode_sequence_number) AND (tbl_dbo_episode_ats.stay_number = tbl_dbo_episode_srg.stay_number) AND (tbl_dbo_episode_ats.facility_identifier = tbl_dbo_episode_srg.facility_identifier)) LEFT JOIN tbl_dbo_episode ON (tbl_dbo_episode_ats.episode_sequence_number = tbl_dbo_episode.episode_sequence_number) AND (tbl_dbo_episode_ats.stay_number = tbl_dbo_episode.stay_number) AND (tbl_dbo_episode_ats.facility_identifier = tbl_dbo_episode.facility_identifier)) INNER JOIN tbl_ExcludedEncounters ON (tbl_dbo_episode_ats.episode_sequence_number = tbl_ExcludedEncounters.episode_sequence_number) AND (tbl_dbo_episode_ats.stay_number = tbl_ExcludedEncounters.Stay_number) AND (tbl_dbo_episode_ats.facility_identifier = tbl_ExcludedEncounters.facility_identifier)
    # 	GROUP BY IIf([tbl_dbo_episode_srg]![ed_status] In ("1","4"),"X",IIf([tbl_dbo_episode_ats]![episode_of_care_type]="5" And [tbl_dbo_episode_ats]![qualified_bed_time]=0,"x",IIf([tbl_dbo_episode_ats]![episode_of_care_type]="M","MH",IIf([tbl_dbo_episode_ats]![episode_of_care_type] In ("1","5","9"),"159",IIf([tbl_dbo_episode_ats]![episode_of_care_type] In ("0",""),"E",[tbl_dbo_episode_ats]![episode_of_care_type])))))
    # 	PIVOT IIf([WIP] In ("1","4"),"14","23");
    # tbl_dbo_episode_ats_dummy = tbl_dbo_episode_ats[['episode_of_care_type', 'qualified_bed_time', 'episode_sequence_number', 'stay_number', 'facility_identifier', 'WIP']]
    tbl_dbo_episode_ats_dummy = tbl_dbo_episode_ats[
        [
            "episode_of_care_type",
            "qualified_bed_time",
            "episode_sequence_number",
            "stay_number",
            "facility_identifier",
        ]
    ]
    tbl_dbo_episode_srg_dummy = tbl_dbo_episode_srg[
        ["ed_status", "episode_sequence_number", "stay_number", "facility_identifier"]
    ]
    tbl_dbo_episode_dummy = tbl_dbo_episode[
        ["episode_sequence_number", "stay_number", "facility_identifier"]
    ]
    recInpatient03 = (
        pd.merge(
            tbl_dbo_episode_ats_dummy,
            tbl_dbo_episode_srg_dummy,
            how="left",
            on=["facility_identifier", "stay_number", "episode_sequence_number"],
            suffixes=("", "_drop"),
        )
        .merge(
            tbl_dbo_episode_dummy,
            how="left",
            on=["facility_identifier", "stay_number", "episode_sequence_number"],
            suffixes=("", "_drop"),
        )
        .merge(
            tbl_ExcludedEncounters[
                ["facility_identifier", "stay_number", "episode_sequence_number"]
            ],
            how="inner",
            on=["facility_identifier", "stay_number", "episode_sequence_number"],
            suffixes=("", "_drop"),
        )
    )
    condlist = [
        recInpatient03["ed_status"].isin(["1", "4"]),
        ~(recInpatient03["ed_status"].isin(["1", "4"]))
        & (recInpatient03["episode_of_care_type"] == "5")
        & (recInpatient03["qualified_bed_time"] == "0"),
        ~(recInpatient03["ed_status"].isin(["1", "4"]))
        & (recInpatient03["episode_of_care_type"] == "M"),
        ~(recInpatient03["ed_status"].isin(["1", "4"]))
        & (recInpatient03["episode_of_care_type"].isin(["1", "5", "9"])),
        ~(recInpatient03["ed_status"].isin(["1", "4"]))
        & (recInpatient03["episode_of_care_type"].isin(["0", ""])),
    ]
    choicelist = ["X", "X", "MH", "159", "E"]
    recInpatient03["Encounter Type"] = np.select(
        condlist, choicelist, recInpatient03["episode_of_care_type"]
    )
    recInpatient03 = recInpatient03[
        ["facility_identifier", "Encounter Type", "stay_number"]
    ]
    recInpatient03 = (
        recInpatient03.groupby(
            ["facility_identifier", "Encounter Type"], as_index=False, dropna=False
        )
        .agg(CountOfstay_number=("stay_number", "count"))
        .reset_index()
    )
    recInpatient03.rename(
        columns={"CountOfstay_number": "Excluded Encounters"}, inplace=True
    )
    recInpatient03 = recInpatient03[
        ["facility_identifier", "Encounter Type", "Excluded Encounters"]
    ]
    # ##################
    # RecInpatient04
    # 	SELECT IIf([tbl_dbo_episode_srg]![ed_status] In ("1","4"),"X",IIf([tbl_dbo_episode_ats]![episode_of_care_type]="5" And [tbl_dbo_episode_ats]![qualified_bed_time]=0,"x",IIf([tbl_dbo_episode_ats]![episode_of_care_type]="M","MH",IIf([tbl_dbo_episode_ats]![episode_of_care_type] In ("1","5","9"),"159",IIf([tbl_dbo_episode_ats]![episode_of_care_type] In ("0",""),"E",[tbl_dbo_episode_ats]![episode_of_care_type]))))) AS [Encounter Type], IIf([WIP] In ("1","4"),"14","23") AS WIP_, Count(tbl_dbo_episode_ats.stay_number) AS CountOfstay_number, Count(tbl_dbo_episode_ats.stay_number) AS CountOfstay_number1, tbl_dbo_episode_ats.stay_number, tbl_dbo_episode_ats.episode_sequence_number, tbl_dbo_episode_ats.facility_identifier
    # 	FROM ((tbl_dbo_episode_ats LEFT JOIN tbl_dbo_episode_srg ON (tbl_dbo_episode_ats.episode_sequence_number = tbl_dbo_episode_srg.episode_sequence_number) AND (tbl_dbo_episode_ats.stay_number = tbl_dbo_episode_srg.stay_number) AND (tbl_dbo_episode_ats.facility_identifier = tbl_dbo_episode_srg.facility_identifier)) LEFT JOIN tbl_dbo_episode ON (tbl_dbo_episode_ats.episode_sequence_number = tbl_dbo_episode.episode_sequence_number) AND (tbl_dbo_episode_ats.stay_number = tbl_dbo_episode.stay_number) AND (tbl_dbo_episode_ats.facility_identifier = tbl_dbo_episode.facility_identifier)) INNER JOIN PPMEncounterRec ON (tbl_dbo_episode_ats.facility_identifier = PPMEncounterRec.Hospital) AND (tbl_dbo_episode_ats.episode_sequence_number = PPMEncounterRec.[Extra:EpisodeSequenceNumber]) AND (tbl_dbo_episode_ats.stay_number = PPMEncounterRec.Stay)
    # 	GROUP BY IIf([tbl_dbo_episode_srg]![ed_status] In ("1","4"),"X",IIf([tbl_dbo_episode_ats]![episode_of_care_type]="5" And [tbl_dbo_episode_ats]![qualified_bed_time]=0,"x",IIf([tbl_dbo_episode_ats]![episode_of_care_type]="M","MH",IIf([tbl_dbo_episode_ats]![episode_of_care_type] In ("1","5","9"),"159",IIf([tbl_dbo_episode_ats]![episode_of_care_type] In ("0",""),"E",[tbl_dbo_episode_ats]![episode_of_care_type]))))), IIf([WIP] In ("1","4"),"14","23"), tbl_dbo_episode_ats.stay_number, tbl_dbo_episode_ats.episode_sequence_number, tbl_dbo_episode_ats.facility_identifier
    # 	HAVING (((Count(tbl_dbo_episode_ats.stay_number))>1));
    tbl_dbo_episode_ats_dummy = tbl_dbo_episode_ats[
        [
            "episode_of_care_type",
            "qualified_bed_time",
            "episode_sequence_number",
            "stay_number",
            "facility_identifier",
            "WIP",
        ]
    ]
    tbl_dbo_episode_srg_dummy = tbl_dbo_episode_srg[
        ["ed_status", "episode_sequence_number", "stay_number", "facility_identifier"]
    ]
    tbl_dbo_episode_dummy = tbl_dbo_episode[
        ["episode_sequence_number", "stay_number", "facility_identifier"]
    ]
    ppmEncounterRec = tbl_PPM_Encounter[
        [
            "EncounterNumber",
            "Extra:HospitalStayNumber",
            "Extra:EpisodeSequenceNumber",
            "Hospital",
        ]
    ]
    ppmEncounterRec.rename(columns={"Extra:HospitalStayNumber": "Stay"}, inplace=True)
    ppmEncounterRec["Stay"] = ppmEncounterRec["Stay"].astype(str).str.replace("SN", "")
    ppmEncounterRec["Stay"] = (
        ppmEncounterRec["Stay"].astype(str).str.pad(8, side="left", fillchar="0")
    )
    ppmEncounterRec["Extra:EpisodeSequenceNumber"] = (
        ppmEncounterRec["Extra:EpisodeSequenceNumber"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    recInpatient04 = pd.merge(
        tbl_dbo_episode_ats_dummy,
        tbl_dbo_episode_srg_dummy,
        how="left",
        on=["facility_identifier", "stay_number", "episode_sequence_number"],
        suffixes=("", "_drop"),
    ).merge(
        tbl_dbo_episode_dummy,
        how="left",
        on=["facility_identifier", "stay_number", "episode_sequence_number"],
        suffixes=("", "_drop"),
    )
    recInpatient04.drop_duplicates(keep="last", inplace=True)
    recInpatient04 = recInpatient04.merge(
        ppmEncounterRec[["Extra:EpisodeSequenceNumber", "Stay", "Hospital"]],
        how="inner",
        left_on=["facility_identifier", "stay_number", "episode_sequence_number"],
        right_on=["Hospital", "Stay", "Extra:EpisodeSequenceNumber"],
        suffixes=("", "_drop"),
    )
    condlist = [
        recInpatient04["ed_status"].isin(["1", "4"]),
        ~(recInpatient04["ed_status"].isin(["1", "4"]))
        & (recInpatient04["episode_of_care_type"] == "5")
        & (recInpatient04["qualified_bed_time"] == "0"),
        ~(recInpatient04["ed_status"].isin(["1", "4"]))
        & (recInpatient04["episode_of_care_type"] == "M"),
        ~(recInpatient04["ed_status"].isin(["1", "4"]))
        & (recInpatient04["episode_of_care_type"].isin(["1", "5", "9"])),
        ~(recInpatient04["ed_status"].isin(["1", "4"]))
        & (recInpatient04["episode_of_care_type"].isin(["0", ""])),
    ]
    choicelist = ["X", "X", "MH", "159", "E"]
    recInpatient04["Encounter Type"] = np.select(
        condlist, choicelist, recInpatient04["episode_of_care_type"]
    )
    recInpatient04["WIP_"] = np.where(
        recInpatient04["WIP"].isin(["1", "4"]), "14", "23"
    )
    recInpatient04 = recInpatient04[
        [
            "Encounter Type",
            "WIP_",
            "stay_number",
            "episode_sequence_number",
            "facility_identifier",
        ]
    ]
    recInpatient04 = (
        recInpatient04.groupby(
            [
                "Encounter Type",
                "WIP_",
                "stay_number",
                "episode_sequence_number",
                "facility_identifier",
            ],
            as_index=False,
            dropna=False,
        )
        .agg(
            CountOfstay_number=("stay_number", "count"),
            CountOfstay_number1=("stay_number", "count"),
        )
        .reset_index()
    )
    recInpatient04 = recInpatient04[recInpatient04["CountOfstay_number"] > 1]
    # ##################
    # RecInpatient05
    # 	TRANSFORM Sum([CountOfstay_number]-1) AS [Count]
    # 	SELECT RecInpatient04.[Encounter Type], Sum(([CountOfstay_number]-1)) AS total
    # 	FROM RecInpatient04
    # 	GROUP BY RecInpatient04.[Encounter Type]
    # 	PIVOT RecInpatient04.WIP_;
    recInpatient04["CountOfstay_number"] = recInpatient04["CountOfstay_number"] - 1
    recInpatient05 = (
        recInpatient04.groupby(
            ["facility_identifier", "Encounter Type"], as_index=False, dropna=False
        )
        .agg(total=("CountOfstay_number", "sum"))
        .reset_index()
    )
    recInpatient05["Additional Phases SNAP AMHCC"] = recInpatient05["total"]
    recInpatient05 = recInpatient05[
        ["facility_identifier", "Encounter Type", "Additional Phases SNAP AMHCC"]
    ]
    # recInpatient05.to_csv('./Output/recInpatient05.csv', index=False, na_rep='', float_format=str, decimal=str, date_format=str)
    # ##################
    # recGroup
    # 	Encounter Type	REcGroup
    # 	159	Inpatient (Acute Excl MH, ED only, and UQB)
    # 	2	Inpatient (Rehabilitation)
    # 	3	Inpatient (Pall Care by Phase)
    # 	4	Inpatient (Maintenance)
    # 	E	Invalid Care Type and Boarders
    # 	MH	Inpatient (Mental Health)
    # 	X	Inpatient (ED only and Unqualified Babies)
    # 	6	Inpatient (Other - Care Type 6)
    # 	7	Inpatient (GEM)
    # 	8	Inpatient (Psychogeriatric)
    recGroup_data = {
        "Encounter Type": ["159", "2", "3", "4", "E", "MH", "X", "6", "7"],
        "REcGroup": [
            "Inpatient (Acute Excl MH, ED only, and UQB)",
            "Inpatient (Rehabilitation)",
            "Inpatient (Pall Care by Phase)",
            "Inpatient (Maintenance)",
            "Invalid Care Type and Boarders",
            "Inpatient (MH - Acute and SubAcute)",
            "Inpatient (ED only and Unqualified Babies)",
            "Inpatient (Other - Care Type 6)",
            "Inpatient (GEM)",
        ],
    }
    recgroup = pd.DataFrame(recGroup_data)
    # ##################
    # RecInpatient06
    # 	SELECT recgroup.REcGroup AS [Reconciliation Group], [RecInpatient01]![14] AS [Local HIE Encounters ATS (WIP 1 and 4)], [RecInpatient01]![23] AS [Local HIE Encounters ATS(WIP 2 and 3)], RecInpatient01.CountOfstay_number AS [Local HIE Encounters ATS], RecInpatient05.total AS [Additional Phases SNAP AMHCC], RecInpatient03.CountOfstay_number AS [Exclude Encounters], RecInpatient02.CountOfstay_number AS [Total Tbl_ppm_encounter]
    # 	FROM (((RecInpatient01 INNER JOIN recgroup ON RecInpatient01.[Encounter Type] = recgroup.[Encounter Type]) LEFT JOIN RecInpatient05 ON RecInpatient01.[Encounter Type] = RecInpatient05.[Encounter Type]) LEFT JOIN RecInpatient03 ON RecInpatient01.[Encounter Type] = RecInpatient03.[Encounter Type]) LEFT JOIN RecInpatient02 ON RecInpatient01.[Encounter Type] = RecInpatient02.[Encounter Type]
    # 	GROUP BY recgroup.REcGroup, [RecInpatient01]![14], [RecInpatient01]![23], RecInpatient01.CountOfstay_number, RecInpatient05.total, RecInpatient03.CountOfstay_number, RecInpatient02.CountOfstay_number;
    recInpatient06 = (
        pd.merge(
            recInpatient01,
            recgroup,
            how="inner",
            on=["Encounter Type"],
            suffixes=("", "_drop"),
        )
        .merge(
            recInpatient03,
            how="left",
            on=["facility_identifier", "Encounter Type"],
            suffixes=("", "_drop"),
        )
        .merge(
            recInpatient05,
            how="left",
            on=["facility_identifier", "Encounter Type"],
            suffixes=("", "_drop"),
        )
        .merge(
            recInpatient03,
            how="left",
            on=["facility_identifier", "Encounter Type"],
            suffixes=("", "_drop"),
        )
        .merge(
            recInpatient02,
            how="left",
            on=["facility_identifier", "Encounter Type"],
            suffixes=("", "_drop"),
        )
    )
    if len(recInpatient06) > 0:
        recInpatient06 = recInpatient06[
            [
                "facility_identifier",
                "REcGroup",
                "14",
                "23",
                "Additional Phases SNAP AMHCC",
                "Excluded Encounters",
            ]
        ]
        recInpatient06["14"] = np.where(
            (recInpatient06["14"].isnull()) | (recInpatient06["14"] == ""),
            0,
            recInpatient06["14"].astype(float),
        )
        recInpatient06["23"] = np.where(
            (recInpatient06["23"].isnull()) | (recInpatient06["23"] == ""),
            0,
            recInpatient06["23"].astype(float),
        )
        recInpatient06["Additional Phases SNAP AMHCC"] = np.where(
            (recInpatient06["Additional Phases SNAP AMHCC"].isnull())
            | (recInpatient06["Additional Phases SNAP AMHCC"] == ""),
            0,
            recInpatient06["Additional Phases SNAP AMHCC"].astype(float),
        )
        recInpatient06["Excluded Encounters"] = np.where(
            (recInpatient06["Excluded Encounters"].isnull())
            | (recInpatient06["Excluded Encounters"] == ""),
            0,
            recInpatient06["Excluded Encounters"].astype(float),
        )
        recInpatient06.drop_duplicates(keep="last", inplace=True)
        recInpatient06.sort_values(by=["facility_identifier", "REcGroup"], inplace=True)
        recInpatient06["Local Encounters ATS"] = recInpatient06["14"].astype(
            float
        ) + recInpatient06["23"].astype(float)
        recInpatient06.rename(
            columns={
                "14": "Local Encounters ATS (WIP 1 and 4)",
                "23": "Local Encounters ATS(WIP 2 and 3)",
                "facility_identifier": "Facility",
                "REcGroup": "Reconciliation Group",
            },
            inplace=True,
        )
        recInpatient06["Total Tbl_ppm_encounter"] = (
            recInpatient06["Local Encounters ATS"].astype(float)
            + recInpatient06["Additional Phases SNAP AMHCC"].astype(float)
            - recInpatient06["Excluded Encounters"].astype(float)
        )
        recInpatient06 = recInpatient06[
            [
                "Facility",
                "Reconciliation Group",
                "Local Encounters ATS (WIP 1 and 4)",
                "Local Encounters ATS(WIP 2 and 3)",
                "Local Encounters ATS",
                "Additional Phases SNAP AMHCC",
                "Excluded Encounters",
                "Total Tbl_ppm_encounter",
            ]
        ]
        ###################################
        recInpatient06_1 = recInpatient06[
            recInpatient06["Reconciliation Group"]
            == "Inpatient (Acute Excl MH, ED only, and UQB)"
        ]
        recInpatient06_1.loc["Total"] = recInpatient06_1.sum()
        recInpatient06_1.at["Total", "Facility"] = "Total"
        recInpatient06_1["Reconciliation Group"] = np.where(
            recInpatient06_1["Facility"] == "Total",
            "Inpatient (Acute Excl MH, ED only, and UQB)",
            recInpatient06_1["Reconciliation Group"],
        )
        #######
        recInpatient06_2 = recInpatient06[
            recInpatient06["Reconciliation Group"] == "Inpatient (Rehabilitation)"
        ]
        recInpatient06_2.loc["Total"] = recInpatient06_2.sum()
        recInpatient06_2.at["Total", "Facility"] = "Total"
        recInpatient06_2["Reconciliation Group"] = np.where(
            recInpatient06_2["Facility"] == "Total",
            "Inpatient (Rehabilitation)",
            recInpatient06_2["Reconciliation Group"],
        )
        #######
        recInpatient06_3 = recInpatient06[
            recInpatient06["Reconciliation Group"] == "Inpatient (Pall Care by Phase)"
        ]
        recInpatient06_3.loc["Total"] = recInpatient06_3.sum()
        recInpatient06_3.at["Total", "Facility"] = "Total"
        recInpatient06_3["Reconciliation Group"] = np.where(
            recInpatient06_3["Facility"] == "Total",
            "Inpatient (Pall Care by Phase)",
            recInpatient06_3["Reconciliation Group"],
        )
        #######
        recInpatient06_4 = recInpatient06[
            recInpatient06["Reconciliation Group"] == "Inpatient (Maintenance)"
        ]
        recInpatient06_4.loc["Total"] = recInpatient06_4.sum()
        recInpatient06_4.at["Total", "Facility"] = "Total"
        recInpatient06_4["Reconciliation Group"] = np.where(
            recInpatient06_4["Facility"] == "Total",
            "Inpatient (Maintenance)",
            recInpatient06_4["Reconciliation Group"],
        )
        #######
        recInpatient06_5 = recInpatient06[
            recInpatient06["Reconciliation Group"] == "Invalid Care Type and Boarders"
        ]
        recInpatient06_5.loc["Total"] = recInpatient06_5.sum()
        recInpatient06_5.at["Total", "Facility"] = "Total"
        recInpatient06_5["Reconciliation Group"] = np.where(
            recInpatient06_5["Facility"] == "Total",
            "Invalid Care Type and Boarders",
            recInpatient06_5["Reconciliation Group"],
        )
        #######
        recInpatient06_6 = recInpatient06[
            recInpatient06["Reconciliation Group"]
            == "Inpatient (MH - Acute and SubAcute)"
        ]
        recInpatient06_6.loc["Total"] = recInpatient06_6.sum()
        recInpatient06_6.at["Total", "Facility"] = "Total"
        recInpatient06_6["Reconciliation Group"] = np.where(
            recInpatient06_6["Facility"] == "Total",
            "Inpatient (MH - Acute and SubAcute)",
            recInpatient06_6["Reconciliation Group"],
        )
        #######
        recInpatient06_7 = recInpatient06[
            recInpatient06["Reconciliation Group"]
            == "Inpatient (ED only and Unqualified Babies)"
        ]
        recInpatient06_7.loc["Total"] = recInpatient06_7.sum()
        recInpatient06_7.at["Total", "Facility"] = "Total"
        recInpatient06_7["Reconciliation Group"] = np.where(
            recInpatient06_7["Facility"] == "Total",
            "Inpatient (ED only and Unqualified Babies)",
            recInpatient06_7["Reconciliation Group"],
        )
        #######
        recInpatient06_8 = recInpatient06[
            recInpatient06["Reconciliation Group"] == "Inpatient (Other - Care Type 6)"
        ]
        recInpatient06_8.loc["Total"] = recInpatient06_8.sum()
        recInpatient06_8.at["Total", "Facility"] = "Total"
        recInpatient06_8["Reconciliation Group"] = np.where(
            recInpatient06_8["Facility"] == "Total",
            "Inpatient (Other - Care Type 6)",
            recInpatient06_8["Reconciliation Group"],
        )
        #######
        recInpatient06_9 = recInpatient06[
            recInpatient06["Reconciliation Group"] == "Inpatient (GEM)"
        ]
        recInpatient06_9.loc["Total"] = recInpatient06_9.sum()
        recInpatient06_9.at["Total", "Facility"] = "Total"
        recInpatient06_9["Reconciliation Group"] = np.where(
            recInpatient06_9["Facility"] == "Total",
            "Inpatient (GEM)",
            recInpatient06_9["Reconciliation Group"],
        )
        #######
        recInpatient06_b = pd.concat(
            [
                recInpatient06_1,
                recInpatient06_2,
                recInpatient06_3,
                recInpatient06_4,
                recInpatient06_5,
                recInpatient06_6,
                recInpatient06_7,
                recInpatient06_8,
                recInpatient06_9,
            ],
            axis=0,
        )
        recInpatient06_b.sort_values(
            by=["Facility", "Reconciliation Group"], inplace=True
        )
        # recInpatient06_b.to_csv('./Output/recInpatient06.csv', index=False, na_rep='', float_format=str, decimal=str, date_format=str)
        # #####################
        # qry_append_Rec_psychogeri
        #     INSERT INTO ReconcileInpatientData ( [Local HIE Encounters ATS], [Reconciliation Group], Facility, [Excluded Encounters], [Total Tbl_ppm_encounter] )
        #     SELECT Count(Tbl_PPM_Encounter_V25.EncounterNumber) AS CountOfEncounterNumber, "Inpatient([PsychoGeri])" AS Expr1, "Total" AS Facility, Count(Tbl_ExcludedEncounters.EncounterNumber) AS CountOfEncounterNumber1, Sum(IIf([Tbl_ExcludedEncounters]![EncounterNumber] Is Null,1,0)) AS Expr2
        #     FROM Tbl_ExcludedEncounters RIGHT JOIN Tbl_PPM_Encounter_V25 ON Tbl_ExcludedEncounters.EncounterNumber = Tbl_PPM_Encounter_V25.EncounterNumber
        #     GROUP BY "Inpatient([PsychoGeri])", "Total", Tbl_PPM_Encounter_V25.EpisodeOfCare
        #     HAVING (((Tbl_PPM_Encounter_V25.EpisodeOfCare)="8"));
        tbl_ExcludedEncounters["EncounterNumber_dummy"] = tbl_ExcludedEncounters[
            "EncounterNumber"
        ]
        recInpatient07 = pd.merge(
            tbl_ExcludedEncounters[["EncounterNumber", "EncounterNumber_dummy"]],
            tbl_PPM_Encounter[["EncounterNumber", "EpisodeOfCare"]],
            how="right",
            on=["EncounterNumber"],
            suffixes=("", "_drop"),
        )
        recInpatient07 = recInpatient07[
            (recInpatient07["EpisodeOfCare"] == "8")
            | (recInpatient07["EpisodeOfCare"] == "8.0")
        ]
        # recInpatient07 = recInpatient07[recInpatient07['EpisodeOfCare'] =='8']
        recInpatient06.drop_duplicates(keep="last", inplace=True)
        recInpatient07 = (
            recInpatient07.groupby(["EpisodeOfCare"], as_index=False, dropna=False)
            .agg(
                CountOfEncounterNumber=("EncounterNumber", "count"),
                CountOfEncounterNumber1=("EncounterNumber_dummy", "count"),
                Expr2=("EncounterNumber_dummy", "sum"),
            )
            .reset_index()
        )
        recInpatient07.rename(
            columns={
                "CountOfEncounterNumber": "Local Encounters ATS",
                "CountOfEncounterNumber1": "Excluded Encounters",
                "Expr2": "Total Tbl_ppm_encounter",
            },
            inplace=True,
        )
        recInpatient07["Reconciliation Group"] = "Inpatient([Psychogeriatric])"
        recInpatient07["Facility"] = "Total"
        recInpatient07 = recInpatient07[
            [
                "Local Encounters ATS",
                "Reconciliation Group",
                "Facility",
                "Excluded Encounters",
                "Total Tbl_ppm_encounter",
            ]
        ]
        ###############################################################################
        reconciliationIpDataReport = pd.concat(
            [recInpatient06_b, recInpatient07], axis=0
        )
        reconciliationIpDataReport.sort_values(
            by=["Facility", "Reconciliation Group"], inplace=True
        )
        reconciliationIpDataReport["Local Encounters ATS (WIP 1 and 4)"] = (
            reconciliationIpDataReport["Local Encounters ATS (WIP 1 and 4)"].astype(
                "Int64", errors="ignore"
            )
        )
        reconciliationIpDataReport["Local Encounters ATS(WIP 2 and 3)"] = (
            reconciliationIpDataReport["Local Encounters ATS(WIP 2 and 3)"].astype(
                "Int64", errors="ignore"
            )
        )
        reconciliationIpDataReport["Local Encounters ATS"] = reconciliationIpDataReport[
            "Local Encounters ATS"
        ].astype("Int64", errors="ignore")
        reconciliationIpDataReport["Additional Phases SNAP AMHCC"] = (
            reconciliationIpDataReport["Additional Phases SNAP AMHCC"].astype(
                "Int64", errors="ignore"
            )
        )
        reconciliationIpDataReport["Excluded Encounters"] = reconciliationIpDataReport[
            "Excluded Encounters"
        ].astype("Int64", errors="ignore")
        reconciliationIpDataReport["Total Tbl_ppm_encounter"] = (
            reconciliationIpDataReport["Total Tbl_ppm_encounter"].astype(
                "Int64", errors="ignore"
            )
        )
    else:
        reconciliationIpDataReport = pd.DataFrame(
            columns=[
                "Facility",
                "Reconciliation Group",
                "Local Encounters ATS (WIP 1 and 4)",
                "Local Encounters ATS(WIP 2 and 3)",
                "Local Encounters ATS",
                "Additional Phases SNAP AMHCC",
                "Excluded Encounters",
                "Total Tbl_ppm_encounter",
            ]
        )
    reconciliationIpDataReport.rename(
        columns={
            "Local Encounters ATS (WIP 1 and 4)": "Local Encounters (WIP 1 and 4)",
            "Local Encounters ATS(WIP 2 and 3)": "Local Encounters (WIP 2 and 3)",
            "Local Encounters ATS": "Local Encounters",
        },
        inplace=True,
    )
    reconciliationIpDataReport.to_csv(
        "./Output/ReconcileInpatientData.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    logging.info("ReconcileInpatientData=%s", len(reconciliationIpDataReport))
    #############################################


def export_complete():
    # disable extract & transform buttons and enable export button
    button_extract["state"] = DISABLED
    button_transform["state"] = DISABLED
    button_export["state"] = DISABLED
    button_QCcheck["state"] = DISABLED
    button_ip_recon.place(x=25, y=250)
    button_ed_recon.place(x=25, y=300)
    button_ed_recon["state"] = ACTIVE
    button_ip_recon["state"] = ACTIVE
    directory_path = "./Output/"
    no_of_files = len(os.listdir(directory_path))
    lhd_global = config["previous_exractor_run"]["prev_lhd"]
    button_omen["state"] = ACTIVE
    messagebox.showinfo("Export Complete", "Export completed.")


def export_data():
    logging.info("EXPORT DATA STARTED.")
    global \
        versionID, \
        lhd_global, \
        facilities_excluded_list_global, \
        facilities_included_list_global, \
        roundid, \
        start_date, \
        end_date, \
        nwau_v, \
        icd10_v, \
        drg1_v, \
        drg2_v, \
        drg4_v, \
        snap_v, \
        amhcc_v, \
        cost_weight_v, \
        srg_drg_v
    versionID = config["previous_exractor_run"]["prev_roundid"]
    lhd_global = config["previous_exractor_run"]["prev_lhd"]
    facilities_excluded_list_global = ast.literal_eval(
        config["previous_exractor_run"]["prev_excluded_facilities"]
    )
    facilities_included_list_global = ast.literal_eval(
        config["previous_exractor_run"]["prev_included_facilities"]
    )
    roundid = config["previous_exractor_run"]["prev_roundid"]
    start_date = config["previous_exractor_run"]["prev_start_dt"]
    end_date = config["previous_exractor_run"]["prev_end_dt"]
    nwau_v = config["previous_exractor_run"]["prev_nwau"]
    icd10_v = config["previous_exractor_run"]["prev_icd10_v"]
    drg1_v = config["previous_exractor_run"]["prev_drg1_v"]
    drg2_v = config["previous_exractor_run"]["prev_drg2_v"]
    drg4_v = config["previous_exractor_run"]["prev_drg4_v"]
    snap_v = config["previous_exractor_run"]["prev_snap_v"]
    amhcc_v = config["previous_exractor_run"]["prev_amhcc_v"]
    cost_weight_v = config["previous_exractor_run"]["prev_cost_weight_v"]
    srg_drg_v = config["previous_exractor_run"]["prev_srg_drg_v"]
    end_date = end_date + " " + "23:59:59"
    start_date = start_date + " " + "00:00:00"
    x = versionID.split(".")
    if len(x) == 1:
        versionID_hash = x[0]
        versionID_underscore = x[0]
        versionID_dot = x[0]
    elif len(x) == 2:
        versionID_hash = x[0] + "#" + x[1]
        versionID_underscore = x[0] + "_" + x[1]
        versionID_dot = x[0] + "." + x[1]
    logging.info("In export_data(), versionID =%s", versionID)
    ############### "1. Export Patient Data"#################
    logging.info("Export Patient Data started.")
    # Set default value of sub-task status to 1
    label_1_status = 1
    label_1_sub.configure(text="In Progress (tbl_PPM_Patient)...", fg="blue")
    main_screen.update()
    file_tbl_PPM_Patient = "./ExtractorDB/tbl_PPM_Patient.csv"
    if os.path.isfile(file_tbl_PPM_Patient):
        try:
            tbl_PPM_Patient = read_csv_file(
                file_tbl_PPM_Patient,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            label_1_status = 0
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_PPM_Patient from ./ExtractorDB/tbl_PPM_Patient.csv.\n"
                + str(e),
            )
            label_1_sub.configure(text="Failed (tbl_PPM_Patient)...", fg="red")
            main_screen.update()
            return
    else:
        tbl_PPM_Patient = pd.DataFrame()
    logging.info("tbl_PPM_Patient has %s records.", len(tbl_PPM_Patient))
    tbl_PPM_Patient = tbl_PPM_Patient.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    tbl_PPM_Patient = tbl_PPM_Patient.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    tbl_PPM_Patient = tbl_PPM_Patient.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    tbl_PPM_Patient = tbl_PPM_Patient[
        [
            "PatientNumber",
            "Gender",
            "EthnicOrigin",
            "Extra:IndigenousStatus",
            "DateOfBirth",
            "mrn_for_matching",
            "AUID",
        ]
    ]
    tbl_PPM_Patient.drop_duplicates(keep="last", inplace=True)
    tbl_PPM_Patient.sort_values(by=["PatientNumber"], inplace=True)
    tbl_PPM_Patient.drop_duplicates(subset=["PatientNumber"], keep="last", inplace=True)
    try:
        tbl_PPM_Patient.to_csv(
            "./ExtractorDB/tbl_PPM_IP_Patient_" + versionID_hash + ".csv",
            index=False,
            na_rep="",
            float_format=str,
            decimal=str,
            date_format=str,
        )
    except Exception as e:
        logging.exception("Exception occurred")
        label_1_status = 0
        messagebox.showerror(
            "Export Error", "Error exporting tbl_PPM_Patient\n" + str(e)
        )
        label_1_sub.configure(text="Failed ()...", fg="red")
        main_screen.update()
        return  # stop export
    if label_1_status == 0:
        label_1_sub.configure(text="Failed", fg="red")
        main_screen.update()
    else:
        label_1_sub.configure(text="Completed", fg="green")
        main_screen.update()
    main_screen.update()
    logging.info("Export Patient Data completed.")
    ############### "2. Export Encounter IP Data"#################
    logging.info("Export Encounter IP Data started.")
    label_2_status = 1
    label_2_sub.configure(
        text="In Progress (tbl_PPM_Encounter).ETC:1 hour...", fg="blue"
    )
    main_screen.update()
    # Note: I have commented the below access query because Inform8 did not do this.
    """Updates the fields in the tbl_excluded encounters """
    # Access query: update tbl_excluded encounters Inpatient
    # UPDATE tbl_ExcludedEncounters SET tbl_ExcludedEncounters.EncounterNumber = IIf([tbl_ExcludedEncounters]![SNAP_encounter] Not Like "XX*",[tbl_ExcludedEncounters]![SNAP_encounter],[tbl_ExcludedEncounters]![facility_identifier] & "-I-" & Format([tbl_ExcludedEncounters]![Stay_number],"00000000") & "-" & Format([tbl_ExcludedEncounters]![episode_sequence_number],"000")) WHERE (((tbl_ExcludedEncounters.Ed_identifier) Like "XX*"));
    file_tbl_ExcludedEncounters = "./ExtractorDB/OutputExcludedEncounters.csv"
    if os.path.isfile(file_tbl_ExcludedEncounters):
        try:
            tbl_ExcludedEncounters = read_csv_file(
                file_tbl_ExcludedEncounters,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            label_2_status = 0
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_ExcludedEncounters from ./ExtractorDB/OutputExcludedEncounters.csv.\n"
                + str(e),
            )
            label_2_sub.configure(text="Failed (tbl_ExcludedEncounters)...", fg="red")
            main_screen.update()
            return
        else:
            # tbl_ExcludedEncounters = tbl_ExcludedEncounters[['facility_identifier', 'stay_number', 'episode_sequence_number', 'ed_identifier', 'SNAP_encounter', 'ReasonForExclusion', 'EncounterNumber']]
            # AQA-315 - remove EDW_Enc_Number - not implemented for this file as it is not an input to PPM
            tbl_ExcludedEncounters = tbl_ExcludedEncounters[
                [
                    "facility_identifier",
                    "stay_number",
                    "episode_sequence_number",
                    "ed_identifier",
                    "SNAP_encounter",
                    "ReasonForExclusion",
                    "EncounterNumber",
                    "EDW_Enc_Number",
                    "HLTH_ORG_OSP_OSP_ID",
                    "MG_AUTH_OSP_OSP_ID",
                    "SE_CBK_SK",
                    "CL_ID_EUID",
                    "CL_ID_IHI",
                ]
            ]
            tbl_ExcludedEncounters["stay_number"] = (
                tbl_ExcludedEncounters["stay_number"].astype(str).str.strip()
            )
            tbl_ExcludedEncounters["episode_sequence_number"] = (
                tbl_ExcludedEncounters["episode_sequence_number"]
                .astype(str)
                .str.strip()
            )
            tbl_ExcludedEncounters["stay_number"] = (
                tbl_ExcludedEncounters["stay_number"]
                .astype(str)
                .str.pad(8, side="left", fillchar="0")
            )
            tbl_ExcludedEncounters["episode_sequence_number"] = (
                tbl_ExcludedEncounters["episode_sequence_number"]
                .astype(str)
                .str.pad(3, side="left", fillchar="0")
            )
            # Note: I have commented the below access query because Inform8 did not do this.
            """            
            condlist=[~(tbl_ExcludedEncounters.SNAP_encounter.astype(str).str.startswith(('XX'))) & (tbl_ExcludedEncounters.ed_identifier.astype(str).str.startswith(('XX'))), (tbl_ExcludedEncounters.SNAP_encounter.astype(str).str.startswith(('XX'))) & (tbl_ExcludedEncounters.ed_identifier.astype(str).str.startswith(('XX')))]
            choicelist = [tbl_ExcludedEncounters['SNAP_encounter'], tbl_ExcludedEncounters['facility_identifier'].astype(str).str.strip()+ "-I-" + tbl_ExcludedEncounters['stay_number'].astype(str).str.strip()+ "-" + tbl_ExcludedEncounters['episode_sequence_number'].astype(str).str.strip()] 
            tbl_ExcludedEncounters['EncounterNumber'] = np.select(condlist, choicelist, tbl_ExcludedEncounters['EncounterNumber'])
            """
    else:
        tbl_ExcludedEncounters = pd.DataFrame()
    tbl_ExcludedEncounters = tbl_ExcludedEncounters.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    tbl_ExcludedEncounters = tbl_ExcludedEncounters.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    tbl_ExcludedEncounters = tbl_ExcludedEncounters.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    try:
        tbl_ExcludedEncounters.to_csv(
            "./ExtractorDB/tbl_ExcludedEncounters.csv",
            index=False,
            na_rep="",
            float_format=str,
            decimal=str,
            date_format=str,
        )
    except Exception as e:
        logging.exception("Exception occurred")
        label_2_status = 0
        messagebox.showerror(
            "Export Error", "Error exporting tbl_ExcludedEncounters\n" + str(e)
        )
        label_2_sub.configure(text="Failed (tbl_ExcludedEncounters)...", fg="red")
        main_screen.update()
        return  # stop export
    logging.info(
        "%s records saved to ./ExtractorDB/tbl_ExcludedEncounters.csv.",
        len(tbl_ExcludedEncounters),
    )
    """qrysnapApp_CostingExtract """
    # access query: qrysnapApp_CostingExtract
    # SELECT snapApp_CostingExtract.PCSNAP_PhaseID, snapApp_CostingExtract.pcPhase, snapApp_CostingExtract.PCPhaseStartDate, snapApp_CostingExtract.PCPhaseEndDate, snapApp_CostingExtract.FacilityCode, snapApp_CostingExtract.MRN, snapApp_CostingExtract.SNAPEpisodeID, snapApp_CostingExtract.SNAPCaseType, snapApp_CostingExtract.EpisodeStartDate_HIE, snapApp_CostingExtract.EpisodeEndDate_HIE, snapApp_CostingExtract.EpisodeStartTime_HIE, snapApp_CostingExtract.EpisodeEndTime_HIE, snapApp_CostingExtract.EpisType, snapApp_CostingExtract.TotalSuspensionDays, snapApp_CostingExtract.AssessmentOnly, snapApp_CostingExtract.PCSymptomScoreStart, snapApp_CostingExtract.PCSeverityStart, snapApp_CostingExtract.PCPsychSpiritualScoreStart, snapApp_CostingExtract.PCFamilyCarerScoreStart, snapApp_CostingExtract.MaintType, snapApp_CostingExtract.RehImpairmentCode, snapApp_CostingExtract.FIMEatingStart, snapApp_CostingExtract.FIMEatingEnd, snapApp_CostingExtract.FIMGroomingStart, snapApp_CostingExtract.FIMGroomingEnd, snapApp_CostingExtract.FIMBathingStart, snapApp_CostingExtract.FIMBathingEnd, snapApp_CostingExtract.FIMDressingUpperStart, snapApp_CostingExtract.FIMDressingUpperEnd, snapApp_CostingExtract.FIMDressingLowerStart, snapApp_CostingExtract.FIMDressingLowerEnd, snapApp_CostingExtract.FIMToiletingStart, snapApp_CostingExtract.FIMToiletingEnd, snapApp_CostingExtract.FIMBladderStart, snapApp_CostingExtract.FIMBladderEnd, snapApp_CostingExtract.FIMBowelStart, snapApp_CostingExtract.FIMBowelEnd, snapApp_CostingExtract.FIMXferBedChairWChairStart, snapApp_CostingExtract.FIMXferBedChairWChairEnd, snapApp_CostingExtract.FIMXferBathShowerStart, snapApp_CostingExtract.FIMXferBathShowerEnd, snapApp_CostingExtract.FIMXferToiletStart, snapApp_CostingExtract.FIMXferToiletEnd, snapApp_CostingExtract.FIMWalkWheelChairStart, snapApp_CostingExtract.FIMWalkWheelChairEnd, snapApp_CostingExtract.FIMStairsStart, snapApp_CostingExtract.FIMStairsEnd, snapApp_CostingExtract.FIMComprehensionStart, snapApp_CostingExtract.FIMComprehensionEnd, snapApp_CostingExtract.FIMExpressionStart, snapApp_CostingExtract.FIMExpressionEnd, snapApp_CostingExtract.FIMSocialInteractionStart, snapApp_CostingExtract.FIMSocialInteractionEnd, snapApp_CostingExtract.FIMProblemSolvingStart, snapApp_CostingExtract.FIMProblemSolvingEnd, snapApp_CostingExtract.FIMMemoryStart, snapApp_CostingExtract.FIMMemoryEnd, snapApp_CostingExtract.[AN SNAP V3], snapApp_CostingExtract.sa_AN_SNAP_Version, snapApp_CostingExtract.HONActivityStart, snapApp_CostingExtract.HONActivityEnd, snapApp_CostingExtract.HONInjuryStart, snapApp_CostingExtract.HONInjuryEnd, snapApp_CostingExtract.HONDrinkStart, snapApp_CostingExtract.HONDrinkEnd, snapApp_CostingExtract.HONCognitStart, snapApp_CostingExtract.HONCognitEnd, snapApp_CostingExtract.HONDisabStart, snapApp_CostingExtract.HONDisabEnd, snapApp_CostingExtract.HONHallucStart, snapApp_CostingExtract.HONHallucEnd, snapApp_CostingExtract.HONDepresStart, snapApp_CostingExtract.HONDepresEnd, snapApp_CostingExtract.HONOtherStart, snapApp_CostingExtract.HONOtherEnd, snapApp_CostingExtract.HONRelatStart, snapApp_CostingExtract.HONRelatEnd, snapApp_CostingExtract.HONAdlStart, snapApp_CostingExtract.HONAdlEnd, snapApp_CostingExtract.HONLivingStart, snapApp_CostingExtract.HONLivingEnd, snapApp_CostingExtract.HONOccupStart, snapApp_CostingExtract.HONOccupEnd, snapApp_CostingExtract.CareFocus, snapApp_CostingExtract.stay_number_cost, snapApp_CostingExtract.sa_episode_sequence_number, snapApp_CostingExtract.sa_nwau_version, snapApp_CostingExtract.sa_EpisodeBegReason, snapApp_CostingExtract.sa_EpisodeEndReason, snapApp_CostingExtract.RUGToiletingStart, snapApp_CostingExtract.RUGBedMobilityStart, snapApp_CostingExtract.RUGTransferStart, snapApp_CostingExtract.RUGEatingStart, snapApp_CostingExtract.caretype, snapApp_CostingExtract.InterupCare, snapApp_CostingExtract.Sequence, snapApp_CostingExtract.EncounterNumber, snapApp_CostingExtract.EncounterStart, snapApp_CostingExtract.EncounterEnd, snapApp_CostingExtract.LHD, snapApp_CostingExtract.sa_nwau, snapApp_CostingExtract.sa_occdays_in_cost_period, snapApp_CostingExtract.sa_leave_days_in_cost_period, snapApp_CostingExtract.sa_total_los, snapApp_CostingExtract.sa_total_leave_days, snapApp_CostingExtract.[Snap ClassV4], snapApp_CostingExtract.Dementia_Flag, snapApp_CostingExtract.Delirium_Flag, tbl_ExcludedEncounters.EncounterNumber
    # FROM snapApp_CostingExtract LEFT JOIN tbl_ExcludedEncounters ON snapApp_CostingExtract.EncounterNumber = tbl_ExcludedEncounters.EncounterNumber
    # WHERE (((tbl_ExcludedEncounters.EncounterNumber) Is Null));
    # download snapApp_CostingExtract
    file_snapApp_CostingExtract = "./ExtractorDB/snapApp_CostingExtract.csv"
    if os.path.isfile(file_snapApp_CostingExtract):
        try:
            snapApp_CostingExtract = read_csv_file(
                file_snapApp_CostingExtract,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            label_2_status = 0
            messagebox.showerror(
                "File Error",
                "Error extracting snapApp_CostingExtract from ./ExtractorDB/snapApp_CostingExtract.csv\n"
                + str(e),
            )
            label_2_sub.configure(
                text="Failed (qrysnapApp_CostingExtract)...", fg="red"
            )
            main_screen.update()
            return
    else:
        snapApp_CostingExtract = pd.DataFrame()
    # download tbl_ExcludedEncounters
    tbl_ExcludedEncounters_list = []
    file_tbl_ExcludedEncounters = "./ExtractorDB/tbl_ExcludedEncounters.csv"
    if os.path.isfile(file_tbl_ExcludedEncounters):
        try:
            tbl_ExcludedEncounters = read_csv_file(
                file_tbl_ExcludedEncounters,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            label_2_status = 0
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_ExcludedEncounters from ./ExtractorDB/tbl_ExcludedEncounters.csv\n"
                + str(e),
            )
            label_2_sub.configure(text="Failed (tbl_ExcludedEncounters)...", fg="red")
            main_screen.update()
            return
        else:
            tbl_ExcludedEncounters_list = tbl_ExcludedEncounters[
                "EncounterNumber"
            ].tolist()
    else:
        tbl_ExcludedEncounters = pd.DataFrame()
    if len(snapApp_CostingExtract) > 0:
        # 11 Jan 2024 - CREATED FACILITY CHANGE - added SE_CBK_SK
        qrysnapApp_CostingExtract = snapApp_CostingExtract[
            [
                "PCSNAP_PhaseID",
                "pcPhase",
                "PCPhaseStartDate",
                "PCPhaseEndDate",
                "FacilityCode",
                "mrn",
                "SNAPEpisodeID",
                "SNAPCaseType",
                "EpisodeStartDate_HIE",
                "EpisodeEndDate_HIE",
                "EpisodeStartTime_HIE",
                "EpisodeEndTime_HIE",
                "EpisType",
                "TotalSuspensionDays",
                "AssessmentOnly",
                "PCSymptomScoreStart",
                "PCSeverityStart",
                "PCPsychSpiritualScoreStart",
                "PCFamilyCarerScoreStart",
                "MaintType",
                "RehImpairmentCode",
                "FIMEatingStart",
                "FIMEatingEnd",
                "FIMGroomingStart",
                "FIMGroomingEnd",
                "FIMBathingStart",
                "FIMBathingEnd",
                "FIMDressingUpperStart",
                "FIMDressingUpperEnd",
                "FIMDressingLowerStart",
                "FIMDressingLowerEnd",
                "FIMToiletingStart",
                "FIMToiletingEnd",
                "FIMBladderStart",
                "FIMBladderEnd",
                "FIMBowelStart",
                "FIMBowelEnd",
                "FIMXferBedChairWChairStart",
                "FIMXferBedChairWChairEnd",
                "FIMXferBathShowerStart",
                "FIMXferBathShowerEnd",
                "FIMXferToiletStart",
                "FIMXferToiletEnd",
                "FIMWalkWheelChairStart",
                "FIMWalkWheelChairEnd",
                "FIMStairsStart",
                "FIMStairsEnd",
                "FIMComprehensionStart",
                "FIMComprehensionEnd",
                "FIMExpressionStart",
                "FIMExpressionEnd",
                "FIMSocialInteractionStart",
                "FIMSocialInteractionEnd",
                "FIMProblemSolvingStart",
                "FIMProblemSolvingEnd",
                "FIMMemoryStart",
                "FIMMemoryEnd",
                "AN SNAP V3",
                "sa_AN_SNAP_Version",
                "HONActivityStart",
                "HONActivityEnd",
                "HONInjuryStart",
                "HONInjuryEnd",
                "HONDrinkStart",
                "HONDrinkEnd",
                "HONCognitStart",
                "HONCognitEnd",
                "HONDisabStart",
                "HONDisabEnd",
                "HONHallucStart",
                "HONHallucEnd",
                "HONDepresStart",
                "HONDepresEnd",
                "HONOtherStart",
                "HONOtherEnd",
                "HONRelatStart",
                "HONRelatEnd",
                "HONAdlStart",
                "HONAdlEnd",
                "HONLivingStart",
                "HONLivingEnd",
                "HONOccupStart",
                "HONOccupEnd",
                "CareFocus",
                "stay_number_cost",
                "sa_episode_sequence_number",
                "sa_nwau_version",
                "sa_EpisodeBegReason",
                "sa_EpisodeEndReason",
                "RUGToiletingStart",
                "RUGBedMobilityStart",
                "RUGTransferStart",
                "RUGEatingStart",
                "caretype",
                "InterupCare",
                "Sequence",
                "EncounterNumber",
                "EncounterStart",
                "EncounterEnd",
                "LHD",
                "sa_nwau",
                "sa_occdays_in_cost_period",
                "sa_leave_days_in_cost_period",
                "sa_total_los",
                "sa_total_leave_days",
                "Snap ClassV4",
                "Dementia_Flag",
                "Delirium_Flag",
                "SE_CBK_SK",
            ]
        ]
        # FROM snapApp_CostingExtract LEFT JOIN tbl_ExcludedEncounters ON snapApp_CostingExtract.EncounterNumber = tbl_ExcludedEncounters.EncounterNumber
        # WHERE (((tbl_ExcludedEncounters.EncounterNumber) Is Null));
        qrysnapApp_CostingExtract = qrysnapApp_CostingExtract[
            ~qrysnapApp_CostingExtract["EncounterNumber"].isin(
                tbl_ExcludedEncounters_list
            )
        ]
        qrysnapApp_CostingExtract = qrysnapApp_CostingExtract.applymap(
            str
        )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
        qrysnapApp_CostingExtract = qrysnapApp_CostingExtract.applymap(
            lambda x: x.strip() if isinstance(x, str) else x
        )
        qrysnapApp_CostingExtract = qrysnapApp_CostingExtract.apply(
            lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
        )
    else:
        # 11 Jan 2024 - CREATED FACILITY CHANGE - added SE_CBK_SK
        qrysnapApp_CostingExtract = pd.DataFrame(
            columns=[
                "PCSNAP_PhaseID",
                "pcPhase",
                "PCPhaseStartDate",
                "PCPhaseEndDate",
                "FacilityCode",
                "mrn",
                "SNAPEpisodeID",
                "SNAPCaseType",
                "EpisodeStartDate_HIE",
                "EpisodeEndDate_HIE",
                "EpisodeStartTime_HIE",
                "EpisodeEndTime_HIE",
                "EpisType",
                "TotalSuspensionDays",
                "AssessmentOnly",
                "PCSymptomScoreStart",
                "PCSeverityStart",
                "PCPsychSpiritualScoreStart",
                "PCFamilyCarerScoreStart",
                "MaintType",
                "RehImpairmentCode",
                "FIMEatingStart",
                "FIMEatingEnd",
                "FIMGroomingStart",
                "FIMGroomingEnd",
                "FIMBathingStart",
                "FIMBathingEnd",
                "FIMDressingUpperStart",
                "FIMDressingUpperEnd",
                "FIMDressingLowerStart",
                "FIMDressingLowerEnd",
                "FIMToiletingStart",
                "FIMToiletingEnd",
                "FIMBladderStart",
                "FIMBladderEnd",
                "FIMBowelStart",
                "FIMBowelEnd",
                "FIMXferBedChairWChairStart",
                "FIMXferBedChairWChairEnd",
                "FIMXferBathShowerStart",
                "FIMXferBathShowerEnd",
                "FIMXferToiletStart",
                "FIMXferToiletEnd",
                "FIMWalkWheelChairStart",
                "FIMWalkWheelChairEnd",
                "FIMStairsStart",
                "FIMStairsEnd",
                "FIMComprehensionStart",
                "FIMComprehensionEnd",
                "FIMExpressionStart",
                "FIMExpressionEnd",
                "FIMSocialInteractionStart",
                "FIMSocialInteractionEnd",
                "FIMProblemSolvingStart",
                "FIMProblemSolvingEnd",
                "FIMMemoryStart",
                "FIMMemoryEnd",
                "AN SNAP V3",
                "sa_AN_SNAP_Version",
                "HONActivityStart",
                "HONActivityEnd",
                "HONInjuryStart",
                "HONInjuryEnd",
                "HONDrinkStart",
                "HONDrinkEnd",
                "HONCognitStart",
                "HONCognitEnd",
                "HONDisabStart",
                "HONDisabEnd",
                "HONHallucStart",
                "HONHallucEnd",
                "HONDepresStart",
                "HONDepresEnd",
                "HONOtherStart",
                "HONOtherEnd",
                "HONRelatStart",
                "HONRelatEnd",
                "HONAdlStart",
                "HONAdlEnd",
                "HONLivingStart",
                "HONLivingEnd",
                "HONOccupStart",
                "HONOccupEnd",
                "CareFocus",
                "stay_number_cost",
                "sa_episode_sequence_number",
                "sa_nwau_version",
                "sa_EpisodeBegReason",
                "sa_EpisodeEndReason",
                "RUGToiletingStart",
                "RUGBedMobilityStart",
                "RUGTransferStart",
                "RUGEatingStart",
                "caretype",
                "InterupCare",
                "Sequence",
                "EncounterNumber",
                "EncounterStart",
                "EncounterEnd",
                "LHD",
                "sa_nwau",
                "sa_occdays_in_cost_period",
                "sa_leave_days_in_cost_period",
                "sa_total_los",
                "sa_total_leave_days",
                "Snap ClassV4",
                "Dementia_Flag",
                "Delirium_Flag",
                "SE_CBK_SK",
            ]
        )
    try:
        qrysnapApp_CostingExtract.to_csv(
            "./ExtractorDB/qrysnapApp_CostingExtract.csv",
            index=False,
            na_rep="",
            float_format=str,
            decimal=str,
            date_format=str,
        )
    except Exception as e:
        logging.exception("Exception occurred")
        label_2_status = 0
        messagebox.showerror(
            "Export Error", "Error exporting qrysnapApp_CostingExtract\n" + str(e)
        )
        label_2_sub.configure(text="Failed (qrysnapApp_CostingExtract)...", fg="red")
        main_screen.update()
        return  # stop export
    logging.info(
        "%s records saved to ./ExtractorDB/qrysnapApp_CostingExtract.csv.",
        len(qrysnapApp_CostingExtract),
    )
    # download OutputDaysEpisode
    file_OutputDaysEpisode = "./ExtractorDB/OutputDaysEpisode.csv"
    if os.path.isfile(file_OutputDaysEpisode):
        try:
            tbl_dbo_days_episode = read_csv_file(
                file_OutputDaysEpisode,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_dbo_days_episode from ./ExtractorDB/OutputDaysEpisode.csv.\n"
                + str(e),
            )
            label_2_sub.configure(text="Failed (tbl_dbo_days_episode)...", fg="red")
            label_2_status = 0
            return
        else:
            tbl_dbo_days_episode = tbl_dbo_days_episode[
                tbl_dbo_days_episode["facility_identifier"].isin(
                    facilities_included_list_global
                )
            ]
    else:
        tbl_dbo_days_episode = pd.DataFrame()
    # download OutputEpisodeAts
    file_OutputEpisodeAts = "./ExtractorDB/OutputEpisodeAts.csv"
    if os.path.isfile(file_OutputEpisodeAts):
        try:
            tbl_dbo_episode_ats = read_csv_file(
                file_OutputEpisodeAts,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_dbo_episode_ats from ./ExtractorDB/OutputEpisodeAts.csv.\n"
                + str(e),
            )
            label_2_sub.configure(text="Failed (tbl_dbo_episode_ats)...", fg="red")
            label_2_status = 0
            return
        else:
            tbl_dbo_episode_ats = tbl_dbo_episode_ats[
                tbl_dbo_episode_ats["facility_identifier"].isin(
                    facilities_included_list_global
                )
            ]
    else:
        tbl_dbo_episode_ats = pd.DataFrame()
    # download tbl_Patient_Contact_Details
    if (
        lhd_global == "X830"
        or lhd_global == "X840"
        or lhd_global == "X850"
        or lhd_global == "X860"
        or lhd_global == "X740"
    ):
        file_tbl_Patient_Contact_Details = "./ExtractorDB/OutputPatient.csv"
    else:
        file_tbl_Patient_Contact_Details = "./ExtractorDB/Patient_contact_details.csv"
    if os.path.isfile(file_tbl_Patient_Contact_Details):
        try:
            tbl_Patient_Contact_Details = read_csv_file(
                file_tbl_Patient_Contact_Details,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            label_2_status = 0
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_Patient_Contact_Details from "
                + file_tbl_Patient_Contact_Details
                + ".\n"
                + str(e),
            )
            label_2_sub.configure(
                text="Failed (tbl_Patient_Contact_Details)...", fg="red"
            )
            main_screen.update()
            return
        else:
            tbl_Patient_Contact_Details = tbl_Patient_Contact_Details[
                [
                    "facility_identifier",
                    "area_identifier",
                    "person_area_uid",
                    "AUID",
                    "contact_identifier",
                    "mrn",
                ]
            ]
    else:
        tbl_Patient_Contact_Details = pd.DataFrame()
    # download Acute_nwau
    file_acute_nwau = "./ExtractorDB/OutputAcuteNwau.csv"
    if os.path.isfile(file_acute_nwau):
        try:
            acute_nwau = read_csv_file(
                file_acute_nwau,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error",
                "Error extracting OutputAcuteNwau from ./ExtractorDB/OutputAcuteNwau.csv.\n"
                + str(e),
            )
            label_2_sub.configure(text="Failed (OutputAcuteNwau)...", fg="red")
            label_2_status = 0
            return
    else:
        acute_nwau = pd.DataFrame()
    # download tbl_dbo_stay
    file_tbl_dbo_stay = "./ExtractorDB/OutputStay.csv"
    if os.path.isfile(file_tbl_dbo_stay):
        try:
            tbl_dbo_stay = read_csv_file(
                file_tbl_dbo_stay,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error",
                "Error extracting OutputStay from ./ExtractorDB/OutputStay.csv.\n"
                + str(e),
            )
            label_2_sub.configure(text="Failed (OutputStay)...", fg="red")
            label_2_status = 0
            return
    else:
        tbl_dbo_stay = pd.DataFrame()
    # download tbl_dbo_episode_srg
    file_tbl_dbo_episode_srg = "./ExtractorDB/OutputEpisodeSrg.csv"
    if os.path.isfile(file_tbl_dbo_episode_srg):
        try:
            tbl_dbo_episode_srg = read_csv_file(
                file_tbl_dbo_episode_srg,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error",
                "Error extracting OutputEpisodeSrg from ./ExtractorDB/OutputEpisodeSrg.csv.\n"
                + str(e),
            )
            label_2_sub.configure(text="Failed (OutputEpisodeSrg)...", fg="red")
            label_2_status = 0
            return
    else:
        tbl_dbo_episode_srg = pd.DataFrame()
    # download tbl_dbo_episode_DRG
    file_tbl_dbo_episode_DRG = "./ExtractorDB/OutputEpisodeDrg.csv"
    if os.path.isfile(file_tbl_dbo_episode_DRG):
        try:
            tbl_dbo_episode_DRG = read_csv_file(
                file_tbl_dbo_episode_DRG,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error",
                "Error extracting OutputEpisodeDrg from ./ExtractorDB/OutputEpisodeDrg.csv.\n"
                + str(e),
            )
            label_2_sub.configure(text="Failed (OutputEpisodeDrg)...", fg="red")
            label_2_status = 0
            return
    else:
        tbl_dbo_episode_DRG = pd.DataFrame()
    # download tbl_dbo_episode
    file_tbl_dbo_episode = "./ExtractorDB/OutputEpisode.csv"
    if os.path.isfile(file_tbl_dbo_episode):
        try:
            tbl_dbo_episode = read_csv_file(
                file_tbl_dbo_episode,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error",
                "Error extracting OutputEpisode from ./ExtractorDB/OutputEpisode.csv.\n"
                + str(e),
            )
            label_2_sub.configure(text="Failed (OutputEpisode)...", fg="red")
            label_2_status = 0
            return
    else:
        tbl_dbo_episode = pd.DataFrame()
    # download [SNAP File 2 01]
    file_snapFile201 = "./ExtractorDB/SnapFile201.csv"
    if os.path.isfile(file_snapFile201):
        try:
            snapFile201 = read_csv_file(
                file_snapFile201,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error",
                "Error extracting SnapFile201 from ./ExtractorDB/SnapFile201.csv.\n"
                + str(e),
            )
            label_2_sub.configure(text="Failed (SnapFile201)...", fg="red")
            label_2_status = 0
            return
    else:
        snapFile201 = pd.DataFrame()
    # download [Episode ATS end date update]
    file_tbl_Episode_ATS_end_date_update = (
        "./ExtractorDB/tbl_Episode_ATS_end_date_update.csv"
    )
    if os.path.isfile(file_tbl_Episode_ATS_end_date_update):
        try:
            tbl_Episode_ATS_end_date_update = read_csv_file(
                file_tbl_Episode_ATS_end_date_update,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_Episode_ATS_end_date_update from ./ExtractorDB/tbl_Episode_ATS_end_date_update.csv.\n"
                + str(e),
            )
            label_2_sub.configure(
                text="Failed (tbl_Episode_ATS_end_date_update)...", fg="red"
            )
            label_2_status = 0
            return
    else:
        tbl_Episode_ATS_end_date_update = pd.DataFrame()
    # download tbl_dbo_wl_exit
    file_tbl_dbo_wl_exit = "./ExtractorDB/OutputWlExit.csv"
    if os.path.isfile(file_tbl_dbo_wl_exit):
        try:
            tbl_dbo_wl_exit = read_csv_file(
                file_tbl_dbo_wl_exit,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error",
                "Error extracting OutputWlExit from ./ExtractorDB/OutputWlExit.csv.\n"
                + str(e),
            )
            label_2_sub.configure(text="Failed (OutputWlExit)...", fg="red")
            label_2_status = 0
            return
    else:
        tbl_dbo_wl_exit = pd.DataFrame()
    # download speciality portal mapping
    file_SpecialtyPortalMapping = "./Output/SpecialityPortalMapping.csv"
    if os.path.isfile(file_SpecialtyPortalMapping):
        try:
            specialtyPortalMapping = read_csv_file(
                file_SpecialtyPortalMapping,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            label_2_status = 0
            messagebox.showerror(
                "File Error",
                "Error extracting SpecialtyPortalMapping from ./Output/SpecialityPortalMapping.csv\n"
                + str(e),
            )
            label_2_sub.configure(text="Failed (SpecialtyPortalMapping)...", fg="red")
            main_screen.update()
            return
    else:
        specialtyPortalMapping = pd.DataFrame()
    # download critical care group
    file_CriticalCareGroup = "./Output/CriticalCareGroup.csv"
    if os.path.isfile(file_CriticalCareGroup):
        try:
            criticalcaregroup = read_csv_file(
                file_CriticalCareGroup,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            label_2_status = 0
            messagebox.showerror(
                "File Error",
                "Error extracting CriticalCareGroup from ./Output/CriticalCareGroup.csv\n"
                + str(e),
            )
            label_2_sub.configure(text="Failed (CriticalCareGroup)...", fg="red")
            main_screen.update()
            return
        else:
            criticalcaregroup["unit_type"] = criticalcaregroup["unit_type"].astype(str)
    else:
        criticalcaregroup = pd.DataFrame()
    # download tbl_PPM_transfer_Leave02
    file_tbl_PPM_transfer_Leave02 = "./ExtractorDB/tbl_PPM_transfer_Leave02.csv"
    if os.path.isfile(file_tbl_PPM_transfer_Leave02):
        try:
            tbl_PPM_transfer_Leave02 = read_csv_file(
                file_tbl_PPM_transfer_Leave02,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            label_2_status = 0
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_PPM_transfer_Leave02 from ./ExtractorDB/tbl_PPM_transfer_Leave02.csv\n"
                + str(e),
            )
            label_2_sub.configure(text="Failed (tbl_PPM_transfer_Leave02)...", fg="red")
            main_screen.update()
            return
    else:
        tbl_PPM_transfer_Leave02 = pd.DataFrame()
    # download IntrerupCare - OBSOLETE
    """
    file_IntrerupCare = "./ExtractorDB/IntrerupCare.csv"
    if os.path.isfile(file_IntrerupCare):
        try:
            intrerupCare = read_csv_file(file_IntrerupCare, encoding = 'unicode_escape', dtype=str, keep_default_na=False, na_values='')
        except Exception as e:
            label_5_status = 0
            messagebox.showerror("File Error","Error extracting intrerupCare from ./ExtractorDB/IntrerupCare.csv.\n"+str(e))
            label_5_sub.configure(text="Failed (intrerupCare)...",fg='red')
            main_screen.update()
            return     
    else:
        intrerupCare = pd.DataFrame() 
    """
    #######################################
    tbl_dbo_episode_ats["episode_start_date"] = (
        tbl_dbo_episode_ats["episode_start_date"].astype(str).str[:10]
    )
    tbl_dbo_episode_ats["episode_start_time"] = (
        tbl_dbo_episode_ats["episode_start_time"].astype(str).str[-8:]
    )
    tbl_dbo_episode_ats["episode_end_date"] = (
        tbl_dbo_episode_ats["episode_end_date"].astype(str).str[:10]
    )
    tbl_dbo_episode_ats["episode_end_time"] = (
        tbl_dbo_episode_ats["episode_end_time"].astype(str).str[-8:]
    )
    tbl_dbo_episode_ats["stay_number"] = (
        tbl_dbo_episode_ats["stay_number"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0")
    )
    tbl_dbo_episode_ats["episode_sequence_number"] = (
        tbl_dbo_episode_ats["episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    tbl_dbo_days_episode["start_date"] = (
        tbl_dbo_days_episode["start_date"].astype(str).str[:10]
    )
    tbl_dbo_days_episode["start_time"] = (
        tbl_dbo_days_episode["start_time"].astype(str).str[-8:]
    )
    tbl_dbo_days_episode["end_date"] = (
        tbl_dbo_days_episode["end_date"].astype(str).str[:10]
    )
    tbl_dbo_days_episode["end_time"] = (
        tbl_dbo_days_episode["end_time"].astype(str).str[-8:]
    )
    tbl_dbo_days_episode["stay_number"] = (
        tbl_dbo_days_episode["stay_number"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0")
    )
    tbl_dbo_days_episode["episode_sequence_number"] = (
        tbl_dbo_days_episode["episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    tbl_dbo_episode["startdate"] = tbl_dbo_episode["startdate"].astype(str).str[:10]
    tbl_dbo_episode["starttime"] = tbl_dbo_episode["starttime"].astype(str).str[-8:]
    tbl_dbo_episode["enddate"] = tbl_dbo_episode["enddate"].astype(str).str[:10]
    tbl_dbo_episode["endtime"] = tbl_dbo_episode["endtime"].astype(str).str[-8:]
    tbl_dbo_episode["stay_number"] = (
        tbl_dbo_episode["stay_number"].astype(str).str.pad(8, side="left", fillchar="0")
    )
    tbl_dbo_episode["episode_sequence_number"] = (
        tbl_dbo_episode["episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    tbl_dbo_stay["stay_number"] = (
        tbl_dbo_stay["stay_number"].astype(str).str.pad(8, side="left", fillchar="0")
    )
    tbl_dbo_stay["person_identifier"] = (
        tbl_dbo_stay["person_identifier"]
        .astype(str)
        .str.pad(10, side="left", fillchar="0")
    )
    # 27 July 2024 - stay episode seq number
    tbl_dbo_stay["episode_sequence_number"] = (
        tbl_dbo_stay["episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    tbl_dbo_episode_srg["stay_number"] = (
        tbl_dbo_episode_srg["stay_number"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0")
    )
    tbl_dbo_episode_srg["episode_sequence_number"] = (
        tbl_dbo_episode_srg["episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    tbl_dbo_episode_DRG["stay_number"] = (
        tbl_dbo_episode_DRG["stay_number"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0")
    )
    tbl_dbo_episode_DRG["episode_sequence_number"] = (
        tbl_dbo_episode_DRG["episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    tbl_Patient_Contact_Details["contact_identifier"] = (
        tbl_Patient_Contact_Details["contact_identifier"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0")
    )
    tbl_Patient_Contact_Details["AUID"] = np.where(
        tbl_Patient_Contact_Details["AUID"] != "",
        tbl_Patient_Contact_Details["AUID"]
        .astype(str)
        .str.pad(10, side="left", fillchar="0"),
        "",
    )
    tbl_Patient_Contact_Details["mrn"] = np.where(
        tbl_Patient_Contact_Details["mrn"] != "",
        tbl_Patient_Contact_Details["mrn"]
        .astype(str)
        .str.pad(10, side="left", fillchar="0"),
        "",
    )
    tbl_Episode_ATS_end_date_update["stay_number"] = (
        tbl_Episode_ATS_end_date_update["stay_number"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0")
    )
    tbl_Episode_ATS_end_date_update["episode_sequence_number"] = (
        tbl_Episode_ATS_end_date_update["episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    tbl_PPM_transfer_Leave02["stay_number"] = (
        tbl_PPM_transfer_Leave02["stay_number"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0")
    )
    tbl_PPM_transfer_Leave02["episode_sequence_number"] = (
        tbl_PPM_transfer_Leave02["episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    acute_nwau["stay_number"] = (
        acute_nwau["stay_number"].astype(str).str.pad(8, side="left", fillchar="0")
    )
    acute_nwau["episode_sequence_number"] = (
        acute_nwau["episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    tbl_dbo_wl_exit["person_identifier"] = (
        tbl_dbo_wl_exit["person_identifier"]
        .astype(str)
        .str.pad(10, side="left", fillchar="0")
    )
    ########################################
    # Access query =  Create Dupto_tbl_WLExit1
    # SELECT tbl_dbo_wl_exit.facility_identifier, tbl_dbo_wl_exit.removal_date, tbl_dbo_wl_exit.person_identifier, Max(tbl_dbo_wl_exit.listing_date) AS MaxOflisting_date, Max(tbl_dbo_wl_exit.clinical_urg_final_crnt) AS MaxOfclinical_urg_final_crnt FROM tbl_dbo_wl_exit GROUP BY tbl_dbo_wl_exit.facility_identifier, tbl_dbo_wl_exit.removal_date, tbl_dbo_wl_exit.person_identifier;
    dupto_tbl_WLExit1 = tbl_dbo_wl_exit[
        [
            "facility_identifier",
            "removal_date",
            "person_identifier",
            "listing_date",
            "clinical_urg_final_crnt",
        ]
    ]
    dupto_tbl_WLExit1 = dupto_tbl_WLExit1.groupby(
        ["facility_identifier", "removal_date", "person_identifier"]
    )[["listing_date", "clinical_urg_final_crnt"]].max()
    dupto_tbl_WLExit1 = dupto_tbl_WLExit1.reset_index()
    dupto_tbl_WLExit1.rename(
        columns={
            "listing_date": "MaxOflisting_date",
            "clinical_urg_final_crnt": "MaxOfclinical_urg_final_crnt",
        },
        inplace=True,
    )
    dupto_tbl_WLExit1 = dupto_tbl_WLExit1.fillna("")
    dupto_tbl_WLExit1 = dupto_tbl_WLExit1.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    dupto_tbl_WLExit1 = dupto_tbl_WLExit1.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    dupto_tbl_WLExit1 = dupto_tbl_WLExit1.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    dupto_tbl_WLExit1.to_csv("./ExtractorDB/dupto_tbl_WLExit1.csv", index=False)
    logging.info(
        "%s records saved to ./ExtractorDB/dupto_tbl_WLExit1.csv.",
        len(dupto_tbl_WLExit1),
    )
    # Access query = Appendto_tbl_WLExit1
    # INSERT INTO tbl_dbo_wl_exit1 ( facility_identifier, removal_date, person_identifier, clinical_urg_final_crnt, indicated_proc_code, booking_identifier, reason_for_removal, waiting_list_category ) SELECT Dupto_tbl_WLExit1.facility_identifier, Dupto_tbl_WLExit1.removal_date, Dupto_tbl_WLExit1.person_identifier, Dupto_tbl_WLExit1.MaxOfclinical_urg_final_crnt, Max(tbl_dbo_wl_exit.indicated_proc_code) AS MaxOfindicated_proc_code, Max(tbl_dbo_wl_exit.booking_identifier) AS MaxOfbooking_identifier, Max(tbl_dbo_wl_exit.reason_for_removal) AS MaxOfreason_for_removal, Max(tbl_dbo_wl_exit.waiting_list_category) AS MaxOfwaiting_list_category FROM Dupto_tbl_WLExit1 INNER JOIN tbl_dbo_wl_exit ON (Dupto_tbl_WLExit1.MaxOfclinical_urg_final_crnt = tbl_dbo_wl_exit.clinical_urg_final_crnt) AND (Dupto_tbl_WLExit1.MaxOflisting_date = tbl_dbo_wl_exit.listing_date) AND (Dupto_tbl_WLExit1.person_identifier = tbl_dbo_wl_exit.person_identifier) AND (tbl_dbo_wl_exit.removal_date = Dupto_tbl_WLExit1.removal_date) AND (Dupto_tbl_WLExit1.facility_identifier = tbl_dbo_wl_exit.facility_identifier) GROUP BY Dupto_tbl_WLExit1.facility_identifier, Dupto_tbl_WLExit1.removal_date, Dupto_tbl_WLExit1.person_identifier, Dupto_tbl_WLExit1.MaxOfclinical_urg_final_crnt;
    dupto_tbl_WLExit1["person_identifier"] = (
        dupto_tbl_WLExit1["person_identifier"]
        .astype(str)
        .str.pad(10, side="left", fillchar="0")
    )
    tbl_dbo_wl_exit1 = pd.merge(
        dupto_tbl_WLExit1[
            [
                "facility_identifier",
                "removal_date",
                "person_identifier",
                "MaxOfclinical_urg_final_crnt",
                "MaxOflisting_date",
            ]
        ],
        tbl_dbo_wl_exit[
            [
                "indicated_proc_code",
                "booking_identifier",
                "person_identifier",
                "reason_for_removal",
                "waiting_list_category",
                "clinical_urg_final_crnt",
                "removal_date",
                "facility_identifier",
                "listing_date",
            ]
        ],
        how="inner",
        left_on=[
            "MaxOfclinical_urg_final_crnt",
            "MaxOflisting_date",
            "person_identifier",
            "removal_date",
            "facility_identifier",
        ],
        right_on=[
            "clinical_urg_final_crnt",
            "listing_date",
            "person_identifier",
            "removal_date",
            "facility_identifier",
        ],
        suffixes=("", "_drop"),
    )
    # 19 Aug - comment conversion to string
    tbl_dbo_wl_exit1 = tbl_dbo_wl_exit1.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    tbl_dbo_wl_exit1 = tbl_dbo_wl_exit1.fillna("")
    tbl_dbo_wl_exit1 = tbl_dbo_wl_exit1[
        [
            "facility_identifier",
            "removal_date",
            "person_identifier",
            "MaxOfclinical_urg_final_crnt",
            "indicated_proc_code",
            "booking_identifier",
            "reason_for_removal",
            "waiting_list_category",
        ]
    ]
    tbl_dbo_wl_exit1 = tbl_dbo_wl_exit1.groupby(
        [
            "facility_identifier",
            "removal_date",
            "person_identifier",
            "MaxOfclinical_urg_final_crnt",
        ]
    )[
        [
            "indicated_proc_code",
            "booking_identifier",
            "reason_for_removal",
            "waiting_list_category",
        ]
    ].max()
    tbl_dbo_wl_exit1.rename(
        columns={
            "indicated_proc_code": "MaxOfindicated_proc_code",
            "booking_identifier": "MaxOfbooking_identifier",
            "reason_for_removal": "MaxOfreason_for_removal",
            "waiting_list_category": "MaxOfwaiting_list_category",
        },
        inplace=True,
    )
    tbl_dbo_wl_exit1 = tbl_dbo_wl_exit1.reset_index()
    tbl_dbo_wl_exit1 = tbl_dbo_wl_exit1[
        [
            "facility_identifier",
            "removal_date",
            "person_identifier",
            "MaxOfclinical_urg_final_crnt",
            "MaxOfindicated_proc_code",
            "MaxOfbooking_identifier",
            "MaxOfreason_for_removal",
            "MaxOfwaiting_list_category",
        ]
    ]
    tbl_dbo_wl_exit1.rename(
        columns={
            "MaxOfclinical_urg_final_crnt": "clinical_urg_final_crnt",
            "MaxOfindicated_proc_code": "indicated_proc_code",
            "MaxOfreason_for_removal": "reason_for_removal",
            "MaxOfwaiting_list_category": "waiting_list_category",
            "MaxOfbooking_identifier": "booking_identifier",
        },
        inplace=True,
    )
    tbl_dbo_wl_exit1 = tbl_dbo_wl_exit1[
        [
            "facility_identifier",
            "removal_date",
            "person_identifier",
            "clinical_urg_final_crnt",
            "indicated_proc_code",
            "booking_identifier",
            "reason_for_removal",
            "waiting_list_category",
        ]
    ]
    tbl_dbo_wl_exit1 = tbl_dbo_wl_exit1.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    tbl_dbo_wl_exit1 = tbl_dbo_wl_exit1.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    tbl_dbo_wl_exit1 = tbl_dbo_wl_exit1.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    tbl_dbo_wl_exit1.to_csv("./ExtractorDB/tbl_dbo_wl_exit1.csv", index=False)
    logging.info(
        "%s records saved to ./ExtractorDB/tbl_dbo_wl_exit1.csv.", len(tbl_dbo_wl_exit1)
    )
    # [qr days episode maxsdtm]
    # Access query : qr days episode maxsdtm
    # SELECT tbl_dbo_days_episode.facility_identifier, tbl_dbo_days_episode.stay_number, tbl_dbo_days_episode.episode_sequence_number, Max([start_date]+TimeValue([start_time])) AS maxsdtm
    # FROM tbl_dbo_days_episode WHERE (((tbl_dbo_days_episode.trans_type)<>"LEA")) GROUP BY tbl_dbo_days_episode.facility_identifier, tbl_dbo_days_episode.stay_number, tbl_dbo_days_episode.episode_sequence_number;
    qr_days_episode_maxsdtm = tbl_dbo_days_episode[
        tbl_dbo_days_episode["trans_type"] != "LEA"
    ]
    qr_days_episode_maxsdtm["sdtm"] = (
        qr_days_episode_maxsdtm["start_date"].astype(str).str[:10]
        + " "
        + qr_days_episode_maxsdtm["start_time"].astype(str).str[-8:]
    )
    qr_days_episode_maxsdtm["sdtm"] = pd.to_datetime(
        qr_days_episode_maxsdtm["sdtm"], errors="coerce", format="%Y-%m-%d %H:%M:%S"
    )
    qr_days_episode_maxsdtm = (
        qr_days_episode_maxsdtm.groupby(
            ["facility_identifier", "stay_number", "episode_sequence_number"],
            as_index=False,
            dropna=False,
        )
        .agg(maxsdtm=("sdtm", "max"))
        .reset_index()
    )
    qr_days_episode_maxsdtm["maxsdtm"] = pd.to_datetime(
        qr_days_episode_maxsdtm["maxsdtm"], errors="coerce", format="%Y-%m-%d %H:%M:%S"
    )
    qr_days_episode_maxsdtm = qr_days_episode_maxsdtm[
        ["facility_identifier", "stay_number", "episode_sequence_number", "maxsdtm"]
    ]
    qr_days_episode_maxsdtm = qr_days_episode_maxsdtm.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    qr_days_episode_maxsdtm = qr_days_episode_maxsdtm.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    qr_days_episode_maxsdtm = qr_days_episode_maxsdtm.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    qr_days_episode_maxsdtm.to_csv(
        "./ExtractorDB/qr_days_episode_maxsdtm.csv", index=False
    )
    logging.info(
        "%s records saved to ./ExtractorDB/qr_days_episode_maxsdtm.csv.",
        len(qr_days_episode_maxsdtm),
    )
    # [qry SpecialtyPortal]
    # Access query : qry SpecialtyPortal
    # SELECT [qr days episode maxsdtm].facility_identifier, [qr days episode maxsdtm].stay_number, [qr days episode maxsdtm].episode_sequence_number, [SpecialityPortalMapping]![Hospital] & "-" & Trim([specialty_unit_code]) AS Expr2, SpecialityPortalMapping.SpecialityPortal
    # FROM SpecialityPortalMapping INNER JOIN (tbl_dbo_days_episode INNER JOIN [qr days episode maxsdtm] ON (tbl_dbo_days_episode.episode_sequence_number = [qr days episode maxsdtm].episode_sequence_number) AND (tbl_dbo_days_episode.stay_number = [qr days episode maxsdtm].stay_number) AND (tbl_dbo_days_episode.facility_identifier = [qr days episode maxsdtm].facility_identifier)) ON SpecialityPortalMapping.Hospital = tbl_dbo_days_episode.facility_identifier
    # WHERE ((([SpecialityPortalMapping]![Hospital] & "-" & Trim([specialty_unit_code]))=[Clinic]) AND (([start_date]+TimeValue([start_time]))=[maxsdtm]));
    qr_days_episode_maxsdtm["stay_number"] = (
        qr_days_episode_maxsdtm["stay_number"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0")
    )
    qr_days_episode_maxsdtm["episode_sequence_number"] = (
        qr_days_episode_maxsdtm["episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    df_query1 = pd.merge(
        tbl_dbo_days_episode[
            [
                "facility_identifier",
                "stay_number",
                "episode_sequence_number",
                "start_date",
                "start_time",
                "specialty_unit_code",
            ]
        ],
        qr_days_episode_maxsdtm,
        how="inner",
        on=["facility_identifier", "stay_number", "episode_sequence_number"],
        suffixes=("", "_drop"),
    )
    df_query1 = df_query1.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    qry_SpecialtyPortal = pd.merge(
        specialtyPortalMapping[["Hospital", "SpecialityPortal", "Clinic"]],
        df_query1,
        how="inner",
        left_on=["Hospital"],
        right_on=["facility_identifier"],
        suffixes=("", "_drop"),
    )
    qry_SpecialtyPortal = qry_SpecialtyPortal.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    qry_SpecialtyPortal["StartDateTime"] = (
        qry_SpecialtyPortal["start_date"].astype(str).str[:10]
        + " "
        + qry_SpecialtyPortal["start_time"].astype(str).str[-8:]
    )
    qry_SpecialtyPortal["StartDateTime"] = pd.to_datetime(
        qry_SpecialtyPortal["StartDateTime"],
        errors="coerce",
        format="%Y-%m-%d %H:%M:%S",
    )
    qry_SpecialtyPortal["clinic_dummy"] = (
        qry_SpecialtyPortal["Hospital"].astype(str).str.strip()
        + "-"
        + qry_SpecialtyPortal["specialty_unit_code"].astype(str).str.strip()
    )
    qry_SpecialtyPortal = qry_SpecialtyPortal[
        (qry_SpecialtyPortal["clinic_dummy"] == qry_SpecialtyPortal["Clinic"])
        & (qry_SpecialtyPortal["StartDateTime"] == qry_SpecialtyPortal["maxsdtm"])
    ]
    qry_SpecialtyPortal["Expr2"] = (
        qry_SpecialtyPortal["Hospital"].astype(str).str.strip()
        + "-"
        + qry_SpecialtyPortal["specialty_unit_code"].astype(str).str.strip()
    )
    qry_SpecialtyPortal = qry_SpecialtyPortal[
        [
            "facility_identifier",
            "stay_number",
            "episode_sequence_number",
            "Expr2",
            "SpecialityPortal",
        ]
    ]
    qry_SpecialtyPortal = qry_SpecialtyPortal.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    qry_SpecialtyPortal = qry_SpecialtyPortal.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    qry_SpecialtyPortal = qry_SpecialtyPortal.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    qry_SpecialtyPortal.to_csv("./ExtractorDB/qry_SpecialtyPortal.csv", index=False)
    logging.info(
        "%s records saved to ./ExtractorDB/qry_SpecialtyPortal.csv.",
        len(qry_SpecialtyPortal),
    )
    # Critical Care Hours
    # SELECT tbl_dbo_days_episode.facility_identifier, tbl_dbo_days_episode.stay_number, tbl_dbo_days_episode.episode_sequence_number, Round(Sum(DateDiff("n",[start_date]+TimeValue([start_time]),IIf([end_time] Is Null,Now(),IIf([end_date] Is Null,Now(),[end_date]+TimeValue([end_time]))))/60),0) AS Hours, Round(Sum(IIf([CritGroup]="AICU1",DateDiff("n",[start_date]+TimeValue([start_time]),IIf([end_time] Is Null,Now(),IIf([end_date] Is Null,Now(),[end_date]+TimeValue([end_time])))),Null)/60)) AS AICU1, Round(Sum(IIf([CritGroup]="AICU3",DateDiff("n",[start_date]+TimeValue([start_time]),IIf([end_time] Is Null,Now(),IIf([end_date] Is Null,Now(),[end_date]+TimeValue([end_time])))),Null)/60)) AS AICU3, Round(Sum(IIf([CritGroup]="PICU",DateDiff("n",[start_date]+TimeValue([start_time]),IIf([end_time] Is Null,Now(),IIf([end_date] Is Null,Now(),[end_date]+TimeValue([end_time])))),Null)/60)) AS PICU, Round(Sum(IIf([CritGroup]="NICU",DateDiff("n",[start_date]+TimeValue([start_time]),IIf([end_time] Is Null,Now(),IIf([end_date] Is Null,Now(),[end_date]+TimeValue([end_time])))),Null)/60)) AS NICU, Round(Sum(IIf([CritGroup]="PSICU",DateDiff("n",[start_date]+TimeValue([start_time]),IIf([end_time] Is Null,Now(),IIf([end_date] Is Null,Now(),[end_date]+TimeValue([end_time])))),Null)/60)) AS PSICU, Round(Sum(IIf([CritGroup]="CCU",DateDiff("n",[start_date]+TimeValue([start_time]),IIf([end_time] Is Null,Now(),IIf([end_date] Is Null,Now(),[end_date]+TimeValue([end_time])))),Null)/60)) AS CCU, Round(Sum(IIf([CritGroup]="HITH",DateDiff("n",[start_date]+TimeValue([start_time]),IIf([end_time] Is Null,Now(),IIf([end_date] Is Null,Now(),[end_date]+TimeValue([end_time])))),Null)/60)) AS HITH, Round(Sum(IIf([CritGroup]="HDU",DateDiff("n",[start_date]+TimeValue([start_time]),IIf([end_time] Is Null,Now(),IIf([end_date] Is Null,Now(),[end_date]+TimeValue([end_time])))),Null)/60)) AS HDU, Round(Sum(IIf([CritGroup]="SCN",DateDiff("n",[start_date]+TimeValue([start_time]),IIf([end_time] Is Null,Now(),IIf([end_date] Is Null,Now(),[end_date]+TimeValue([end_time])))),Null)/60)) AS SCN, Round(Sum(IIf([CritGroup]="AICU2",DateDiff("n",[start_date]+TimeValue([start_time]),IIf([end_time] Is Null,Now(),IIf([end_date] Is Null,Now(),[end_date]+TimeValue([end_time])))),Null)/60)) AS AICU2
    # FROM tbl_dbo_episode_ats INNER JOIN (tbl_dbo_days_episode INNER JOIN CriticalCareGroup ON (tbl_dbo_days_episode.unit_type = CriticalCareGroup.unit_type) AND (tbl_dbo_days_episode.ward_identifier = CriticalCareGroup.ward_identifier) AND (tbl_dbo_days_episode.facility_identifier = CriticalCareGroup.facility_identifier)) ON (tbl_dbo_episode_ats.episode_sequence_number = tbl_dbo_days_episode.episode_sequence_number) AND (tbl_dbo_episode_ats.stay_number = tbl_dbo_days_episode.stay_number) AND (tbl_dbo_episode_ats.facility_identifier = tbl_dbo_days_episode.facility_identifier)
    # WHERE (((CriticalCareGroup.CritGroup) Is Not Null) AND ((tbl_dbo_days_episode.trans_type)<>"LEA"))
    # GROUP BY tbl_dbo_days_episode.facility_identifier, tbl_dbo_days_episode.stay_number, tbl_dbo_days_episode.episode_sequence_number;
    criticalcaregroup["unit_type"] = criticalcaregroup["unit_type"].astype(str)
    tbl_dbo_days_episode["unit_type"] = tbl_dbo_days_episode["unit_type"].astype(str)
    criticalcaregroup["ward_identifier"] = criticalcaregroup["ward_identifier"].astype(
        str
    )
    criticalcaregroup["facility_identifier"] = criticalcaregroup[
        "facility_identifier"
    ].astype(str)
    tbl_dbo_days_episode["ward_identifier"] = tbl_dbo_days_episode[
        "ward_identifier"
    ].astype(str)
    tbl_dbo_days_episode["facility_identifier"] = tbl_dbo_days_episode[
        "facility_identifier"
    ].astype(str)
    tbl_dbo_episode_ats["stay_number"] = (
        tbl_dbo_episode_ats["stay_number"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0")
    )
    tbl_dbo_episode_ats["episode_sequence_number"] = (
        tbl_dbo_episode_ats["episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    df_query_cc = pd.merge(
        tbl_dbo_days_episode[tbl_dbo_days_episode["trans_type"] != "LEA"],
        criticalcaregroup[
            pd.notna(criticalcaregroup["CritGroup"])
            & (criticalcaregroup["CritGroup"] != "")
        ],
        how="inner",
        on=["facility_identifier", "unit_type", "ward_identifier"],
        suffixes=("", "_drop"),
    )
    df_query_cc = df_query_cc.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    df_query_cc["stay_number"] = (
        df_query_cc["stay_number"].astype(str).str.pad(8, side="left", fillchar="0")
    )
    df_query_cc["episode_sequence_number"] = (
        df_query_cc["episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    criticalcarehours = pd.merge(
        tbl_dbo_episode_ats,
        df_query_cc,
        how="inner",
        on=["facility_identifier", "stay_number", "episode_sequence_number"],
        suffixes=("", "_drop"),
    )
    criticalcarehours = criticalcarehours.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    criticalcarehours["start_date_dummy"] = pd.to_datetime(
        (
            criticalcarehours["start_date"].astype(str).str[:10]
            + " "
            + criticalcarehours["start_time"].astype(str).str[-8:]
        ),
        errors="coerce",
        format="%Y-%m-%d %H:%M:%S",
    )
    criticalcarehours["today_dummy"] = pd.Timestamp.today()
    criticalcarehours["today_dummy"] = pd.to_datetime(
        criticalcarehours["today_dummy"].astype(str).str[:19],
        errors="coerce",
        format="%Y-%m-%d %H:%M:%S",
    )
    criticalcarehours["end_date_dummy"] = np.where(
        (
            (criticalcarehours["end_date"].isnull())
            | (criticalcarehours["end_date"] == "")
            | (criticalcarehours["end_date"] == " ")
            | (criticalcarehours["end_time"].isnull())
            | (criticalcarehours["end_time"] == "")
            | (criticalcarehours["end_time"] == " ")
        ),
        criticalcarehours["today_dummy"],
        pd.to_datetime(
            (
                criticalcarehours["end_date"].astype(str).str[:10]
                + " "
                + criticalcarehours["end_time"].astype(str).str[-8:]
            ),
            errors="coerce",
            format="%Y-%m-%d %H:%M:%S",
        ),
    )
    criticalcarehours["Hours"] = (
        criticalcarehours["end_date_dummy"] - criticalcarehours["start_date_dummy"]
    ) / pd.Timedelta(hours=1)
    criticalcarehours["AICU1"] = np.where(
        criticalcarehours["CritGroup"] == "AICU1",
        (criticalcarehours["end_date_dummy"] - criticalcarehours["start_date_dummy"])
        / pd.Timedelta(hours=1),
        0,
    )
    criticalcarehours["AICU3"] = np.where(
        criticalcarehours["CritGroup"] == "AICU3",
        (criticalcarehours["end_date_dummy"] - criticalcarehours["start_date_dummy"])
        / pd.Timedelta(hours=1),
        0,
    )
    criticalcarehours["PICU"] = np.where(
        criticalcarehours["CritGroup"] == "PICU",
        (criticalcarehours["end_date_dummy"] - criticalcarehours["start_date_dummy"])
        / pd.Timedelta(hours=1),
        0,
    )
    criticalcarehours["NICU"] = np.where(
        criticalcarehours["CritGroup"] == "NICU",
        (criticalcarehours["end_date_dummy"] - criticalcarehours["start_date_dummy"])
        / pd.Timedelta(hours=1),
        0,
    )
    criticalcarehours["PSICU"] = np.where(
        criticalcarehours["CritGroup"] == "PSICU",
        (criticalcarehours["end_date_dummy"] - criticalcarehours["start_date_dummy"])
        / pd.Timedelta(hours=1),
        0,
    )
    criticalcarehours["CCU"] = np.where(
        criticalcarehours["CritGroup"] == "CCU",
        (criticalcarehours["end_date_dummy"] - criticalcarehours["start_date_dummy"])
        / pd.Timedelta(hours=1),
        0,
    )
    criticalcarehours["HITH"] = np.where(
        criticalcarehours["CritGroup"] == "HITH",
        (criticalcarehours["end_date_dummy"] - criticalcarehours["start_date_dummy"])
        / pd.Timedelta(hours=1),
        0,
    )
    criticalcarehours["HDU"] = np.where(
        criticalcarehours["CritGroup"] == "HDU",
        (criticalcarehours["end_date_dummy"] - criticalcarehours["start_date_dummy"])
        / pd.Timedelta(hours=1),
        0,
    )
    criticalcarehours["SCN"] = np.where(
        criticalcarehours["CritGroup"] == "SCN",
        (criticalcarehours["end_date_dummy"] - criticalcarehours["start_date_dummy"])
        / pd.Timedelta(hours=1),
        0,
    )
    criticalcarehours["AICU2"] = np.where(
        criticalcarehours["CritGroup"] == "AICU2",
        (criticalcarehours["end_date_dummy"] - criticalcarehours["start_date_dummy"])
        / pd.Timedelta(hours=1),
        0,
    )
    criticalcarehours.to_csv(
        "./ExtractorDB/CriticalCareHours_before_groupby.csv", index=False
    )
    criticalcarehours = (
        criticalcarehours.groupby(
            ["facility_identifier", "stay_number", "episode_sequence_number"],
            as_index=False,
            dropna=False,
        )
        .agg(
            Hours=("Hours", "sum"),
            AICU1=("AICU1", "sum"),
            AICU3=("AICU3", "sum"),
            PICU=("PICU", "sum"),
            NICU=("NICU", "sum"),
            PSICU=("PSICU", "sum"),
            CCU=("CCU", "sum"),
            HITH=("HITH", "sum"),
            HDU=("HDU", "sum"),
            SCN=("SCN", "sum"),
            AICU2=("AICU2", "sum"),
        )
        .reset_index()
    )
    criticalcarehours = criticalcarehours[
        [
            "facility_identifier",
            "stay_number",
            "episode_sequence_number",
            "Hours",
            "AICU1",
            "AICU3",
            "PICU",
            "NICU",
            "PSICU",
            "CCU",
            "HITH",
            "HDU",
            "SCN",
            "AICU2",
        ]
    ]
    criticalcarehours = criticalcarehours.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    criticalcarehours = criticalcarehours.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    criticalcarehours = criticalcarehours.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    criticalcarehours.to_csv("./ExtractorDB/CriticalCareHours.csv", index=False)
    logging.info(
        "%s records saved to ./ExtractorDB/CriticalCareHours.csv.",
        len(criticalcarehours),
    )
    """Appends data from multitude of tables where the encounter is not in the snapApp_CostingExtract table or the  tbl_ExcludedEncounters table to the tbl_PPM_Encounter"""
    # Access query: Append_to_tbl_PPM_Encounter_AUID
    # INSERT INTO tbl_PPM_Encounter ( EncounterType, EncounterNumber, PostCode, Suburb, MaritalStatus, PatientNumber, EpisodeOfCare, AttendingConsultant, AdmissionCategory, AdmissionElection, DischargeElection, AdmissionType, AdmissionSource, Hospital, FinancialClass, DischargeStatus, DRG1, DRG1Version, DRG2, DRG2Version, LengthOfStay, ICUHours, MechVentHours, StartDateTime, EndDateTime, Age, HealthFund, AdmissionWeight, WeightedSeparation, [Extra:LGACode], [Extra:HospitalStayNumber], [Extra:LHDIdentifier], [Extra:LegalStatus], [Extra:DVANumber], [Extra:DVAType], [Extra:IntendedSameDay], [Extra:ReferralFurtherHealthcare], [Extra:UnplannedReadmission], [Extra:MedicareNumber], [Extra:DaysinPsychUnit], [Extra:UnplannedTheatre], [Extra:EDStatus], [Extra:ICUStatus], [Extra:SRGcurrent], [Extra:ESRGcurrent], [Extra:CW_A], [Extra:CW_B], [Extra:CW_C], [Extra:CW_D], [Extra:CW_E], [Extra:CW_F], [Extra:TrimPoint], [Extra:Outlierdays], [Extra:SurgeryIndicator], [Extra:AreaDOHRSCode],[Extra:FacilityTransferredto], [Extra:FacilityTransferredfrom], [Extra:MRN], [Extra:MDC], [Extra:indicatorProcedurecode], [Extra:bookingIdentifier], [Extra:waitinglistcategory], [Extra:ClinicalURGfinal], [Extra:ReasonforRemoval], [Extra:DRG1_pccl], [Extra:EpisodeLeaveDays], [Extra:QualifiedBedDays], [Extra:IndigenousStatus], [Extra:MothersMRN], [Extra:MothersStayNumber], [Extra:MothersPersonIdentifier], [Extra:ElectionStatusSummary], [Extra:FacilityType], [Extra:MedicareEligibility],  [Extra:LOSinCostingPeriod], [Extra:LeaveinCostingPeriod], [Extra:VersionID], [Extra:AICU1_Hours], [Extra:AICU3_Hours], [Extra:PICU_Hours], [Extra:NICU_Hours], [Extra:PSICU_Hours], [Extra:CCU_Hours], [Extra:AICU2_Hours], AttendingConsultantSpecialty, [Extra:nwau], [Extra:nwau_PublicEquivModel], [Extra:nwau_base], [Extra:nwau_paed_incr], [Extra:nwau_indig_incr], [Extra:nwau_remote_incr], [Extra:nwau_icu_incr], [Extra:nwau_private_patient_service_incr], [Extra:nwau_private_patient_accom_incr], [Extra:AUID], [Extra:HITH_Hours], [Extra:HDU_Hours], [Extra:SCN_Hours], [Extra:SRG_Version], [Extra:Collabrtve_Care_Facility], [Extra:Contract_Status], [Extra:Collabrtve_Care_Role], [Extra:Collabrtve_Care_Type], [Extra:Radiotherapy_adj], [Extra:nwau_version], [Extra:LHD_of_Usual_Residence], [Extra:sp_psy_age_adj], [Extra:compensable_nwau], [Extra:SpecialtyPortal], [Extra:ExtractDate] , [Extra:WIP], [Extra:StartDateTime_EpisodeTable], [Extra:EndDateTime_EpisodeATSTable], [Extra:EndDateTime_EpisodeTable], [Extra:LengthofStay_EpisodeTable], [Extra:LengthofStay_EpisodeATSTable], [Extra:EpisodeLeaveDays_EpisodeTable], [Extra:EpisodeLeaveDays_EpisodeATSTable], [Extra:EpisodeofCare_EpisodeTable], [Extra:EpisodeofCare_EpisodeATSTable], [Extra:MothersEncounterNumber])
    # SELECT  IIf([tbl_dbo_episode_srg]![ed_status] In ("1","4","04","01"),"X",IIf([tbl_dbo_episode_ats]![episode_of_care_type]='5' And [tbl_dbo_episode_ats]![qualified_bed_time]=0 And [tbl_dbo_episode_ats]![qualified_bed_days]=0,"X","I")) AS Expr15, [tbl_dbo_episode_ats]![facility_identifier] & "-" & "I" & "-" & Format$([tbl_dbo_episode_ats]![stay_number],"00000000") & "-" & Format([tbl_dbo_episode_ats]![episode_sequence_number],"000") as Expr1, tbl_dbo_stay.patient_postcode, tbl_dbo_stay.patient_suburb, tbl_dbo_stay.marital_status, [tbl_dbo_episode_ats]![facility_identifier] & "-" & Format(IIf([tbl_Patient_Contact_Details]![AUID] Is Not Null,[tbl_Patient_Contact_Details]![AUID],Right([tbl_dbo_stay]![mrn],10)),"0000000000") AS Expr3, tbl_dbo_episode_ats.episode_of_care_type,  [tbl_dbo_episode_ats]![facility_identifier] & "-" & Trim([tbl_dbo_days_episode]![mo_code]) as Expr2, tbl_dbo_stay.emergency_status, tbl_dbo_stay.election_status_on_admit, tbl_dbo_episode_ats.payment_status_on_sep, IIf([tbl_dbo_episode_ats]![episode_end_date]=[tbl_dbo_episode_ats]![episode_start_date],"SD","ON") as Expr6, tbl_dbo_episode_ats.source_of_referral, tbl_dbo_episode_ats.facility_identifier, tbl_dbo_episode_ats.financial_class, tbl_dbo_episode_ats.mode_of_separation, IIf([tbl_dbo_episode_DRG]![an_drg] Is Null,"960Z",[tbl_dbo_episode_DRG]![an_drg]) as Expr9, IIf([tbl_dbo_episode_DRG]![an_drg_version] Is Null,[Forms]![Frm:1-ExtractSetUp]![DRG1V],[tbl_dbo_episode_DRG]![an_drg_version]) as Expr12, IIf([2_an_drg] Is Null,"960Z",[2_an_drg]) as Expr22, IIf([tbl_dbo_episode_DRG]![2_an_drg_version] Is Null,[Forms]![Frm:1-ExtractSetUp]![DRG2V],[tbl_dbo_episode_DRG]![2_an_drg_version]) as Expr21, tbl_dbo_episode_ats.episode_length_of_stay, tbl_dbo_episode_ats.hours_in_icu, tbl_dbo_episode.hours_on_mech_vent_num, Format([tbl_dbo_episode_ats]![episode_start_date] & " " & [tbl_dbo_episode_ats]![episode_start_time],"yyyy-mm-dd hh:nn:ss") as Expr10, Format([tbl_dbo_episode_ats]![episode_end_date] & " " & [tbl_dbo_episode_ats]![episode_end_time],"yyyy-mm-dd hh:nn:ss") as Expr7, tbl_dbo_stay.age, tbl_dbo_stay.insurance_fund_master, IIf([tbl_dbo_episode_ats]![infant_start_weight]="",0,[tbl_dbo_episode_ats]![infant_start_weight]) as Expr4, tbl_dbo_episode_srg.cost_weight_e_current, tbl_dbo_stay.area_of_usual_residence, "SN" & Trim([tbl_dbo_episode_ats]![stay_number]) as Expr11, tbl_dbo_episode_ats.area_identifier, tbl_dbo_episode_ats.legal_status_on_admit, tbl_dbo_stay.dva_card_number, tbl_dbo_stay.dva_card_type, tbl_dbo_stay.stay_discharge_intention, tbl_dbo_stay.referred_to_on_separation, tbl_dbo_stay.readmit_this_hosp_28_days, tbl_dbo_episode_ats.episode_sequence_number, tbl_dbo_stay.medicare_number,  IIf([tbl_dbo_episode_ats]![hours_in_psych_unit]>0 And [tbl_dbo_episode_ats]![days_in_psych_unit]=0,1,[tbl_dbo_episode_ats]![days_in_psych_unit]) as Expr17, tbl_dbo_episode_ats.unplanned_theatre, tbl_dbo_episode_srg.ed_status, tbl_dbo_episode_srg.icu_status, tbl_dbo_episode_srg.srg_current, tbl_dbo_episode_srg.esrg_current, tbl_dbo_episode_srg.cost_weight_a_current, tbl_dbo_episode_srg.cost_weight_b_current, tbl_dbo_episode_srg.cost_weight_c_current, tbl_dbo_episode_srg.cost_weight_d_current, tbl_dbo_episode_srg.cost_weight_e_current, tbl_dbo_episode_srg.cost_weight_f_current, tbl_dbo_episode_srg.trim_point,  [outlier_days_1]+[outlier_days_2] as Expr8, tbl_dbo_episode_srg.surgery_indicator, tbl_dbo_episode_ats.financial_program, tbl_dbo_stay.facility_trans_to, tbl_dbo_stay.facility_trans_from, tbl_dbo_episode_ats.mrn, tbl_dbo_episode_DRG.mdc, tbl_dbo_wl_exit1.indicated_proc_code, tbl_dbo_wl_exit1.booking_identifier, tbl_dbo_wl_exit1.waiting_list_category, tbl_dbo_wl_exit1.clinical_urg_final_crnt, tbl_dbo_wl_exit1.reason_for_removal, tbl_dbo_episode_DRG.an_drg_pccl, tbl_dbo_episode_ats.episode_leav_days_total, tbl_dbo_episode_ats.qualified_bed_days, tbl_dbo_stay.indigenous_status, tbl_dbo_stay.mothers_mrn, IIf([mothers_stay_number]="","",IIf([mothers_stay_number] Is Null,"","SN" & Trim([mothers_stay_number]))) as Expr20, tbl_dbo_stay.mothers_person_identifier, IIf([tbl_dbo_episode_ats]![payment_status_on_sep] In ("20","23","24","45"),"Public",IIf([tbl_dbo_episode_ats]![payment_status_on_sep] In ("30","31","32","33","34","35","36","46"),"Private",IIf([tbl_dbo_episode_ats]![payment_status_on_sep] In ("40","41","42","43","50","51","52","60"),"Compensable"))) as Expr5, tbl_dbo_episode_ats.facility_type, tbl_dbo_stay.medicare_eligibility_status,  (IIf([tbl_dbo_episode_ats]![episode_start_date]=[tbl_dbo_episode_ats]![episode_end_date],1,(DateDiff("d",IIf([tbl_dbo_episode_ats]![episode_start_date]<DateValue([Forms]![Frm:1-ExtractSetUp]![Start_Date]),DateValue([Forms]![Frm:1-ExtractSetUp]![Start_Date]),IIf([tbl_dbo_episode_ats]![episode_start_date]>DateValue([Forms]![Frm:1-ExtractSetUp]![end_Date]),DateValue([Forms]![Frm:1-ExtractSetUp]![Start_Date]),[tbl_dbo_episode_ats]![episode_start_date])),IIf([tbl_dbo_episode_ats]![episode_end_date] Is Null,[Forms]![Frm:1-ExtractSetUp]![End_Date],IIf([tbl_dbo_episode_ats]![episode_end_date]>DateValue([Forms]![Frm:1-ExtractSetUp]![End_Date]),DateValue([Forms]![Frm:1-ExtractSetUp]![End_Date]),[tbl_dbo_episode_ats]![episode_end_date]))))-Nz([tbl_PPM_transfer_Leave 02]![LeaveDays]))) as Expr14, tbl_PPM_transfer_Leave 02.LeaveDays as Expr13, Replace([Forms]![Frm:1-ExtractSetUp]![fm_round],"V","") as versionid,  IIf([AICU1]=0,1,[AICU1]) as Expr23,  IIf([AICU3]=0,1,[AICU3]) as Expr24,  IIf([PICU]=0,1,[PICU]) as Expr24,  IIf([NICU]=0,1,[NICU]) as Expr26,  IIf([PSICU]=0,1,[PSICU]) as Expr27,  IIf([CCU]=0,1,[CCU]) as Expr28, IIf([AICU2]=0,1,[AICU2]) as Expr29,  (Trim([tbl_dbo_DAYS_EPISODE]![facility_identifier] & "-" & [tbl_dbo_DAYS_EPISODE]![specialty_unit_code])) as Expr18, Acute_nwau.NWAU_final, Acute_nwau.public_equiv_nwau, Acute_nwau.nwau_base, Acute_nwau.paediatric_adj, Acute_nwau.indigenous_adj, Acute_nwau.remoteness_area_adj, Acute_nwau.icu_adj, Acute_nwau.private_service_adj, Acute_nwau.private_accom_adj, IIf([tbl_Patient_Contact_Details]![AUID] Is Not Null,[tbl_Patient_Contact_Details]![AUID]) as Expr16, IIf([HITH]=0,1,[HITH]) as Expr30, IIf([HDU]=0,1,[HDU]) as Expr31, IIf([SCN]=0,1,[SCN]) as Expr32, tbl_dbo_episode_srg.srg_version_number, tbl_dbo_stay.collabrtve_care_facility, tbl_dbo_stay.contract_status,  tbl_dbo_stay.collabrtve_care_role, tbl_dbo_stay.collabrtve_care_type, Acute_nwau.radiotherapy_adj, Acute_nwau.nwau_version, tbl_dbo_stay.LHD_of_Usual_residence, Acute_nwau.sp_psy_age_adj, Acute_nwau.compensable_nwau, [qry specialtyportal].[SpecialityPortal],  Format([getdate],"yyyy-mm-dd hh:nn:ss") as Expr33, tbl_dbo_episode_ats.WIP,  Format([tbl_dbo_episode]![startdate] & " " & [tbl_dbo_episode]![starttime],"yyyy-mm-dd hh:nn:ss") as Expr35, IIf([Episode ATS end date update]![facility_identifier] Is Not Null,Null,Format([tbl_dbo_episode_ats]![episode_end_date] & " " & [tbl_dbo_episode_ats]![episode_end_time],"yyyy-mm-dd hh:nn:ss")) as Expr36, Format([tbl_dbo_episode]![enddate] & " " & [tbl_dbo_episode]![endtime],"yyyy-mm-dd hh:nn:ss") as Expr34, tbl_dbo_episode.episode_length_of_stay, tbl_dbo_episode_ats.episode_length_of_stay, tbl_dbo_episode_ats.episode_leave_days_total, tbl_dbo_episode_ats.episode_leave_days_total, tbl_dbo_episode.episode_of_care_type, tbl_dbo_episode_ats.episode_of_care_type, IIf([mothers_stay_number]="","",IIf([mothers_stay_number] Is Null,"",[tbl_dbo_episode_ats]![facility_identifier] & "-I-" & Format(Trim([mothers_stay_number]),"00000000") & "-001")) as Expr19
    # FROM """-----------------------------"""
    # GROUP BY  IIf([tbl_dbo_episode_srg]![ed_status] In ("1","4","04","01"),"X",IIf([tbl_dbo_episode_ats]![episode_of_care_type]='5' And [tbl_dbo_episode_ats]![qualified_bed_time]=0 And [tbl_dbo_episode_ats]![qualified_bed_days]=0,"X","I")), [tbl_dbo_episode_ats]![facility_identifier] & "-" & "I" & "-" & Format$([tbl_dbo_episode_ats]![stay_number],"00000000") & "-" & Format([tbl_dbo_episode_ats]![episode_sequence_number],"000"), tbl_dbo_stay.patient_postcode, tbl_dbo_stay.patient_suburb, tbl_dbo_stay.marital_status, [tbl_dbo_episode_ats]![facility_identifier] & "-" & Format(IIf([tbl_Patient_Contact_Details]![AUID] Is Not Null,[tbl_Patient_Contact_Details]![AUID],Right([tbl_dbo_stay]![mrn],10)),"0000000000"),  [tbl_dbo_episode_ats]![facility_identifier] & "-" & Trim([tbl_dbo_days_episode]![mo_code]), tbl_dbo_stay.emergency_status, tbl_dbo_stay.election_status_on_admit, tbl_dbo_episode_ats.payment_status_on_sep,  IIf([tbl_dbo_episode_ats]![episode_end_date]=[tbl_dbo_episode_ats]![episode_start_date],"SD","ON"), tbl_dbo_episode_ats.source_of_referral, tbl_dbo_episode_ats.facility_identifier, tbl_dbo_episode_ats.financial_class, tbl_dbo_episode_ats.mode_of_separation, IIf([tbl_dbo_episode_DRG]![an_drg] Is Null,"960Z",[tbl_dbo_episode_DRG]![an_drg]), IIf([tbl_dbo_episode_DRG]![an_drg_version] Is Null,[Forms]![Frm:1-ExtractSetUp]![DRG1V],[tbl_dbo_episode_DRG]![an_drg_version]),  IIf([2_an_drg] Is Null,"960Z",[2_an_drg]),  IIf([tbl_dbo_episode_DRG]![2_an_drg_version] Is Null,[Forms]![Frm:1-ExtractSetUp]![DRG2V],[tbl_dbo_episode_DRG]![2_an_drg_version]), tbl_dbo_episode_ats.hours_in_icu, tbl_dbo_episode.hours_on_mech_vent_num, Format([tbl_dbo_episode_ats]![episode_start_date] & " " & [tbl_dbo_episode_ats]![episode_start_time],"yyyy-mm-dd hh:nn:ss"), Format([tbl_dbo_episode_ats]![episode_end_date] & " " & [tbl_dbo_episode_ats]![episode_end_time],"yyyy-mm-dd hh:nn:ss"), tbl_dbo_stay.age, tbl_dbo_stay.insurance_fund_master, IIf([tbl_dbo_episode_ats]![infant_start_weight]="",0,[tbl_dbo_episode_ats]![infant_start_weight]), tbl_dbo_stay.area_of_usual_residence, "SN" & Trim([tbl_dbo_episode_ats]![stay_number]), tbl_dbo_episode_ats.area_identifier, tbl_dbo_episode_ats.legal_status_on_admit, tbl_dbo_stay.dva_card_number, tbl_dbo_stay.dva_card_type, tbl_dbo_stay.stay_discharge_intention, tbl_dbo_stay.referred_to_on_separation, tbl_dbo_stay.readmit_this_hosp_28_days, tbl_dbo_episode_ats.episode_sequence_number, tbl_dbo_stay.medicare_number,  IIf([tbl_dbo_episode_ats]![hours_in_psych_unit]>0 And [tbl_dbo_episode_ats]![days_in_psych_unit]=0,1,[tbl_dbo_episode_ats]![days_in_psych_unit]), tbl_dbo_episode_ats.unplanned_theatre, tbl_dbo_episode_srg.ed_status, tbl_dbo_episode_srg.icu_status, tbl_dbo_episode_srg.srg_current, tbl_dbo_episode_srg.esrg_current, tbl_dbo_episode_srg.cost_weight_a_current, tbl_dbo_episode_srg.cost_weight_b_current, tbl_dbo_episode_srg.cost_weight_c_current, tbl_dbo_episode_srg.cost_weight_d_current, tbl_dbo_episode_srg.cost_weight_e_current, tbl_dbo_episode_srg.cost_weight_f_current, tbl_dbo_episode_srg.trim_point,  [outlier_days_1]+[outlier_days_2], tbl_dbo_episode_srg.surgery_indicator, tbl_dbo_episode_ats.financial_program, tbl_dbo_stay.facility_trans_to, tbl_dbo_stay.facility_trans_from, tbl_dbo_episode_ats.mrn, tbl_dbo_episode_DRG.mdc, tbl_dbo_wl_exit1.indicated_proc_code, tbl_dbo_wl_exit1.booking_identifier, tbl_dbo_wl_exit1.waiting_list_category, tbl_dbo_wl_exit1.clinical_urg_final_crnt, tbl_dbo_wl_exit1.reason_for_removal, tbl_dbo_episode_DRG.an_drg_pccl, tbl_dbo_episode_ats.qualified_bed_days, tbl_dbo_stay.indigenous_status, tbl_dbo_stay.mothers_mrn, IIf([mothers_stay_number]="","",IIf([mothers_stay_number] Is Null,"","SN" & Trim([mothers_stay_number]))), tbl_dbo_stay.mothers_person_identifier, IIf([tbl_dbo_episode_ats]![payment_status_on_sep] In ("20","23","24","45"),"Public",IIf([tbl_dbo_episode_ats]![payment_status_on_sep] In ("30","31","32","33","34","35","36","46"),"Private",IIf([tbl_dbo_episode_ats]![payment_status_on_sep] In ("40","41","42","43","50","51","52","60"),"Compensable"))), tbl_dbo_episode_ats.facility_type, tbl_dbo_stay.medicare_eligibility_status,  (IIf([tbl_dbo_episode_ats]![episode_start_date]=[tbl_dbo_episode_ats]![episode_end_date],1,(DateDiff("d",IIf([tbl_dbo_episode_ats]![episode_start_date]<DateValue([Forms]![Frm:1-ExtractSetUp]![Start_Date]),DateValue([Forms]![Frm:1-ExtractSetUp]![Start_Date]),IIf([tbl_dbo_episode_ats]![episode_start_date]>DateValue([Forms]![Frm:1-ExtractSetUp]![end_Date]),DateValue([Forms]![Frm:1-ExtractSetUp]![Start_Date]),[tbl_dbo_episode_ats]![episode_start_date])),IIf([tbl_dbo_episode_ats]![episode_end_date] Is Null,[Forms]![Frm:1-ExtractSetUp]![End_Date],IIf([tbl_dbo_episode_ats]![episode_end_date]>DateValue([Forms]![Frm:1-ExtractSetUp]![End_Date]),DateValue([Forms]![Frm:1-ExtractSetUp]![End_Date]),[tbl_dbo_episode_ats]![episode_end_date]))))-Nz([tbl_PPM_transfer_Leave 02]![LeaveDays]))), tbl_PPM_transfer_Leave 02.LeaveDays, Replace([Forms]![Frm:1-ExtractSetUp]![fm_round],"V",""),  IIf([AICU1]=0,1,[AICU1]),  IIf([AICU3]=0,1,[AICU3]),  IIf([PICU]=0,1,[PICU]),  IIf([NICU]=0,1,[NICU]), IIf([PSICU]=0,1,[PSICU]),  IIf([CCU]=0,1,[CCU]), IIf([AICU2]=0,1,[AICU2]), (Trim([tbl_dbo_DAYS_EPISODE]![facility_identifier] & "-" & [tbl_dbo_DAYS_EPISODE]![specialty_unit_code])), Acute_nwau.NWAU_final, Acute_nwau.public_equiv_nwau, Acute_nwau.nwau_base, Acute_nwau.paediatric_adj, Acute_nwau.indigenous_adj, Acute_nwau.remoteness_area_adj, Acute_nwau.icu_adj, Acute_nwau.private_service_adj, Acute_nwau.private_accom_adj, IIf([tbl_Patient_Contact_Details]![AUID] Is Not Null,[tbl_Patient_Contact_Details]![AUID]), IIf([HITH]=0,1,[HITH]), IIf([HDU]=0,1,[HDU]), IIf([SCN]=0,1,[SCN]), tbl_dbo_episode_srg.srg_version_number, tbl_dbo_stay.collabrtve_care_facility, tbl_dbo_stay.contract_status,  tbl_dbo_stay.collabrtve_care_role, tbl_dbo_stay.collabrtve_care_type, Acute_nwau.radiotherapy_adj, Acute_nwau.nwau_version, tbl_dbo_stay.LHD_of_Usual_residence, Acute_nwau.sp_psy_age_adj, Acute_nwau.compensable_nwau, [qry specialtyportal].[SpecialityPortal],  Format([getdate],"yyyy-mm-dd hh:nn:ss"), tbl_dbo_episode_ats.WIP,  Format([tbl_dbo_episode]![startdate] & " " & [tbl_dbo_episode]![starttime],"yyyy-mm-dd hh:nn:ss"), IIf([Episode ATS end date update]![facility_identifier] Is Not Null,Null,Format([tbl_dbo_episode_ats]![episode_end_date] & " " & [tbl_dbo_episode_ats]![episode_end_time],"yyyy-mm-dd hh:nn:ss")), Format([tbl_dbo_episode]![enddate] & " " & [tbl_dbo_episode]![endtime],"yyyy-mm-dd hh:nn:ss"), tbl_dbo_episode.episode_length_of_stay, tbl_dbo_episode_ats.episode_length_of_stay, tbl_dbo_episode_ats.episode_leave_days_total, tbl_dbo_episode.episode_of_care_type, tbl_dbo_episode_ats.episode_of_care_type, IIf([mothers_stay_number]="","",IIf([mothers_stay_number] Is Null,"",[tbl_dbo_episode_ats]![facility_identifier] & "-I-" & Format(Trim([mothers_stay_number]),"00000000") & "-001")), tbl_dbo_episode_ats.episode_length_of_stay, tbl_dbo_episode_ats.episode_leave_days_total, tbl_dbo_episode_ats.episode_leave_days_total, tbl_dbo_episode_ats.episode_of_care_type, [qrysnapApp_CostingExtract].SNAPEpisodeID, IntrerupCare.facility_identifier, tbl_ExcludedEncounters.facility_identifier, [qrysnapApp_CostingExtract].[Snap ClassV4]
    # HAVING (((qrysnapApp_CostingExtract.SNAPEpisodeID) Is Null AND (IntrerupCare.facility_identifier) Is Null) AND ((tbl_ExcludedEncounters.facility_identifier) Is Null) AND ([qrysnapApp_CostingExtract].[Snap ClassV4] is Null));
    tbl_dbo_days_episode["facility_identifier_tbl_dbo_days_episode"] = (
        tbl_dbo_days_episode["facility_identifier"]
    )
    tbl_dbo_episode_ats["facility_identifier_tbl_dbo_episode_ats"] = (
        tbl_dbo_episode_ats["facility_identifier"]
    )
    tbl_dbo_episode_ats["episode_leave_days_total_tbl_dbo_episode_ats"] = (
        tbl_dbo_episode_ats["episode_leave_days_total"]
    )
    tbl_dbo_episode_ats["episode_length_of_stay_tbl_dbo_episode_ats"] = (
        tbl_dbo_episode_ats["episode_length_of_stay"]
    )
    tbl_dbo_episode_ats["episode_of_care_type_tbl_dbo_episode_ats"] = (
        tbl_dbo_episode_ats["episode_of_care_type"]
    )
    tbl_dbo_episode_ats["mrn_tbl_dbo_episode_ats"] = tbl_dbo_episode_ats["mrn"]
    df_query1 = pd.merge(
        tbl_dbo_episode_ats[
            [
                "facility_identifier",
                "area_identifier",
                "days_in_psych_unit",
                "episode_end_date",
                "episode_end_time",
                "episode_leave_days_total_tbl_dbo_episode_ats",
                "episode_length_of_stay_tbl_dbo_episode_ats",
                "episode_of_care_type_tbl_dbo_episode_ats",
                "episode_sequence_number",
                "episode_start_date",
                "episode_start_time",
                "facility_identifier_tbl_dbo_episode_ats",
                "facility_type",
                "financial_class",
                "financial_program",
                "hours_in_icu",
                "hours_in_psych_unit",
                "infant_start_weight",
                "legal_status_on_admit",
                "mode_of_separation",
                "mrn_tbl_dbo_episode_ats",
                "payment_status_on_sep",
                "qualified_bed_days",
                "qualified_bed_time",
                "source_of_referral",
                "stay_number",
                "unplanned_theatre",
                "WIP",
                "HLTH_ORG_OSP_OSP_ID",
                "MG_AUTH_OSP_OSP_ID",
                "SE_CBK_SK",
                "CL_ID_EUID",
                "CL_ID_IHI",
                "HLTH_ORG_OSP_TYP",
                "ICU1_Hours",
                "ICU2_Hours",
                "ICU_Hours",
                "CCU_Hours",
                "HDU_Hours",
                "NICU_Hours",
                "SRV_ENC_REC_ID",
                "FRML_DISCH_MODE_CD",
                "SE_SEP_MODE_NHDD_CD",
                "Responsible_Facility",
                "SE_TYP_CD",
                "SE_ADM_MODE_NHDD_CD",
            ]
        ],
        tbl_dbo_days_episode[
            [
                "facility_identifier_tbl_dbo_days_episode",
                "mo_code",
                "specialty_unit_code",
                "episode_sequence_number",
                "stay_number",
                "start_date",
                "start_time",
                "DIM_RSP_ISP_SK",
            ]
        ],
        how="left",
        left_on=[
            "episode_sequence_number",
            "stay_number",
            "facility_identifier_tbl_dbo_episode_ats",
            "episode_start_date",
            "episode_start_time",
        ],
        right_on=[
            "episode_sequence_number",
            "stay_number",
            "facility_identifier_tbl_dbo_days_episode",
            "start_date",
            "start_time",
        ],
        suffixes=("", "_drop"),
    )
    df_query1["mo_code"] = np.where(
        df_query1["mo_code"] == "nan", "", df_query1["mo_code"]
    )
    df_query1 = df_query1.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    tbl_dbo_stay["mrn_tbl_dbo_stay"] = tbl_dbo_stay["mrn"]
    tbl_dbo_stay["facility_identifier_tbl_dbo_stay"] = tbl_dbo_stay[
        "facility_identifier"
    ]
    tbl_dbo_wl_exit1["facility_identifier_tbl_dbo_wl_exit1"] = tbl_dbo_wl_exit1[
        "facility_identifier"
    ]
    # 27 July - stay - add seq number
    # df_query2 = pd.merge(tbl_dbo_stay[['facility_identifier_tbl_dbo_stay','age', 'area_of_usual_residence', 'collabrtve_care_facility', 'collabrtve_care_role', 'collabrtve_care_type', 'contract_status', 'dva_card_number', 'dva_card_type', 'election_status_on_admit', 'emergency_status', 'facility_trans_from', 'facility_trans_to', 'indigenous_status', 'insurance_fund_master', 'LHD_of_Usual_residence', 'marital_status', 'medicare_eligibility_status', 'medicare_number', 'mothers_mrn', 'mothers_person_identifier', 'mothers_stay_number', 'mrn_tbl_dbo_stay', 'patient_postcode', 'patient_suburb', 'readmit_this_hosp_28_days', 'referred_to_on_separation', 'stay_discharge_intention', 'person_identifier', 'admission_date', 'stay_number']], tbl_dbo_wl_exit1[['booking_identifier', 'clinical_urg_final_crnt', 'indicated_proc_code', 'reason_for_removal', 'waiting_list_category', 'person_identifier', 'removal_date', 'facility_identifier_tbl_dbo_wl_exit1']], how='left', left_on=['facility_identifier_tbl_dbo_stay', 'person_identifier', 'admission_date'], right_on=['facility_identifier_tbl_dbo_wl_exit1', 'person_identifier', 'removal_date'], suffixes=('', '_drop'))
    df_query2 = pd.merge(
        tbl_dbo_stay[
            [
                "facility_identifier_tbl_dbo_stay",
                "age",
                "area_of_usual_residence",
                "collabrtve_care_facility",
                "collabrtve_care_role",
                "collabrtve_care_type",
                "contract_status",
                "dva_card_number",
                "dva_card_type",
                "election_status_on_admit",
                "emergency_status",
                "facility_trans_from",
                "facility_trans_to",
                "indigenous_status",
                "insurance_fund_master",
                "LHD_of_Usual_residence",
                "marital_status",
                "medicare_eligibility_status",
                "medicare_number",
                "mothers_mrn",
                "mothers_person_identifier",
                "mothers_stay_number",
                "mrn_tbl_dbo_stay",
                "patient_postcode",
                "patient_suburb",
                "readmit_this_hosp_28_days",
                "referred_to_on_separation",
                "stay_discharge_intention",
                "person_identifier",
                "admission_date",
                "stay_number",
                "episode_sequence_number",
                "ASGS_SA_L2_16_CD",
                "CL_URES_ADDR_ASGS21_SA_L2_CD",
            ]
        ],
        tbl_dbo_wl_exit1[
            [
                "booking_identifier",
                "clinical_urg_final_crnt",
                "indicated_proc_code",
                "reason_for_removal",
                "waiting_list_category",
                "person_identifier",
                "removal_date",
                "facility_identifier_tbl_dbo_wl_exit1",
            ]
        ],
        how="left",
        left_on=[
            "facility_identifier_tbl_dbo_stay",
            "person_identifier",
            "admission_date",
        ],
        right_on=[
            "facility_identifier_tbl_dbo_wl_exit1",
            "person_identifier",
            "removal_date",
        ],
        suffixes=("", "_drop"),
    )
    df_query2 = df_query2.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    # 27 July - stay - add seq number
    # df_query3 = pd.merge(df_query1, df_query2, how='left', left_on=['facility_identifier_tbl_dbo_episode_ats', 'stay_number'], right_on=['facility_identifier_tbl_dbo_stay', 'stay_number'], suffixes=('', '_drop'))
    df_query3 = pd.merge(
        df_query1,
        df_query2,
        how="left",
        left_on=[
            "facility_identifier_tbl_dbo_episode_ats",
            "stay_number",
            "episode_sequence_number",
        ],
        right_on=[
            "facility_identifier_tbl_dbo_stay",
            "stay_number",
            "episode_sequence_number",
        ],
        suffixes=("", "_drop"),
    )
    df_query3["mrn_tbl_dbo_stay"] = (
        df_query3["mrn_tbl_dbo_stay"].astype(str).apply(lambda x: x.replace(".0", ""))
    )
    df_query3 = df_query3.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    # tbl_dbo_episode_srg['ed_status'] = tbl_dbo_episode_srg['ed_status'].replace('','0').apply(lambda x: int(float(x)))#.astype('Int64', errors='ignore')
    tbl_dbo_episode_srg["ed_status"] = (
        tbl_dbo_episode_srg["ed_status"].fillna(0).astype(int, errors="ignore")
    )
    tbl_dbo_episode_srg["ed_status"] = (
        tbl_dbo_episode_srg["ed_status"].astype(str).str.strip()
    )
    df_query4 = pd.merge(
        df_query3,
        tbl_dbo_episode_srg[
            [
                "cost_weight_a_current",
                "cost_weight_b_current",
                "cost_weight_c_current",
                "cost_weight_d_current",
                "cost_weight_e_current",
                "cost_weight_f_current",
                "ed_status",
                "esrg_current",
                "icu_status",
                "outlier_days_1",
                "outlier_days_2",
                "srg_current",
                "srg_version_number",
                "surgery_indicator",
                "trim_point",
                "facility_identifier",
                "stay_number",
                "episode_sequence_number",
            ]
        ],
        how="left",
        left_on=["facility_identifier", "stay_number", "episode_sequence_number"],
        right_on=["facility_identifier", "stay_number", "episode_sequence_number"],
        suffixes=("", "_drop"),
    )
    df_query4 = df_query4.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    df_query5 = pd.merge(
        df_query4,
        tbl_dbo_episode_DRG[
            [
                "2_an_drg",
                "2_an_drg_version",
                "an_drg",
                "an_drg_pccl",
                "an_drg_version",
                "facility_identifier",
                "stay_number",
                "episode_sequence_number",
                "mdc",
                "2_mdc",
                "AR_DRG_ECCS_RAW",
            ]
        ],
        how="left",
        left_on=["facility_identifier", "stay_number", "episode_sequence_number"],
        right_on=["facility_identifier", "stay_number", "episode_sequence_number"],
        suffixes=("", "_drop"),
    )
    df_query5 = df_query5.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    df_query5["stay_number"] = (
        df_query5["stay_number"].astype(str).str.pad(8, side="left", fillchar="0")
    )
    df_query6 = pd.merge(
        df_query5,
        tbl_Patient_Contact_Details[
            ["AUID", "contact_identifier", "facility_identifier"]
        ],
        how="left",
        left_on=["facility_identifier", "stay_number"],
        right_on=["facility_identifier", "contact_identifier"],
        suffixes=("", "_drop"),
    )
    df_query6 = df_query6.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    tbl_dbo_episode["episode_length_of_stay_tbl_dbo_episode"] = tbl_dbo_episode[
        "episode_length_of_stay"
    ]
    tbl_dbo_episode["episode_of_care_type_tbl_dbo_episode"] = tbl_dbo_episode[
        "episode_of_care_type"
    ]
    tbl_dbo_episode["episode_of_care_type_dbo"] = tbl_dbo_episode[
        "episode_of_care_type"
    ]
    tbl_dbo_episode.drop(
        ["episode_of_care_type"], axis=1, inplace=True, errors="ignore"
    )
    df_query7 = pd.merge(
        df_query6,
        tbl_dbo_episode[
            [
                "enddate",
                "endtime",
                "episode_length_of_stay_tbl_dbo_episode",
                "episode_of_care_type_tbl_dbo_episode",
                "hours_on_mech_vent_num",
                "startdate",
                "starttime",
                "facility_identifier",
                "stay_number",
                "episode_sequence_number",
            ]
        ],
        how="left",
        on=["facility_identifier", "stay_number", "episode_sequence_number"],
        suffixes=("", "_drop"),
    )
    df_query7 = df_query7.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    tbl_dbo_episode["episode_of_care_type"] = tbl_dbo_episode[
        "episode_of_care_type_dbo"
    ]
    df_query7["episode_leave_days_total_tbl_dbo_episode"] = df_query7[
        "episode_leave_days_total_tbl_dbo_episode_ats"
    ]
    tbl_Episode_ATS_end_date_update[
        "facility_identifier_tbl_Episode_ATS_end_date_update"
    ] = tbl_Episode_ATS_end_date_update["facility_identifier"]
    df_query8 = pd.merge(
        df_query7,
        tbl_Episode_ATS_end_date_update[
            [
                "episode_sequence_number",
                "facility_identifier",
                "stay_number",
                "facility_identifier_tbl_Episode_ATS_end_date_update",
            ]
        ],
        how="left",
        on=["facility_identifier", "stay_number", "episode_sequence_number"],
        suffixes=("", "_drop"),
    )
    df_query8 = df_query8.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    qry_SpecialtyPortal["stay_number"] = (
        qry_SpecialtyPortal["stay_number"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0")
    )
    qry_SpecialtyPortal["episode_sequence_number"] = (
        qry_SpecialtyPortal["episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    df_query9 = pd.merge(
        df_query8,
        qry_SpecialtyPortal[
            [
                "facility_identifier",
                "stay_number",
                "episode_sequence_number",
                "SpecialityPortal",
            ]
        ],
        how="left",
        on=["facility_identifier", "stay_number", "episode_sequence_number"],
        suffixes=("", "_drop"),
    )
    df_query9 = df_query9.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    df_query9["stay_number"] = (
        df_query9["stay_number"].astype(str).str.pad(8, side="left", fillchar="0")
    )
    tbl_PPM_transfer_Leave02["stay_number"] = (
        tbl_PPM_transfer_Leave02["stay_number"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0")
    )
    df_query9["episode_sequence_number"] = (
        df_query9["episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    tbl_PPM_transfer_Leave02["episode_sequence_number"] = (
        tbl_PPM_transfer_Leave02["episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    df_query10 = pd.merge(
        df_query9,
        tbl_PPM_transfer_Leave02[
            [
                "facility_identifier",
                "stay_number",
                "episode_sequence_number",
                "LeaveDays",
            ]
        ],
        how="left",
        on=["facility_identifier", "stay_number", "episode_sequence_number"],
        suffixes=("", "_drop"),
    )
    df_query10 = df_query10.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    criticalcarehours["stay_number"] = (
        criticalcarehours["stay_number"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0")
    )
    criticalcarehours["episode_sequence_number"] = (
        criticalcarehours["episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    ############# https://abft101.atlassian.net/browse/AQA-109 - Fetch LOS of Key Locations from EDW #############
    # Extra:CCU_Hours -> Unit Type of Extra:CCU is 33. The equivalent of Extra:CCU_Hours is CT_TOT_SE_CCU_HRS in EDW
    # Extra:HDU_Hours -> Unit Type of Extra:CCU is 34. The equivalent of Extra:HDU_Hours is CT_TOT_SE_HDU_HRS in EDW
    # Extra:NICU_Hours -> The equivalent of Extra:NICU_Hours is CT_TOT_SE_NICU_HRS in EDW
    # Extra:AICU1_Hours -> Unit Type of Extra:AICU1 is 91. The equivalent of Extra:AICU1_Hours is CT_TOT_SE_ICU1_HRS in EDW
    # Extra:AICU2_Hours -> Unit Type of Extra:AICU2 is 92. The equivalent of Extra:AICU2_Hours is CT_TOT_SE_ICU2_HRS in EDW
    # df_query11 = pd.merge(df_query10, criticalcarehours[['facility_identifier', 'stay_number', 'episode_sequence_number', 'Hours', 'AICU1', 'AICU3', 'PICU', 'NICU', 'PSICU', 'CCU', 'HITH', 'HDU', 'SCN', 'AICU2']], how='left', on=['facility_identifier', 'stay_number', 'episode_sequence_number'], suffixes=('', '_drop'))
    df_query11 = pd.merge(
        df_query10,
        criticalcarehours[
            [
                "facility_identifier",
                "stay_number",
                "episode_sequence_number",
                "Hours",
                "AICU3",
                "PICU",
                "PSICU",
                "HITH",
                "SCN",
            ]
        ],
        how="left",
        on=["facility_identifier", "stay_number", "episode_sequence_number"],
        suffixes=("", "_drop"),
    )
    df_query11 = df_query11.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    df_query11["AICU1"] = df_query11["ICU1_Hours"]
    df_query11["AICU2"] = df_query11["ICU2_Hours"]
    df_query11["NICU"] = df_query11["NICU_Hours"]
    df_query11["CCU"] = df_query11["CCU_Hours"]
    df_query11["HDU"] = df_query11["HDU_Hours"]
    ##########################################
    df_query11 = df_query11.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    df_query11["episode_sequence_number"] = (
        df_query11["episode_sequence_number"].astype(str).str.strip()
    )
    df_query11["episode_sequence_number"] = (
        df_query11["episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    df_query11["stay_number"] = (
        df_query11["stay_number"].astype(str).str.pad(8, side="left", fillchar="0")
    )

    qrysnapApp_CostingExtract["stay_number_cost"] = (
        qrysnapApp_CostingExtract["stay_number_cost"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0")
    )
    qrysnapApp_CostingExtract["sa_episode_sequence_number"] = (
        qrysnapApp_CostingExtract["sa_episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    # NOT IN qrysnapApp_CostingExtract
    # 11 Jan 2024 - CREATED FACILITY CHANGE
    # df_queryd = pd.merge(df_query11, qrysnapApp_CostingExtract[['FacilityCode', 'stay_number_cost', 'sa_episode_sequence_number', 'SNAPEpisodeID', 'Snap ClassV4']], how='left', left_on=['facility_identifier', 'stay_number', 'episode_sequence_number'], right_on=['FacilityCode', 'stay_number_cost', 'sa_episode_sequence_number'], suffixes=('', '_drop'), indicator=True)
    # 11 Jan 2025 - CREATED FACILITY CHANGE
    qrysnapApp_CostingExtract["SE_CBK_SK"] = qrysnapApp_CostingExtract[
        "SE_CBK_SK"
    ].astype("Int64")
    df_queryd = pd.merge(
        df_query11,
        qrysnapApp_CostingExtract[
            [
                "FacilityCode",
                "stay_number_cost",
                "sa_episode_sequence_number",
                "SNAPEpisodeID",
                "Snap ClassV4",
                "SE_CBK_SK",
            ]
        ],
        how="left",
        left_on=["SE_CBK_SK"],
        right_on=["SE_CBK_SK"],
        suffixes=("", "_drop"),
        indicator=True,
    )
    df_queryd = df_queryd[(df_queryd["_merge"] == "left_only")]
    acute_nwau["stay_number"] = acute_nwau["stay_number"].astype(str).str.strip()
    acute_nwau["episode_sequence_number"] = (
        acute_nwau["episode_sequence_number"].astype(str).str.strip()
    )
    df_queryd = pd.merge(
        df_queryd,
        acute_nwau[
            [
                "facility_identifier",
                "stay_number",
                "episode_sequence_number",
                "nwau_final",
                "public_equiv_nwau",
                "nwau_base",
                "paediatric_adj",
                "indigenous_adj",
                "remoteness_area_adj",
                "icu_adj",
                "private_service_adj",
                "private_accom_adj",
                "radiotherapy_adj",
                "nwau_version",
                "sp_psy_age_adj",
                "compensable_nwau",
                "WAU_ADJ_PT_TX_REMT_AREA",
                "WAU_ADJ_DIALYSIS",
                "WAU_ADJ_COVID19",
                "WAU_ADJ_HAC",
            ]
        ],
        how="left",
        left_on=["facility_identifier", "stay_number", "episode_sequence_number"],
        right_on=["facility_identifier", "stay_number", "episode_sequence_number"],
        suffixes=("", "_drop"),
    )
    df_queryd = df_queryd.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    # NOT IN tbl_ExcludedEncounters
    # commented as i don't think it is right to exclude all encounters of a facility identifier present in excluded encounter table
    """
    df_queryd = pd.merge(df_queryd, tbl_ExcludedEncounters[['facility_identifier']], how='left', left_on=['facility_identifier'], right_on=['facility_identifier'], suffixes=('', '_drop'), indicator='new_merge')
    df_queryd = df_queryd[(df_queryd['new_merge']=='left_only')]
    """
    # ValueError: cannot convert float NaN to integer
    # df_queryd['ed_status'] = df_queryd['ed_status'].replace('','0').apply(lambda x: int(float(x)))#.astype('Int64', errors='ignore')
    df_queryd["ed_status"] = (
        df_queryd["ed_status"].fillna(0).astype(int, errors="ignore")
    )
    df_queryd["ed_status"] = df_queryd["ed_status"].astype(str).str.strip()
    # IIf(tbl_dbo_episode_srg['ed_status'] In ("1","4","04","01"),"X",IIf(tbl_dbo_episode_ats['episode_of_care_type']='5' And tbl_dbo_episode_ats['qualified_bed_time']=0 And tbl_dbo_episode_ats['qualified_bed_days']=0,"X","I")) AS Expr15
    """
    condlist = [df_queryd['ed_status'].isin(['1', '4', '04', '01']), ~(df_queryd['ed_status'].isin(['1', '4', '04', '01'])) & (df_queryd['episode_of_care_type_tbl_dbo_episode_ats']=='5') & (df_queryd['qualified_bed_time'].astype('Int64', errors='ignore')==0) & (df_queryd['qualified_bed_days'].astype('Int64', errors='ignore')==0)]
    choicelist = ['X', 'X']
    df_queryd['EncounterType'] = np.select(condlist, choicelist, 'I') 
    """
    df_queryd["EncounterType"] = np.where(
        (df_queryd["ed_status"].isin(["1", "4", "04", "01"]))
        | (
            ~(df_queryd["ed_status"].isin(["1", "4", "04", "01"]))
            & (
                df_queryd["episode_of_care_type_tbl_dbo_episode_ats"]
                .astype(str)
                .str.strip()
                == "5"
            )
            & (
                df_queryd["qualified_bed_time"]
                .replace("", "0")
                .apply(lambda x: int(float(x)))
                == 0
            )
            & (
                df_queryd["qualified_bed_days"]
                .replace("", "0")
                .apply(lambda x: int(float(x)))
                == 0
            )
        ),
        "X",
        "I",
    )
    # tbl_dbo_episode_ats['facility_identifier'] & "-" & "I" & "-" & Format$(tbl_dbo_episode_ats['stay_number'],"00000000") & "-" & Format(tbl_dbo_episode_ats['episode_sequence_number'],"000") as Expr1
    df_queryd["stay_number"] = df_queryd["stay_number"].astype(str).str.strip()
    df_queryd["episode_sequence_number"] = (
        df_queryd["episode_sequence_number"].astype(str).str.strip()
    )
    df_queryd["stay_number"] = (
        df_queryd["stay_number"].astype(str).str.pad(8, side="left", fillchar="0")
    )
    df_queryd["episode_sequence_number"] = (
        df_queryd["episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    df_queryd["EncounterNumber"] = (
        df_queryd["facility_identifier_tbl_dbo_episode_ats"].astype(str).str.strip()
        + "-I-"
        + df_queryd["stay_number"].astype(str).str.strip()
        + "-"
        + df_queryd["episode_sequence_number"].astype(str).str.strip()
    )
    tbl_ExcludedEncounters_list = tbl_ExcludedEncounters["EncounterNumber"].tolist()
    df_queryd = df_queryd[
        ~df_queryd["EncounterNumber"].isin(tbl_ExcludedEncounters_list)
    ]
    df_queryd["PostCode"] = df_queryd[
        "patient_postcode"
    ]  # tbl_dbo_stay['patient_postcode']
    df_queryd["Suburb"] = df_queryd["patient_suburb"]  # tbl_dbo_stay['patient_suburb']
    df_queryd["MaritalStatus"] = df_queryd[
        "marital_status"
    ]  # tbl_dbo_stay['marital_status']
    # tbl_dbo_episode_ats['facility_identifier'] & "-" & Format(IIf(tbl_Patient_Contact_Details['AUID'] Is Not Null,tbl_Patient_Contact_Details['AUID'],Right(tbl_dbo_stay['mrn'],10)),"0000000000") AS Expr3
    df_queryd["mrn"] = df_queryd["mrn_tbl_dbo_stay"].astype(str).str.strip()
    df_queryd["MRN_dummy"] = df_queryd["mrn"].str[-10:]
    df_queryd["MRN_dummy"] = np.where(
        df_queryd["MRN_dummy"] == "",
        "",
        df_queryd["MRN_dummy"].astype(str).str.pad(10, side="left", fillchar="0"),
    )
    df_queryd["AUID_dummy"] = df_queryd["AUID"].astype(str).str.strip()
    df_queryd["AUID"] = df_queryd["AUID"].astype(str).str.replace("nan", "")
    df_queryd["AUID_dummy"] = df_queryd["AUID_dummy"].astype(str).str.replace("nan", "")
    # df_queryd['dummy_mrn_auid'] = np.where(pd.notna(df_queryd['AUID_dummy']) & df_queryd['AUID_dummy']!='', df_queryd['AUID_dummy'].astype(str).str.pad(10, side ='left', fillchar ='0'), df_queryd['MRN_dummy'])
    # df_queryd['dummy_mrn_auid'] = np.where((df_queryd['AUID_dummy']==''), df_queryd['MRN_dummy'], df_queryd['AUID_dummy'].astype(str).str.pad(10, side ='left', fillchar ='0'))
    # AQA-270 - InpatientStayNumber not populated for X740
    # df_queryd['dummy_mrn_auid'] = np.where((df_queryd['AUID_dummy']=='') | ((df_queryd['AUID_dummy']!='') & ~(df_queryd['area_identifier'].isin(['X830','X860','X840', 'X850', 'X740']))), df_queryd['MRN_dummy'], df_queryd['AUID_dummy'].astype(str).str.pad(10, side ='left', fillchar ='0'))
    # df_queryd['dummy_mrn_auid'] = np.where((df_queryd['AUID_dummy']=='')  | (df_queryd['area_identifier'].isin(['X740']))  | ((df_queryd['AUID_dummy']!='') & ~(df_queryd['area_identifier'].isin(['X830','X860','X840', 'X850']))), df_queryd['MRN_dummy'], df_queryd['AUID_dummy'].astype(str).str.pad(10, side ='left', fillchar ='0'))
    df_queryd["dummy_mrn_auid"] = np.where(
        (df_queryd["AUID_dummy"] == "")
        | (
            (df_queryd["AUID_dummy"] != "")
            & ~(
                df_queryd["area_identifier"].isin(
                    ["X830", "X860", "X840", "X850", "X740", "X170"]
                )
            )
        ),
        df_queryd["MRN_dummy"],
        df_queryd["AUID_dummy"].astype(str).str.pad(10, side="left", fillchar="0"),
    )
    df_queryd["PatientNumber"] = (
        df_queryd["facility_identifier_tbl_dbo_episode_ats"].astype(str).str.strip()
        + "-"
        + df_queryd["dummy_mrn_auid"].astype(str).str.strip()
    )
    df_queryd["PatientNumber"] = df_queryd["PatientNumber"]
    df_queryd["EpisodeOfCare"] = df_queryd[
        "episode_of_care_type_tbl_dbo_episode_ats"
    ]  # tbl_dbo_episode_ats['episode_of_care_type']
    df_queryd["mo_code"] = np.where(
        df_queryd["mo_code"] == "nan", "", df_queryd["mo_code"]
    )
    df_queryd["AttendingConsultant"] = np.where(
        (df_queryd["mo_code"] == "") | (df_queryd["mo_code"].isnull()),
        "",
        df_queryd["facility_identifier_tbl_dbo_episode_ats"].astype(str).str.strip()
        + "-"
        + df_queryd["mo_code"].astype(str).str.strip(),
    )  # tbl_dbo_episode_ats['facility_identifier'] & "-" & Trim(tbl_dbo_days_episode['mo_code']) as Expr2
    df_queryd["AdmissionCategory"] = df_queryd[
        "emergency_status"
    ]  # tbl_dbo_stay['emergency_status']
    df_queryd["AdmissionElection"] = df_queryd[
        "election_status_on_admit"
    ]  # tbl_dbo_stay['election_status_on_admit']
    df_queryd["DischargeElection"] = df_queryd[
        "payment_status_on_sep"
    ]  # tbl_dbo_episode_ats['payment_status_on_sep']
    df_queryd["AdmissionType"] = np.where(
        df_queryd["episode_end_date"] == df_queryd["episode_start_date"], "SD", "ON"
    )  # IIf(tbl_dbo_episode_ats['episode_end_date']=tbl_dbo_episode_ats['episode_start_date'],"SD","ON") as Expr6
    df_queryd["AdmissionSource"] = df_queryd[
        "source_of_referral"
    ]  # tbl_dbo_episode_ats['source_of_referral']
    df_queryd["Hospital"] = df_queryd[
        "facility_identifier_tbl_dbo_episode_ats"
    ]  # tbl_dbo_episode_ats['facility_identifier']
    df_queryd["FinancialClass"] = df_queryd[
        "financial_class"
    ]  # tbl_dbo_episode_ats['financial_class']
    df_queryd["DischargeStatus"] = df_queryd[
        "mode_of_separation"
    ]  # tbl_dbo_episode_ats['mode_of_separation']
    # IIf(tbl_dbo_episode_DRG['an_drg'] Is Null,"960Z",tbl_dbo_episode_DRG['an_drg']) as Expr9
    df_queryd["DRG1"] = np.where(
        ((df_queryd["an_drg"].isnull()) | (df_queryd["an_drg"] == "")),
        "960Z",
        df_queryd["an_drg"],
    )
    df_queryd["DRG1Version"] = np.where(
        (df_queryd["an_drg_version"].isnull()) | (df_queryd["an_drg_version"] == ""),
        drg1_v,
        df_queryd["an_drg_version"],
    )  # IIf(tbl_dbo_episode_DRG['an_drg_version'] Is Null,[Forms['Frm:1-ExtractSetUp['DRG1V'],tbl_dbo_episode_DRG['an_drg_version']) as Expr12
    df_queryd["DRG2"] = np.where(
        ((df_queryd["2_an_drg"].isnull()) | (df_queryd["2_an_drg"] == "")),
        "960Z",
        df_queryd["2_an_drg"],
    )  # IIf([2_an_drg'] Is Null,"960Z",[2_an_drg']) as Expr22
    df_queryd["DRG2Version"] = np.where(
        (df_queryd["2_an_drg_version"].isnull())
        | (df_queryd["2_an_drg_version"] == ""),
        drg2_v,
        df_queryd["2_an_drg_version"],
    )  # IIf(tbl_dbo_episode_DRG['2_an_drg_version'] Is Null,[Forms['Frm:1-ExtractSetUp['DRG2V'],tbl_dbo_episode_DRG['2_an_drg_version']) as Expr21
    df_queryd["LengthOfStay"] = df_queryd[
        "episode_length_of_stay_tbl_dbo_episode_ats"
    ]  # tbl_dbo_episode_ats['episode_length_of_stay']
    df_queryd["ICUHours"] = df_queryd[
        "hours_in_icu"
    ]  # tbl_dbo_episode_ats['hours_in_icu']
    df_queryd["MechVentHours"] = df_queryd[
        "hours_on_mech_vent_num"
    ]  # tbl_dbo_episode['hours_on_mech_vent_num']
    df_queryd["StartDateTime"] = pd.to_datetime(
        (
            df_queryd["episode_start_date"].astype(str).str[:10]
            + " "
            + df_queryd["episode_start_time"].astype(str).str[-8:]
        ),
        errors="coerce",
        format="%Y-%m-%d %H:%M:%S",
    )  # Format(tbl_dbo_episode_ats['episode_start_date'] & " " & tbl_dbo_episode_ats['episode_start_time'],"yyyy-mm-dd hh:nn:ss") as Expr10
    df_queryd["EndDateTime"] = pd.to_datetime(
        (
            df_queryd["episode_end_date"].astype(str).str[:10]
            + " "
            + df_queryd["episode_end_time"].astype(str).str[-8:]
        ),
        errors="coerce",
        format="%Y-%m-%d %H:%M:%S",
    )  # Format(tbl_dbo_episode_ats['episode_end_date'] & " " & tbl_dbo_episode_ats['episode_end_time'],"yyyy-mm-dd hh:nn:ss") as Expr7
    df_queryd["Age"] = df_queryd["age"]  # tbl_dbo_stay['age']
    df_queryd["HealthFund"] = df_queryd[
        "insurance_fund_master"
    ]  # tbl_dbo_stay['insurance_fund_master']
    df_queryd["AdmissionWeight"] = np.where(
        (
            df_queryd["infant_start_weight"].isnull()
            | (df_queryd["infant_start_weight"] == "")
        ),
        0,
        df_queryd["infant_start_weight"],
    )  # IIf(tbl_dbo_episode_ats['infant_start_weight']="",0,tbl_dbo_episode_ats['infant_start_weight']) as Expr4
    df_queryd["WeightedSeparation"] = df_queryd[
        "cost_weight_e_current"
    ]  # tbl_dbo_episode_srg['cost_weight_e_current']
    df_queryd["Extra:LGACode"] = df_queryd[
        "area_of_usual_residence"
    ]  # tbl_dbo_stay['area_of_usual_residence']
    df_queryd["Extra:HospitalStayNumber"] = (
        "SN" + df_queryd["stay_number"].astype(str).str.strip()
    )  # "SN" & Trim(tbl_dbo_episode_ats['stay_number']) as Expr11
    df_queryd["Extra:LHDIdentifier"] = df_queryd[
        "area_identifier"
    ]  # tbl_dbo_episode_ats['area_identifier']
    df_queryd["Extra:LegalStatus"] = df_queryd[
        "legal_status_on_admit"
    ]  # tbl_dbo_episode_ats['legal_status_on_admit']
    df_queryd["Extra:DVANumber"] = df_queryd[
        "dva_card_number"
    ]  # tbl_dbo_stay['dva_card_number']
    df_queryd["Extra:DVAType"] = df_queryd[
        "dva_card_type"
    ]  # tbl_dbo_stay['dva_card_type']
    df_queryd["Extra:IntendedSameDay"] = df_queryd[
        "stay_discharge_intention"
    ]  # tbl_dbo_stay['stay_discharge_intention']
    df_queryd["Extra:ReferralFurtherHealthcare"] = df_queryd[
        "referred_to_on_separation"
    ]  # tbl_dbo_stay['referred_to_on_separation']
    df_queryd["Extra:UnplannedReadmission"] = df_queryd[
        "readmit_this_hosp_28_days"
    ]  # tbl_dbo_stay['readmit_this_hosp_28_days']
    df_queryd["Extra:EpisodeSequenceNumber"] = df_queryd[
        "episode_sequence_number"
    ]  # tbl_dbo_episode_ats['episode_sequence_number']
    df_queryd["Extra:MedicareNumber"] = df_queryd[
        "medicare_number"
    ]  # tbl_dbo_stay['medicare_number']
    df_queryd["hours_in_psych_unit"] = df_queryd["hours_in_psych_unit"].astype(
        int, errors="ignore"
    )
    df_queryd["days_in_psych_unit"] = df_queryd["days_in_psych_unit"].astype(
        int, errors="ignore"
    )
    df_queryd["Extra:DaysinPsychUnit"] = np.where(
        (df_queryd["hours_in_psych_unit"] > 0) & (df_queryd["days_in_psych_unit"] == 0),
        1,
        df_queryd["days_in_psych_unit"],
    )  # IIf(tbl_dbo_episode_ats['hours_in_psych_unit']>0 And tbl_dbo_episode_ats['days_in_psych_unit']=0,1,tbl_dbo_episode_ats['days_in_psych_unit']) as Expr17
    df_queryd["Extra:UnplannedTheatre"] = df_queryd[
        "unplanned_theatre"
    ]  # tbl_dbo_episode_ats['unplanned_theatre']
    df_queryd["Extra:EDStatus"] = df_queryd[
        "ed_status"
    ]  # tbl_dbo_episode_srg['ed_status']
    df_queryd["Extra:ICUStatus"] = df_queryd[
        "icu_status"
    ]  # tbl_dbo_episode_srg['icu_status']
    df_queryd["Extra:SRGcurrent"] = df_queryd[
        "srg_current"
    ]  # tbl_dbo_episode_srg['srg_current']
    df_queryd["Extra:ESRGcurrent"] = df_queryd[
        "esrg_current"
    ]  # tbl_dbo_episode_srg['esrg_current']
    df_queryd["Extra:CW_A"] = df_queryd[
        "cost_weight_a_current"
    ]  # tbl_dbo_episode_srg['cost_weight_a_current']
    df_queryd["Extra:CW_B"] = df_queryd[
        "cost_weight_b_current"
    ]  # tbl_dbo_episode_srg['cost_weight_b_current']
    df_queryd["Extra:CW_C"] = df_queryd[
        "cost_weight_c_current"
    ]  # tbl_dbo_episode_srg['cost_weight_c_current']
    df_queryd["Extra:CW_D"] = df_queryd[
        "cost_weight_d_current"
    ]  # tbl_dbo_episode_srg['cost_weight_d_current']
    df_queryd["Extra:CW_E"] = df_queryd[
        "cost_weight_e_current"
    ]  # tbl_dbo_episode_srg['cost_weight_e_current']
    df_queryd["Extra:CW_F"] = df_queryd[
        "cost_weight_f_current"
    ]  # tbl_dbo_episode_srg['cost_weight_f_current']
    df_queryd["Extra:TrimPoint"] = df_queryd[
        "trim_point"
    ]  # tbl_dbo_episode_srg['trim_point']
    # ValueError: cannot convert float NaN to integer
    df_queryd["outlier_days_1"] = (
        df_queryd["outlier_days_1"].fillna(0).astype(int, errors="ignore")
    )
    df_queryd["outlier_days_2"] = (
        df_queryd["outlier_days_2"].fillna(0).astype(int, errors="ignore")
    )
    # df_queryd['Extra:Outlierdays'] = df_queryd['outlier_days_1'].replace('','0').apply(lambda x: int(float(x)))+ df_queryd['outlier_days_2'].replace('','0').apply(lambda x: int(float(x)))#.astype('Int64', errors='ignore')
    df_queryd["Extra:Outlierdays"] = (
        df_queryd["outlier_days_1"] + df_queryd["outlier_days_2"]
    )  # ['outlier_days_1']+['outlier_days_2'] as Expr8
    df_queryd["Extra:SurgeryIndicator"] = df_queryd[
        "surgery_indicator"
    ]  # tbl_dbo_episode_srg['surgery_indicator']
    df_queryd["Extra:AreaDOHRSCode"] = ""
    df_queryd["Extra:FinancialProgram"] = df_queryd[
        "financial_program"
    ]  # tbl_dbo_episode_ats['financial_program']
    df_queryd["Extra:FacilityTransferredto"] = df_queryd[
        "facility_trans_to"
    ]  # tbl_dbo_stay['facility_trans_to']
    df_queryd["Extra:FacilityTransferredfrom"] = df_queryd[
        "facility_trans_from"
    ]  # tbl_dbo_stay['facility_trans_from']
    df_queryd["Extra:MRN"] = (
        df_queryd["mrn_tbl_dbo_episode_ats"].astype(str).str.strip()
    )  # tbl_dbo_episode_ats['mrn']
    df_queryd["Extra:MDC"] = df_queryd["mdc"]  # tbl_dbo_episode_ats['mdc']
    # Is this required??? not present in access, but Inform8 output has it.
    df_queryd["Extra:MDC2"] = df_queryd["2_mdc"]
    df_queryd["Extra:indicatorProcedurecode"] = df_queryd[
        "indicated_proc_code"
    ]  # tbl_dbo_wl_exit1['indicated_proc_code']
    df_queryd["Extra:bookingIdentifier"] = df_queryd[
        "booking_identifier"
    ]  # tbl_dbo_wl_exit1['booking_identifier']
    df_queryd["Extra:waitinglistcategory"] = df_queryd[
        "waiting_list_category"
    ]  # tbl_dbo_wl_exit1['waiting_list_category']
    df_queryd["Extra:ClinicalURGfinal"] = df_queryd[
        "clinical_urg_final_crnt"
    ]  # tbl_dbo_wl_exit1['clinical_urg_final_crnt']
    df_queryd["Extra:ReasonforRemoval"] = df_queryd[
        "reason_for_removal"
    ]  # tbl_dbo_wl_exit1['reason_for_removal']
    df_queryd["Extra:DRG1_pccl"] = df_queryd[
        "an_drg_pccl"
    ]  # tbl_dbo_episode_DRG['an_drg_pccl']
    df_queryd["Extra:EpisodeLeaveDays"] = df_queryd[
        "episode_leave_days_total_tbl_dbo_episode_ats"
    ]  # tbl_dbo_episode_ats['episode_leav_days_total']
    df_queryd["Extra:QualifiedBedDays"] = df_queryd[
        "qualified_bed_days"
    ]  # tbl_dbo_episode_ats['qualified_bed_days']
    df_queryd["Extra:IndigenousStatus"] = df_queryd[
        "indigenous_status"
    ]  # tbl_dbo_stay['indigenous_status']
    df_queryd["Extra:MothersMRN"] = df_queryd[
        "mothers_mrn"
    ]  # tbl_dbo_stay['mothers_mrn']
    df_queryd["Extra:MothersStayNumber"] = np.where(
        (
            (df_queryd["mothers_stay_number"].isnull())
            | (df_queryd["mothers_stay_number"].astype(str).str.strip() == "")
            | (df_queryd["mothers_stay_number"].astype(str).str.strip() == "nan")
            | (df_queryd["mothers_stay_number"] == "00000nan")
        ),
        "",
        "SN" + df_queryd["mothers_stay_number"].astype(str).str.strip(),
    )  # IIf([mothers_stay_number']="","",IIf([mothers_stay_number'] Is Null,"","SN" & Trim([mothers_stay_number']))) as Expr20
    df_queryd["Extra:MothersPersonIdentifier"] = df_queryd[
        "mothers_person_identifier"
    ]  # tbl_dbo_stay['mothers_person_identifier']
    # IIf(tbl_dbo_episode_ats['payment_status_on_sep'] In ("20","23","24","45"),"Public",IIf(tbl_dbo_episode_ats['payment_status_on_sep'] In ("30","31","32","33","34","35","36","46"),"Private",IIf(tbl_dbo_episode_ats['payment_status_on_sep'] In ("40","41","42","43","50","51","52","60"),"Compensable"))) as Expr5
    # condlist = [df_queryd['payment_status_on_sep'].isin(["20","23","24","45"]), df_queryd['payment_status_on_sep'].isin(["30","31","32","33","34","35","36","46"]), df_queryd['payment_status_on_sep'].isin(["40","41","42","43","50","51","52","60"])]
    condlist = [
        df_queryd["payment_status_on_sep"].isin([20, 23, 24, 45]),
        df_queryd["payment_status_on_sep"].isin([30, 31, 32, 33, 34, 35, 36, 46]),
        df_queryd["payment_status_on_sep"].isin([40, 41, 42, 43, 50, 51, 52, 60]),
    ]
    choicelist = ["Public", "Private", "Compensable"]
    # payment status on sep is wrong variable.
    df_queryd["Extra:ElectionStatusSummary"] = np.select(
        condlist, choicelist, "NULL"
    )  # make public (even -1) . chck with Derek.
    df_queryd["Extra:FacilityType"] = df_queryd[
        "facility_type"
    ]  # tbl_dbo_episode_ats['facility_type']
    df_queryd["Extra:MedicareEligibility"] = df_queryd[
        "medicare_eligibility_status"
    ]  # tbl_dbo_stay['medicare_eligibility_status']
    df_queryd["Extra:LeaveinCostingPeriod"] = df_queryd[
        "LeaveDays"
    ]  # tbl_PPM_transfer_Leave 02['LeaveDays'] as Expr13
    """df_queryd['Extra:VersionID'] = versionID_dot # Replace([Forms['Frm:1-ExtractSetUp['fm_round'],"V","") as versionid
    df_queryd['Extra:VersionID'] = df_queryd['Extra:VersionID'].astype(str).str.replace('V' ,'')"""
    df_queryd["Extra:ExtractorVersion"] = "1.17"
    # commenting below access logic to be replaced by inform8 logic
    """
    df_queryd['Extra:AICU1_Hours'] = np.where(df_queryd['AICU1'].astype(float)==0.0,1, df_queryd['AICU1']) # IIf(['AICU1']=0,1,['AICU1']) as Expr23
    df_queryd['Extra:AICU3_Hours'] = np.where(df_queryd['AICU3'].astype(float)==0.0,1, df_queryd['AICU3']) # IIf(['AICU3']=0,1,['AICU3']) as Expr24
    df_queryd['Extra:PICU_Hours'] = np.where(df_queryd['PICU'].astype(float)==0.0,1, df_queryd['PICU']) # IIf(['PICU']=0,1,['PICU']) as Expr24
    df_queryd['Extra:NICU_Hours'] = np.where(df_queryd['NICU'].astype(float)==0.0,1, df_queryd['NICU']) # IIf(['NICU']=0,1,['NICU']) as Expr26
    df_queryd['Extra:PSICU_Hours'] = np.where(df_queryd['PSICU'].astype(float)==0.0,1, df_queryd['PSICU']) # IIf(['PSICU']=0,1,['PSICU']) as Expr27
    df_queryd['Extra:CCU_Hours'] = np.where(df_queryd['CCU'].astype(float)==0.0,1, df_queryd['CCU']) # IIf(['CCU']=0,1,['CCU']) as Expr28
    df_queryd['Extra:AICU2_Hours'] = np.where(df_queryd['AICU2'].astype(float)==0.0,1, df_queryd['AICU2']) # IIf(['AICU2']=0,1,['AICU2']) as Expr29
    df_queryd['Extra:HITH_Hours'] = np.where(df_queryd['HITH'].astype(float)==0.0,1, df_queryd['HITH']) # IIf(['HITH']=0,1,['HITH']) as Expr30
    df_queryd['Extra:HDU_Hours'] = np.where(df_queryd['HDU'].astype(float)==0.0,1, df_queryd['HDU']) # IIf(['HDU']=0,1,['HDU']) as Expr31
    df_queryd['Extra:SCN_Hours'] = np.where(df_queryd['SCN'].astype(float)==0.0,1, df_queryd['SCN']) # IIf(['SCN']=0,1,['SCN']) as Expr32
    """
    df_queryd["AICU1"] = df_queryd["AICU1"].fillna(0)  # .astype(int, errors='ignore')
    df_queryd["AICU3"] = df_queryd["AICU3"].fillna(0)  # .astype(int, errors='ignore')
    df_queryd["AICU2"] = df_queryd["AICU2"].fillna(0)  # .astype(int, errors='ignore')
    df_queryd["PICU"] = df_queryd["PICU"].fillna(0)  # .astype(int, errors='ignore')
    df_queryd["NICU"] = df_queryd["NICU"].fillna(0)  # .astype(int, errors='ignore')
    df_queryd["PSICU"] = df_queryd["PSICU"].fillna(0)  # .astype(int, errors='ignore')
    df_queryd["CCU"] = df_queryd["CCU"].fillna(0)  # .astype(int, errors='ignore')
    df_queryd["HITH"] = df_queryd["HITH"].fillna(0)  # .astype(int, errors='ignore')
    df_queryd["HDU"] = df_queryd["HDU"].fillna(0)  # .astype(int, errors='ignore')
    df_queryd["SCN"] = df_queryd["SCN"].fillna(0)  # .astype(int, errors='ignore')
    df_queryd["AICU1"] = df_queryd["AICU1"].astype(float)
    df_queryd["AICU3"] = df_queryd["AICU3"].astype(float)
    df_queryd["AICU2"] = df_queryd["AICU2"].astype(float)
    df_queryd["PICU"] = df_queryd["PICU"].astype(float)
    df_queryd["NICU"] = df_queryd["NICU"].astype(float)
    df_queryd["PSICU"] = df_queryd["PSICU"].astype(float)
    df_queryd["CCU"] = df_queryd["CCU"].astype(float)
    df_queryd["HITH"] = df_queryd["HITH"].astype(float)
    df_queryd["HDU"] = df_queryd["HDU"].astype(float)
    df_queryd["SCN"] = df_queryd["SCN"].astype(float)
    # df_queryd['Extra:HITH_Hours'] = np.where(df_queryd['HITH'].astype(float) > 0.0,np.round(df_queryd['HITH'].astype(float)),0)
    # df_queryd['Extra:AICU1_Hours'] = np.where(df_queryd['AICU1'].astype(float)>0.0, df_queryd['AICU1'].apply(np.ceil), 0) # IIf(['AICU1']=0,1,['AICU1']) as Expr23
    # df_queryd['Extra:AICU1_Hours'] = np.where(df_queryd['AICU1'].astype(float)>0.0, df_queryd['AICU1'].apply(lambda x: np.ceil(x) if x % 1 >= 0.5 else x),0)
    df_queryd["Extra:AICU1_Hours"] = np.where(
        df_queryd["AICU1"].astype(float) > 0.0,
        df_queryd["AICU1"].apply(lambda x: np.ceil(x) if x % 1 >= 0.5 else np.floor(x)),
        0,
    )

    # df_queryd['Extra:AICU3_Hours'] = np.where(df_queryd['AICU3'].astype(float)>0.0, df_queryd['AICU3'].apply(np.ceil), 0) # IIf(['AICU3']=0,1,['AICU3']) as Expr24
    df_queryd["Extra:AICU3_Hours"] = np.where(
        df_queryd["AICU3"].astype(float) > 0.0,
        df_queryd["AICU3"].apply(lambda x: np.ceil(x) if x % 1 >= 0.5 else np.floor(x)),
        0,
    )

    # df_queryd['Extra:PICU_Hours'] = np.where(df_queryd['PICU'].astype(float)>0.0, df_queryd['PICU'].apply(np.ceil), 0) # IIf(['PICU']=0,1,['PICU']) as Expr24
    df_queryd["Extra:PICU_Hours"] = np.where(
        df_queryd["PICU"].astype(float) > 0.0,
        df_queryd["PICU"].apply(lambda x: np.ceil(x) if x % 1 >= 0.5 else np.floor(x)),
        0,
    )

    # df_queryd['Extra:NICU_Hours'] = np.where(df_queryd['NICU'].astype(float)>0.0, df_queryd['NICU'].apply(np.ceil), 0) # IIf(['NICU']=0,1,['NICU']) as Expr26
    df_queryd["Extra:NICU_Hours"] = np.where(
        df_queryd["NICU"].astype(float) > 0.0,
        df_queryd["NICU"].apply(lambda x: np.ceil(x) if x % 1 >= 0.5 else np.floor(x)),
        0,
    )

    # df_queryd['Extra:PSICU_Hours'] = np.where(df_queryd['PSICU'].astype(float)>0.0, df_queryd['PSICU'].apply(np.ceil), 0) # IIf(['PSICU']=0,1,['PSICU']) as Expr27
    df_queryd["Extra:PSICU_Hours"] = np.where(
        df_queryd["PSICU"].astype(float) > 0.0,
        df_queryd["PSICU"].apply(lambda x: np.ceil(x) if x % 1 >= 0.5 else np.floor(x)),
        0,
    )

    # df_queryd['Extra:CCU_Hours'] = np.where(df_queryd['CCU'].astype(float)>0.0, df_queryd['CCU'].apply(np.ceil), 0) # IIf(['CCU']=0,1,['CCU']) as Expr28
    df_queryd["Extra:CCU_Hours"] = np.where(
        df_queryd["CCU"].astype(float) > 0.0,
        df_queryd["CCU"].apply(lambda x: np.ceil(x) if x % 1 >= 0.5 else np.floor(x)),
        0,
    )

    # df_queryd['Extra:AICU2_Hours'] = np.where(df_queryd['AICU2'].astype(float)>0.0, df_queryd['AICU2'].apply(np.ceil), 0) # IIf(['AICU2']=0,1,['AICU2']) as Expr29
    df_queryd["Extra:AICU2_Hours"] = np.where(
        df_queryd["AICU2"].astype(float) > 0.0,
        df_queryd["AICU2"].apply(lambda x: np.ceil(x) if x % 1 >= 0.5 else np.floor(x)),
        0,
    )

    # df_queryd['Extra:HITH_Hours'] = np.where(df_queryd['HITH'].astype(float)>0.0, df_queryd['HITH'].apply(np.ceil), 0) # IIf(['HITH']=0,1,['HITH']) as Expr30
    df_queryd["Extra:HITH_Hours"] = np.where(
        df_queryd["HITH"].astype(float) > 0.0,
        df_queryd["HITH"].apply(lambda x: np.ceil(x) if x % 1 >= 0.5 else np.floor(x)),
        0,
    )

    # df_queryd['Extra:HDU_Hours'] = np.where(df_queryd['HDU'].astype(float)>0.0, df_queryd['HDU'].apply(np.ceil), 0) # IIf(['HDU']=0,1,['HDU']) as Expr31
    df_queryd["Extra:HDU_Hours"] = np.where(
        df_queryd["HDU"].astype(float) > 0.0,
        df_queryd["HDU"].apply(lambda x: np.ceil(x) if x % 1 >= 0.5 else np.floor(x)),
        0,
    )

    # df_queryd['Extra:SCN_Hours'] = np.where(df_queryd['SCN'].astype(float)>0.0, df_queryd['SCN'].apply(np.ceil), 0) # IIf(['SCN']=0,1,['SCN']) as Expr32
    df_queryd["Extra:SCN_Hours"] = np.where(
        df_queryd["SCN"].astype(float) > 0.0,
        df_queryd["SCN"].apply(lambda x: np.ceil(x) if x % 1 >= 0.5 else np.floor(x)),
        0,
    )
    ######################
    df_queryd["facility_identifier_tbl_dbo_days_episode"] = np.where(
        df_queryd["facility_identifier_tbl_dbo_days_episode"] == "nan",
        "",
        df_queryd["facility_identifier_tbl_dbo_days_episode"],
    )
    df_queryd["specialty_unit_code"] = np.where(
        df_queryd["specialty_unit_code"] == "nan", "", df_queryd["specialty_unit_code"]
    )
    df_queryd["AttendingConsultantSpecialty"] = np.where(
        (df_queryd["specialty_unit_code"] == "")
        | (df_queryd["specialty_unit_code"].isnull()),
        "",
        df_queryd["facility_identifier_tbl_dbo_days_episode"].astype(str).str.strip()
        + "-"
        + df_queryd["specialty_unit_code"].astype(str).str.strip(),
    )  # (Trim(tbl_dbo_DAYS_EPISODE['facility_identifier'] & "-" & tbl_dbo_DAYS_EPISODE['specialty_unit_code'])) as Expr18
    df_queryd["Extra:nwau"] = df_queryd["nwau_final"]  # Acute_nwau['NWAU_final']
    df_queryd["Extra:nwau_PublicEquivModel"] = df_queryd[
        "public_equiv_nwau"
    ]  # Acute_nwau['public_equiv_nwau']
    df_queryd["Extra:nwau_base"] = df_queryd["nwau_base"]  # Acute_nwau['nwau_base']
    df_queryd["Extra:nwau_paed_incr"] = df_queryd[
        "paediatric_adj"
    ]  # Acute_nwau['paediatric_adj']
    df_queryd["Extra:nwau_indig_incr"] = df_queryd[
        "indigenous_adj"
    ]  # Acute_nwau['indigenous_adj']
    df_queryd["Extra:nwau_remote_incr"] = df_queryd[
        "remoteness_area_adj"
    ]  # Acute_nwau['remoteness_area_adj']
    df_queryd["Extra:nwau_icu_incr"] = df_queryd["icu_adj"]  # Acute_nwau['icu_adj']
    df_queryd["Extra:nwau_private_patient_service_incr"] = df_queryd[
        "private_service_adj"
    ]  # Acute_nwau['private_service_adj']
    df_queryd["Extra:nwau_private_patient_accom_incr"] = df_queryd[
        "private_accom_adj"
    ]  # Acute_nwau['private_accom_adj']
    df_queryd["Extra:AUID"] = np.where(
        pd.notna(df_queryd["AUID"]) & (df_queryd["AUID"] != ""), df_queryd["AUID"], ""
    )  # IIf(tbl_Patient_Contact_Details['AUID'] Is Not Null,tbl_Patient_Contact_Details['AUID']) as Expr16
    df_queryd["Extra:SRG_Version"] = df_queryd[
        "srg_version_number"
    ]  # tbl_dbo_episode_srg['srg_version_number']
    df_queryd["Extra:Collabrtve_Care_Facility"] = df_queryd[
        "collabrtve_care_facility"
    ]  # tbl_dbo_stay['collabrtve_care_facility']
    df_queryd["Extra:Contract_Status"] = df_queryd[
        "contract_status"
    ]  # tbl_dbo_stay['contract_status']
    df_queryd["Extra:Collabrtve_Care_Role"] = df_queryd[
        "collabrtve_care_role"
    ]  # tbl_dbo_stay['collabrtve_care_role']
    df_queryd["Extra:Collabrtve_Care_Type"] = df_queryd[
        "collabrtve_care_type"
    ]  # tbl_dbo_stay['collabrtve_care_type']
    df_queryd["Extra:Radiotherapy_adj"] = df_queryd[
        "radiotherapy_adj"
    ]  # Acute_nwau['radiotherapy_adj']
    df_queryd["Extra:nwau_version"] = df_queryd[
        "nwau_version"
    ]  # Acute_nwau['nwau_version']
    df_queryd["Extra:LHD_of_Usual_Residence"] = df_queryd[
        "LHD_of_Usual_residence"
    ]  # tbl_dbo_stay['LHD_of_Usual_residence']
    df_queryd["Extra:sp_psy_age_adj"] = df_queryd[
        "sp_psy_age_adj"
    ]  # Acute_nwau['sp_psy_age_adj']
    df_queryd["Extra:compensable_nwau"] = df_queryd[
        "compensable_nwau"
    ]  # Acute_nwau['compensable_nwau']
    df_queryd["Extra:SpecialtyPortal"] = df_queryd[
        "SpecialityPortal"
    ]  # qry_SpecialtyPortal['SpecialityPortal']
    df_queryd["Extra:ExtractDate"] = (
        pd.Timestamp.today()
    )  # pd.to_datetime(date.today(), errors='coerce', format="%Y-%m-%d") # Format([getdate],"yyyy-mm-dd hh:nn:ss") as Expr33
    df_queryd["Extra:ExtractDate"] = pd.to_datetime(
        df_queryd["Extra:ExtractDate"].astype(str).str[:19],
        errors="coerce",
        format="%Y-%m-%d %H:%M:%S",
    )
    df_queryd["Extra:WIP"] = df_queryd["WIP"]  # tbl_dbo_episode_ats['WIP']
    # In inform8,   ipObj.Extra:StartDateTime_EpisodeTable = ret.day.start_date.ToString("yyyy-MM-dd") + " " + ret.day.start_time;
    #               ipObj.Extra:EndDateTime_EpisodeTable = ret.epi.enddate.ToString("yyyy-MM-dd") + " " + ret.epi.endtime;
    #               ipObj.Extra:EndDateTime_EpisodeATSTable = ret.ats.episode_end_date.ToString("yyyy-MM-dd") + " " + ret.ats.episode_end_time;
    df_queryd["Extra:StartDateTime_EpisodeTable"] = pd.to_datetime(
        (
            df_queryd["start_date"].astype(str).str[:10]
            + " "
            + df_queryd["start_time"].astype(str).str[-8:]
        ),
        errors="coerce",
        format="%Y-%m-%d %H:%M:%S",
    )  # Format(tbl_dbo_episode['startdate'] & " " & tbl_dbo_episode['starttime'],"yyyy-mm-dd hh:nn:ss") as Expr35
    df_queryd["Extra:EndDateTime_EpisodeTable"] = pd.to_datetime(
        (
            df_queryd["enddate"].astype(str).str[:10]
            + " "
            + df_queryd["endtime"].astype(str).str[-8:]
        ),
        errors="coerce",
        format="%Y-%m-%d %H:%M:%S",
    )  # Format(tbl_dbo_episode['enddate'] & " " & tbl_dbo_episode['endtime'],"yyyy-mm-dd hh:nn:ss") as Expr34
    df_queryd["Extra:LengthofStay_EpisodeTable"] = df_queryd[
        "episode_length_of_stay_tbl_dbo_episode"
    ]  # tbl_dbo_episode['episode_length_of_stay']
    df_queryd["Extra:LengthofStay_EpisodeATSTable"] = df_queryd[
        "episode_length_of_stay_tbl_dbo_episode_ats"
    ]  # tbl_dbo_episode_ats['episode_length_of_stay']
    df_queryd["Extra:EpisodeLeaveDays_EpisodeTable"] = df_queryd[
        "episode_leave_days_total_tbl_dbo_episode"
    ]  # tbl_dbo_episode['episode_leave_days_total']
    df_queryd["Extra:EpisodeLeaveDays_EpisodeATSTable"] = df_queryd[
        "episode_leave_days_total_tbl_dbo_episode_ats"
    ]  # tbl_dbo_episode_ats['episode_leave_days_total']
    # for below, in inform8 it is 'Extra:EpisodeofCare_EpisodeTable' = tbl_dbo_episode_ats['episode_of_care_type']
    # df_queryd['Extra:EpisodeofCare_EpisodeTable'] = df_queryd['episode_of_care_type_tbl_dbo_episode'] # tbl_dbo_episode['episode_of_care_type']
    df_queryd["Extra:EpisodeofCare_EpisodeTable"] = df_queryd[
        "episode_of_care_type_tbl_dbo_episode_ats"
    ]
    df_queryd["Extra:EpisodeofCare_EpisodeATSTable"] = df_queryd[
        "episode_of_care_type_tbl_dbo_episode_ats"
    ]  # tbl_dbo_episode_ats['episode_of_care_type']
    df_queryd["mothers_stay_number"] = (
        df_queryd["mothers_stay_number"].astype(str).str.strip()
    )
    df_queryd["mothers_stay_number"] = (
        df_queryd["mothers_stay_number"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0")
    )
    df_queryd["Extra:MothersEncounterNumber"] = np.where(
        (
            (df_queryd["mothers_stay_number"].isnull())
            | (df_queryd["mothers_stay_number"] == "00000000")
            | (df_queryd["mothers_stay_number"].astype(str).str.strip() == "")
            | (df_queryd["mothers_stay_number"] == "00000nan")
            | (df_queryd["mothers_stay_number"] == "nan")
        ),
        "",
        df_queryd["facility_identifier_tbl_dbo_episode_ats"].astype(str).str.strip()
        + "-I-"
        + df_queryd["mothers_stay_number"].astype(str).str.strip()
        + "-001",
    )  # IIf(['mothers_stay_number']="","",IIf(['mothers_stay_number'] Is Null,"",tbl_dbo_episode_ats['facility_identifier'] & "-I-" & Format(Trim(['mothers_stay_number']),"00000000") & "-001")) as Expr19
    # df_queryd['Extra:EndDateTime_EpisodeATSTable'] = np.where(pd.notna(df_queryd['facility_identifier_tbl_Episode_ATS_end_date_update']) ,'', pd.to_datetime((df_queryd['episode_end_date'].astype(str).str[:10] +' '+ df_queryd['episode_end_time'].astype(str).str[-8:]), errors='coerce', format="%Y-%m-%d %H:%M:%S"))# IIf(tbl_Episode_ATS_end_date_update['facility_identifier'] Is Not Null,Null,Format(tbl_dbo_episode_ats['episode_end_date'] & " " & tbl_dbo_episode_ats['episode_end_time'],"yyyy-mm-dd hh:nn:ss")) as Expr36
    df_queryd["Extra:EndDateTime_EpisodeATSTable"] = np.where(
        pd.notna(df_queryd["facility_identifier_tbl_Episode_ATS_end_date_update"])
        & (df_queryd["facility_identifier_tbl_Episode_ATS_end_date_update"] != ""),
        "",
        (
            df_queryd["episode_end_date"].astype(str).str[:10]
            + " "
            + df_queryd["episode_end_time"].astype(str).str[-8:]
        ),
    )  # IIf(tbl_Episode_ATS_end_date_update['facility_identifier'] Is Not Null,Null,Format(tbl_dbo_episode_ats['episode_end_date'] & " " & tbl_dbo_episode_ats['episode_end_time'],"yyyy-mm-dd hh:nn:ss")) as Expr36
    ########################### Extra:LOSinCostingPeriod - Start################################
    # Extra:LOSinCostingPeriod logic:
    """if episode_start_date < date(start_date_dt): then dummy_start = date(start_date_dt)
    if episode_start_date >= start_date_dt and episode_start_date >  date(end_date_dt): then dummy_start = date(start_date_dt)
    if episode_start_date >= start_date_dt and episode_start_date <= end_date_dt: then dummy_start = episode_start_date
    if episode_end_date is null: then dummy_end = end_date_dt
    if episode_end_date is not null, and episode_end_date > date(end_date_dt): then dummy_end = date(end_date_dt)
    if episode_end_date is not null, and episode_end_date <= date(end_date_dt): then dummy_end = episode_end_date"""
    # (IIf(tbl_dbo_episode_ats['episode_start_date'] = tbl_dbo_episode_ats['episode_end_date'], 1, (DateDiff("d", IIf(tbl_dbo_episode_ats['episode_start_date'] < DateValue([Forms['Frm:1-ExtractSetUp['Start_Date']), DateValue([Forms['Frm:1-ExtractSetUp['Start_Date']), IIf(tbl_dbo_episode_ats['episode_start_date'] > DateValue([Forms['Frm:1-ExtractSetUp['end_Date']), DateValue([Forms['Frm:1-ExtractSetUp['Start_Date']), tbl_dbo_episode_ats['episode_start_date'])), IIf(tbl_dbo_episode_ats['episode_end_date'] Is Null, [Forms['Frm:1-ExtractSetUp['End_Date'], IIf(tbl_dbo_episode_ats['episode_end_date'] > DateValue([Forms['Frm:1-ExtractSetUp['End_Date']), DateValue([Forms['Frm:1-ExtractSetUp['End_Date']),tbl_dbo_episode_ats['episode_end_date'])))) - Nz(tbl_PPM_transfer_Leave 02['LeaveDays']))) as Expr14
    df_queryd["start_date_dt"] = (
        start_date  # pd.to_datetime(start_date, format="%Y-%m-%d %H:%M:%S")
    )
    df_queryd["end_date_dt"] = (
        end_date  # pd.to_datetime(end_date, format="%Y-%m-%d %H:%M:%S")
    )
    df_queryd["start_date_dt"] = pd.to_datetime(
        df_queryd["start_date_dt"].astype(str).str[:10], format="%Y-%m-%d"
    )
    df_queryd["end_date_dt"] = pd.to_datetime(
        df_queryd["end_date_dt"].astype(str).str[:10], format="%Y-%m-%d"
    )
    condlist = [
        pd.to_datetime(
            df_queryd["episode_start_date"].astype(str).str[:10],
            errors="coerce",
            format="%Y-%m-%d",
        )
        < df_queryd["start_date_dt"],
        (
            (
                pd.to_datetime(
                    df_queryd["episode_start_date"].astype(str).str[:10],
                    errors="coerce",
                    format="%Y-%m-%d",
                )
                >= df_queryd["start_date_dt"]
            )
            & (
                pd.to_datetime(
                    df_queryd["episode_start_date"].astype(str).str[:10],
                    errors="coerce",
                    format="%Y-%m-%d",
                )
                > df_queryd["end_date_dt"]
            )
        ),
    ]
    choicelist = [df_queryd["start_date_dt"], df_queryd["start_date_dt"]]
    df_queryd["start_date_df_queryd"] = np.select(
        condlist,
        choicelist,
        pd.to_datetime(
            df_queryd["episode_start_date"].astype(str).str[:10],
            errors="coerce",
            format="%Y-%m-%d",
        ),
    )
    condlist = [
        (df_queryd["episode_start_date"].isnull())
        | (df_queryd["episode_start_date"].astype(str).str[:10] == ""),
        (
            (pd.notna(df_queryd["episode_start_date"]))
            & (df_queryd["episode_start_date"].astype(str).str[:10] != "")
        )
        & (
            pd.to_datetime(
                df_queryd["episode_end_date"].astype(str).str[:10],
                errors="coerce",
                format="%Y-%m-%d",
            )
            > df_queryd["end_date_dt"]
        ),
    ]
    choicelist = [df_queryd["end_date_dt"], df_queryd["end_date_dt"]]
    df_queryd["end_date_df_queryd"] = np.select(
        condlist,
        choicelist,
        pd.to_datetime(
            df_queryd["episode_end_date"].astype(str).str[:10],
            errors="coerce",
            format="%Y-%m-%d",
        ),
    )
    df_queryd["LeaveDays"] = df_queryd["LeaveDays"].fillna(0)
    df_queryd["LeaveDays_dummy"] = np.where(
        (df_queryd["LeaveDays"] == "")
        | (df_queryd["LeaveDays"].isnull() | (df_queryd["LeaveDays"] == 0)),
        0,
        df_queryd["LeaveDays"].astype(int, errors="ignore"),
    )
    df_queryd["start_date_dt_full"] = (
        start_date  # pd.to_datetime(start_date, format="%Y-%m-%d %H:%M:%S")
    )
    df_queryd["end_date_dt_full"] = (
        end_date  # pd.to_datetime(end_date, format="%Y-%m-%d %H:%M:%S")
    )
    df_queryd["start_date_dt_full"] = pd.to_datetime(
        df_queryd["start_date_dt_full"].astype(str).str[:19], format="%Y-%m-%d %H:%M:%S"
    )
    df_queryd["end_date_dt_full"] = pd.to_datetime(
        df_queryd["end_date_dt_full"].astype(str).str[:19], format="%Y-%m-%d %H:%M:%S"
    )
    condlist = [
        pd.to_datetime(
            df_queryd["episode_start_date"].astype(str).str[:10],
            errors="coerce",
            format="%Y-%m-%d",
        )
        < df_queryd["start_date_dt"],
        (
            (
                pd.to_datetime(
                    df_queryd["episode_start_date"].astype(str).str[:10],
                    errors="coerce",
                    format="%Y-%m-%d",
                )
                >= df_queryd["start_date_dt"]
            )
            & (
                pd.to_datetime(
                    df_queryd["episode_start_date"].astype(str).str[:10],
                    errors="coerce",
                    format="%Y-%m-%d",
                )
                > df_queryd["end_date_dt"]
            )
        ),
    ]
    choicelist = [df_queryd["start_date_dt_full"], df_queryd["start_date_dt_full"]]
    df_queryd["start_date_df_queryd_full"] = np.select(
        condlist,
        choicelist,
        pd.to_datetime(
            (
                df_queryd["episode_start_date"].astype(str).str[:10]
                + " "
                + df_queryd["episode_start_time"].astype(str).str[-8:]
            ),
            errors="coerce",
            format="%Y-%m-%d %H:%M:%S",
        ),
    )
    # Ranjit 12 Dec 2024 - Issue 114: Length of stay in costing period not calculating correctly.  Ex.  H770-I-04529915-001 Long stay RAC patient admitted prior to 1 July 23 and not discharged as at 30 June 24.  LOS in costing period = 1
    """condlist = [(df_queryd['episode_start_date'].isnull()) | (df_queryd['episode_start_date'].astype(str).str[:10]=='') , \
    ((pd.notna(df_queryd['episode_start_date'])) & (df_queryd['episode_start_date'].astype(str).str[:10]!='')) & (pd.to_datetime(df_queryd['episode_end_date'].astype(str).str[:10], errors='coerce', format="%Y-%m-%d") > df_queryd['end_date_dt'])]"""
    condlist = [
        (df_queryd["episode_end_date"].isnull())
        | (df_queryd["episode_end_date"].astype(str).str[:10] == "")
        | (df_queryd["episode_start_date"].isnull())
        | (df_queryd["episode_start_date"].astype(str).str[:10] == ""),
        (
            (pd.notna(df_queryd["episode_start_date"]))
            & (df_queryd["episode_start_date"].astype(str).str[:10] != "")
        )
        & (
            pd.to_datetime(
                df_queryd["episode_end_date"].astype(str).str[:10],
                errors="coerce",
                format="%Y-%m-%d",
            )
            > df_queryd["end_date_dt"]
        ),
    ]
    choicelist = [df_queryd["end_date_dt_full"], df_queryd["end_date_dt_full"]]
    df_queryd["end_date_df_queryd_full"] = np.select(
        condlist,
        choicelist,
        pd.to_datetime(
            (
                df_queryd["episode_end_date"].astype(str).str[:10]
                + " "
                + df_queryd["episode_end_time"].astype(str).str[-8:]
            ),
            errors="coerce",
            format="%Y-%m-%d %H:%M:%S",
        ),
    )
    # 183: Fix LOS in Costing period - do not include time component.
    # df_queryd['Extra:LOSinCostingPeriod'] = np.where((df_queryd['episode_start_date'].astype(str).str[:10] == df_queryd['episode_end_date'].astype(str).str[:10]), 1, ((df_queryd['end_date_df_queryd_full'] - df_queryd['start_date_df_queryd_full'])/ np.timedelta64(1, 'D')) - df_queryd['LeaveDays_dummy'])
    df_queryd["Extra:LOSinCostingPeriod"] = np.where(
        (
            df_queryd["episode_start_date"].astype(str).str[:10]
            == df_queryd["episode_end_date"].astype(str).str[:10]
        ),
        1,
        (
            (
                df_queryd["end_date_df_queryd_full"].dt.floor("D")
                - df_queryd["start_date_df_queryd_full"].dt.floor("D")
            )
            / np.timedelta64(1, "D")
        )
        - df_queryd["LeaveDays_dummy"],
    )
    # df_queryd.to_csv('./ExtractorDB/tbl_PPM_Encounter_AUID_test_0.csv',index=False)
    df_queryd["Extra:LOSinCostingPeriod"] = df_queryd["Extra:LOSinCostingPeriod"].round(
        decimals=0
    )
    df_queryd["Extra:HLTH_ORG_OSP_OSP_ID"] = df_queryd["HLTH_ORG_OSP_OSP_ID"]
    df_queryd["Extra:MG_AUTH_OSP_OSP_ID"] = df_queryd["MG_AUTH_OSP_OSP_ID"]
    df_queryd["Extra:SE_CBK_SK"] = df_queryd["SE_CBK_SK"]
    df_queryd["Extra:CL_ID_EUID"] = df_queryd["CL_ID_EUID"]
    df_queryd["Extra:CL_ID_IHI"] = df_queryd["CL_ID_IHI"]
    df_queryd["Extra:HLTH_ORG_OSP_TYP"] = df_queryd["HLTH_ORG_OSP_TYP"]
    df_queryd["Extra:SRV_ENC_REC_ID"] = df_queryd["SRV_ENC_REC_ID"]
    # issue 134 - 28 Jan 2025
    df_queryd["Extra:FRML_DISCH_MODE_CD"] = df_queryd["FRML_DISCH_MODE_CD"]
    df_queryd["Extra:SE_SEP_MODE_NHDD_CD"] = df_queryd["SE_SEP_MODE_NHDD_CD"]
    df_queryd["Extra:Responsible_Facility"] = df_queryd["Responsible_Facility"]
    df_queryd["Extra:SE_TYP_CD"] = df_queryd["SE_TYP_CD"]
    df_queryd["Extra:SE_ADM_MODE_NHDD_CD"] = df_queryd["SE_ADM_MODE_NHDD_CD"]
    df_queryd["Extra:DIM_RSP_ISP_SK"] = df_queryd["DIM_RSP_ISP_SK"]
    df_queryd["Extra:AR_DRG_ECCS_RAW"] = df_queryd["AR_DRG_ECCS_RAW"]
    df_queryd["Extra:WAU_ADJ_PT_TX_REMT_AREA"] = df_queryd["WAU_ADJ_PT_TX_REMT_AREA"]
    df_queryd["Extra:WAU_ADJ_DIALYSIS"] = df_queryd["WAU_ADJ_DIALYSIS"]
    df_queryd["Extra:WAU_ADJ_COVID19"] = df_queryd["WAU_ADJ_COVID19"]
    df_queryd["Extra:WAU_ADJ_HAC"] = df_queryd["WAU_ADJ_HAC"]
    df_queryd["Extra:ASGS_SA_L2_16_CD"] = df_queryd["ASGS_SA_L2_16_CD"]
    df_queryd["Extra:CL_URES_ADDR_ASGS21_SA_L2_CD"] = df_queryd[
        "CL_URES_ADDR_ASGS21_SA_L2_CD"
    ]
    # df_queryd['Extra:HLTH_ORG_OSP_TYP_CD_DESC'] = df_queryd['HLTH_ORG_OSP_TYP_CD_DESC']
    # df_queryd.to_csv('./ExtractorDB/tbl_PPM_Encounter_AUID_test_1.csv',index=False)
    ########################### Extra:LOSinCostingPeriod - Stop ################################
    tbl_PPM_Encounter_AUID = df_queryd[
        [
            "EncounterType",
            "EncounterNumber",
            "PostCode",
            "Suburb",
            "MaritalStatus",
            "PatientNumber",
            "EpisodeOfCare",
            "AttendingConsultant",
            "AdmissionCategory",
            "AdmissionElection",
            "DischargeElection",
            "AdmissionType",
            "AdmissionSource",
            "Hospital",
            "FinancialClass",
            "DischargeStatus",
            "DRG1",
            "DRG1Version",
            "DRG2",
            "DRG2Version",
            "LengthOfStay",
            "ICUHours",
            "MechVentHours",
            "StartDateTime",
            "EndDateTime",
            "Age",
            "HealthFund",
            "AdmissionWeight",
            "WeightedSeparation",
            "Extra:LGACode",
            "Extra:HospitalStayNumber",
            "Extra:LHDIdentifier",
            "Extra:LegalStatus",
            "Extra:DVANumber",
            "Extra:DVAType",
            "Extra:IntendedSameDay",
            "Extra:ReferralFurtherHealthcare",
            "Extra:UnplannedReadmission",
            "Extra:EpisodeSequenceNumber",
            "Extra:MedicareNumber",
            "Extra:DaysinPsychUnit",
            "Extra:UnplannedTheatre",
            "Extra:EDStatus",
            "Extra:ICUStatus",
            "Extra:SRGcurrent",
            "Extra:ESRGcurrent",
            "Extra:CW_A",
            "Extra:CW_B",
            "Extra:CW_C",
            "Extra:CW_D",
            "Extra:CW_E",
            "Extra:CW_F",
            "Extra:TrimPoint",
            "Extra:Outlierdays",
            "Extra:SurgeryIndicator",
            "Extra:AreaDOHRSCode",
            "Extra:FacilityTransferredto",
            "Extra:FacilityTransferredfrom",
            "Extra:MRN",
            "Extra:MDC",
            "Extra:MDC2",
            "Extra:FinancialProgram",
            "Extra:indicatorProcedurecode",
            "Extra:bookingIdentifier",
            "Extra:waitinglistcategory",
            "Extra:ClinicalURGfinal",
            "Extra:ReasonforRemoval",
            "Extra:DRG1_pccl",
            "Extra:EpisodeLeaveDays",
            "Extra:QualifiedBedDays",
            "Extra:IndigenousStatus",
            "Extra:MothersMRN",
            "Extra:MothersStayNumber",
            "Extra:MothersPersonIdentifier",
            "Extra:ElectionStatusSummary",
            "Extra:FacilityType",
            "Extra:MedicareEligibility",
            "Extra:LOSinCostingPeriod",
            "Extra:LeaveinCostingPeriod",
            "Extra:ExtractorVersion",
            "Extra:AICU1_Hours",
            "Extra:AICU3_Hours",
            "Extra:PICU_Hours",
            "Extra:NICU_Hours",
            "Extra:PSICU_Hours",
            "Extra:CCU_Hours",
            "Extra:AICU2_Hours",
            "AttendingConsultantSpecialty",
            "Extra:nwau",
            "Extra:nwau_PublicEquivModel",
            "Extra:nwau_base",
            "Extra:nwau_paed_incr",
            "Extra:nwau_indig_incr",
            "Extra:nwau_remote_incr",
            "Extra:nwau_icu_incr",
            "Extra:nwau_private_patient_service_incr",
            "Extra:nwau_private_patient_accom_incr",
            "Extra:AUID",
            "Extra:HITH_Hours",
            "Extra:HDU_Hours",
            "Extra:SCN_Hours",
            "Extra:SRG_Version",
            "Extra:Collabrtve_Care_Facility",
            "Extra:Contract_Status",
            "Extra:Collabrtve_Care_Role",
            "Extra:Collabrtve_Care_Type",
            "Extra:Radiotherapy_adj",
            "Extra:nwau_version",
            "Extra:LHD_of_Usual_Residence",
            "Extra:sp_psy_age_adj",
            "Extra:compensable_nwau",
            "Extra:SpecialtyPortal",
            "Extra:ExtractDate",
            "Extra:WIP",
            "Extra:StartDateTime_EpisodeTable",
            "Extra:EndDateTime_EpisodeATSTable",
            "Extra:EndDateTime_EpisodeTable",
            "Extra:LengthofStay_EpisodeTable",
            "Extra:LengthofStay_EpisodeATSTable",
            "Extra:EpisodeLeaveDays_EpisodeTable",
            "Extra:EpisodeLeaveDays_EpisodeATSTable",
            "Extra:EpisodeofCare_EpisodeTable",
            "Extra:EpisodeofCare_EpisodeATSTable",
            "Extra:MothersEncounterNumber",
            "Extra:HLTH_ORG_OSP_OSP_ID",
            "Extra:MG_AUTH_OSP_OSP_ID",
            "Extra:SE_CBK_SK",
            "Extra:CL_ID_EUID",
            "Extra:CL_ID_IHI",
            "Extra:HLTH_ORG_OSP_TYP",
            "Extra:SRV_ENC_REC_ID",
            "Extra:FRML_DISCH_MODE_CD",
            "Extra:SE_SEP_MODE_NHDD_CD",
            "Extra:Responsible_Facility",
            "Extra:SE_TYP_CD",
            "Extra:SE_ADM_MODE_NHDD_CD",
            "Extra:DIM_RSP_ISP_SK",
            "Extra:AR_DRG_ECCS_RAW",
            "Extra:WAU_ADJ_PT_TX_REMT_AREA",
            "Extra:WAU_ADJ_DIALYSIS",
            "Extra:WAU_ADJ_COVID19",
            "Extra:WAU_ADJ_HAC",
            "Extra:ASGS_SA_L2_16_CD",
            "Extra:CL_URES_ADDR_ASGS21_SA_L2_CD",
        ]
    ]
    # sorting by first name
    tbl_PPM_Encounter_AUID.sort_values("EncounterNumber", inplace=True)
    # dropping duplicate values
    tbl_PPM_Encounter_AUID.drop_duplicates(keep="last", inplace=True)
    """    
    tbl_PPM_Encounter_AUID_col_list = tbl_PPM_Encounter_AUID.columns.values.tolist()
    for col in tbl_PPM_Encounter_AUID_col_list:
        tbl_PPM_Encounter_AUID[col] = tbl_PPM_Encounter_AUID[col].astype("category")
    """
    logging.info(
        "tbl_PPM_Encounter_AUID created with %s records.", len(tbl_PPM_Encounter_AUID)
    )
    tbl_PPM_Encounter_AUID.to_csv(
        "./ExtractorDB/tbl_PPM_Encounter_AUID.csv", index=False
    )
    cleanup_memory(df_query1)
    cleanup_memory(df_query2)
    cleanup_memory(df_query3)
    cleanup_memory(df_query4)
    cleanup_memory(df_query5)
    cleanup_memory(df_query6)
    cleanup_memory(df_query7)
    cleanup_memory(df_query8)
    cleanup_memory(df_query9)
    cleanup_memory(df_query10)
    cleanup_memory(df_query11)
    cleanup_memory(df_queryd)
    """Appends data from multitude of tables where the encounter is is in the snapApp_CostingExtract table and not in the  tbl_ExcludedEncounters table to the tbl_PPM_Encounter"""
    # Access query: Append_to_tbl_PPM_Encounter_AUID_SNAP
    # INSERT INTO tbl_PPM_Encounter ( EncounterType, EncounterNumber, PostCode, Suburb, MaritalStatus, PatientNumber, EpisodeOfCare, AttendingConsultant, AdmissionCategory, AdmissionElection, DischargeElection, AdmissionType, AdmissionSource, Hospital, FinancialClass, DischargeStatus, DRG1, DRG1Version, DRG2, DRG2Version, DRG3, DRG3Version, LengthOfStay, ICUHours, MechVentHours, StartDateTime, EndDateTime, Age, HealthFund, AdmissionWeight, WeightedSeparation, [Extra:LGACode], [Extra:HospitalStayNumber], [Extra:LHDIdentifier], [Extra:LegalStatus], [Extra:DVANumber], [Extra:DVAType], [Extra:IntendedSameDay], [Extra:ReferralFurtherHealthcare], [Extra:UnplannedReadmission], [Extra:MedicareNumber], [Extra:DaysinPsychUnit], [Extra:UnplannedTheatre], [Extra:EDStatus], [Extra:ICUStatus], [Extra:SRGcurrent], [Extra:ESRGcurrent], [Extra:CW_A], [Extra:CW_B], [Extra:CW_C], [Extra:CW_D], [Extra:CW_E], [Extra:CW_F], [Extra:TrimPoint], [Extra:Outlierdays], [Extra:SurgeryIndicator], [Extra:AreaDOHRSCode],[Extra:FacilityTransferredto], [Extra:FacilityTransferredfrom], [Extra:MRN], [Extra:MDC], [Extra:indicatorProcedurecode], [Extra:bookingIdentifier], [Extra:waitinglistcategory], [Extra:ClinicalURGfinal], [Extra:ReasonforRemoval], [Extra:DRG1_pccl], [Extra:QualifiedBedDays], [Extra:IndigenousStatus], [Extra:MothersMRN], [Extra:MothersStayNumber], [Extra:MothersPersonIdentifier], [Extra:ElectionStatusSummary], [Extra:MedicareEligibility], [Extra:FacilityType], [Extra:VersionID], [Extra:ProdType], [Extra:CaseType], [Extra:EpisType], [Extra:AssessOnly], [Extra:PCPhase], [Extra:PCSymptomScoreStart], [Extra:PCSeverityStart], [Extra:PCPsychSpiritualScoreStart], [Extra:PCFamilyCarerScoreStart], [Extra:MaintType], [Extra:CareFocus], [Extra:Impair], [Extra:RugBedBeg], [Extra:RugToilBeg], [Extra:RugXferBeg], [Extra:RugEatBeg], [Extra:Cost_Weight], [Extra:FIMEatBeg], [Extra:FIMEatEnd], [Extra:FIMGroomBeg], [Extra:FIMGroomEnd], [Extra:FIMBathBeg], [Extra:FIMBathEnd], [Extra:FIMUpperBeg], [Extra:FIMUpperEnd], [Extra:FIMLowerBeg], [Extra:FIMLowerEnd], [Extra:FIMToiletBeg], [Extra:FIMToiletEnd], [Extra:FIMBladderBeg], [Extra:FIMBladderEnd], [Extra:FIMBowelBeg], [Extra:FIMBowelEnd], [Extra:FIMXferBeg], [Extra:FIMXferEnd], [Extra:FIMXferToilBeg], [Extra:FIMXferToilEnd], [Extra:FIMTubBeg], [Extra:FIMTubEnd], [Extra:FIMWalkBeg], [Extra:FIMWalkEnd], [Extra:FIMStairBeg], [Extra:FIMStairEnd], [Extra:FIMCompBeg], [Extra:FIMCompEnd], [Extra:FIMExpBeg], [Extra:FIMExpEnd], [Extra:FIMSocialBeg], [Extra:FIMSocialEnd], [Extra:FIMProbBeg], [Extra:FIMProbEnd], [Extra:FIMMemoryBeg], [Extra:FIMMemoryEnd], [Extra:HonActiveBeg], [Extra:HonActiveEnd], [Extra:HonInjuryBeg], [Extra:HonInjuryEnd], [Extra:HonDrinkBeg], [Extra:HonDrinkEnd], [Extra:HonCognitBeg], [Extra:HonCognitEnd], [Extra:HonDisabBeg], [Extra:HonDisabEnd], [Extra:HonHallucBeg], [Extra:HonHallucEnd], [Extra:HonDeprsBeg], [Extra:HonDeprsEnd], [Extra:HonOtherBeg], [Extra:HonOtherEnd], [Extra:HonRelatBeg], [Extra:HonRelatEnd], [Extra:HonADLBeg], [Extra:HonADLEnd], [Extra:HonLivingBeg], [Extra:HonLivingEnd], [Extra:HonOccupBeg], [Extra:HonOccupEnd], [Extra:AUID], [Extra:LHD_of_Usual_Residence], [Extra:MDC2], [Extra:EpisodeLeaveDays], [Extra:SNAP_Class], [Extra:LOSinCostingPeriod], [Extra:LeaveinCostingPeriod], AttendingConsultantSpecialty, [Extra:SpecialtyPortal], [Extra:SNAP_ClassV4], [Extra:Dementia_Flag], [Extra:Delirium_Flag], [Extra:Contract_Status], [Extra:Collabrtve_Care_Role], [Extra:Collabrtve_Care_Facility], [Extra:Collabrtve_Care_Type], [Extra:ExtractDate], [Extra:AMHCC_Class], [Extra:AMHCC_ClassVersion], [Extra:HON1], [Extra:HON2], [Extra:HON3], [Extra:HON4], [Extra:HON5], [Extra:HON6], [Extra:HON7], [Extra:HON8], [Extra:HON9], [Extra:HON10], [Extra:HON11], [Extra:HON12], [Extra:HON13], [Extra:HON14], [Extra:HON15], [Extra:WIP], [Extra:StartDateTime_EpisodeTable], [Extra:EndDateTime_EpisodeATSTable], [Extra:EndDateTime_EpisodeTable], [Extra:LengthofStay_EpisodeTable], [Extra:LengthofStay_EpisodeATSTable], [Extra:EpisodeLeaveDays_EpisodeTable], [Extra:EpisodeLeaveDays_EpisodeATSTable], [Extra:EpisodeofCare_EpisodeTable], [Extra:EpisodeofCare_EpisodeATSTable], [Extra:MHPhaseSeqNo] )
    # SELECT IIf([tbl_dbo_episode_srg]![ed_status] In ("1","4","04","01"),"X",IIf([tbl_dbo_episode_ats]![episode_of_care_type]='5' And [tbl_dbo_episode_ats]![qualified_bed_time]=0 And [tbl_dbo_episode_ats]![qualified_bed_days]=0,"X","I")) AS Expr13, snapApp_CostingExtract.EncounterNumber, tbl_dbo_stay.patient_postcode, tbl_dbo_stay.patient_suburb, tbl_dbo_stay.marital_status, [tbl_dbo_episode_ats]![facility_identifier] & "-" & Format(IIf([tbl_Patient_Contact_Details]![AUID] Is Not Null,[tbl_Patient_Contact_Details]![AUID],Right([tbl_dbo_stay]![mrn],10)),"0000000000") AS Expr9, tbl_dbo_episode_ats.episode_of_care_type, [tbl_dbo_episode_ats]![facility_identifier] & "-" & Trim([tbl_dbo_days_episode]![mo_code]) AS Expr2, tbl_dbo_stay.emergency_status, tbl_dbo_stay.election_status_on_admit, tbl_dbo_episode_ats.payment_status_on_sep,  IIf([tbl_dbo_episode_ats]![episode_end_date]=[tbl_dbo_episode_ats]![episode_start_date],"SD","ON") AS Expr6, tbl_dbo_episode_ats.source_of_referral, tbl_dbo_episode_ats.facility_identifier, tbl_dbo_episode_ats.financial_class, IIf([SNAP File 2 01]![Snap ClassV4] Is Null,"4999",IIf([SNAP File 2 01]![Snap ClassV4]="","4999",[SNAP File 2 01]![Snap ClassV4])) & "-" & IIf([tbl_dbo_episode_DRG]![an_drg] Is Null,"960Z",[tbl_dbo_episode_DRG]![an_drg]) AS Expr15, IIf([snapApp_CostingExtract]![Grouped Status]="AMHCC",[Forms]![Frm:1-ExtractSetUp]![AMHCCV],[Forms]![Frm:1-ExtractSetUp]![SNAPV]) AS Expr18, IIf([2_an_drg] Is Null,"960Z",[2_an_drg]) AS Expr21, IIf([tbl_dbo_episode_DRG]![2_an_drg_version] Is Null,[Forms]![Frm:1-ExtractSetUp]![DRG2V],[tbl_dbo_episode_DRG]![2_an_drg_version]) AS Expr22, IIf([tbl_dbo_episode_DRG]![an_drg] Is Null,"960Z",[tbl_dbo_episode_DRG]![an_drg]) AS Expr3, IIf([tbl_dbo_episode_DRG]![an_drg_version] Is Null,[Forms]![Frm:1-ExtractSetUp]![DRG1V],[tbl_dbo_episode_DRG]![an_drg_version]) AS Expr17, snapApp_CostingExtract.sa_total_los AS Expr12, tbl_dbo_episode_ats.hours_in_icu,  tbl_dbo_episode.hours_on_mech_vent_num, Format([snapApp_CostingExtract]![EncounterStart],"yyyy-mm-dd hh:nn:ss") AS Expr10, Format([snapApp_CostingExtract]![EncounterEnd],"yyyy-mm-dd hh:nn:ss") AS Expr7, tbl_dbo_stay.age, tbl_dbo_stay.insurance_fund_master, IIf([tbl_dbo_episode]![infant_start_weight]="",0,[tbl_dbo_episode]![infant_start_weight]) AS Expr4, tbl_dbo_episode_srg.cost_weight_e_current, tbl_dbo_stay.area_of_usual_residence, "SN" & Trim([tbl_dbo_episode_ats]![stay_number]) AS Expr11,  tbl_dbo_episode_ats.area_identifier, tbl_dbo_episode_ats.legal_status_on_admit, tbl_dbo_stay.dva_card_number, tbl_dbo_stay.dva_card_type, tbl_dbo_stay.stay_discharge_intention, tbl_dbo_stay.referred_to_on_separation, tbl_dbo_stay.readmit_this_hosp_28_days, tbl_dbo_episode_ats.episode_sequence_number, tbl_dbo_stay.medicare_number, IIf([tbl_dbo_episode_ats]![hours_in_psych_unit]>0 And [tbl_dbo_episode_ats]![days_in_psych_unit]=0,1,[tbl_dbo_episode_ats]![days_in_psych_unit]) AS Expr28, tbl_dbo_episode_ats.unplanned_theatre, tbl_dbo_episode_srg.ed_status, tbl_dbo_episode_srg.icu_status, tbl_dbo_episode_srg.srg_current, tbl_dbo_episode_srg.esrg_current, tbl_dbo_episode_srg.cost_weight_a_current, tbl_dbo_episode_srg.cost_weight_b_current, tbl_dbo_episode_srg.cost_weight_c_current, tbl_dbo_episode_srg.cost_weight_d_current, tbl_dbo_episode_srg.cost_weight_e_current, tbl_dbo_episode_srg.cost_weight_f_current, tbl_dbo_episode_srg.trim_point, [outlier_days_1]+[outlier_days_2] AS Expr8, tbl_dbo_episode_srg.surgery_indicator, tbl_dbo_episode_ats.area_identifier,  tbl_dbo_episode_ats.financial_program, tbl_dbo_stay.facility_trans_to, tbl_dbo_stay.facility_trans_from, [tbl_dbo_episode_ats]![mrn] AS Expr14, tbl_dbo_episode_DRG.mdc, tbl_dbo_stay.indicator_procedure_code, tbl_dbo_wl_exit1.booking_identifier, tbl_dbo_wl_exit1.waiting_list_category, tbl_dbo_wl_exit1.clinical_urg_final_crnt, tbl_dbo_wl_exit1.reason_for_removal, tbl_dbo_episode_DRG.an_drg_pccl, tbl_dbo_episode_ats.indigenous_status, tbl_dbo_stay.indigenous_status, tbl_dbo_stay.mothers_mrn, IIf([mothers_stay_number]="","",IIf([mothers_stay_number] Is Null,"","SN" & Trim([mothers_stay_number]))) AS Expr20, tbl_dbo_stay.mothers_person_identifier, IIf([tbl_dbo_episode_ats]![payment_status_on_sep] In ("20","23","24","45"),"Public",IIf([tbl_dbo_episode_ats]![payment_status_on_sep] In ("30","31","32","33","34","35","36","46"),"Private",IIf([tbl_dbo_episode_ats]![payment_status_on_sep] In ("40","41","42","43","50","51","52","60"),"Compensable"))) AS Expr16, tbl_dbo_stay.medicare_eligibility_status, tbl_dbo_episode_ats.facility_type, Replace([Forms]![Frm:1-ExtractSetUp]![fm_round],"V","") AS versionid, Max([SNAP File 2 01].ProdType) AS MaxOfProdType, Max([SNAP File 2 01].CaseType) AS MaxOfCaseType, Max([SNAP File 2 01].EpisType) AS MaxOfEpisType, Max([SNAP File 2 01].AssessOnly) AS MaxOfAssessOnly, Max([SNAP File 2 01].Phase) AS MaxOfPhase, Max([SNAP File 2 01].PCSymptomScoreStart) AS MaxOfPCSymptomScoreStart, Max([SNAP File 2 01].PCSeverityStart) AS MaxOfPCSeverityStart, Max([SNAP File 2 01].PCPsychSpiritualScoreStart) AS MaxOfPCPsychSpiritualScoreStart, Max([SNAP File 2 01].PCFamilyCarerScoreStart) AS MaxOfPCFamilyCarerScoreStart, Max([SNAP File 2 01].MaintType) AS MaxOfMaintType, Max([SNAP File 2 01].CareFocus) AS MaxOfCareFocus, Max([SNAP File 2 01].Impair) AS MaxOfImpair, Max([SNAP File 2 01].RugBedBeg) AS MaxOfRugBedBeg, Max([SNAP File 2 01].RugToilBeg) AS MaxOfRugToilBeg, Max([SNAP File 2 01].RugXferBeg) AS MaxOfRugXferBeg, Max([SNAP File 2 01].RugEatBeg) AS MaxOfRugEatBeg, Min(Null) AS MaxOfCost_Weight, Max([SNAP File 2 01].FIMEatBeg) AS MaxOfFIMEatBeg, Max([SNAP File 2 01].FIMEatEnd) AS MaxOfFIMEatEnd, Max([SNAP File 2 01].FIMGroomBeg) AS MaxOfFIMGroomBeg, Max([SNAP File 2 01].FIMGroomEnd) AS MaxOfFIMGroomEnd, Max([SNAP File 2 01].FIMBathBeg) AS MaxOfFIMBathBeg, Max([SNAP File 2 01].FIMBathEnd) AS MaxOfFIMBathEnd, Max([SNAP File 2 01].FIMUpperBeg) AS MaxOfFIMUpperBeg, Max([SNAP File 2 01].FIMUpperEnd) AS MaxOfFIMUpperEnd, Max([SNAP File 2 01].FIMLowerBeg) AS MaxOfFIMLowerBeg, Max([SNAP File 2 01].FIMLowerEnd) AS MaxOfFIMLowerEnd, Max([SNAP File 2 01].FIMToiletBeg) AS MaxOfFIMToiletBeg, Max([SNAP File 2 01].FIMToiletEnd) AS MaxOfFIMToiletEnd, Max([SNAP File 2 01].FIMBladderBeg) AS MaxOfFIMBladderBeg, Max([SNAP File 2 01].FIMBladderEnd) AS MaxOfFIMBladderEnd, Max([SNAP File 2 01].FIMBowelBeg) AS MaxOfFIMBowelBeg, Max([SNAP File 2 01].FIMBowelEnd) AS MaxOfFIMBowelEnd, Max([SNAP File 2 01].FIMXferBeg) AS MaxOfFIMXferBeg, Max([SNAP File 2 01].FIMXferEnd) AS MaxOfFIMXferEnd, Max([SNAP File 2 01].FIMXferToilBeg) AS MaxOfFIMXferToilBeg, Max([SNAP File 2 01].FIMXferToilEnd) AS MaxOfFIMXferToilEnd, Max([SNAP File 2 01].FIMTubBeg) AS MaxOfFIMTubBeg, Max([SNAP File 2 01].FIMTubEnd) AS MaxOfFIMTubEnd, Max([SNAP File 2 01].FIMWalkBeg) AS MaxOfFIMWalkBeg, Max([SNAP File 2 01].FIMWalkEnd) AS MaxOfFIMWalkEnd, Max([SNAP File 2 01].FIMStairBeg) AS MaxOfFIMStairBeg, Max([SNAP File 2 01].FIMStairEnd) AS MaxOfFIMStairEnd, Max([SNAP File 2 01].FIMCompBeg) AS MaxOfFIMCompBeg, Max([SNAP File 2 01].FIMCompEnd) AS MaxOfFIMCompEnd, Max([SNAP File 2 01].FIMExpBeg) AS MaxOfFIMExpBeg, Max([SNAP File 2 01].FIMExpEnd) AS MaxOfFIMExpEnd, Max([SNAP File 2 01].FIMSocialBeg) AS MaxOfFIMSocialBeg, Max([SNAP File 2 01].FIMSocialEnd) AS MaxOfFIMSocialEnd, Max([SNAP File 2 01].FIMProbBeg) AS MaxOfFIMProbBeg, Max([SNAP File 2 01].FIMProbEnd) AS MaxOfFIMProbEnd, Max([SNAP File 2 01].FIMMemoryBeg) AS MaxOfFIMMemoryBeg, Max([SNAP File 2 01].FIMMemoryEnd) AS MaxOfFIMMemoryEnd, Max([SNAP File 2 01].HonActiveBeg) AS MaxOfHonActiveBeg, Max([SNAP File 2 01].HonActiveEnd) AS MaxOfHonActiveEnd, Max([SNAP File 2 01].HonInjuryBeg) AS MaxOfHonInjuryBeg, Max([SNAP File 2 01].HonInjuryEnd) AS MaxOfHonInjuryEnd, Max([SNAP File 2 01].HonDrinkBeg) AS MaxOfHonDrinkBeg, Max([SNAP File 2 01].HonDrinkEnd) AS MaxOfHonDrinkEnd, Max([SNAP File 2 01].HonCognitBeg) AS MaxOfHonCognitBeg, Max([SNAP File 2 01].HonCognitEnd) AS MaxOfHonCognitEnd, Max([SNAP File 2 01].HonDisabBeg) AS MaxOfHonDisabBeg, Max([SNAP File 2 01].HonDisabEnd) AS MaxOfHonDisabEnd, Max([SNAP File 2 01].HonHallucBeg) AS MaxOfHonHallucBeg, Max([SNAP File 2 01].HonHallucEnd) AS MaxOfHonHallucEnd, Max([SNAP File 2 01].HonDeprsBeg) AS MaxOfHonDeprsBeg, Max([SNAP File 2 01].HonDeprsEnd) AS MaxOfHonDeprsEnd, Max([SNAP File 2 01].HonOtherBeg) AS MaxOfHonOtherBeg, Max([SNAP File 2 01].HonOtherEnd) AS MaxOfHonOtherEnd, Max([SNAP File 2 01].HonRelatBeg) AS MaxOfHonRelatBeg, Max([SNAP File 2 01].HonRelatEnd) AS MaxOfHonRelatEnd, Max([SNAP File 2 01].HonADLBeg) AS MaxOfHonADLBeg, Max([SNAP File 2 01].HonADLEnd) AS MaxOfHonADLEnd, Max([SNAP File 2 01].HonLivingBeg) AS MaxOfHonLivingBeg, Max([SNAP File 2 01].HonLivingEnd) AS MaxOfHonLivingEnd, Max([SNAP File 2 01].HonOccupBeg) AS MaxOfHonOccupBeg, Max([SNAP File 2 01].HonOccupEnd) AS MaxOfHonOccupEnd, IIf([tbl_Patient_Contact_Details]![AUID] Is Not Null,[tbl_Patient_Contact_Details]![AUID]) AS Expr19, tbl_dbo_stay.LHD_of_Usual_residence, tbl_dbo_episode_DRG.[2_mdc], [SNAP File 2 01].sa_total_leave_days, IIf([Grouped status]="AMHCC","",IIf([SNAP File 2 01]![Snap ClassV4] Is Null,"4999",IIf([SNAP File 2 01]![Snap ClassV4]="","4999",[SNAP File 2 01]![Snap ClassV4]))) AS Expr23, snapApp_CostingExtract.sa_occdays_in_cost_period, snapApp_CostingExtract.sa_leave_days_in_cost_period, (Trim([tbl_dbo_DAYS_EPISODE]![facility_identifier] & "-" & [tbl_dbo_DAYS_EPISODE]![specialty_unit_code])) AS Expr1, [qry specialtyportal].SpecialityPortal, IIf([Grouped status]="AMHCC","",[snapApp_CostingExtract]![Snap ClassV4]) AS Expr27, [SNAP File 2 01].Dementia_Flag, [SNAP File 2 01].Delirium_Flag, tbl_dbo_stay.contract_status, tbl_dbo_stay.collabrtve_care_role, tbl_dbo_stay.collabrtve_care_facility, tbl_dbo_stay.collabrtve_care_type, Format([HIE Extract Date],"yyyy-mm-dd hh:nn:ss") AS Expr24, IIf([grouped status]="AMHCC",[snapApp_CostingExtract]![Snap ClassV4]) AS Expr25, IIf([grouped status]="AMHCC",1) AS Expr26, snapApp_CostingExtract.HON1, snapApp_CostingExtract.HON2, snapApp_CostingExtract.HON3, snapApp_CostingExtract.HON4, snapApp_CostingExtract.HON5, snapApp_CostingExtract.HON6, snapApp_CostingExtract.HON7, snapApp_CostingExtract.HON8, snapApp_CostingExtract.HON9, snapApp_CostingExtract.HON10, snapApp_CostingExtract.HON11, snapApp_CostingExtract.HON12, snapApp_CostingExtract.HON13, snapApp_CostingExtract.HON14, snapApp_CostingExtract.HON15, snapApp_CostingExtract.WIP, Format([tbl_dbo_episode]![startdate] & " " & [tbl_dbo_episode]![starttime],"yyyy-mm-dd hh:nn:ss") AS Expr35, IIf([Episode ATS end date update]![facility_identifier] Is Not Null,Null,Format([tbl_dbo_episode_ats]![episode_end_date] & " " & [tbl_dbo_episode_ats]![episode_end_time],"yyyy-mm-dd hh:nn:ss")) AS Expr36, Format([tbl_dbo_episode]![enddate] & " " & [tbl_dbo_episode]![endtime],"yyyy-mm-dd hh:nn:ss") AS Expr34, tbl_dbo_episode.episode_length_of_stay, tbl_dbo_episode_ats.episode_length_of_stay, tbl_dbo_episode_ats.episode_leave_days_total,  tbl_dbo_episode_ats.episode_leave_days_total, tbl_dbo_episode.episode_of_care_type, tbl_dbo_episode_ats.episode_of_care_type, snapApp_CostingExtract.PhaseSeqNo
    # FROM ((tbl_dbo_episode_ats LEFT JOIN tbl_dbo_days_episode ON (tbl_dbo_episode_ats.episode_sequence_number = tbl_dbo_days_episode.episode_sequence_number) AND (tbl_dbo_episode_ats.stay_number = tbl_dbo_days_episode.stay_number) AND (tbl_dbo_episode_ats.facility_identifier = tbl_dbo_days_episode.facility_identifier) AND (tbl_dbo_episode_ats.episode_start_date = tbl_dbo_days_episode.start_date)  AND (tbl_dbo_episode_ats.episode_start_time = tbl_dbo_days_episode.start_time))
    # LEFT JOIN (tbl_dbo_stay LEFT JOIN tbl_dbo_wl_exit1 ON (tbl_dbo_stay.facility_identifier = tbl_dbo_wl_exit1.facility_identifier) AND (tbl_dbo_stay.person_identifier = tbl_dbo_wl_exit1.person_identifier) AND (tbl_dbo_stay.admission_date = tbl_dbo_wl_exit1.removal_date)) ON ((tbl_dbo_episode_ats.facility_identifier = tbl_dbo_stay.facility_identifier) AND (tbl_dbo_episode_ats.stay_number = tbl_dbo_stay.stay_number))
    # LEFT JOIN tbl_dbo_episode_srg ON ((tbl_dbo_episode_srg.facility_identifier = tbl_dbo_episode_ats.facility_identifier ) AND (tbl_dbo_episode_srg.stay_number = tbl_dbo_episode_ats.stay_number ) AND (tbl_dbo_episode_srg.episode_sequence_number = tbl_dbo_episode_ats.episode_sequence_number ))
    # LEFT JOIN tbl_dbo_episode_DRG ON ((tbl_dbo_episode_DRG.facility_identifier = tbl_dbo_episode_ats.facility_identifier ) AND (tbl_dbo_episode_DRG.stay_number = tbl_dbo_episode_ats.stay_number ) AND (tbl_dbo_episode_DRG.episode_sequence_number = tbl_dbo_episode_ats.episode_sequence_number ))
    # LEFT JOIN tbl_Patient_Contact_Details ON ((tbl_dbo_episode_ats.facility_identifier = tbl_Patient_Contact_Details.facility_identifier) AND (tbl_dbo_episode_ats.stay_number = tbl_Patient_Contact_Details.contact_identifier))
    # LEFT JOIN tbl_dbo_episode ON ((tbl_dbo_episode.facility_identifier = tbl_dbo_episode_ats.facility_identifier ) AND (tbl_dbo_episode.stay_number = tbl_dbo_episode_ats.stay_number ) AND (tbl_dbo_episode.episode_sequence_number = tbl_dbo_episode_ats.episode_sequence_number ))
    # LEFT JOIN [Episode ATS end date update] ON (([Episode ATS end date update].facility_identifier = tbl_dbo_episode_ats.facility_identifier ) AND ([Episode ATS end date update].stay_number = tbl_dbo_episode_ats.stay_number ) AND ([Episode ATS end date update].episode_sequence_number = tbl_dbo_episode_ats.episode_sequence_number ))
    # LEFT JOIN [qry SpecialtyPortal] ON (([qry SpecialtyPortal].facility_identifier = tbl_dbo_episode_ats.facility_identifier ) AND ([qry SpecialtyPortal].stay_number = tbl_dbo_episode_ats.stay_number ) AND ([qry SpecialtyPortal].episode_sequence_number = tbl_dbo_episode_ats.episode_sequence_number ))
    # INNER JOIN ((snapApp_CostingExtract INNER JOIN [SNAP File 2 01] ON snapApp_CostingExtract.EncounterNumber = [SNAP File 2 01].EncounterNumber) LEFT JOIN tbl_ExcludedEncounters ON snapApp_CostingExtract.EncounterNumber = tbl_ExcludedEncounters.SNAP_encounter) ON ((snapApp_CostingExtract.FacilityCode = tbl_dbo_episode_ats.facility_identifier ) AND (snapApp_CostingExtract.stay_number_cost = tbl_dbo_episode_ats.stay_number ) AND (snapApp_CostingExtract.sa_episode_sequence_number = tbl_dbo_episode_ats.episode_sequence_number )))
    # WHERE (((tbl_ExcludedEncounters.SNAP_encounter) Is Null))
    # GROUP BY IIf([tbl_dbo_episode_srg]![ed_status] In ("1","4","04","01"),"X",IIf([tbl_dbo_episode_ats]![episode_of_care_type]='5' And [tbl_dbo_episode_ats]![qualified_bed_time]=0 And [tbl_dbo_episode_ats]![qualified_bed_days]=0,"X","I")), snapApp_CostingExtract.EncounterNumber, tbl_dbo_stay.patient_postcode, tbl_dbo_stay.patient_suburb, tbl_dbo_stay.marital_status, [tbl_dbo_episode_ats]![facility_identifier] & "-" & Format(IIf([tbl_Patient_Contact_Details]![AUID] Is Not Null,[tbl_Patient_Contact_Details]![AUID],Right([tbl_dbo_stay]![mrn],10)),"0000000000"), [tbl_dbo_episode_ats]![facility_identifier] & "-" & Trim([tbl_dbo_days_episode]![mo_code]), tbl_dbo_stay.emergency_status, tbl_dbo_stay.election_status_on_admit, tbl_dbo_episode_ats.payment_status_on_sep,  IIf([tbl_dbo_episode_ats]![episode_end_date]=[tbl_dbo_episode_ats]![episode_start_date],"SD","ON"), tbl_dbo_episode_ats.source_of_referral, tbl_dbo_episode_ats.facility_identifier, tbl_dbo_episode_ats.financial_class, tbl_dbo_episode_ats.mode_of_separation, IIf([SNAP File 2 01]![Snap ClassV4] Is Null,"4999",IIf([SNAP File 2 01]![Snap ClassV4]="","4999",[SNAP File 2 01]![Snap ClassV4])) & "-" & IIf([tbl_dbo_episode_DRG]![an_drg] Is Null,"960Z",[tbl_dbo_episode_DRG]![an_drg]), IIf([snapApp_CostingExtract]![Grouped Status]="AMHCC",[Forms]![Frm:1-ExtractSetUp]![AMHCCV],[Forms]![Frm:1-ExtractSetUp]![SNAPV]), IIf([2_an_drg] Is Null,"960Z",[2_an_drg]), IIf([tbl_dbo_episode_DRG]![2_an_drg_version] Is Null,[Forms]![Frm:1-ExtractSetUp]![DRG2V],[tbl_dbo_episode_DRG]![2_an_drg_version]), IIf([tbl_dbo_episode_DRG]![an_drg] Is Null,"960Z",[tbl_dbo_episode_DRG]![an_drg]), IIf([tbl_dbo_episode_DRG]![an_drg_version] Is Null,[Forms]![Frm:1-ExtractSetUp]![DRG1V],[tbl_dbo_episode_DRG]![an_drg_version]), snapApp_CostingExtract.sa_total_los, tbl_dbo_episode_ats.hours_in_icu,  tbl_dbo_episode.hours_on_mech_vent_num, Format([snapApp_CostingExtract]![EncounterStart],"yyyy-mm-dd hh:nn:ss"), Format([snapApp_CostingExtract]![EncounterEnd],"yyyy-mm-dd hh:nn:ss"), tbl_dbo_stay.age, tbl_dbo_stay.insurance_fund_master, IIf([tbl_dbo_episode]![infant_start_weight]="",0,[tbl_dbo_episode]![infant_start_weight]),  tbl_dbo_stay.area_of_usual_residence, "SN" & Trim([tbl_dbo_episode_ats]![stay_number]),   tbl_dbo_episode_ats.legal_status_on_admit, tbl_dbo_stay.dva_card_number, tbl_dbo_stay.dva_card_type, tbl_dbo_stay.stay_discharge_intention, tbl_dbo_stay.referred_to_on_separation, tbl_dbo_stay.readmit_this_hosp_28_days, tbl_dbo_episode_ats.episode_sequence_number, tbl_dbo_stay.medicare_number, IIf([tbl_dbo_episode_ats]![hours_in_psych_unit]>0 And [tbl_dbo_episode_ats]![days_in_psych_unit]=0,1,[tbl_dbo_episode_ats]![days_in_psych_unit]),
    # tbl_dbo_episode_ats.unplanned_theatre, tbl_dbo_episode_srg.ed_status, tbl_dbo_episode_srg.icu_status, tbl_dbo_episode_srg.srg_current, tbl_dbo_episode_srg.esrg_current, tbl_dbo_episode_srg.cost_weight_a_current, tbl_dbo_episode_srg.cost_weight_b_current, tbl_dbo_episode_srg.cost_weight_c_current, tbl_dbo_episode_srg.cost_weight_d_current, tbl_dbo_episode_srg.cost_weight_e_current, tbl_dbo_episode_srg.cost_weight_f_current, tbl_dbo_episode_srg.trim_point, [outlier_days_1]+[outlier_days_2], tbl_dbo_episode_srg.surgery_indicator, tbl_dbo_episode_ats.area_identifier,  tbl_dbo_episode_ats.financial_program, tbl_dbo_stay.facility_trans_to, tbl_dbo_stay.facility_trans_from, [tbl_dbo_episode_ats]![mrn], tbl_dbo_episode_DRG.mdc, tbl_dbo_stay.indicator_procedure_code, tbl_dbo_wl_exit1.booking_identifier, tbl_dbo_wl_exit1.waiting_list_category, tbl_dbo_wl_exit1.clinical_urg_final_crnt, tbl_dbo_wl_exit1.reason_for_removal, tbl_dbo_episode_DRG.an_drg_pccl, tbl_dbo_episode_ats.indigenous_status, tbl_dbo_stay.indigenous_status, tbl_dbo_stay.mothers_mrn, IIf([mothers_stay_number]="","",IIf([mothers_stay_number] Is Null,"","SN" & Trim([mothers_stay_number]))), tbl_dbo_stay.mothers_person_identifier, IIf([tbl_dbo_episode_ats]![payment_status_on_sep] In ("20","23","24","45"),"Public",IIf([tbl_dbo_episode_ats]![payment_status_on_sep] In ("30","31","32","33","34","35","36","46"),"Private",IIf([tbl_dbo_episode_ats]![payment_status_on_sep] In ("40","41","42","43","50","51","52","60"),"Compensable"))), tbl_dbo_stay.medicare_eligibility_status, tbl_dbo_episode_ats.facility_type, Replace([Forms]![Frm:1-ExtractSetUp]![fm_round],"V",""), IIf([tbl_Patient_Contact_Details]![AUID] Is Not Null,[tbl_Patient_Contact_Details]![AUID]), tbl_dbo_stay.LHD_of_Usual_residence, tbl_dbo_episode_DRG.[2_mdc], [SNAP File 2 01].sa_total_leave_days, IIf([Grouped status]="AMHCC","",IIf([SNAP File 2 01]![Snap ClassV4] Is Null,"4999",IIf([SNAP File 2 01]![Snap ClassV4]="","4999",[SNAP File 2 01]![Snap ClassV4]))), snapApp_CostingExtract.sa_occdays_in_cost_period, snapApp_CostingExtract.sa_leave_days_in_cost_period, (Trim([tbl_dbo_DAYS_EPISODE]![facility_identifier] & "-" & [tbl_dbo_DAYS_EPISODE]![specialty_unit_code])), [qry specialtyportal].SpecialityPortal, IIf([Grouped status]="AMHCC","",[snapApp_CostingExtract]![Snap ClassV4]), [SNAP File 2 01].Dementia_Flag, [SNAP File 2 01].Delirium_Flag, tbl_dbo_stay.contract_status, tbl_dbo_stay.collabrtve_care_role, tbl_dbo_stay.collabrtve_care_facility, tbl_dbo_stay.collabrtve_care_type, Format([HIE Extract Date],"yyyy-mm-dd hh:nn:ss"), IIf([grouped status]="AMHCC",[snapApp_CostingExtract]![Snap ClassV4]), IIf([grouped status]="AMHCC",1), snapApp_CostingExtract.HON1, snapApp_CostingExtract.HON2, snapApp_CostingExtract.HON3, snapApp_CostingExtract.HON4, snapApp_CostingExtract.HON5, snapApp_CostingExtract.HON6, snapApp_CostingExtract.HON7, snapApp_CostingExtract.HON8, snapApp_CostingExtract.HON9, snapApp_CostingExtract.HON10, snapApp_CostingExtract.HON11, snapApp_CostingExtract.HON12, snapApp_CostingExtract.HON13, snapApp_CostingExtract.HON14, snapApp_CostingExtract.HON15, snapApp_CostingExtract.WIP, Format([tbl_dbo_episode]![startdate] & " " & [tbl_dbo_episode]![starttime],"yyyy-mm-dd hh:nn:ss"), IIf([Episode ATS end date update]![facility_identifier] Is Not Null,Null,Format([tbl_dbo_episode_ats]![episode_end_date] & " " & [tbl_dbo_episode_ats]![episode_end_time],"yyyy-mm-dd hh:nn:ss")), Format([tbl_dbo_episode]![enddate] & " " & [tbl_dbo_episode]![endtime],"yyyy-mm-dd hh:nn:ss"), tbl_dbo_episode.episode_length_of_stay, tbl_dbo_episode_ats.episode_length_of_stay, tbl_dbo_episode_ats.episode_leave_days_total, tbl_dbo_episode.episode_of_care_type, tbl_dbo_episode_ats.episode_of_care_type, snapApp_CostingExtract.PhaseSeqNo, bl_dbo_episode_srg.cost_weight_e_current, bl_dbo_episode_ats.area_identifier, snapApp_CostingExtract.[Snap ClassV4], tbl_dbo_episode_ats.episode_leave_days_total, tbl_dbo_episode_ats.episode_of_care_type
    tbl_dbo_episode_ats["mrn_ats"] = tbl_dbo_episode_ats["mrn"]
    # df_query1 = pd.merge(tbl_dbo_episode_ats[['area_identifier', 'days_in_psych_unit', 'episode_end_date', 'episode_end_time', 'episode_leave_days_total', 'episode_length_of_stay', 'episode_of_care_type', 'episode_sequence_number', 'episode_start_date', 'episode_start_time', 'facility_identifier', 'facility_type', 'financial_class', 'financial_program', 'hours_in_icu', 'hours_in_psych_unit', 'legal_status_on_admit', 'mode_of_separation', 'mrn_ats', 'payment_status_on_sep', 'qualified_bed_time', 'qualified_bed_days', 'source_of_referral', 'stay_number', 'unplanned_theatre']], tbl_dbo_days_episode[['episode_sequence_number', 'facility_identifier', 'mo_code', 'specialty_unit_code', 'start_date', 'start_time', 'stay_number']], how='left', left_on=['episode_sequence_number', 'stay_number', 'facility_identifier', 'episode_start_date', 'episode_start_time'], right_on=['episode_sequence_number', 'stay_number', 'facility_identifier', 'start_date', 'start_time'], suffixes=('', '_drop'))
    df_query1 = pd.merge(
        tbl_dbo_episode_ats[
            [
                "area_identifier",
                "days_in_psych_unit",
                "episode_end_date",
                "episode_end_time",
                "episode_leave_days_total",
                "episode_length_of_stay",
                "episode_of_care_type",
                "episode_sequence_number",
                "episode_start_date",
                "episode_start_time",
                "facility_identifier",
                "facility_type",
                "financial_class",
                "financial_program",
                "hours_in_icu",
                "hours_in_psych_unit",
                "legal_status_on_admit",
                "mode_of_separation",
                "mrn_ats",
                "payment_status_on_sep",
                "qualified_bed_time",
                "qualified_bed_days",
                "source_of_referral",
                "stay_number",
                "unplanned_theatre",
                "HLTH_ORG_OSP_OSP_ID",
                "MG_AUTH_OSP_OSP_ID",
                "SE_CBK_SK",
                "CL_ID_EUID",
                "CL_ID_IHI",
                "HLTH_ORG_OSP_TYP",
                "ICU1_Hours",
                "ICU2_Hours",
                "ICU_Hours",
                "CCU_Hours",
                "HDU_Hours",
                "NICU_Hours",
                "SRV_ENC_REC_ID",
                "FRML_DISCH_MODE_CD",
                "SE_SEP_MODE_NHDD_CD",
                "Responsible_Facility",
                "SE_TYP_CD",
                "SE_ADM_MODE_NHDD_CD",
            ]
        ],
        tbl_dbo_days_episode[
            [
                "episode_sequence_number",
                "facility_identifier",
                "mo_code",
                "specialty_unit_code",
                "start_date",
                "start_time",
                "stay_number",
                "DIM_RSP_ISP_SK",
            ]
        ],
        how="left",
        left_on=[
            "episode_sequence_number",
            "stay_number",
            "facility_identifier",
            "episode_start_date",
            "episode_start_time",
        ],
        right_on=[
            "episode_sequence_number",
            "stay_number",
            "facility_identifier",
            "start_date",
            "start_time",
        ],
        suffixes=("", "_drop"),
    )
    df_query1 = df_query1.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    # 27 July 2024 - stay - episode seq number
    # df_query2 = pd.merge(tbl_dbo_stay[['admission_date', 'age', 'area_of_usual_residence', 'collabrtve_care_facility', 'collabrtve_care_role', 'collabrtve_care_type', 'contract_status', 'dva_card_number', 'dva_card_type', 'election_status_on_admit', 'emergency_status', 'facility_identifier', 'facility_trans_from', 'facility_trans_to', 'indicator_procedure_code', 'insurance_fund_master', 'LHD_of_Usual_residence', 'marital_status', 'medicare_eligibility_status', 'medicare_number', 'mothers_mrn', 'mothers_person_identifier', 'mrn', 'patient_postcode', 'patient_suburb', 'person_identifier', 'readmit_this_hosp_28_days', 'referred_to_on_separation', 'stay_discharge_intention', 'mothers_stay_number', 'stay_number', 'indigenous_status']], tbl_dbo_wl_exit1[['booking_identifier', 'clinical_urg_final_crnt', 'facility_identifier', 'person_identifier', 'reason_for_removal', 'removal_date', 'waiting_list_category']], how='left', left_on=['facility_identifier', 'person_identifier', 'admission_date'], right_on=['facility_identifier', 'person_identifier', 'removal_date'], suffixes=('', '_drop'))
    df_query2 = pd.merge(
        tbl_dbo_stay[
            [
                "admission_date",
                "age",
                "area_of_usual_residence",
                "collabrtve_care_facility",
                "collabrtve_care_role",
                "collabrtve_care_type",
                "contract_status",
                "dva_card_number",
                "dva_card_type",
                "election_status_on_admit",
                "emergency_status",
                "facility_identifier",
                "facility_trans_from",
                "facility_trans_to",
                "indicator_procedure_code",
                "insurance_fund_master",
                "LHD_of_Usual_residence",
                "marital_status",
                "medicare_eligibility_status",
                "medicare_number",
                "mothers_mrn",
                "mothers_person_identifier",
                "mrn",
                "patient_postcode",
                "patient_suburb",
                "person_identifier",
                "readmit_this_hosp_28_days",
                "referred_to_on_separation",
                "stay_discharge_intention",
                "mothers_stay_number",
                "stay_number",
                "indigenous_status",
                "episode_sequence_number",
                "ASGS_SA_L2_16_CD",
                "CL_URES_ADDR_ASGS21_SA_L2_CD",
            ]
        ],
        tbl_dbo_wl_exit1[
            [
                "booking_identifier",
                "clinical_urg_final_crnt",
                "facility_identifier",
                "person_identifier",
                "reason_for_removal",
                "removal_date",
                "waiting_list_category",
            ]
        ],
        how="left",
        left_on=["facility_identifier", "person_identifier", "admission_date"],
        right_on=["facility_identifier", "person_identifier", "removal_date"],
        suffixes=("", "_drop"),
    )
    df_query2 = df_query2.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    # 27 July 2024 - stay - episode seq number
    # df_query3 = pd.merge(df_query1, df_query2, how='left', on=['facility_identifier', 'stay_number'], suffixes=('', '_drop'))
    df_query3 = pd.merge(
        df_query1,
        df_query2,
        how="left",
        on=["facility_identifier", "stay_number", "episode_sequence_number"],
        suffixes=("", "_drop"),
    )
    df_query3["mrn"] = df_query3["mrn"].astype(str).apply(lambda x: x.replace(".0", ""))
    df_query3 = df_query3.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    df_query4 = pd.merge(
        df_query3,
        tbl_dbo_episode_srg[
            [
                "cost_weight_a_current",
                "cost_weight_b_current",
                "cost_weight_c_current",
                "cost_weight_d_current",
                "cost_weight_e_current",
                "cost_weight_f_current",
                "ed_status",
                "episode_sequence_number",
                "esrg_current",
                "facility_identifier",
                "icu_status",
                "outlier_days_1",
                "outlier_days_2",
                "srg_current",
                "stay_number",
                "surgery_indicator",
                "trim_point",
                "srg_version_number",
            ]
        ],
        how="left",
        on=["facility_identifier", "stay_number", "episode_sequence_number"],
        suffixes=("", "_drop"),
    )
    df_query4 = df_query4.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    # df_query4['Extra:SRG_Version'] = df_query4['srg_version_number']
    df_query4["stay_number"] = (
        df_query4["stay_number"].astype(str).str.pad(8, side="left", fillchar="0")
    )
    tbl_dbo_episode_DRG["stay_number"] = (
        tbl_dbo_episode_DRG["stay_number"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0")
    )
    df_query4["episode_sequence_number"] = (
        df_query4["episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    tbl_dbo_episode_DRG["episode_sequence_number"] = (
        tbl_dbo_episode_DRG["episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    df_query5 = pd.merge(
        df_query4,
        tbl_dbo_episode_DRG[
            [
                "2_an_drg_version",
                "2_mdc",
                "an_drg",
                "an_drg_pccl",
                "an_drg_version",
                "episode_sequence_number",
                "facility_identifier",
                "mdc",
                "stay_number",
                "2_an_drg",
                "AR_DRG_ECCS_RAW",
            ]
        ],
        how="left",
        on=["facility_identifier", "stay_number", "episode_sequence_number"],
        suffixes=("", "_drop"),
    )
    df_query5 = df_query5.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    tbl_Patient_Contact_Details["contact_identifier"] = (
        tbl_Patient_Contact_Details["contact_identifier"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0")
    )
    tbl_Patient_Contact_Details["AUID"] = np.where(
        tbl_Patient_Contact_Details["AUID"] != "",
        tbl_Patient_Contact_Details["AUID"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0"),
        "",
    )
    df_query5["stay_number"] = (
        df_query5["stay_number"].astype(str).str.pad(8, side="left", fillchar="0")
    )
    df_query6 = pd.merge(
        df_query5,
        tbl_Patient_Contact_Details[
            ["AUID", "contact_identifier", "facility_identifier"]
        ],
        how="left",
        left_on=["facility_identifier", "stay_number"],
        right_on=["facility_identifier", "contact_identifier"],
        suffixes=("", "_drop"),
    )
    df_query6 = df_query6.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    tbl_dbo_episode["episode_of_care_type_dbo"] = tbl_dbo_episode[
        "episode_of_care_type"
    ]
    tbl_dbo_episode.drop(
        ["episode_of_care_type"], axis=1, inplace=True, errors="ignore"
    )
    tbl_dbo_episode["episode_length_of_stay_dbo"] = tbl_dbo_episode[
        "episode_length_of_stay"
    ]
    tbl_dbo_episode.drop(
        ["episode_length_of_stay"], axis=1, inplace=True, errors="ignore"
    )
    df_query7 = pd.merge(
        df_query6,
        tbl_dbo_episode[
            [
                "enddate",
                "endtime",
                "episode_length_of_stay_dbo",
                "episode_of_care_type_dbo",
                "episode_sequence_number",
                "facility_identifier",
                "hours_on_mech_vent_num",
                "infant_start_weight",
                "startdate",
                "starttime",
                "stay_number",
            ]
        ],
        how="left",
        on=["facility_identifier", "stay_number", "episode_sequence_number"],
        suffixes=("", "_drop"),
    )
    df_query7 = df_query7.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    tbl_dbo_episode["episode_of_care_type"] = tbl_dbo_episode[
        "episode_of_care_type_dbo"
    ]
    tbl_dbo_episode["episode_length_of_stay"] = tbl_dbo_episode[
        "episode_length_of_stay_dbo"
    ]
    tbl_Episode_ATS_end_date_update[
        "facility_identifier_tbl_Episode_ATS_end_date_update"
    ] = tbl_Episode_ATS_end_date_update["facility_identifier"]
    df_query8 = pd.merge(
        df_query7,
        tbl_Episode_ATS_end_date_update[
            [
                "episode_sequence_number",
                "facility_identifier",
                "stay_number",
                "facility_identifier_tbl_Episode_ATS_end_date_update",
            ]
        ],
        how="left",
        on=["facility_identifier", "stay_number", "episode_sequence_number"],
        suffixes=("", "_drop"),
    )
    df_query8 = df_query8.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    qry_SpecialtyPortal["stay_number"] = (
        qry_SpecialtyPortal["stay_number"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0")
    )
    qry_SpecialtyPortal["episode_sequence_number"] = (
        qry_SpecialtyPortal["episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    df_query9 = pd.merge(
        df_query8,
        qry_SpecialtyPortal[
            [
                "facility_identifier",
                "stay_number",
                "episode_sequence_number",
                "SpecialityPortal",
            ]
        ],
        how="left",
        on=["facility_identifier", "stay_number", "episode_sequence_number"],
        suffixes=("", "_drop"),
    )
    df_query9 = df_query9.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    df_query9["stay_number"] = df_query9["stay_number"].astype(str).str.strip()
    df_query9["episode_sequence_number"] = (
        df_query9["episode_sequence_number"].astype(str).str.strip()
    )
    df_query9["stay_number"] = (
        df_query9["stay_number"].astype(str).str.pad(8, side="left", fillchar="0")
    )
    df_query9["episode_sequence_number"] = (
        df_query9["episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    snapFile201["Snap ClassV4 snapFile201"] = snapFile201["Snap ClassV4"]
    # df_query10 = pd.merge(snapApp_CostingExtract[['EncounterEnd', 'EncounterNumber', 'EncounterStart', 'Grouped Status', 'HON1', 'HON10', 'HON11', 'HON12', 'HON13', 'HON14', 'HON15', 'HON2', 'HON3', 'HON4', 'HON5', 'HON6', 'HON7', 'HON8', 'HON9', 'PhaseSeqNo', 'sa_leave_days_in_cost_period', 'sa_occdays_in_cost_period', 'sa_total_los', 'Snap ClassV4', 'WIP', 'HIE Extract Date', 'sa_episode_sequence_number', 'stay_number_cost', 'FacilityCode']], snapFile201[['Delirium_Flag', 'Dementia_Flag', 'EncounterNumber', 'sa_total_leave_days', 'Snap ClassV4 snapFile201']], how='inner', on=['EncounterNumber'], suffixes=('', '_drop'))

    # 21 Jan 2025 - no need to change the below merge as EncounterNUmber has been derived using 'PCSNAP_PhaseID', 'SNAPEpisodeID'
    df_query10 = pd.merge(
        snapApp_CostingExtract,
        snapFile201,
        how="inner",
        on=["EncounterNumber"],
        suffixes=("", "_drop"),
    )
    # df_query10 = pd.merge(snapApp_CostingExtract, snapFile201, how='inner', on=['SE_CBK_SK', 'PCSNAP_PhaseID', 'SNAPEpisodeID'], suffixes=('', '_drop'))

    df_query10 = df_query10.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    # tbl_ExcludedEncounters ON snapApp_CostingExtract.EncounterNumber = tbl_ExcludedEncounters.SNAP_encounter) ON ((snapApp_CostingExtract.FacilityCode = tbl_dbo_episode_ats.facility_identifier ) AND (snapApp_CostingExtract.stay_number_cost = tbl_dbo_episode_ats.stay_number ) AND (snapApp_CostingExtract.sa_episode_sequence_number = tbl_dbo_episode_ats.episode_sequence_number )))
    # WHERE (((tbl_ExcludedEncounters.SNAP_encounter) Is Null))
    # df_query11 = pd.merge(df_query10, tbl_ExcludedEncounters[['SNAP_encounter']], how='left', left_on=['EncounterNumber'], right_on=['SNAP_encounter'], suffixes=('', '_drop'), indicator=True)
    # NOTE BY RANJIT - SNAP+AMHCC uses Resp Facility. Excluded Encounters may be using Created fAcility (depends on user). So this step might not work from v1.14 onwards.
    df_query11 = pd.merge(
        df_query10,
        tbl_ExcludedEncounters[["SNAP_encounter", "EncounterNumber"]],
        how="left",
        left_on=["EncounterNumber"],
        right_on=["EncounterNumber"],
        suffixes=("", "_drop"),
        indicator=True,
    )
    df_query11 = df_query11.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    df_query11 = df_query11[(df_query11["_merge"] == "left_only")]
    df_query11 = df_query11[
        (df_query11["SNAP_encounter"] == "") | (df_query11["SNAP_encounter"].isnull())
    ]
    df_query11["stay_number_cost"] = (
        df_query11["stay_number_cost"].astype(str).str.strip()
    )
    df_query11["sa_episode_sequence_number"] = (
        df_query11["sa_episode_sequence_number"].astype(str).str.strip()
    )
    df_query11["stay_number_cost"] = (
        df_query11["stay_number_cost"].astype(str).str.pad(8, side="left", fillchar="0")
    )
    df_query11["sa_episode_sequence_number"] = (
        df_query11["sa_episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    # 11 Jan 2024 - CREATED FACILITY CHANGE
    # df_query12 = pd.merge(df_query9, df_query11, how='inner', left_on=['facility_identifier', 'stay_number', 'episode_sequence_number'], right_on=['FacilityCode', 'stay_number_cost', 'sa_episode_sequence_number'], suffixes=('', '_drop'))
    df_query12 = pd.merge(
        df_query9,
        df_query11,
        how="inner",
        left_on=["SE_CBK_SK"],
        right_on=["SE_CBK_SK"],
        suffixes=("", "_drop"),
    )
    df_query12 = df_query12.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    # IIf([tbl_dbo_episode_ats]![payment_status_on_sep] In ("20","23","24","45"),"Public",IIf([tbl_dbo_episode_ats]![payment_status_on_sep] In ("30","31","32","33","34","35","36","46"),"Private",IIf([tbl_dbo_episode_ats]![payment_status_on_sep] In ("40","41","42","43","50","51","52","60"),"Compensable"))) AS Expr16
    # condlist = [df_query12['payment_status_on_sep'].isin(["20","23","24","45"]), df_query12['payment_status_on_sep'].isin(["30","31","32","33","34","35","36","46"]), df_query12['payment_status_on_sep'].isin(["40","41","42","43","50","51","52","60"])]
    condlist = [
        df_query12["payment_status_on_sep"].isin([20, 23, 24, 45]),
        df_query12["payment_status_on_sep"].isin([30, 31, 32, 33, 34, 35, 36, 46]),
        df_query12["payment_status_on_sep"].isin([40, 41, 42, 43, 50, 51, 52, 60]),
    ]
    choicelist = ["Public", "Private", "Compensable"]
    df_query12["Extra:ElectionStatusSummary"] = np.select(condlist, choicelist, "NULL")
    # IIf([Grouped status]="AMHCC","",IIf([SNAP File 2 01]![Snap ClassV4] Is Null,"4999",IIf([SNAP File 2 01]![Snap ClassV4]="","4999",[SNAP File 2 01]![Snap ClassV4]))) AS Expr23
    condlist = [
        df_query12["Grouped Status"] == "AMHCC",
        (df_query12["Grouped Status"] != "AMHCC")
        & (
            (df_query12["sa_nwau_version"] == "23")
            | (df_query12["sa_nwau_version"] == 23)
        )
        & (
            (df_query12["Snap ClassV4 snapFile201"].isnull())
            | (df_query12["Snap ClassV4 snapFile201"] == "")
        ),
        (df_query12["Grouped Status"] != "AMHCC")
        & (
            (df_query12["sa_nwau_version"].isin(["24", "25", "26"]))
            | (df_query12["sa_nwau_version"].isin([24, 25, 26]))
        )
        & (
            (df_query12["Snap ClassV4 snapFile201"].isnull())
            | (df_query12["Snap ClassV4 snapFile201"] == "")
        ),
    ]
    choicelist = ["", "4999", "5999"]
    df_query12["Extra:SNAP_Class"] = np.select(
        condlist, choicelist, df_query12["Snap ClassV4 snapFile201"]
    )
    df_query12["Extra:MothersStayNumber"] = np.where(
        (
            (df_query12["mothers_stay_number"].isnull())
            | (df_query12["mothers_stay_number"].astype(str).str.strip() == "")
            | (df_query12["mothers_stay_number"].astype(str).str.strip() == "nan")
            | (df_query12["mothers_stay_number"] == "00000nan")
        ),
        "",
        "SN" + df_query12["mothers_stay_number"].astype(str).str.strip(),
    )  # IIf([mothers_stay_number]="","",IIf([mothers_stay_number] Is Null,"","SN" & Trim([mothers_stay_number]))) AS Expr20
    # IIf([SNAP File 2 01]![Snap ClassV4] Is Null,"4999",IIf([SNAP File 2 01]![Snap ClassV4]="","4999",[SNAP File 2 01]![Snap ClassV4])) & "-" & IIf([tbl_dbo_episode_DRG]![an_drg] Is Null,"960Z",[tbl_dbo_episode_DRG]![an_drg]) AS Expr15
    # df_query12['Snap ClassV4 snapFile201_dummy'] = np.where((df_query12['Snap ClassV4 snapFile201'].isnull()) | (df_query12['Snap ClassV4 snapFile201']==''),'4999', df_query12['Snap ClassV4 snapFile201'])
    condlist = [
        (
            (df_query12["sa_nwau_version"] == "23")
            | (df_query12["sa_nwau_version"] == 23)
        )
        & (
            (df_query12["Snap ClassV4 snapFile201"].isnull())
            | (df_query12["Snap ClassV4 snapFile201"] == "")
        ),
        (
            (df_query12["sa_nwau_version"].isin(["24", "25", "26"]))
            | (df_query12["sa_nwau_version"].isin([24, 25, 26]))
        )
        & (
            (df_query12["Snap ClassV4 snapFile201"].isnull())
            | (df_query12["Snap ClassV4 snapFile201"] == "")
        ),
    ]
    choicelist = ["4999", "5999"]
    df_query12["Snap ClassV4 snapFile201_dummy"] = np.select(
        condlist, choicelist, df_query12["Snap ClassV4 snapFile201"]
    )
    df_query12["an_drg_dummy"] = np.where(
        (df_query12["an_drg"].isnull()) | (df_query12["an_drg"] == ""),
        "960Z",
        df_query12["an_drg"],
    )
    """
    From: Kylie Hawkins <Kylie.Hawkins2@health.nsw.gov.au> 
    Sent: Friday, July 26, 2024 1:39 PM
    To: Ranjit Sukumaran <Ranjit.Sukumaran@health.nsw.gov.au>; Badari Lanka Venkata <Badari.LankaVenkata@health.nsw.gov.au>; Janardan Gollada <Janardan.Gollada@health.nsw.gov.au>
    Cc: Tony Hutton <Tony.Hutton@health.nsw.gov.au>; Jeanette Friend <Jeanette.Friend@health.nsw.gov.au>
    Subject: Classification IP Encounter File
    Hi guys
    WSLHD have indicated that the SNAP and DRG or AMHCC combination codes are still in the DRGV11 classification column. So there is a lot of codes being added to the reference tables which shouldnt be there. Can you please check if DRG only is going into the DRGV11 column, SNAP into SNAP and AMHCC into AMHCC and they are not mixing?
    """
    # df_query12['DRG1'] = df_query12['Snap ClassV4 snapFile201_dummy'].astype(str).str.strip()+'-'+df_query12['an_drg_dummy'].astype(str).str.strip()
    df_query12["DRG1"] = df_query12["an_drg_dummy"].astype(str).str.strip()
    """
    condlist = [((df_query12['Snap ClassV4 snapFile201'].isnull()) | (df_query12['Snap ClassV4 snapFile201']=='')), (df_query12['Snap ClassV4 snapFile201']!='') & (pd.notna(df_query12['Snap ClassV4 snapFile201'])) & ((df_query12['an_drg'].isnull()) | (df_query12['an_drg']==''))]
    choicelist = ['4999', df_query12['Snap ClassV4 snapFile201'].astype(str).str.strip()+'960Z']
    df_query12['DRG1'] = np.select(condlist, choicelist, df_query12['Snap ClassV4 snapFile201'].astype(str).str.strip()+df_query12['an_drg'].astype(str).str.strip())
    """
    # [tbl_dbo_episode_ats]![facility_identifier] & "-" & Format(IIf([tbl_Patient_Contact_Details]![AUID] Is Not Null,[tbl_Patient_Contact_Details]![AUID],Right([tbl_dbo_stay]![mrn],10)),"0000000000") AS Expr9
    df_query12["mrn"] = df_query12["mrn"].astype(str).str.strip()
    df_query12["MRN_dummy"] = df_query12["mrn"].str[-10:]
    df_query12["MRN_dummy"] = np.where(
        df_query12["MRN_dummy"] == "",
        "",
        df_query12["MRN_dummy"].astype(str).str.pad(10, side="left", fillchar="0"),
    )
    df_query12["AUID_dummy"] = df_query12["AUID"].astype(str).str.strip()
    df_query12["AUID"] = df_query12["AUID"].astype(str).str.replace("nan", "")
    df_query12["AUID_dummy"] = (
        df_query12["AUID_dummy"].astype(str).str.replace("nan", "")
    )
    # AQA-270 - In Patient Stay Number not visible for X740
    # df_query12['dummy_mrn_auid'] = np.where((df_query12['AUID_dummy']=='') | ((df_query12['AUID_dummy']!='') & ~(df_query12['area_identifier'].isin(['X830','X860','X840', 'X850', 'X740']))), df_query12['MRN_dummy'], df_query12['AUID_dummy'].astype(str).str.pad(10, side ='left', fillchar ='0'))
    # df_query12['dummy_mrn_auid'] = np.where((df_query12['AUID_dummy']=='') | (df_query12['area_identifier'].isin(['X740'])) | ((df_query12['AUID_dummy']!='') & ~(df_query12['area_identifier'].isin(['X830','X860','X840', 'X850']))), df_query12['MRN_dummy'], df_query12['AUID_dummy'].astype(str).str.pad(10, side ='left', fillchar ='0'))
    df_query12["dummy_mrn_auid"] = np.where(
        (df_query12["AUID_dummy"] == "")
        | (
            (df_query12["AUID_dummy"] != "")
            & ~(
                df_query12["area_identifier"].isin(
                    ["X830", "X860", "X840", "X850", "X740", "X170"]
                )
            )
        ),
        df_query12["MRN_dummy"],
        df_query12["AUID_dummy"].astype(str).str.pad(10, side="left", fillchar="0"),
    )
    # 29 Jan 2025 - 151 for SNAP and MH, use responsible facility for MH. so use FacilityCode from InforMH/SIA instead of facility_identifier from EDW DB.
    df_query12["PatientNumber"] = (
        df_query12["facility_identifier"].astype(str).str.strip()
        + "-"
        + df_query12["dummy_mrn_auid"].astype(str).str.strip()
    )
    # df_query12['PatientNumber'] = df_query12['FacilityCode'].astype(str).str.strip()+ "-" + df_query12['dummy_mrn_auid'].astype(str).str.strip()

    df_query12["PatientNumber"] = df_query12["PatientNumber"]
    df_query12["Extra:SRG_Version"] = df_query12["srg_version_number"]
    # IIf([tbl_dbo_episode_srg]![ed_status] In ("1","4","04","01"),"X",IIf([tbl_dbo_episode_ats]![episode_of_care_type]='5' And [tbl_dbo_episode_ats]![qualified_bed_time]=0 And [tbl_dbo_episode_ats]![qualified_bed_days]=0,"X","I")) AS Expr13
    df_query12["qualified_bed_time"] = (
        df_query12["qualified_bed_time"].fillna(0).astype(int, errors="ignore")
    )
    df_query12["qualified_bed_days"] = (
        df_query12["qualified_bed_days"].fillna(0).astype(int, errors="ignore")
    )
    # df_query12['EncounterType'] = np.where((df_query12['ed_status'].isin(['1', '4', '04', '01'])) | (~(df_query12['ed_status'].isin(['1', '4', '04', '01'])) & (df_query12['episode_of_care_type']=='5') & (df_query12['qualified_bed_time'].replace('','0').apply(lambda x: int(float(x)))==0) & (df_query12['qualified_bed_days'].replace('','0').apply(lambda x: int(float(x)))==0)), 'X','I')
    df_query12["EncounterType"] = np.where(
        (df_query12["ed_status"].isin(["1", "4", "04", "01"]))
        | (
            ~(df_query12["ed_status"].isin(["1", "4", "04", "01"]))
            & (df_query12["episode_of_care_type"].astype(str).str.strip() == "5")
            & (df_query12["qualified_bed_time"] == 0)
            & (df_query12["qualified_bed_days"] == 0)
        ),
        "X",
        "I",
    )
    df_query12["DRG1Version"] = np.where(
        (df_query12["Grouped Status"] == "AMHCC"), amhcc_v, snap_v
    )  # IIf([snapApp_CostingExtract]![Grouped Status]="AMHCC", [Forms]![Frm:1-ExtractSetUp]![AMHCCV], [Forms]![Frm:1-ExtractSetUp]![SNAPV]) AS Expr18
    df_query12["DRG3Version"] = np.where(
        (df_query12["an_drg_version"].isnull()) | (df_query12["an_drg_version"] == ""),
        drg1_v,
        df_query12["an_drg_version"],
    )  # IIf([tbl_dbo_episode_DRG]![an_drg_version] Is Null, [Forms]![Frm:1-ExtractSetUp]![DRG1V], [tbl_dbo_episode_DRG]![an_drg_version]) AS Expr17
    df_query12["DRG2Version"] = np.where(
        (df_query12["2_an_drg_version"].isnull())
        | (df_query12["2_an_drg_version"] == ""),
        drg2_v,
        df_query12["2_an_drg_version"],
    )  # IIf([tbl_dbo_episode_DRG]![2_an_drg_version] Is Null, [Forms]![Frm:1-ExtractSetUp]![DRG2V], [tbl_dbo_episode_DRG]![2_an_drg_version]) AS Expr22
    # df_query12['hours_in_psych_unit'] = np.where((df_query12['hours_in_psych_unit'].isnull()) | (df_query12['hours_in_psych_unit'].astype(str)=='') | (df_query12['hours_in_psych_unit'].astype(str)=='nan'), 0, df_query12['hours_in_psych_unit'].astype(int, errors='ignore'))
    # df_query12['days_in_psych_unit'] = np.where((df_query12['days_in_psych_unit'].isnull()) | (df_query12['days_in_psych_unit']=='') | (df_query12['days_in_psych_unit'].astype(str)=='nan'), 0, df_query12['days_in_psych_unit'].astype(int, errors='ignore'))
    df_query12["hours_in_psych_unit"] = df_query12["hours_in_psych_unit"].astype(
        int, errors="ignore"
    )
    df_query12["days_in_psych_unit"] = df_query12["days_in_psych_unit"].astype(
        int, errors="ignore"
    )
    df_query12["Extra:DaysinPsychUnit"] = np.where(
        (df_query12["hours_in_psych_unit"] > 0)
        & (df_query12["days_in_psych_unit"] == 0),
        1,
        df_query12["days_in_psych_unit"],
    )  # IIf([tbl_dbo_episode_ats]![hours_in_psych_unit]>0 And [tbl_dbo_episode_ats]![days_in_psych_unit]=0,1, [tbl_dbo_episode_ats]![days_in_psych_unit]) AS Expr28
    df_query12["AdmissionWeight"] = np.where(
        (
            df_query12["infant_start_weight"].isnull()
            | (df_query12["infant_start_weight"] == "")
        ),
        0,
        df_query12["infant_start_weight"],
    )  # IIf([tbl_dbo_episode]![infant_start_weight]="",0,[tbl_dbo_episode]![infant_start_weight]) AS Expr4
    df_query12["DRG2"] = np.where(
        (df_query12["2_an_drg"].isnull() | (df_query12["2_an_drg"] == "")),
        "960Z",
        df_query12["2_an_drg"],
    )  # IIf([2_an_drg] Is Null,"960Z",[2_an_drg]) AS Expr21
    df_query12["DRG3"] = np.where(
        (df_query12["an_drg"].isnull() | (df_query12["an_drg"] == "")),
        "960Z",
        df_query12["an_drg"],
    )  # IIf([tbl_dbo_episode_DRG]![an_drg] Is Null,"960Z",[tbl_dbo_episode_DRG]![an_drg]) AS Expr3
    df_query12["Extra:AUID"] = np.where(
        pd.notna(df_query12["AUID"]) & (df_query12["AUID"] != ""),
        df_query12["AUID"],
        "",
    )  # IIf([tbl_Patient_Contact_Details]![AUID] Is Not Null,[tbl_Patient_Contact_Details]![AUID]) AS Expr19
    """df_query12['Extra:VersionID'] = versionID_dot #Replace([Forms]![Frm:1-ExtractSetUp]![fm_round],"V","") AS versionid
    df_query12['Extra:VersionID'] = df_query12['Extra:VersionID'].astype(str).str.replace('V' ,'')"""
    df_query12["Extra:ExtractorVersion"] = "1.17"
    df_query12["facility_identifier"] = np.where(
        df_query12["facility_identifier"] == "nan",
        "",
        df_query12["facility_identifier"],
    )
    df_query12["specialty_unit_code"] = np.where(
        df_query12["specialty_unit_code"] == "nan",
        "",
        df_query12["specialty_unit_code"],
    )
    # df_query12['AttendingConsultantSpecialty'] = df_query12['facility_identifier'].astype(str).str.strip() +'-'+ df_query12['specialty_unit_code'].astype(str).str.strip()
    df_query12["AttendingConsultantSpecialty"] = np.where(
        (df_query12["specialty_unit_code"] == "")
        | (df_query12["specialty_unit_code"].isnull()),
        "",
        df_query12["facility_identifier"].astype(str).str.strip()
        + "-"
        + df_query12["specialty_unit_code"].astype(str).str.strip(),
    )
    # (Trim([tbl_dbo_DAYS_EPISODE]![facility_identifier] & "-" & [tbl_dbo_DAYS_EPISODE]![specialty_unit_code])) AS Expr1
    df_query12["Extra:StartDateTime_EpisodeTable"] = pd.to_datetime(
        (
            df_query12["startdate"].astype(str).str[:10]
            + " "
            + df_query12["starttime"].astype(str).str[-8:]
        ),
        errors="coerce",
        format="%Y-%m-%d %H:%M:%S",
    )  # Format([tbl_dbo_episode]![startdate] & " " & [tbl_dbo_episode]![starttime],"yyyy-mm-dd hh:nn:ss") AS Expr35
    df_query12["Extra:EndDateTime_EpisodeATSTable"] = np.where(
        pd.notna(df_query12["facility_identifier_tbl_Episode_ATS_end_date_update"]),
        "",
        (
            df_query12["episode_end_date"].astype(str).str[:10]
            + " "
            + df_query12["episode_end_time"].astype(str).str[-8:]
        ),
    )  # IIf([Episode ATS end date update]![facility_identifier] Is Not Null,Null,Format([tbl_dbo_episode_ats]![episode_end_date] & " " & [tbl_dbo_episode_ats]![episode_end_time],"yyyy-mm-dd hh:nn:ss")) AS Expr36
    df_query12["Extra:EndDateTime_EpisodeTable"] = (
        df_query12["enddate"].astype(str).str[:10]
        + " "
        + df_query12["endtime"].astype(str).str[-8:]
    )  # Format([tbl_dbo_episode]![enddate] & " " & [tbl_dbo_episode]![endtime],"yyyy-mm-dd hh:nn:ss") AS Expr34
    df_query12["Extra:EndDateTime_EpisodeTable"] = pd.to_datetime(
        df_query12["Extra:EndDateTime_EpisodeTable"],
        errors="coerce",
        format="%Y-%m-%d %H:%M:%S",
    )
    df_query12["Extra:SNAP_ClassV4"] = np.where(
        df_query12["Grouped Status"] == "AMHCC", "", df_query12["Snap ClassV4"]
    )  # IIf([Grouped status]="AMHCC","",[snapApp_CostingExtract]![Snap ClassV4]) AS Expr27
    df_query12["Extra:AMHCC_Class"] = np.where(
        df_query12["Grouped Status"] == "AMHCC", df_query12["Snap ClassV4"], ""
    )  # IIf([grouped status]="AMHCC",[snapApp_CostingExtract]![Snap ClassV4]) AS Expr25
    df_query12["Extra:AMHCC_ClassVersion"] = np.where(
        df_query12["Grouped Status"] == "AMHCC", 1, ""
    )  # IIf([grouped status]="AMHCC",1) AS Expr26
    df_query12["mo_code"] = np.where(
        df_query12["mo_code"] == "nan", "", df_query12["mo_code"]
    )
    df_query12["facility_identifier"] = np.where(
        df_query12["facility_identifier"] == "nan",
        "",
        df_query12["facility_identifier"],
    )
    # df_query12['AttendingConsultant'] = df_query12['facility_identifier'].astype(str).str.strip()+"-"+df_query12['mo_code'].astype(str).str.strip()
    df_query12["AttendingConsultant"] = np.where(
        (df_query12["mo_code"] == "") | (df_query12["mo_code"].isnull()),
        "",
        df_query12["facility_identifier"].astype(str).str.strip()
        + "-"
        + df_query12["mo_code"].astype(str).str.strip(),
    )
    # [tbl_dbo_episode_ats]![facility_identifier] & "-" & Trim([tbl_dbo_days_episode]![mo_code]) AS Expr2
    df_query12["AdmissionType"] = np.where(
        df_query12["episode_end_date"] == df_query12["episode_start_date"], "SD", "ON"
    )  # IIf([tbl_dbo_episode_ats]![episode_end_date] = [tbl_dbo_episode_ats]![episode_start_date],"SD","ON") AS Expr6
    df_query12["Extra:MothersPersonIdentifier"] = df_query12[
        "mothers_person_identifier"
    ]  # tbl_dbo_stay.mothers_person_identifier
    df_query12["WeightedSeparation"] = df_query12[
        "cost_weight_e_current"
    ]  # tbl_dbo_episode_srg.cost_weight_e_current
    df_query12["Extra:LGACode"] = df_query12[
        "area_of_usual_residence"
    ]  # tbl_dbo_stay.area_of_usual_residence
    df_query12["stay_number"] = df_query12["stay_number"].astype(str).str.strip()
    df_query12["stay_number"] = np.where(
        df_query12["stay_number"].str[:1] == "0",
        df_query12["stay_number"].str[1:],
        df_query12["stay_number"].astype(str).str.replace("SN", ""),
    )
    df_query12["stay_number"] = np.where(
        (pd.notna(df_query12["stay_number"]) & (df_query12["stay_number"] != "")),
        df_query12["stay_number"].astype(str).str.pad(8, side="left", fillchar="0"),
        "",
    )
    df_query12["Extra:HospitalStayNumber"] = np.where(
        (pd.notna(df_query12["stay_number"]) & (df_query12["stay_number"] != "")),
        "SN" + df_query12["stay_number"].astype(str).str.strip(),
        "",
    )  # "SN" & Trim([tbl_dbo_episode_ats]![stay_number]) AS Expr11
    df_query12["Extra:LHDIdentifier"] = df_query12[
        "area_identifier"
    ]  # tbl_dbo_episode_ats.area_identifier
    df_query12["Extra:LegalStatus"] = df_query12[
        "legal_status_on_admit"
    ]  # tbl_dbo_episode_ats.legal_status_on_admit
    df_query12["Extra:DVANumber"] = df_query12[
        "dva_card_number"
    ]  # tbl_dbo_stay.dva_card_number
    df_query12["Extra:DVAType"] = df_query12[
        "dva_card_type"
    ]  # tbl_dbo_stay.dva_card_type
    df_query12["Extra:IntendedSameDay"] = df_query12[
        "stay_discharge_intention"
    ]  # tbl_dbo_stay.stay_discharge_intention
    df_query12["Extra:ReferralFurtherHealthcare"] = df_query12[
        "referred_to_on_separation"
    ]  # tbl_dbo_stay.referred_to_on_separation
    df_query12["Extra:UnplannedReadmission"] = df_query12[
        "readmit_this_hosp_28_days"
    ]  # tbl_dbo_stay.readmit_this_hosp_28_days
    df_query12["Extra:EpisodeSequenceNumber"] = df_query12[
        "episode_sequence_number"
    ]  # tbl_dbo_episode_ats.episode_sequence_number
    df_query12["Extra:MedicareNumber"] = df_query12[
        "medicare_number"
    ]  # tbl_dbo_stay.medicare_number
    # df_query12['Extra:Outlierdays'] = df_query12['outlier_days_1'].replace('','0').apply(lambda x: int(float(x)))+ df_query12['outlier_days_2'].replace('','0').apply(lambda x: int(float(x)))#.astype('Int64', errors='ignore')
    df_query12["outlier_days_1"] = (
        df_query12["outlier_days_1"].fillna(0).astype(int, errors="ignore")
    )
    df_query12["outlier_days_2"] = (
        df_query12["outlier_days_2"].fillna(0).astype(int, errors="ignore")
    )
    df_query12["Extra:Outlierdays"] = (
        df_query12["outlier_days_1"] + df_query12["outlier_days_2"]
    )  # tbl_dbo_episode_srg.[outlier_days_1] + tbl_dbo_episode_srg.[outlier_days_2] AS Expr8
    df_query12["Extra:SurgeryIndicator"] = df_query12[
        "surgery_indicator"
    ]  # tbl_dbo_episode_srg.surgery_indicator
    df_query12["Extra:AreaDOHRSCode"] = df_query12[
        "area_identifier"
    ]  # tbl_dbo_episode_ats.area_identifier
    df_query12["Extra:FinancialProgram"] = df_query12[
        "financial_program"
    ]  # tbl_dbo_episode_ats.financial_program
    df_query12["Extra:FacilityTransferredto"] = df_query12[
        "facility_trans_to"
    ]  # tbl_dbo_stay.facility_trans_to
    df_query12["Extra:FacilityTransferredfrom"] = df_query12[
        "facility_trans_from"
    ]  # tbl_dbo_stay.facility_trans_from
    df_query12["Extra:MRN"] = df_query12[
        "mrn_ats"
    ]  # [tbl_dbo_episode_ats]![mrn] AS Expr14
    df_query12["Extra:MDC"] = df_query12["mdc"]  # tbl_dbo_episode_DRG.mdc
    df_query12["Extra:indicatorProcedurecode"] = df_query12[
        "indicator_procedure_code"
    ]  # tbl_dbo_stay.indicator_procedure_code
    df_query12["Extra:bookingIdentifier"] = df_query12[
        "booking_identifier"
    ]  # tbl_dbo_wl_exit1.booking_identifier
    df_query12["Extra:waitinglistcategory"] = df_query12[
        "waiting_list_category"
    ]  # tbl_dbo_wl_exit1.waiting_list_category
    df_query12["Extra:ClinicalURGfinal"] = df_query12[
        "clinical_urg_final_crnt"
    ]  # tbl_dbo_wl_exit1.clinical_urg_final_crnt
    df_query12["Extra:ReasonforRemoval"] = df_query12[
        "reason_for_removal"
    ]  # tbl_dbo_wl_exit1.reason_for_removal
    df_query12["Extra:DRG1_pccl"] = df_query12[
        "an_drg_pccl"
    ]  # tbl_dbo_episode_DRG.an_drg_pccl
    df_query12["Extra:QualifiedBedDays"] = df_query12[
        "qualified_bed_days"
    ]  # tbl_dbo_episode_ats.qualified_bed_days
    df_query12["Extra:IndigenousStatus"] = df_query12[
        "indigenous_status"
    ]  # tbl_dbo_episode_ats.indigenous_status
    df_query12["Extra:MothersMRN"] = df_query12[
        "mothers_mrn"
    ]  # tbl_dbo_stay.mothers_mrn
    df_query12["Extra:MedicareEligibility"] = df_query12[
        "medicare_eligibility_status"
    ]  # tbl_dbo_stay.medicare_eligibility_status
    df_query12["Extra:FacilityType"] = df_query12[
        "facility_type"
    ]  # tbl_dbo_episode_ats.facility_type
    df_query12["Extra:LHD_of_Usual_Residence"] = df_query12[
        "LHD_of_Usual_residence"
    ]  # tbl_dbo_stay.LHD_of_Usual_residence
    df_query12["Extra:MDC2"] = df_query12[
        "2_mdc"
    ]  # np.where((df_query12['2_mdc']=='') | (df_query12['2_mdc'].isnull()),'',df_query12['2_mdc']) #tbl_dbo_episode_DRG.[2_mdc]
    df_query12["Extra:EpisodeLeaveDays"] = df_query12[
        "sa_total_leave_days"
    ]  # [SNAP File 2 01].sa_total_leave_days
    df_query12["Extra:SpecialtyPortal"] = df_query12[
        "SpecialityPortal"
    ]  # [qry specialtyportal].SpecialityPortal
    df_query12["Extra:Dementia_Flag"] = df_query12[
        "Dementia_Flag"
    ]  # [SNAP File 2 01].Dementia_Flag
    df_query12["Extra:Delirium_Flag"] = df_query12[
        "Delirium_Flag"
    ]  # [SNAP File 2 01].Delirium_Flag
    df_query12["Extra:Contract_Status"] = df_query12[
        "contract_status"
    ]  # tbl_dbo_stay.contract_status
    df_query12["Extra:Collabrtve_Care_Role"] = df_query12[
        "collabrtve_care_role"
    ]  # tbl_dbo_stay.collabrtve_care_role
    df_query12["Extra:Collabrtve_Care_Facility"] = df_query12[
        "collabrtve_care_facility"
    ]  # tbl_dbo_stay.collabrtve_care_facility
    df_query12["Extra:Collabrtve_Care_Type"] = df_query12[
        "collabrtve_care_type"
    ]  # tbl_dbo_stay.collabrtve_care_type
    df_query12["Extra:ExtractDate"] = pd.to_datetime(
        df_query12["HIE Extract Date"], errors="coerce", format="%Y-%m-%d %H:%M:%S"
    )  # Format([HIE Extract Date],"yyyy-mm-dd hh:nn:ss") AS Expr24
    df_query12["Extra:LOSinCostingPeriod"] = df_query12[
        "sa_occdays_in_cost_period"
    ]  # snapApp_CostingExtract.sa_occdays_in_cost_period # Note: for SNAP , sa_occdays_in_cost_period is the los in costing period after subtracting leave in costing period
    df_query12["Extra:LeaveinCostingPeriod"] = df_query12[
        "sa_leave_days_in_cost_period"
    ]  # snapApp_CostingExtract.sa_leave_days_in_cost_period
    df_query12["LengthOfStay"] = df_query12[
        "sa_total_los"
    ]  # snapApp_CostingExtract.sa_total_los AS Expr12
    df_query12["ICUHours"] = df_query12[
        "hours_in_icu"
    ]  # tbl_dbo_episode_ats.hours_in_icu
    df_query12["MechVentHours"] = df_query12[
        "hours_on_mech_vent_num"
    ]  # tbl_dbo_episode.hours_on_mech_vent_num
    df_query12["StartDateTime"] = pd.to_datetime(
        df_query12["EncounterStart"], errors="coerce", format="%Y-%m-%d %H:%M:%S"
    )  # Format([snapApp_CostingExtract]![EncounterStart],"yyyy-mm-dd hh:nn:ss") AS Expr10
    df_query12["EndDateTime"] = pd.to_datetime(
        df_query12["EncounterEnd"], errors="coerce", format="%Y-%m-%d %H:%M:%S"
    )  # Format([snapApp_CostingExtract]![EncounterEnd],"yyyy-mm-dd hh:nn:ss") AS Expr7
    df_query12["Age"] = df_query12["age"]  # tbl_dbo_stay.age
    df_query12["HealthFund"] = df_query12[
        "insurance_fund_master"
    ]  # tbl_dbo_stay.insurance_fund_master
    df_query12["AdmissionSource"] = df_query12[
        "source_of_referral"
    ]  # tbl_dbo_episode_ats.source_of_referral
    df_query12["Hospital"] = df_query12[
        "facility_identifier"
    ]  # tbl_dbo_episode_ats.facility_identifier
    df_query12["FinancialClass"] = df_query12[
        "financial_class"
    ]  # tbl_dbo_episode_ats.financial_class
    df_query12["DischargeStatus"] = df_query12[
        "mode_of_separation"
    ]  # tbl_dbo_episode_ats.mode_of_separation
    df_query12["AdmissionCategory"] = df_query12[
        "emergency_status"
    ]  # tbl_dbo_stay.emergency_status
    df_query12["AdmissionElection"] = df_query12[
        "election_status_on_admit"
    ]  # tbl_dbo_stay.election_status_on_admit
    df_query12["DischargeElection"] = df_query12[
        "payment_status_on_sep"
    ]  # tbl_dbo_episode_ats.payment_status_on_sep
    df_query12["EncounterNumber"] = df_query12[
        "EncounterNumber"
    ]  # snapApp_CostingExtract.EncounterNumber
    df_query12["PostCode"] = df_query12[
        "patient_postcode"
    ]  # tbl_dbo_stay.patient_postcode
    df_query12["Suburb"] = df_query12["patient_suburb"]  # tbl_dbo_stay.patient_suburb
    df_query12["MaritalStatus"] = df_query12[
        "marital_status"
    ]  # tbl_dbo_stay.marital_status
    df_query12["Extra:HON1"] = df_query12["HON1"]  # snapApp_CostingExtract.HON1
    df_query12["Extra:HON2"] = df_query12["HON2"]  # snapApp_CostingExtract.HON2
    df_query12["Extra:HON3"] = df_query12["HON3"]  # snapApp_CostingExtract.HON3
    df_query12["Extra:HON4"] = df_query12["HON4"]  # snapApp_CostingExtract.HON4
    df_query12["Extra:HON5"] = df_query12["HON5"]  # snapApp_CostingExtract.HON5
    df_query12["Extra:HON6"] = df_query12["HON6"]  # snapApp_CostingExtract.HON6
    df_query12["Extra:HON7"] = df_query12["HON7"]  # snapApp_CostingExtract.HON7
    df_query12["Extra:HON8"] = df_query12["HON8"]  # snapApp_CostingExtract.HON8
    df_query12["Extra:HON9"] = df_query12["HON9"]  # snapApp_CostingExtract.HON9
    df_query12["Extra:HON10"] = df_query12["HON10"]  # snapApp_CostingExtract.HON10
    df_query12["Extra:HON11"] = df_query12["HON11"]  # snapApp_CostingExtract.HON11
    df_query12["Extra:HON12"] = df_query12["HON12"]  # snapApp_CostingExtract.HON12
    df_query12["Extra:HON13"] = df_query12["HON13"]  # snapApp_CostingExtract.HON13
    df_query12["Extra:HON14"] = df_query12["HON14"]  # snapApp_CostingExtract.HON14
    df_query12["Extra:HON15"] = df_query12["HON15"]  # snapApp_CostingExtract.HON15
    # AQA-349 - START
    df_query12["Extra:HONOS1"] = df_query12["HONOS1"]
    df_query12["Extra:HONOS2"] = df_query12["HONOS2"]
    df_query12["Extra:HONOS3"] = df_query12["HONOS3"]
    df_query12["Extra:HONOS4"] = df_query12["HONOS4"]
    df_query12["Extra:HONOS5"] = df_query12["HONOS5"]
    df_query12["Extra:HONOS6"] = df_query12["HONOS6"]
    df_query12["Extra:HONOS7"] = df_query12["HONOS7"]
    df_query12["Extra:HONOS8"] = df_query12["HONOS8"]
    df_query12["Extra:HONOS9"] = df_query12["HONOS9"]
    df_query12["Extra:HONOS10"] = df_query12["HONOS10"]
    df_query12["Extra:HONOS11"] = df_query12["HONOS11"]
    df_query12["Extra:HONOS12"] = df_query12["HONOS12"]
    df_query12["Extra:HONOS65_1"] = df_query12["HONOS65_1"]
    df_query12["Extra:HONOS65_2"] = df_query12["HONOS65_2"]
    df_query12["Extra:HONOS65_3"] = df_query12["HONOS65_3"]
    df_query12["Extra:HONOS65_4"] = df_query12["HONOS65_4"]
    df_query12["Extra:HONOS65_5"] = df_query12["HONOS65_5"]
    df_query12["Extra:HONOS65_6"] = df_query12["HONOS65_6"]
    df_query12["Extra:HONOS65_7"] = df_query12["HONOS65_7"]
    df_query12["Extra:HONOS65_8"] = df_query12["HONOS65_8"]
    df_query12["Extra:HONOS65_9"] = df_query12["HONOS65_9"]
    df_query12["Extra:HONOS65_10"] = df_query12["HONOS65_10"]
    df_query12["Extra:HONOS65_11"] = df_query12["HONOS65_11"]
    df_query12["Extra:HONOS65_12"] = df_query12["HONOS65_12"]
    df_query12["Extra:HONOSCA1"] = df_query12["HONOSCA1"]
    df_query12["Extra:HONOSCA2"] = df_query12["HONOSCA2"]
    df_query12["Extra:HONOSCA3"] = df_query12["HONOSCA3"]
    df_query12["Extra:HONOSCA4"] = df_query12["HONOSCA4"]
    df_query12["Extra:HONOSCA5"] = df_query12["HONOSCA5"]
    df_query12["Extra:HONOSCA6"] = df_query12["HONOSCA6"]
    df_query12["Extra:HONOSCA7"] = df_query12["HONOSCA7"]
    df_query12["Extra:HONOSCA8"] = df_query12["HONOSCA8"]
    df_query12["Extra:HONOSCA9"] = df_query12["HONOSCA9"]
    df_query12["Extra:HONOSCA10"] = df_query12["HONOSCA10"]
    df_query12["Extra:HONOSCA11"] = df_query12["HONOSCA11"]
    df_query12["Extra:HONOSCA12"] = df_query12["HONOSCA12"]
    df_query12["Extra:HONOSCA13"] = df_query12["HONOSCA13"]
    df_query12["Extra:HONOSCA14"] = df_query12["HONOSCA14"]
    df_query12["Extra:HONOSCA15"] = df_query12["HONOSCA15"]
    df_query12["Extra:IHPA_LSP_01"] = df_query12["IHPA_LSP_01"]
    df_query12["Extra:IHPA_LSP_02"] = df_query12["IHPA_LSP_02"]
    df_query12["Extra:IHPA_LSP_03"] = df_query12["IHPA_LSP_03"]
    df_query12["Extra:IHPA_LSP_04"] = df_query12["IHPA_LSP_04"]
    df_query12["Extra:IHPA_LSP_05"] = df_query12["IHPA_LSP_05"]
    df_query12["Extra:IHPA_LSP_06"] = df_query12["IHPA_LSP_06"]
    df_query12["Extra:IHPA_LSP_07"] = df_query12["IHPA_LSP_07"]
    df_query12["Extra:IHPA_LSP_08"] = df_query12["IHPA_LSP_08"]
    df_query12["Extra:IHPA_LSP_09"] = df_query12["IHPA_LSP_09"]
    df_query12["Extra:IHPA_LSP_10"] = df_query12["IHPA_LSP_10"]
    df_query12["Extra:IHPA_LSP_11"] = df_query12["IHPA_LSP_11"]
    df_query12["Extra:IHPA_LSP_12"] = df_query12["IHPA_LSP_12"]
    df_query12["Extra:IHPA_LSP_13"] = df_query12["IHPA_LSP_13"]
    df_query12["Extra:IHPA_LSP_14"] = df_query12["IHPA_LSP_14"]
    df_query12["Extra:IHPA_LSP_15"] = df_query12["IHPA_LSP_15"]
    df_query12["Extra:IHPA_LSP_16"] = df_query12["IHPA_LSP_16"]
    # AQA-349 - STOP

    df_query12["Extra:WIP"] = df_query12["WIP"]  # snapApp_CostingExtract.WIP
    df_query12["Extra:LengthofStay_EpisodeTable"] = df_query12[
        "episode_length_of_stay_dbo"
    ]  # tbl_dbo_episode.episode_length_of_stay
    df_query12["Extra:LengthofStay_EpisodeATSTable"] = df_query12[
        "episode_length_of_stay"
    ]  # tbl_dbo_episode_ats.episode_length_of_stay
    df_query12["Extra:EpisodeLeaveDays_EpisodeTable"] = df_query12[
        "episode_leave_days_total"
    ]  # tbl_dbo_episode_ats.episode_leave_days_total
    df_query12["Extra:EpisodeLeaveDays_EpisodeATSTable"] = df_query12[
        "episode_leave_days_total"
    ]  # tbl_dbo_episode_ats.episode_leave_days_total
    df_query12["EpisodeOfCare"] = df_query12[
        "episode_of_care_type"
    ]  # tbl_dbo_episode_ats.episode_of_care_type
    df_query12["Extra:EpisodeofCare_EpisodeTable"] = df_query12[
        "episode_of_care_type_dbo"
    ]  # tbl_dbo_episode.episode_of_care_type
    df_query12["Extra:EpisodeofCare_EpisodeATSTable"] = df_query12[
        "episode_of_care_type"
    ]  # tbl_dbo_episode_ats.episode_of_care_type
    df_query12["Extra:MHPhaseSeqNo"] = np.where(
        (df_query12["PhaseSeqNo"].isnull()) | (df_query12["PhaseSeqNo"] == ""),
        "0",
        df_query12["PhaseSeqNo"].astype(str),
    )  # snapApp_CostingExtract.PhaseSeqNo
    df_query12["Extra:UnplannedTheatre"] = df_query12[
        "unplanned_theatre"
    ]  # tbl_dbo_episode_ats.unplanned_theatre
    df_query12["Extra:EDStatus"] = df_query12[
        "ed_status"
    ]  # tbl_dbo_episode_srg.ed_status
    df_query12["Extra:ICUStatus"] = df_query12[
        "icu_status"
    ]  # tbl_dbo_episode_srg.icu_status
    df_query12["Extra:SRGcurrent"] = df_query12[
        "srg_current"
    ]  # tbl_dbo_episode_srg.srg_current
    df_query12["Extra:ESRGcurrent"] = df_query12[
        "esrg_current"
    ]  # tbl_dbo_episode_srg.esrg_current
    df_query12["Extra:CW_A"] = df_query12[
        "cost_weight_a_current"
    ]  # tbl_dbo_episode_srg.cost_weight_a_current
    df_query12["Extra:CW_B"] = df_query12[
        "cost_weight_b_current"
    ]  # tbl_dbo_episode_srg.cost_weight_b_current
    df_query12["Extra:CW_C"] = df_query12[
        "cost_weight_c_current"
    ]  # tbl_dbo_episode_srg.cost_weight_c_current
    df_query12["Extra:CW_D"] = df_query12[
        "cost_weight_d_current"
    ]  # tbl_dbo_episode_srg.cost_weight_d_current
    df_query12["Extra:CW_E"] = df_query12[
        "cost_weight_e_current"
    ]  # tbl_dbo_episode_srg.cost_weight_e_current
    df_query12["Extra:CW_F"] = df_query12[
        "cost_weight_f_current"
    ]  # tbl_dbo_episode_srg.cost_weight_f_current
    df_query12["Extra:TrimPoint"] = df_query12[
        "trim_point"
    ]  # tbl_dbo_episode_srg.trim_point
    df_query12["Extra:Cost_Weight"] = ""  # min(null)
    df_query12["Extra:HLTH_ORG_OSP_OSP_ID"] = df_query12["HLTH_ORG_OSP_OSP_ID"]
    df_query12["Extra:MG_AUTH_OSP_OSP_ID"] = df_query12["MG_AUTH_OSP_OSP_ID"]
    df_query12["Extra:SE_CBK_SK"] = df_query12["SE_CBK_SK"]
    df_query12["Extra:CL_ID_EUID"] = df_query12["CL_ID_EUID"]
    df_query12["Extra:CL_ID_IHI"] = df_query12["CL_ID_IHI"]
    df_query12["Extra:HLTH_ORG_OSP_TYP"] = df_query12["HLTH_ORG_OSP_TYP"]
    df_query12["Extra:SRV_ENC_REC_ID"] = df_query12["SRV_ENC_REC_ID"]
    # Issue 134 - 28 Jan 2025
    df_query12["Extra:FRML_DISCH_MODE_CD"] = df_query12["FRML_DISCH_MODE_CD"]
    df_query12["Extra:SE_SEP_MODE_NHDD_CD"] = df_query12["SE_SEP_MODE_NHDD_CD"]
    # df_query12['Extra:HLTH_ORG_OSP_TYP_CD_DESC'] = df_query12['HLTH_ORG_OSP_TYP_CD_DESC']

    # Ranjit 12 Dec 2024 - Issue 115: Length of stay in costing period not calculating correctly.  Ex.  H770-I-04529915-001 Long stay RAC patient admitted prior to 1 July 23 and not discharged as at 30 June 24.  LOS in costing period = 1
    # START (tbl_PPM_Encounter_AUID_SNAP.EncounterNumber.str.contains('-M-') == True)
    df_query12["start_date_dt"] = (
        start_date  # pd.to_datetime(start_date, format="%Y-%m-%d %H:%M:%S")
    )
    df_query12["end_date_dt"] = (
        end_date  # pd.to_datetime(end_date, format="%Y-%m-%d %H:%M:%S")
    )
    df_query12["start_date_dt"] = pd.to_datetime(
        df_query12["start_date_dt"].astype(str).str[:10], format="%Y-%m-%d"
    )
    df_query12["end_date_dt"] = pd.to_datetime(
        df_query12["end_date_dt"].astype(str).str[:10], format="%Y-%m-%d"
    )
    df_query12["start_date_dt_full"] = (
        start_date  # pd.to_datetime(start_date, format="%Y-%m-%d %H:%M:%S")
    )
    df_query12["end_date_dt_full"] = (
        end_date  # pd.to_datetime(end_date, format="%Y-%m-%d %H:%M:%S")
    )
    df_query12["start_date_dt_full"] = pd.to_datetime(
        df_query12["start_date_dt_full"].astype(str).str[:19],
        format="%Y-%m-%d %H:%M:%S",
    )
    df_query12["end_date_dt_full"] = pd.to_datetime(
        df_query12["end_date_dt_full"].astype(str).str[:19], format="%Y-%m-%d %H:%M:%S"
    )

    condlist = [
        (df_query12.EncounterNumber.str.contains("-M-") == True)
        & (
            pd.to_datetime(
                df_query12["EncounterStart"].astype(str).str[:10],
                errors="coerce",
                format="%Y-%m-%d",
            )
            < df_query12["start_date_dt"]
        ),
        (df_query12.EncounterNumber.str.contains("-M-") == True)
        & (
            (
                pd.to_datetime(
                    df_query12["EncounterStart"].astype(str).str[:10],
                    errors="coerce",
                    format="%Y-%m-%d",
                )
                >= df_query12["start_date_dt"]
            )
            & (
                pd.to_datetime(
                    df_query12["EncounterStart"].astype(str).str[:10],
                    errors="coerce",
                    format="%Y-%m-%d",
                )
                > df_query12["end_date_dt"]
            )
        ),
    ]
    choicelist = [df_query12["start_date_dt_full"], df_query12["start_date_dt_full"]]
    df_query12["start_date_tbl_PPM_Encounter_AUID_SNAP_full"] = np.select(
        condlist,
        choicelist,
        pd.to_datetime(
            (
                df_query12["EncounterStart"].astype(str).str[:10]
                + " "
                + df_query12["episode_start_time"].astype(str).str[-8:]
            ),
            errors="coerce",
            format="%Y-%m-%d %H:%M:%S",
        ),
    )

    condlist = [
        (df_query12.EncounterNumber.str.contains("-M-") == True)
        & (
            (df_query12["EncounterEnd"].isnull())
            | (df_query12["EncounterEnd"].astype(str).str[:10] == "")
            | (df_query12["EncounterStart"].isnull())
            | (df_query12["EncounterStart"].astype(str).str[:10] == "")
        ),
        (df_query12.EncounterNumber.str.contains("-M-") == True)
        & (
            (
                (pd.notna(df_query12["EncounterStart"]))
                & (df_query12["EncounterStart"].astype(str).str[:10] != "")
            )
            & (
                pd.to_datetime(
                    df_query12["EncounterEnd"].astype(str).str[:10],
                    errors="coerce",
                    format="%Y-%m-%d",
                )
                > df_query12["end_date_dt"]
            )
        ),
    ]
    choicelist = [df_query12["end_date_dt_full"], df_query12["end_date_dt_full"]]
    df_query12["end_date_tbl_PPM_Encounter_AUID_SNAP_full"] = np.select(
        condlist,
        choicelist,
        pd.to_datetime(
            (
                df_query12["EncounterEnd"].astype(str).str[:10]
                + " "
                + df_query12["episode_end_time"].astype(str).str[-8:]
            ),
            errors="coerce",
            format="%Y-%m-%d %H:%M:%S",
        ),
    )
    # 29 Jan 2025 - #146
    # Note: for SNAP , sa_occdays_in_cost_period is the los in costing period after subtracting leave in costing period
    # df_query12['Extra:LOSinCostingPeriod'] = np.where((df_query12.EncounterNumber.str.contains('-M-') == True) & (df_query12['EncounterStart'].astype(str).str[:10] == df_query12['EncounterEnd'].astype(str).str[:10]), ((df_query12['end_date_tbl_PPM_Encounter_AUID_SNAP_full'] - df_query12['start_date_tbl_PPM_Encounter_AUID_SNAP_full'])/ np.timedelta64(1, 'D')) - df_query12['sa_total_leave_days'], df_query12['Extra:LOSinCostingPeriod'])
    condlist = [
        (df_query12.EncounterNumber.str.contains("-M-") == True)
        & (
            df_query12["end_date_tbl_PPM_Encounter_AUID_SNAP_full"]
            == df_query12["start_date_tbl_PPM_Encounter_AUID_SNAP_full"]
        ),
        (df_query12.EncounterNumber.str.contains("-M-") == True)
        & (
            df_query12["end_date_tbl_PPM_Encounter_AUID_SNAP_full"]
            != df_query12["start_date_tbl_PPM_Encounter_AUID_SNAP_full"]
        ),
    ]
    # 183: fix LOS in Costing period
    # choicelist = [1, ((df_query12['end_date_tbl_PPM_Encounter_AUID_SNAP_full'] - df_query12['start_date_tbl_PPM_Encounter_AUID_SNAP_full'])/ np.timedelta64(1, 'D')) - df_query12['sa_total_leave_days']]
    choicelist = [
        1,
        (
            (
                df_query12["end_date_tbl_PPM_Encounter_AUID_SNAP_full"].dt.floor("D")
                - df_query12["start_date_tbl_PPM_Encounter_AUID_SNAP_full"].dt.floor(
                    "D"
                )
            )
            / np.timedelta64(1, "D")
        )
        - df_query12["sa_total_leave_days"],
    ]
    df_query12["Extra:LOSinCostingPeriod"] = np.select(
        condlist, choicelist, df_query12["Extra:LOSinCostingPeriod"]
    )

    # Convert the column to numeric type
    df_query12["Extra:LOSinCostingPeriod"] = pd.to_numeric(
        df_query12["Extra:LOSinCostingPeriod"], errors="coerce"
    )
    df_query12["Extra:LOSinCostingPeriod"] = df_query12[
        "Extra:LOSinCostingPeriod"
    ].round(decimals=0)
    # STOP #115
    df_query12["Extra:Responsible_Facility"] = df_query12["Responsible_Facility"]
    df_query12["Extra:SE_TYP_CD"] = df_query12["SE_TYP_CD"]
    df_query12["Extra:SE_ADM_MODE_NHDD_CD"] = df_query12["SE_ADM_MODE_NHDD_CD"]
    df_query12["Extra:DIM_RSP_ISP_SK"] = df_query12["DIM_RSP_ISP_SK"]
    df_query12["Extra:AR_DRG_ECCS_RAW"] = df_query12["AR_DRG_ECCS_RAW"]
    df_query12["Extra:ASGS_SA_L2_16_CD"] = df_query12["ASGS_SA_L2_16_CD"]
    df_query12["Extra:CL_URES_ADDR_ASGS21_SA_L2_CD"] = df_query12[
        "CL_URES_ADDR_ASGS21_SA_L2_CD"
    ]
    tbl_PPM_Encounter_AUID_SNAP = df_query12.copy()
    tbl_PPM_Encounter_AUID_SNAP = (
        tbl_PPM_Encounter_AUID_SNAP.groupby(
            [
                "EncounterType",
                "EncounterNumber",
                "PostCode",
                "Suburb",
                "MaritalStatus",
                "PatientNumber",
                "EpisodeOfCare",
                "AttendingConsultant",
                "AdmissionCategory",
                "AdmissionElection",
                "DischargeElection",
                "AdmissionType",
                "AdmissionSource",
                "Hospital",
                "FinancialClass",
                "DischargeStatus",
                "DRG1",
                "DRG1Version",
                "DRG2",
                "DRG2Version",
                "DRG3",
                "DRG3Version",
                "LengthOfStay",
                "ICUHours",
                "MechVentHours",
                "StartDateTime",
                "EndDateTime",
                "Age",
                "HealthFund",
                "AdmissionWeight",
                "WeightedSeparation",
                "Extra:LGACode",
                "Extra:HospitalStayNumber",
                "Extra:LHDIdentifier",
                "Extra:LegalStatus",
                "Extra:DVANumber",
                "Extra:DVAType",
                "Extra:IntendedSameDay",
                "Extra:ReferralFurtherHealthcare",
                "Extra:UnplannedReadmission",
                "Extra:EpisodeSequenceNumber",
                "Extra:MedicareNumber",
                "Extra:DaysinPsychUnit",
                "Extra:UnplannedTheatre",
                "Extra:EDStatus",
                "Extra:ICUStatus",
                "Extra:SRGcurrent",
                "Extra:ESRGcurrent",
                "Extra:CW_A",
                "Extra:CW_B",
                "Extra:CW_C",
                "Extra:CW_D",
                "Extra:CW_E",
                "Extra:CW_F",
                "Extra:TrimPoint",
                "Extra:Outlierdays",
                "Extra:SurgeryIndicator",
                "Extra:AreaDOHRSCode",
                "Extra:FinancialProgram",
                "Extra:FacilityTransferredto",
                "Extra:FacilityTransferredfrom",
                "Extra:MRN",
                "Extra:MDC",
                "Extra:indicatorProcedurecode",
                "Extra:bookingIdentifier",
                "Extra:waitinglistcategory",
                "Extra:ClinicalURGfinal",
                "Extra:ReasonforRemoval",
                "Extra:DRG1_pccl",
                "Extra:QualifiedBedDays",
                "Extra:IndigenousStatus",
                "Extra:MothersMRN",
                "Extra:MothersStayNumber",
                "Extra:MothersPersonIdentifier",
                "Extra:ElectionStatusSummary",
                "Extra:MedicareEligibility",
                "Extra:FacilityType",
                "Extra:ExtractorVersion",
                "Extra:AUID",
                "Extra:LHD_of_Usual_Residence",
                "Extra:MDC2",
                "Extra:EpisodeLeaveDays",
                "Extra:SNAP_Class",
                "Extra:LOSinCostingPeriod",
                "Extra:LeaveinCostingPeriod",
                "AttendingConsultantSpecialty",
                "Extra:SpecialtyPortal",
                "Extra:SNAP_ClassV4",
                "Extra:Dementia_Flag",
                "Extra:Delirium_Flag",
                "Extra:Contract_Status",
                "Extra:Collabrtve_Care_Role",
                "Extra:Collabrtve_Care_Facility",
                "Extra:Collabrtve_Care_Type",
                "Extra:ExtractDate",
                "Extra:AMHCC_Class",
                "Extra:AMHCC_ClassVersion",
                "Extra:HON1",
                "Extra:HON2",
                "Extra:HON3",
                "Extra:HON4",
                "Extra:HON5",
                "Extra:HON6",
                "Extra:HON7",
                "Extra:HON8",
                "Extra:HON9",
                "Extra:HON10",
                "Extra:HON11",
                "Extra:HON12",
                "Extra:HON13",
                "Extra:HON14",
                "Extra:HON15",
                "Extra:HONOS1",
                "Extra:HONOS2",
                "Extra:HONOS3",
                "Extra:HONOS4",
                "Extra:HONOS5",
                "Extra:HONOS6",
                "Extra:HONOS7",
                "Extra:HONOS8",
                "Extra:HONOS9",
                "Extra:HONOS10",
                "Extra:HONOS11",
                "Extra:HONOS12",
                "Extra:HONOS65_1",
                "Extra:HONOS65_2",
                "Extra:HONOS65_3",
                "Extra:HONOS65_4",
                "Extra:HONOS65_5",
                "Extra:HONOS65_6",
                "Extra:HONOS65_7",
                "Extra:HONOS65_8",
                "Extra:HONOS65_9",
                "Extra:HONOS65_10",
                "Extra:HONOS65_11",
                "Extra:HONOS65_12",
                "Extra:HONOSCA1",
                "Extra:HONOSCA2",
                "Extra:HONOSCA3",
                "Extra:HONOSCA4",
                "Extra:HONOSCA5",
                "Extra:HONOSCA6",
                "Extra:HONOSCA7",
                "Extra:HONOSCA8",
                "Extra:HONOSCA9",
                "Extra:HONOSCA10",
                "Extra:HONOSCA11",
                "Extra:HONOSCA12",
                "Extra:HONOSCA13",
                "Extra:HONOSCA14",
                "Extra:HONOSCA15",
                "Extra:IHPA_LSP_01",
                "Extra:IHPA_LSP_02",
                "Extra:IHPA_LSP_03",
                "Extra:IHPA_LSP_04",
                "Extra:IHPA_LSP_05",
                "Extra:IHPA_LSP_06",
                "Extra:IHPA_LSP_07",
                "Extra:IHPA_LSP_08",
                "Extra:IHPA_LSP_09",
                "Extra:IHPA_LSP_10",
                "Extra:IHPA_LSP_11",
                "Extra:IHPA_LSP_12",
                "Extra:IHPA_LSP_13",
                "Extra:IHPA_LSP_14",
                "Extra:IHPA_LSP_15",
                "Extra:IHPA_LSP_16",
                "Extra:WIP",
                "Extra:StartDateTime_EpisodeTable",
                "Extra:EndDateTime_EpisodeATSTable",
                "Extra:EndDateTime_EpisodeTable",
                "Extra:LengthofStay_EpisodeTable",
                "Extra:LengthofStay_EpisodeATSTable",
                "Extra:EpisodeLeaveDays_EpisodeTable",
                "Extra:EpisodeLeaveDays_EpisodeATSTable",
                "Extra:EpisodeofCare_EpisodeTable",
                "Extra:EpisodeofCare_EpisodeATSTable",
                "Extra:MHPhaseSeqNo",
                "Extra:Cost_Weight",
                "Extra:SRG_Version",
                "Extra:HLTH_ORG_OSP_OSP_ID",
                "Extra:MG_AUTH_OSP_OSP_ID",
                "Extra:SE_CBK_SK",
                "Extra:CL_ID_EUID",
                "Extra:CL_ID_IHI",
                "Extra:HLTH_ORG_OSP_TYP",
                "Extra:SRV_ENC_REC_ID",
                "Extra:FRML_DISCH_MODE_CD",
                "Extra:SE_SEP_MODE_NHDD_CD",
                "Extra:Responsible_Facility",
                "Extra:SE_TYP_CD",
                "Extra:SE_ADM_MODE_NHDD_CD",
                "Extra:DIM_RSP_ISP_SK",
                "Extra:AR_DRG_ECCS_RAW",
                "Extra:ASGS_SA_L2_16_CD",
                "Extra:CL_URES_ADDR_ASGS21_SA_L2_CD",
            ],
            as_index=False,
            dropna=False,
        )
        .agg(
            Extra_ProdType=("ProdType", "max"),
            Extra_CaseType=("CaseType", "max"),
            Extra_EpisType=("EpisType", "max"),
            Extra_AssessOnly=("AssessOnly", "max"),
            Extra_PCPhase=("Phase", "max"),
            Extra_PCSymptomScoreStart=("PCSymptomScoreStart", "max"),
            Extra_PCSeverityStart=("PCSeverityStart", "max"),
            Extra_PCPsychSpiritualScoreStart=("PCPsychSpiritualScoreStart", "max"),
            Extra_PCFamilyCarerScoreStart=("PCFamilyCarerScoreStart", "max"),
            Extra_MaintType=("MaintType", "max"),
            Extra_CareFocus=("CareFocus", "max"),
            Extra_Impair=("Impair", "max"),
            Extra_RugBedBeg=("RugBedBeg", "max"),
            Extra_RugToilBeg=("RugToilBeg", "max"),
            Extra_RugXferBeg=("RugXferBeg", "max"),
            Extra_RugEatBeg=("RugEatBeg", "max"),
            Extra_FIMEatBeg=("FIMEatBeg", "max"),
            Extra_FIMEatEnd=("FIMEatEnd", "max"),
            Extra_FIMGroomBeg=("FIMGroomBeg", "max"),
            Extra_FIMGroomEnd=("FIMGroomEnd", "max"),
            Extra_FIMBathBeg=("FIMBathBeg", "max"),
            Extra_FIMBathEnd=("FIMBathEnd", "max"),
            Extra_FIMUpperBeg=("FIMUpperBeg", "max"),
            Extra_FIMUpperEnd=("FIMUpperEnd", "max"),
            Extra_FIMLowerBeg=("FIMLowerBeg", "max"),
            Extra_FIMLowerEnd=("FIMLowerEnd", "max"),
            Extra_FIMToiletBeg=("FIMToiletBeg", "max"),
            Extra_FIMToiletEnd=("FIMToiletEnd", "max"),
            Extra_FIMBladderBeg=("FIMBladderBeg", "max"),
            Extra_FIMBladderEnd=("FIMBladderEnd", "max"),
            Extra_FIMBowelBeg=("FIMBowelBeg", "max"),
            Extra_FIMBowelEnd=("FIMBowelEnd", "max"),
            Extra_FIMXferBeg=("FIMXferBeg", "max"),
            Extra_FIMXferEnd=("FIMXferEnd", "max"),
            Extra_FIMXferToilBeg=("FIMXferToilBeg", "max"),
            Extra_FIMXferToilEnd=("FIMXferToilEnd", "max"),
            Extra_FIMTubBeg=("FIMTubBeg", "max"),
            Extra_FIMTubEnd=("FIMTubEnd", "max"),
            Extra_FIMWalkBeg=("FIMWalkBeg", "max"),
            Extra_FIMWalkEnd=("FIMWalkEnd", "max"),
            Extra_FIMStairBeg=("FIMStairBeg", "max"),
            Extra_FIMStairEnd=("FIMStairEnd", "max"),
            Extra_FIMCompBeg=("FIMCompBeg", "max"),
            Extra_FIMCompEnd=("FIMCompEnd", "max"),
            Extra_FIMExpBeg=("FIMExpBeg", "max"),
            Extra_FIMExpEnd=("FIMExpEnd", "max"),
            Extra_FIMSocialBeg=("FIMSocialBeg", "max"),
            Extra_FIMSocialEnd=("FIMSocialEnd", "max"),
            Extra_FIMProbBeg=("FIMProbBeg", "max"),
            Extra_FIMProbEnd=("FIMProbEnd", "max"),
            Extra_FIMMemoryBeg=("FIMMemoryBeg", "max"),
            Extra_FIMMemoryEnd=("FIMMemoryEnd", "max"),
            Extra_HonActiveBeg=("HonActiveBeg", "max"),
            Extra_HonActiveEnd=("HonActiveEnd", "max"),
            Extra_HonInjuryBeg=("HonInjuryBeg", "max"),
            Extra_HonInjuryEnd=("HonInjuryEnd", "max"),
            Extra_HonDrinkBeg=("HonDrinkBeg", "max"),
            Extra_HonDrinkEnd=("HonDrinkEnd", "max"),
            Extra_HonCognitBeg=("HonCognitBeg", "max"),
            Extra_HonCognitEnd=("HonCognitEnd", "max"),
            Extra_HonDisabBeg=("HonDisabBeg", "max"),
            Extra_HonDisabEnd=("HonDisabEnd", "max"),
            Extra_HonHallucBeg=("HonHallucBeg", "max"),
            Extra_HonHallucEnd=("HonHallucEnd", "max"),
            Extra_HonDeprsBeg=("HonDeprsBeg", "max"),
            Extra_HonDeprsEnd=("HonDeprsEnd", "max"),
            Extra_HonOtherBeg=("HonOtherBeg", "max"),
            Extra_HonOtherEnd=("HonOtherEnd", "max"),
            Extra_HonRelatBeg=("HonRelatBeg", "max"),
            Extra_HonRelatEnd=("HonRelatEnd", "max"),
            Extra_HonADLBeg=("HonADLBeg", "max"),
            Extra_HonADLEnd=("HonADLEnd", "max"),
            Extra_HonLivingBeg=("HonLivingBeg", "max"),
            Extra_HonLivingEnd=("HonLivingEnd", "max"),
            Extra_HonOccupBeg=("HonOccupBeg", "max"),
            Extra_HonOccupEnd=("HonOccupEnd", "max"),
        )
        .reset_index()
    )
    tbl_PPM_Encounter_AUID_SNAP.rename(
        columns={
            "Extra_ProdType": "Extra:ProdType",
            "Extra_CaseType": "Extra:CaseType",
            "Extra_EpisType": "Extra:EpisType",
            "Extra_AssessOnly": "Extra:AssessOnly",
            "Extra_PCPhase": "Extra:PCPhase",
            "Extra_PCSymptomScoreStart": "Extra:PCSymptomScoreStart",
            "Extra_PCSeverityStart": "Extra:PCSeverityStart",
            "Extra_PCPsychSpiritualScoreStart": "Extra:PCPsychSpiritualScoreStart",
            "Extra_PCFamilyCarerScoreStart": "Extra:PCFamilyCarerScoreStart",
            "Extra_MaintType": "Extra:MaintType",
            "Extra_CareFocus": "Extra:CareFocus",
            "Extra_Impair": "Extra:Impair",
            "Extra_RugBedBeg": "Extra:RugBedBeg",
            "Extra_RugToilBeg": "Extra:RugToilBeg",
            "Extra_RugXferBeg": "Extra:RugXferBeg",
            "Extra_RugEatBeg": "Extra:RugEatBeg",
            "Extra_FIMEatBeg": "Extra:FIMEatBeg",
            "Extra_FIMEatEnd": "Extra:FIMEatEnd",
            "Extra_FIMGroomBeg": "Extra:FIMGroomBeg",
            "Extra_FIMGroomEnd": "Extra:FIMGroomEnd",
            "Extra_FIMBathBeg": "Extra:FIMBathBeg",
            "Extra_FIMBathEnd": "Extra:FIMBathEnd",
            "Extra_FIMUpperBeg": "Extra:FIMUpperBeg",
            "Extra_FIMUpperEnd": "Extra:FIMUpperEnd",
            "Extra_FIMLowerBeg": "Extra:FIMLowerBeg",
            "Extra_FIMLowerEnd": "Extra:FIMLowerEnd",
            "Extra_FIMToiletBeg": "Extra:FIMToiletBeg",
            "Extra_FIMToiletEnd": "Extra:FIMToiletEnd",
            "Extra_FIMBladderBeg": "Extra:FIMBladderBeg",
            "Extra_FIMBladderEnd": "Extra:FIMBladderEnd",
            "Extra_FIMBowelBeg": "Extra:FIMBowelBeg",
            "Extra_FIMBowelEnd": "Extra:FIMBowelEnd",
            "Extra_FIMXferBeg": "Extra:FIMXferBeg",
            "Extra_FIMXferEnd": "Extra:FIMXferEnd",
            "Extra_FIMXferToilBeg": "Extra:FIMXferToilBeg",
            "Extra_FIMXferToilEnd": "Extra:FIMXferToilEnd",
            "Extra_FIMTubBeg": "Extra:FIMTubBeg",
            "Extra_FIMTubEnd": "Extra:FIMTubEnd",
            "Extra_FIMWalkBeg": "Extra:FIMWalkBeg",
            "Extra_FIMWalkEnd": "Extra:FIMWalkEnd",
            "Extra_FIMStairBeg": "Extra:FIMStairBeg",
            "Extra_FIMStairEnd": "Extra:FIMStairEnd",
            "Extra_FIMCompBeg": "Extra:FIMCompBeg",
            "Extra_FIMCompEnd": "Extra:FIMCompEnd",
            "Extra_FIMExpBeg": "Extra:FIMExpBeg",
            "Extra_FIMExpEnd": "Extra:FIMExpEnd",
            "Extra_FIMSocialBeg": "Extra:FIMSocialBeg",
            "Extra_FIMSocialEnd": "Extra:FIMSocialEnd",
            "Extra_FIMProbBeg": "Extra:FIMProbBeg",
            "Extra_FIMProbEnd": "Extra:FIMProbEnd",
            "Extra_FIMMemoryBeg": "Extra:FIMMemoryBeg",
            "Extra_FIMMemoryEnd": "Extra:FIMMemoryEnd",
            "Extra_HonActiveBeg": "Extra:HonActiveBeg",
            "Extra_HonActiveEnd": "Extra:HonActiveEnd",
            "Extra_HonInjuryBeg": "Extra:HonInjuryBeg",
            "Extra_HonInjuryEnd": "Extra:HonInjuryEnd",
            "Extra_HonDrinkBeg": "Extra:HonDrinkBeg",
            "Extra_HonDrinkEnd": "Extra:HonDrinkEnd",
            "Extra_HonCognitBeg": "Extra:HonCognitBeg",
            "Extra_HonCognitEnd": "Extra:HonCognitEnd",
            "Extra_HonDisabBeg": "Extra:HonDisabBeg",
            "Extra_HonDisabEnd": "Extra:HonDisabEnd",
            "Extra_HonHallucBeg": "Extra:HonHallucBeg",
            "Extra_HonHallucEnd": "Extra:HonHallucEnd",
            "Extra_HonDeprsBeg": "Extra:HonDeprsBeg",
            "Extra_HonDeprsEnd": "Extra:HonDeprsEnd",
            "Extra_HonOtherBeg": "Extra:HonOtherBeg",
            "Extra_HonOtherEnd": "Extra:HonOtherEnd",
            "Extra_HonRelatBeg": "Extra:HonRelatBeg",
            "Extra_HonRelatEnd": "Extra:HonRelatEnd",
            "Extra_HonADLBeg": "Extra:HonADLBeg",
            "Extra_HonADLEnd": "Extra:HonADLEnd",
            "Extra_HonLivingBeg": "Extra:HonLivingBeg",
            "Extra_HonLivingEnd": "Extra:HonLivingEnd",
            "Extra_HonOccupBeg": "Extra:HonOccupBeg",
            "Extra_HonOccupEnd": "Extra:HonOccupEnd",
        },
        inplace=True,
    )

    tbl_PPM_Encounter_AUID_SNAP = tbl_PPM_Encounter_AUID_SNAP[
        [
            "EncounterType",
            "EncounterNumber",
            "PostCode",
            "Suburb",
            "MaritalStatus",
            "PatientNumber",
            "EpisodeOfCare",
            "AttendingConsultant",
            "AdmissionCategory",
            "AdmissionElection",
            "DischargeElection",
            "AdmissionType",
            "AdmissionSource",
            "Hospital",
            "FinancialClass",
            "DischargeStatus",
            "DRG1",
            "DRG1Version",
            "DRG2",
            "DRG2Version",
            "DRG3",
            "DRG3Version",
            "LengthOfStay",
            "ICUHours",
            "MechVentHours",
            "StartDateTime",
            "EndDateTime",
            "Age",
            "HealthFund",
            "AdmissionWeight",
            "WeightedSeparation",
            "Extra:LGACode",
            "Extra:HospitalStayNumber",
            "Extra:LHDIdentifier",
            "Extra:LegalStatus",
            "Extra:DVANumber",
            "Extra:DVAType",
            "Extra:IntendedSameDay",
            "Extra:ReferralFurtherHealthcare",
            "Extra:UnplannedReadmission",
            "Extra:EpisodeSequenceNumber",
            "Extra:MedicareNumber",
            "Extra:DaysinPsychUnit",
            "Extra:UnplannedTheatre",
            "Extra:EDStatus",
            "Extra:ICUStatus",
            "Extra:SRGcurrent",
            "Extra:ESRGcurrent",
            "Extra:CW_A",
            "Extra:CW_B",
            "Extra:CW_C",
            "Extra:CW_D",
            "Extra:CW_E",
            "Extra:CW_F",
            "Extra:TrimPoint",
            "Extra:Outlierdays",
            "Extra:SurgeryIndicator",
            "Extra:AreaDOHRSCode",
            "Extra:FinancialProgram",
            "Extra:FacilityTransferredto",
            "Extra:FacilityTransferredfrom",
            "Extra:MRN",
            "Extra:MDC",
            "Extra:indicatorProcedurecode",
            "Extra:bookingIdentifier",
            "Extra:waitinglistcategory",
            "Extra:ClinicalURGfinal",
            "Extra:ReasonforRemoval",
            "Extra:DRG1_pccl",
            "Extra:QualifiedBedDays",
            "Extra:IndigenousStatus",
            "Extra:MothersMRN",
            "Extra:MothersStayNumber",
            "Extra:MothersPersonIdentifier",
            "Extra:ElectionStatusSummary",
            "Extra:MedicareEligibility",
            "Extra:FacilityType",
            "Extra:ExtractorVersion",
            "Extra:AUID",
            "Extra:LHD_of_Usual_Residence",
            "Extra:MDC2",
            "Extra:EpisodeLeaveDays",
            "Extra:SNAP_Class",
            "Extra:LOSinCostingPeriod",
            "Extra:LeaveinCostingPeriod",
            "AttendingConsultantSpecialty",
            "Extra:SpecialtyPortal",
            "Extra:SNAP_ClassV4",
            "Extra:Dementia_Flag",
            "Extra:Delirium_Flag",
            "Extra:Contract_Status",
            "Extra:Collabrtve_Care_Role",
            "Extra:Collabrtve_Care_Facility",
            "Extra:Collabrtve_Care_Type",
            "Extra:ExtractDate",
            "Extra:AMHCC_Class",
            "Extra:AMHCC_ClassVersion",
            "Extra:HON1",
            "Extra:HON2",
            "Extra:HON3",
            "Extra:HON4",
            "Extra:HON5",
            "Extra:HON6",
            "Extra:HON7",
            "Extra:HON8",
            "Extra:HON9",
            "Extra:HON10",
            "Extra:HON11",
            "Extra:HON12",
            "Extra:HON13",
            "Extra:HON14",
            "Extra:HON15",
            "Extra:HONOS1",
            "Extra:HONOS2",
            "Extra:HONOS3",
            "Extra:HONOS4",
            "Extra:HONOS5",
            "Extra:HONOS6",
            "Extra:HONOS7",
            "Extra:HONOS8",
            "Extra:HONOS9",
            "Extra:HONOS10",
            "Extra:HONOS11",
            "Extra:HONOS12",
            "Extra:HONOS65_1",
            "Extra:HONOS65_2",
            "Extra:HONOS65_3",
            "Extra:HONOS65_4",
            "Extra:HONOS65_5",
            "Extra:HONOS65_6",
            "Extra:HONOS65_7",
            "Extra:HONOS65_8",
            "Extra:HONOS65_9",
            "Extra:HONOS65_10",
            "Extra:HONOS65_11",
            "Extra:HONOS65_12",
            "Extra:HONOSCA1",
            "Extra:HONOSCA2",
            "Extra:HONOSCA3",
            "Extra:HONOSCA4",
            "Extra:HONOSCA5",
            "Extra:HONOSCA6",
            "Extra:HONOSCA7",
            "Extra:HONOSCA8",
            "Extra:HONOSCA9",
            "Extra:HONOSCA10",
            "Extra:HONOSCA11",
            "Extra:HONOSCA12",
            "Extra:HONOSCA13",
            "Extra:HONOSCA14",
            "Extra:HONOSCA15",
            "Extra:IHPA_LSP_01",
            "Extra:IHPA_LSP_02",
            "Extra:IHPA_LSP_03",
            "Extra:IHPA_LSP_04",
            "Extra:IHPA_LSP_05",
            "Extra:IHPA_LSP_06",
            "Extra:IHPA_LSP_07",
            "Extra:IHPA_LSP_08",
            "Extra:IHPA_LSP_09",
            "Extra:IHPA_LSP_10",
            "Extra:IHPA_LSP_11",
            "Extra:IHPA_LSP_12",
            "Extra:IHPA_LSP_13",
            "Extra:IHPA_LSP_14",
            "Extra:IHPA_LSP_15",
            "Extra:IHPA_LSP_16",
            "Extra:WIP",
            "Extra:StartDateTime_EpisodeTable",
            "Extra:EndDateTime_EpisodeATSTable",
            "Extra:EndDateTime_EpisodeTable",
            "Extra:LengthofStay_EpisodeTable",
            "Extra:LengthofStay_EpisodeATSTable",
            "Extra:EpisodeLeaveDays_EpisodeTable",
            "Extra:EpisodeLeaveDays_EpisodeATSTable",
            "Extra:EpisodeofCare_EpisodeTable",
            "Extra:EpisodeofCare_EpisodeATSTable",
            "Extra:MHPhaseSeqNo",
            "Extra:Cost_Weight",
            "Extra:ProdType",
            "Extra:CaseType",
            "Extra:EpisType",
            "Extra:AssessOnly",
            "Extra:PCPhase",
            "Extra:PCSymptomScoreStart",
            "Extra:PCSeverityStart",
            "Extra:PCPsychSpiritualScoreStart",
            "Extra:PCFamilyCarerScoreStart",
            "Extra:MaintType",
            "Extra:CareFocus",
            "Extra:Impair",
            "Extra:RugBedBeg",
            "Extra:RugToilBeg",
            "Extra:RugXferBeg",
            "Extra:RugEatBeg",
            "Extra:FIMEatBeg",
            "Extra:FIMEatEnd",
            "Extra:FIMGroomBeg",
            "Extra:FIMGroomEnd",
            "Extra:FIMBathBeg",
            "Extra:FIMBathEnd",
            "Extra:FIMUpperBeg",
            "Extra:FIMUpperEnd",
            "Extra:FIMLowerBeg",
            "Extra:FIMLowerEnd",
            "Extra:FIMToiletBeg",
            "Extra:FIMToiletEnd",
            "Extra:FIMBladderBeg",
            "Extra:FIMBladderEnd",
            "Extra:FIMBowelBeg",
            "Extra:FIMBowelEnd",
            "Extra:FIMXferBeg",
            "Extra:FIMXferEnd",
            "Extra:FIMXferToilBeg",
            "Extra:FIMXferToilEnd",
            "Extra:FIMTubBeg",
            "Extra:FIMTubEnd",
            "Extra:FIMWalkBeg",
            "Extra:FIMWalkEnd",
            "Extra:FIMStairBeg",
            "Extra:FIMStairEnd",
            "Extra:FIMCompBeg",
            "Extra:FIMCompEnd",
            "Extra:FIMExpBeg",
            "Extra:FIMExpEnd",
            "Extra:FIMSocialBeg",
            "Extra:FIMSocialEnd",
            "Extra:FIMProbBeg",
            "Extra:FIMProbEnd",
            "Extra:FIMMemoryBeg",
            "Extra:FIMMemoryEnd",
            "Extra:HonActiveBeg",
            "Extra:HonActiveEnd",
            "Extra:HonInjuryBeg",
            "Extra:HonInjuryEnd",
            "Extra:HonDrinkBeg",
            "Extra:HonDrinkEnd",
            "Extra:HonCognitBeg",
            "Extra:HonCognitEnd",
            "Extra:HonDisabBeg",
            "Extra:HonDisabEnd",
            "Extra:HonHallucBeg",
            "Extra:HonHallucEnd",
            "Extra:HonDeprsBeg",
            "Extra:HonDeprsEnd",
            "Extra:HonOtherBeg",
            "Extra:HonOtherEnd",
            "Extra:HonRelatBeg",
            "Extra:HonRelatEnd",
            "Extra:HonADLBeg",
            "Extra:HonADLEnd",
            "Extra:HonLivingBeg",
            "Extra:HonLivingEnd",
            "Extra:HonOccupBeg",
            "Extra:HonOccupEnd",
            "Extra:SRG_Version",
            "Extra:HLTH_ORG_OSP_OSP_ID",
            "Extra:MG_AUTH_OSP_OSP_ID",
            "Extra:SE_CBK_SK",
            "Extra:CL_ID_EUID",
            "Extra:CL_ID_IHI",
            "Extra:HLTH_ORG_OSP_TYP",
            "Extra:SRV_ENC_REC_ID",
            "Extra:FRML_DISCH_MODE_CD",
            "Extra:SE_SEP_MODE_NHDD_CD",
            "Extra:Responsible_Facility",
            "Extra:SE_TYP_CD",
            "Extra:SE_ADM_MODE_NHDD_CD",
            "Extra:DIM_RSP_ISP_SK",
            "Extra:AR_DRG_ECCS_RAW",
            "Extra:ASGS_SA_L2_16_CD",
            "Extra:CL_URES_ADDR_ASGS21_SA_L2_CD",
        ]
    ]
    logging.info(
        "tbl_PPM_Encounter_AUID_SNAP created with %s records.",
        len(tbl_PPM_Encounter_AUID_SNAP),
    )
    """
    tbl_PPM_Encounter_AUID_SNAP_col_list = tbl_PPM_Encounter_AUID_SNAP.columns.values.tolist()
    for col in tbl_PPM_Encounter_AUID_SNAP_col_list:
        tbl_PPM_Encounter_AUID_SNAP[col] = tbl_PPM_Encounter_AUID_SNAP[col].astype("category")
    """
    tbl_PPM_Encounter_AUID_SNAP.drop_duplicates(keep="last", inplace=True)
    tbl_PPM_Encounter_AUID_SNAP.to_csv(
        "./ExtractorDB/tbl_PPM_Encounter_AUID_SNAP.csv", index=False
    )
    cleanup_memory(df_query1)
    cleanup_memory(df_query2)
    cleanup_memory(df_query3)
    cleanup_memory(df_query4)
    cleanup_memory(df_query5)
    cleanup_memory(df_query6)
    cleanup_memory(df_query7)
    cleanup_memory(df_query8)
    cleanup_memory(df_query9)
    cleanup_memory(df_query10)
    cleanup_memory(df_query11)
    cleanup_memory(df_query12)
    ################### concatenate all tbl_ppm_encounters
    tbl_PPM_Encounter = pd.concat(
        [tbl_PPM_Encounter_AUID, tbl_PPM_Encounter_AUID_SNAP], axis=0
    )
    tbl_PPM_Encounter.drop_duplicates(keep="last", inplace=True)
    # 11 Jan 2025 - CREATED FACILITY CHANGE
    # ValueError: You are trying to merge on object and int64 columns
    tbl_PPM_Encounter["Extra:SE_CBK_SK"] = tbl_PPM_Encounter["Extra:SE_CBK_SK"].astype(
        "Int64", errors="ignore"
    )

    tbl_PPM_Encounter["Extra:MHPhaseSeqNo"] = tbl_PPM_Encounter[
        "Extra:MHPhaseSeqNo"
    ].fillna(0)
    tbl_PPM_Encounter["Extra:SCN_Hours"] = tbl_PPM_Encounter["Extra:SCN_Hours"].fillna(
        0
    )
    tbl_PPM_Encounter["Extra:HDU_Hours"] = tbl_PPM_Encounter["Extra:HDU_Hours"].fillna(
        0
    )
    tbl_PPM_Encounter["Extra:HITH_Hours"] = tbl_PPM_Encounter[
        "Extra:HITH_Hours"
    ].fillna(0)
    tbl_PPM_Encounter["Extra:AICU1_Hours"] = tbl_PPM_Encounter[
        "Extra:AICU1_Hours"
    ].fillna(0)
    tbl_PPM_Encounter["Extra:AICU2_Hours"] = tbl_PPM_Encounter[
        "Extra:AICU2_Hours"
    ].fillna(0)
    tbl_PPM_Encounter["Extra:AICU3_Hours"] = tbl_PPM_Encounter[
        "Extra:AICU3_Hours"
    ].fillna(0)
    tbl_PPM_Encounter["Extra:PICU_Hours"] = tbl_PPM_Encounter[
        "Extra:PICU_Hours"
    ].fillna(0)
    tbl_PPM_Encounter["Extra:NICU_Hours"] = tbl_PPM_Encounter[
        "Extra:NICU_Hours"
    ].fillna(0)
    tbl_PPM_Encounter["Extra:PSICU_Hours"] = tbl_PPM_Encounter[
        "Extra:PSICU_Hours"
    ].fillna(0)
    tbl_PPM_Encounter["Extra:CCU_Hours"] = tbl_PPM_Encounter["Extra:CCU_Hours"].fillna(
        0
    )
    tbl_PPM_Encounter["Extra:MHPhaseSeqNo"] = np.where(
        (tbl_PPM_Encounter["Extra:MHPhaseSeqNo"].isnull())
        | (tbl_PPM_Encounter["Extra:MHPhaseSeqNo"] == ""),
        "0",
        tbl_PPM_Encounter["Extra:MHPhaseSeqNo"].astype(str),
    )
    tbl_PPM_Encounter["Extra:SCN_Hours"] = np.where(
        (tbl_PPM_Encounter["Extra:SCN_Hours"].isnull())
        | (tbl_PPM_Encounter["Extra:SCN_Hours"] == ""),
        0,
        tbl_PPM_Encounter["Extra:SCN_Hours"],
    )
    tbl_PPM_Encounter["Extra:HDU_Hours"] = np.where(
        (tbl_PPM_Encounter["Extra:HDU_Hours"].isnull())
        | (tbl_PPM_Encounter["Extra:HDU_Hours"] == ""),
        0,
        tbl_PPM_Encounter["Extra:HDU_Hours"],
    )
    tbl_PPM_Encounter["Extra:HITH_Hours"] = np.where(
        (tbl_PPM_Encounter["Extra:HITH_Hours"].isnull())
        | (tbl_PPM_Encounter["Extra:HITH_Hours"] == ""),
        0,
        tbl_PPM_Encounter["Extra:HITH_Hours"],
    )
    tbl_PPM_Encounter["Extra:AICU1_Hours"] = np.where(
        (tbl_PPM_Encounter["Extra:AICU1_Hours"].isnull())
        | (tbl_PPM_Encounter["Extra:AICU1_Hours"] == ""),
        0,
        tbl_PPM_Encounter["Extra:AICU1_Hours"],
    )
    tbl_PPM_Encounter["Extra:AICU2_Hours"] = np.where(
        (tbl_PPM_Encounter["Extra:AICU2_Hours"].isnull())
        | (tbl_PPM_Encounter["Extra:AICU2_Hours"] == ""),
        0,
        tbl_PPM_Encounter["Extra:AICU2_Hours"],
    )
    tbl_PPM_Encounter["Extra:AICU3_Hours"] = np.where(
        (tbl_PPM_Encounter["Extra:AICU3_Hours"].isnull())
        | (tbl_PPM_Encounter["Extra:AICU3_Hours"] == ""),
        0,
        tbl_PPM_Encounter["Extra:AICU3_Hours"],
    )
    tbl_PPM_Encounter["Extra:PICU_Hours"] = np.where(
        (tbl_PPM_Encounter["Extra:PICU_Hours"].isnull())
        | (tbl_PPM_Encounter["Extra:PICU_Hours"] == ""),
        0,
        tbl_PPM_Encounter["Extra:PICU_Hours"],
    )
    tbl_PPM_Encounter["Extra:NICU_Hours"] = np.where(
        (tbl_PPM_Encounter["Extra:NICU_Hours"].isnull())
        | (tbl_PPM_Encounter["Extra:NICU_Hours"] == ""),
        0,
        tbl_PPM_Encounter["Extra:NICU_Hours"],
    )
    tbl_PPM_Encounter["Extra:PSICU_Hours"] = np.where(
        (tbl_PPM_Encounter["Extra:PSICU_Hours"].isnull())
        | (tbl_PPM_Encounter["Extra:PSICU_Hours"] == ""),
        0,
        tbl_PPM_Encounter["Extra:PSICU_Hours"],
    )
    tbl_PPM_Encounter["Extra:CCU_Hours"] = np.where(
        (tbl_PPM_Encounter["Extra:CCU_Hours"].isnull())
        | (tbl_PPM_Encounter["Extra:CCU_Hours"] == ""),
        0,
        tbl_PPM_Encounter["Extra:CCU_Hours"],
    )
    tbl_PPM_Encounter["Extra:nwau_paed_incr"] = np.where(
        (tbl_PPM_Encounter["Extra:nwau_paed_incr"] == 0),
        "",
        tbl_PPM_Encounter["Extra:nwau_paed_incr"].astype(str),
    )
    tbl_PPM_Encounter["Extra:nwau_indig_incr"] = np.where(
        (tbl_PPM_Encounter["Extra:nwau_indig_incr"] == 0),
        "",
        tbl_PPM_Encounter["Extra:nwau_indig_incr"].astype(str),
    )
    tbl_PPM_Encounter["Extra:nwau_remote_incr"] = np.where(
        (tbl_PPM_Encounter["Extra:nwau_remote_incr"] == 0),
        "",
        tbl_PPM_Encounter["Extra:nwau_remote_incr"].astype(str),
    )
    tbl_PPM_Encounter["Extra:nwau_icu_incr"] = np.where(
        (tbl_PPM_Encounter["Extra:nwau_icu_incr"] == 0),
        "",
        tbl_PPM_Encounter["Extra:nwau_icu_incr"].astype(str),
    )
    tbl_PPM_Encounter["Extra:nwau_private_patient_service_incr"] = np.where(
        (tbl_PPM_Encounter["Extra:nwau_private_patient_service_incr"] == 0),
        "",
        tbl_PPM_Encounter["Extra:nwau_private_patient_service_incr"].astype(str),
    )
    tbl_PPM_Encounter["Extra:nwau_private_patient_accom_incr"] = np.where(
        (tbl_PPM_Encounter["Extra:nwau_private_patient_accom_incr"] == 0),
        "",
        tbl_PPM_Encounter["Extra:nwau_private_patient_accom_incr"].astype(str),
    )
    tbl_PPM_Encounter["Extra:LeaveinCostingPeriod"] = np.where(
        (tbl_PPM_Encounter["Extra:LeaveinCostingPeriod"] == 0),
        "",
        tbl_PPM_Encounter["Extra:LeaveinCostingPeriod"].astype(str),
    )
    tbl_PPM_Encounter = tbl_PPM_Encounter.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    tbl_PPM_Encounter = tbl_PPM_Encounter.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    tbl_PPM_Encounter = tbl_PPM_Encounter.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    tbl_PPM_Encounter = tbl_PPM_Encounter.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    logging.info(
        "tbl_PPM_Encounter created with %s records. Of these, %s encounters were from tbl_PPM_Encounter_AUID and %s encounters from  tbl_PPM_Encounter_AUID_SNAP.",
        len(tbl_PPM_Encounter),
        len(tbl_PPM_Encounter_AUID),
        len(tbl_PPM_Encounter_AUID_SNAP),
    )
    tbl_ExcludedEncounters_list = tbl_ExcludedEncounters["EncounterNumber"].tolist()
    tbl_PPM_Encounter = tbl_PPM_Encounter[
        ~(tbl_PPM_Encounter["EncounterNumber"].isin(tbl_ExcludedEncounters_list))
    ]
    logging.info(
        "tbl_PPM_Encounter has %s records after removing excluded encounters.",
        len(tbl_PPM_Encounter),
    )
    tbl_PPM_Encounter.sort_values(
        by=[
            "EncounterType",
            "EncounterNumber",
            "PostCode",
            "Suburb",
            "MaritalStatus",
            "PatientNumber",
            "EpisodeOfCare",
            "AttendingConsultant",
            "AdmissionCategory",
            "AdmissionElection",
            "DischargeElection",
            "AdmissionType",
            "AdmissionSource",
            "Hospital",
            "FinancialClass",
            "DischargeStatus",
            "DRG1",
            "DRG1Version",
            "DRG2",
            "DRG2Version",
            "DRG3",
            "DRG3Version",
            "LengthOfStay",
            "ICUHours",
            "MechVentHours",
            "StartDateTime",
            "EndDateTime",
            "Age",
            "HealthFund",
            "AdmissionWeight",
            "WeightedSeparation",
            "AttendingConsultantSpecialty",
            "Extra:LGACode",
            "Extra:HospitalStayNumber",
            "Extra:LHDIdentifier",
            "Extra:LegalStatus",
            "Extra:DVANumber",
            "Extra:DVAType",
            "Extra:IntendedSameDay",
            "Extra:ReferralFurtherHealthcare",
            "Extra:UnplannedReadmission",
            "Extra:MedicareNumber",
            "Extra:DaysinPsychUnit",
            "Extra:UnplannedTheatre",
            "Extra:EDStatus",
            "Extra:ICUStatus",
            "Extra:SRGcurrent",
            "Extra:ESRGcurrent",
            "Extra:CW_A",
            "Extra:CW_B",
            "Extra:CW_C",
            "Extra:CW_D",
            "Extra:CW_E",
            "Extra:CW_F",
            "Extra:TrimPoint",
            "Extra:Outlierdays",
            "Extra:SurgeryIndicator",
            "Extra:AreaDOHRSCode",
            "Extra:FacilityTransferredto",
            "Extra:FacilityTransferredfrom",
            "Extra:MRN",
            "Extra:MDC",
            "Extra:indicatorProcedurecode",
            "Extra:bookingIdentifier",
            "Extra:waitinglistcategory",
            "Extra:ClinicalURGfinal",
            "Extra:ReasonforRemoval",
            "Extra:DRG1_pccl",
            "Extra:QualifiedBedDays",
            "Extra:IndigenousStatus",
            "Extra:MothersMRN",
            "Extra:MothersStayNumber",
            "Extra:MothersPersonIdentifier",
            "Extra:ElectionStatusSummary",
            "Extra:MedicareEligibility",
            "Extra:FacilityType",
            "Extra:ExtractorVersion",
            "Extra:ProdType",
            "Extra:CaseType",
            "Extra:EpisType",
            "Extra:AssessOnly",
            "Extra:PCPhase",
            "Extra:PCSymptomScoreStart",
            "Extra:PCSeverityStart",
            "Extra:PCPsychSpiritualScoreStart",
            "Extra:PCFamilyCarerScoreStart",
            "Extra:MaintType",
            "Extra:CareFocus",
            "Extra:Impair",
            "Extra:RugBedBeg",
            "Extra:RugToilBeg",
            "Extra:RugXferBeg",
            "Extra:RugEatBeg",
            "Extra:Cost_Weight",
            "Extra:FIMEatBeg",
            "Extra:FIMEatEnd",
            "Extra:FIMGroomBeg",
            "Extra:FIMGroomEnd",
            "Extra:FIMBathBeg",
            "Extra:FIMBathEnd",
            "Extra:FIMUpperBeg",
            "Extra:FIMUpperEnd",
            "Extra:FIMLowerBeg",
            "Extra:FIMLowerEnd",
            "Extra:FIMToiletBeg",
            "Extra:FIMToiletEnd",
            "Extra:FIMBladderBeg",
            "Extra:FIMBladderEnd",
            "Extra:FIMBowelBeg",
            "Extra:FIMBowelEnd",
            "Extra:FIMXferBeg",
            "Extra:FIMXferEnd",
            "Extra:FIMXferToilBeg",
            "Extra:FIMXferToilEnd",
            "Extra:FIMTubBeg",
            "Extra:FIMTubEnd",
            "Extra:FIMWalkBeg",
            "Extra:FIMWalkEnd",
            "Extra:FIMStairBeg",
            "Extra:FIMStairEnd",
            "Extra:FIMCompBeg",
            "Extra:FIMCompEnd",
            "Extra:FIMExpBeg",
            "Extra:FIMExpEnd",
            "Extra:FIMSocialBeg",
            "Extra:FIMSocialEnd",
            "Extra:FIMProbBeg",
            "Extra:FIMProbEnd",
            "Extra:FIMMemoryBeg",
            "Extra:FIMMemoryEnd",
            "Extra:HonActiveBeg",
            "Extra:HonActiveEnd",
            "Extra:HonInjuryBeg",
            "Extra:HonInjuryEnd",
            "Extra:HonDrinkBeg",
            "Extra:HonDrinkEnd",
            "Extra:HonCognitBeg",
            "Extra:HonCognitEnd",
            "Extra:HonDisabBeg",
            "Extra:HonDisabEnd",
            "Extra:HonHallucBeg",
            "Extra:HonHallucEnd",
            "Extra:HonDeprsBeg",
            "Extra:HonDeprsEnd",
            "Extra:HonOtherBeg",
            "Extra:HonOtherEnd",
            "Extra:HonRelatBeg",
            "Extra:HonRelatEnd",
            "Extra:HonADLBeg",
            "Extra:HonADLEnd",
            "Extra:HonLivingBeg",
            "Extra:HonLivingEnd",
            "Extra:HonOccupBeg",
            "Extra:HonOccupEnd",
            "Extra:AUID",
            "Extra:LHD_of_Usual_Residence",
            "Extra:MDC2",
            "Extra:EpisodeLeaveDays",
            "Extra:SNAP_Class",
            "Extra:LOSinCostingPeriod",
            "Extra:LeaveinCostingPeriod",
            "Extra:SpecialtyPortal",
            "Extra:SNAP_ClassV4",
            "Extra:Dementia_Flag",
            "Extra:Delirium_Flag",
            "Extra:Contract_Status",
            "Extra:Collabrtve_Care_Role",
            "Extra:Collabrtve_Care_Facility",
            "Extra:Collabrtve_Care_Type",
            "Extra:ExtractDate",
            "Extra:AMHCC_Class",
            "Extra:AMHCC_ClassVersion",
            "Extra:HON1",
            "Extra:HON2",
            "Extra:HON3",
            "Extra:HON4",
            "Extra:HON5",
            "Extra:HON6",
            "Extra:HON7",
            "Extra:HON8",
            "Extra:HON9",
            "Extra:HON10",
            "Extra:HON11",
            "Extra:HON12",
            "Extra:HON13",
            "Extra:HON14",
            "Extra:HON15",
            "Extra:HONOS1",
            "Extra:HONOS2",
            "Extra:HONOS3",
            "Extra:HONOS4",
            "Extra:HONOS5",
            "Extra:HONOS6",
            "Extra:HONOS7",
            "Extra:HONOS8",
            "Extra:HONOS9",
            "Extra:HONOS10",
            "Extra:HONOS11",
            "Extra:HONOS12",
            "Extra:HONOS65_1",
            "Extra:HONOS65_2",
            "Extra:HONOS65_3",
            "Extra:HONOS65_4",
            "Extra:HONOS65_5",
            "Extra:HONOS65_6",
            "Extra:HONOS65_7",
            "Extra:HONOS65_8",
            "Extra:HONOS65_9",
            "Extra:HONOS65_10",
            "Extra:HONOS65_11",
            "Extra:HONOS65_12",
            "Extra:HONOSCA1",
            "Extra:HONOSCA2",
            "Extra:HONOSCA3",
            "Extra:HONOSCA4",
            "Extra:HONOSCA5",
            "Extra:HONOSCA6",
            "Extra:HONOSCA7",
            "Extra:HONOSCA8",
            "Extra:HONOSCA9",
            "Extra:HONOSCA10",
            "Extra:HONOSCA11",
            "Extra:HONOSCA12",
            "Extra:HONOSCA13",
            "Extra:HONOSCA14",
            "Extra:HONOSCA15",
            "Extra:IHPA_LSP_01",
            "Extra:IHPA_LSP_02",
            "Extra:IHPA_LSP_03",
            "Extra:IHPA_LSP_04",
            "Extra:IHPA_LSP_05",
            "Extra:IHPA_LSP_06",
            "Extra:IHPA_LSP_07",
            "Extra:IHPA_LSP_08",
            "Extra:IHPA_LSP_09",
            "Extra:IHPA_LSP_10",
            "Extra:IHPA_LSP_11",
            "Extra:IHPA_LSP_12",
            "Extra:IHPA_LSP_13",
            "Extra:IHPA_LSP_14",
            "Extra:IHPA_LSP_15",
            "Extra:IHPA_LSP_16",
            "Extra:WIP",
            "Extra:StartDateTime_EpisodeTable",
            "Extra:EndDateTime_EpisodeATSTable",
            "Extra:EndDateTime_EpisodeTable",
            "Extra:LengthofStay_EpisodeTable",
            "Extra:LengthofStay_EpisodeATSTable",
            "Extra:EpisodeLeaveDays_EpisodeTable",
            "Extra:EpisodeLeaveDays_EpisodeATSTable",
            "Extra:EpisodeofCare_EpisodeTable",
            "Extra:EpisodeofCare_EpisodeATSTable",
            "Extra:MHPhaseSeqNo",
            "Extra:AICU1_Hours",
            "Extra:AICU3_Hours",
            "Extra:PICU_Hours",
            "Extra:NICU_Hours",
            "Extra:PSICU_Hours",
            "Extra:CCU_Hours",
            "Extra:AICU2_Hours",
            "Extra:nwau",
            "Extra:nwau_PublicEquivModel",
            "Extra:nwau_base",
            "Extra:nwau_paed_incr",
            "Extra:nwau_indig_incr",
            "Extra:nwau_remote_incr",
            "Extra:nwau_icu_incr",
            "Extra:nwau_private_patient_service_incr",
            "Extra:nwau_private_patient_accom_incr",
            "Extra:HITH_Hours",
            "Extra:HDU_Hours",
            "Extra:SCN_Hours",
            "Extra:SRG_Version",
            "Extra:Radiotherapy_adj",
            "Extra:nwau_version",
            "Extra:sp_psy_age_adj",
            "Extra:compensable_nwau",
            "Extra:MothersEncounterNumber",
            "Extra:FRML_DISCH_MODE_CD",
            "Extra:SE_SEP_MODE_NHDD_CD",
        ],
        inplace=True,
    )

    # tbl_PPM_Encounter.to_csv('./ExtractorDB/tbl_PPM_Encounter_testLOS_0a2.csv', index = False)
    """
    tbl_PPM_Encounter_col_list = tbl_PPM_Encounter.columns.values.tolist()
    for col in tbl_PPM_Encounter_col_list:
        tbl_PPM_Encounter[col] = tbl_PPM_Encounter[col].astype("category")
    """
    logging.info("tbl_PPM_Encounter created with %s records.", len(tbl_PPM_Encounter))
    """
    tbl_PPM_Encounter.drop_duplicates(subset=['EncounterType', 'EncounterNumber', 'PostCode', 'Suburb', 'MaritalStatus', 'PatientNumber', 'EpisodeOfCare', 'AttendingConsultant', 'AdmissionCategory', 'AdmissionElection', 'DischargeElection', 'AdmissionType', 'AdmissionSource', 'Hospital', 'FinancialClass', 'DischargeStatus', 'DRG1', 'DRG1Version', 'DRG2', 'DRG2Version', 'DRG3', 'DRG3Version', 'LengthOfStay', 'ICUHours', 'MechVentHours', 'StartDateTime', 'EndDateTime', 'Age', 'HealthFund', 'AdmissionWeight', 'WeightedSeparation', 'AttendingConsultantSpecialty'], keep='last', inplace=True)
    logging.info('tbl_PPM_Encounter has %s records after deleting duplicates.', len(tbl_PPM_Encounter))
    """
    """If the length of the patient number is <15 in the tbl_PPM_Encounter table  then the patient number is updated as shown [tbl_PPM_Encounter]![Hospital] & "-" & Format(Right([tbl_PPM_Encounter]![Extra:MRN],7),"0000000000")"""
    # Access query: Update Patient Number
    # UPDATE tbl_PPM_Encounter SET tbl_PPM_Encounter.PatientNumber = [tbl_PPM_Encounter]![Hospital] & "-" & Format(Right([tbl_PPM_Encounter]![Extra:MRN],7),"0000000000") WHERE (((Len([PatientNumber]))<15));
    tbl_PPM_Encounter["Extra:MRN_fmt"] = (
        tbl_PPM_Encounter["Extra:MRN"].astype(str).str.strip()
    )
    tbl_PPM_Encounter["Extra:MRN_fmt"] = tbl_PPM_Encounter["Extra:MRN_fmt"].str[-7:]
    tbl_PPM_Encounter["Extra:MRN_fmt"] = (
        tbl_PPM_Encounter["Extra:MRN_fmt"]
        .astype(str)
        .str.pad(10, side="left", fillchar="0")
    )
    logging.info(
        "Query: Update Patient Number completed. %s records will be updated in tbl_PPM_Encounter. tbl_PPM_Encounter has %s records.",
        len(
            tbl_PPM_Encounter[
                tbl_PPM_Encounter["PatientNumber"].astype(str).str.len() < 15
            ]
        ),
        len(tbl_PPM_Encounter),
    )
    tbl_PPM_Encounter["PatientNumber"] = np.where(
        tbl_PPM_Encounter["PatientNumber"].astype(str).str.len() < 15,
        tbl_PPM_Encounter["Hospital"].astype(str).str.strip()
        + "-"
        + tbl_PPM_Encounter["Extra:MRN_fmt"].astype(str).str.strip(),
        tbl_PPM_Encounter["PatientNumber"],
    )
    tbl_PPM_Encounter.drop(["Extra:MRN_fmt"], axis=1, inplace=True, errors="ignore")
    """ If the EndDateTime in the tbl_PPM_Encounter table  has an empty string then the DATE WILL BE UPDATED """
    # Access query: Update_EncounterIP_EndDateTime
    # UPDATE tbl_PPM_Encounter SET tbl_PPM_Encounter.EndDateTime = Format(DateValue([Forms]![Frm:1-ExtractSetUp]![End_Date])+1,"yyyy-mm-dd hh:nn:ss") WHERE (((tbl_PPM_Encounter.EndDateTime)=""));
    # enddatetime (Inform8 = 2023-01-01 00:00:00, App2 = 2023-01-01 23:59:59)
    # enddatetime (Inform8 = 2023-01-01 00:00:00, App2 = 2023-01-01 23:59:59)
    # end_date_dt = pd.to_datetime(end_date, format="%Y-%m-%d %H:%M:%S")
    # tbl_PPM_Encounter['EndDateTimeplus1'] = end_date_dt+pd.DateOffset(1)
    tbl_PPM_Encounter["EndDateTimeplus1"] = end_date
    tbl_PPM_Encounter["EndDateTimeplus1"] = pd.to_datetime(
        tbl_PPM_Encounter["EndDateTimeplus1"].astype(str).str[:10],
        errors="coerce",
        format="%Y-%m-%d",
    )
    tbl_PPM_Encounter["EndDateTimeplus1"] = tbl_PPM_Encounter[
        "EndDateTimeplus1"
    ] + pd.DateOffset(1)
    tbl_PPM_Encounter["EndDateTimeplus1"] = tbl_PPM_Encounter[
        "EndDateTimeplus1"
    ].astype(str)
    logging.info(
        "Query: Update_EncounterIP_EndDateTime completed. %s records will be updated in tbl_PPM_Encounter. tbl_PPM_Encounter has %s records.",
        len(
            tbl_PPM_Encounter[
                (tbl_PPM_Encounter["EndDateTime"].isnull())
                | (tbl_PPM_Encounter["EndDateTime"] == "")
            ]
        ),
        len(tbl_PPM_Encounter),
    )
    tbl_PPM_Encounter["EndDateTime"] = np.where(
        (tbl_PPM_Encounter["EndDateTime"].isnull())
        | (tbl_PPM_Encounter["EndDateTime"] == ""),
        tbl_PPM_Encounter["EndDateTimeplus1"],
        tbl_PPM_Encounter["EndDateTime"],
    )
    """ Updates the WIP in tbl_PPM_Encounter"""
    # 22 Oct: Check the hard coding of dates and how it affects the wIp assignment
    # Access query: Update_WIP_EncounterIP
    # UPDATE tbl_PPM_Encounter SET tbl_PPM_Encounter.[Extra:WIP] = IIf(DateValue([StartDateTime])<(DateValue([Forms]![Frm:1-ExtractSetUp]![Start_Date])) And DateValue([endDateTime])<DateValue([Forms]![Frm:1-ExtractSetUp]![end_Date])+1,1,IIf(DateValue([StartDateTime])>=(DateValue([Forms]![Frm:1-ExtractSetUp]![Start_Date])) And DateValue([endDateTime])>=DateValue([Forms]![Frm:1-ExtractSetUp]![end_Date])+1 Or DateValue([StartDateTime])>=DateValue([Forms]![Frm:1-ExtractSetUp]![Start_Date]) And [DischargeStatus]="" And [enddatetime]="2012-07-01 00:00:00",2,IIf(DateValue([StartDateTime])<(DateValue([Forms]![Frm:1-ExtractSetUp]![Start_Date])) And DateValue([endDateTime])>=(DateValue([Forms]![Frm:1-ExtractSetUp]![end_Date])) Or DateValue([StartDateTime])<(DateValue([Forms]![Frm:1-ExtractSetUp]![Start_Date])) And [DischargeStatus]="" And [enddatetime]="2012-07-01 00:00:00",3,4)));
    end_date_dt = pd.to_datetime(end_date, format="%Y-%m-%d %H:%M:%S")
    start_date_dt = pd.to_datetime(start_date, format="%Y-%m-%d %H:%M:%S")
    tbl_PPM_Encounter["StartDateTime"] = pd.to_datetime(
        tbl_PPM_Encounter["StartDateTime"], errors="coerce", format="%Y-%m-%d %H:%M:%S"
    )
    tbl_PPM_Encounter["EndDateTime"] = pd.to_datetime(
        tbl_PPM_Encounter["EndDateTime"], errors="coerce", format="%Y-%m-%d %H:%M:%S"
    )
    tbl_PPM_Encounter["EndDateTimeplus1"] = pd.to_datetime(
        tbl_PPM_Encounter["EndDateTimeplus1"],
        errors="coerce",
        format="%Y-%m-%d %H:%M:%S",
    )
    condlist = [
        (tbl_PPM_Encounter["StartDateTime"] < start_date_dt)
        & (tbl_PPM_Encounter["EndDateTime"] < (tbl_PPM_Encounter["EndDateTimeplus1"])),
        ~(
            (tbl_PPM_Encounter["StartDateTime"] < start_date_dt)
            & (
                tbl_PPM_Encounter["EndDateTime"]
                < (tbl_PPM_Encounter["EndDateTimeplus1"])
            )
        )
        & (
            (
                (tbl_PPM_Encounter["StartDateTime"] >= start_date_dt)
                & (
                    tbl_PPM_Encounter["EndDateTime"]
                    >= (tbl_PPM_Encounter["EndDateTimeplus1"])
                )
            )
            | (
                (tbl_PPM_Encounter["StartDateTime"] >= start_date_dt)
                & (
                    (tbl_PPM_Encounter["DischargeStatus"] == "")
                    | (tbl_PPM_Encounter["DischargeStatus"].isnull())
                )
                & (
                    tbl_PPM_Encounter["EndDateTime"]
                    == pd.to_datetime("2012-07-01 00:00:00", format="%Y-%m-%d %H:%M:%S")
                )
            )
        ),
        ~(
            (tbl_PPM_Encounter["StartDateTime"] < start_date_dt)
            & (
                tbl_PPM_Encounter["EndDateTime"]
                < (tbl_PPM_Encounter["EndDateTimeplus1"])
            )
        )
        & ~(
            (
                (tbl_PPM_Encounter["StartDateTime"] >= start_date_dt)
                & (
                    tbl_PPM_Encounter["EndDateTime"]
                    >= (tbl_PPM_Encounter["EndDateTimeplus1"])
                )
            )
            | (
                (tbl_PPM_Encounter["StartDateTime"] >= start_date_dt)
                & (
                    (tbl_PPM_Encounter["DischargeStatus"] == "")
                    | (tbl_PPM_Encounter["DischargeStatus"].isnull())
                )
                & (
                    tbl_PPM_Encounter["EndDateTime"]
                    == pd.to_datetime("2012-07-01 00:00:00", format="%Y-%m-%d %H:%M:%S")
                )
            )
        )
        & (
            (
                (tbl_PPM_Encounter["StartDateTime"] < start_date_dt)
                & (tbl_PPM_Encounter["EndDateTime"] >= end_date_dt)
            )
            | (
                (tbl_PPM_Encounter["StartDateTime"] < start_date_dt)
                & (
                    (tbl_PPM_Encounter["DischargeStatus"] == "")
                    | (tbl_PPM_Encounter["DischargeStatus"].isnull())
                )
                & (
                    tbl_PPM_Encounter["EndDateTime"]
                    == pd.to_datetime("2012-07-01 00:00:00", format="%Y-%m-%d %H:%M:%S")
                )
            )
        ),
    ]
    choicelist = ["1", "2", "3"]
    tbl_PPM_Encounter["Extra:WIP"] = np.select(condlist, choicelist, "4")
    logging.info(
        "Query: Update_WIP_EncounterIP completed. tbl_PPM_Encounter has %s records.",
        len(tbl_PPM_Encounter),
    )
    # Is this step required?
    """ If the length of the encounternumber = 18 in tbl_PPM_Encounter table  """
    # query: Format Encounter EN to len 19"
    """If the length of the encounternumber = 18 in tbl_PPM_Encounter table  then 
        IIf(Len([EncounterNumber])=18,Left([Encounternumber],7) & "0" & Mid([EncounterNumber],8),IIf(Len([EncounterNumber])=16,Left([Encounternumber],7) & "000" & Mid([EncounterNumber],8),[EncounterNumber]))
    """
    tbl_PPM_Encounter["Extra:LeaveinCostingPeriod"] = tbl_PPM_Encounter[
        "Extra:LeaveinCostingPeriod"
    ].fillna(0)
    tbl_PPM_Encounter["Extra:LeaveinCostingPeriod"] = np.where(
        (tbl_PPM_Encounter["Extra:LeaveinCostingPeriod"] == "")
        | (tbl_PPM_Encounter["Extra:LeaveinCostingPeriod"].isnull()),
        0,
        tbl_PPM_Encounter["Extra:LeaveinCostingPeriod"],
    )
    tbl_PPM_Encounter["Extra:LeaveinCostingPeriod"] = tbl_PPM_Encounter[
        "Extra:LeaveinCostingPeriod"
    ].astype(float)
    tbl_PPM_Encounter["Extra:LeaveinCostingPeriod"] = tbl_PPM_Encounter[
        "Extra:LeaveinCostingPeriod"
    ].astype(int, errors="ignore")
    # tbl_PPM_Encounter['Extra:LeaveinCostingPeriod'] = tbl_PPM_Encounter['Extra:LeaveinCostingPeriod'].astype(str)
    tbl_PPM_Encounter["Extra:LOSinCostingPeriod"] = tbl_PPM_Encounter[
        "Extra:LOSinCostingPeriod"
    ].fillna(0)
    tbl_PPM_Encounter["Extra:LOSinCostingPeriod"] = np.where(
        (tbl_PPM_Encounter["Extra:LOSinCostingPeriod"] == "")
        | (tbl_PPM_Encounter["Extra:LOSinCostingPeriod"].isnull()),
        0,
        tbl_PPM_Encounter["Extra:LOSinCostingPeriod"],
    )
    tbl_PPM_Encounter["Extra:LOSinCostingPeriod"] = tbl_PPM_Encounter[
        "Extra:LOSinCostingPeriod"
    ].astype(float)
    tbl_PPM_Encounter["Extra:LOSinCostingPeriod"] = tbl_PPM_Encounter[
        "Extra:LOSinCostingPeriod"
    ].astype(int, errors="ignore")
    # tbl_PPM_Encounter['Extra:LOSinCostingPeriod'] = tbl_PPM_Encounter['Extra:LOSinCostingPeriod'].astype(str)
    """ Updates the Extra:LOSinCostingPeriod in the tbl_PPM_Encounter table"""
    # Access query: Update LOS tbl_PPM_Encounter
    # UPDATE tbl_PPM_Encounter SET tbl_PPM_Encounter.[Extra:LOSinCostingPeriod] = (IIf(DateValue([tbl_PPM_Encounter]![StartDateTime])=DateValue([tbl_PPM_Encounter]![EndDateTime]),1,(DateDiff("d",IIf(DateValue([tbl_PPM_Encounter]![StartDateTime])<DateValue([Forms]![Frm:1-ExtractSetUp]![Start_Date]),DateValue([Forms]![Frm:1-ExtractSetUp]![Start_Date]),IIf((DateValue([tbl_PPM_Encounter]![StartDateTime]))>DateValue([Forms]![Frm:1-ExtractSetUp]![end_Date]),DateValue([Forms]![Frm:1-ExtractSetUp]![End_Date]),DateValue([tbl_PPM_Encounter]![StartDateTime]))),IIf([tbl_PPM_Encounter]![EndDateTime] Is Null,DateValue([Forms]![Frm:1-ExtractSetUp]![End_Date])+1,IIf(DateValue([tbl_PPM_Encounter]![EndDateTime])>DateValue([Forms]![Frm:1-ExtractSetUp]![End_Date]),DateValue([Forms]![Frm:1-ExtractSetUp]![End_Date])+1,DateValue([tbl_PPM_Encounter]![EndDateTime])))))-Nz([Extra:LeaveinCostingPeriod]))) WHERE (((tbl_PPM_Encounter.EncounterNumber) Not Like "*[_]*")) OR (((tbl_PPM_Encounter.EpisodeOfCare)<>"M") AND ((tbl_PPM_Encounter.[Extra:WIP])<>"4"));
    end_date_dt = pd.to_datetime(end_date, format="%Y-%m-%d %H:%M:%S")
    start_date_dt = pd.to_datetime(start_date, format="%Y-%m-%d %H:%M:%S")
    # 184 - fix Leave in Costing period = 1 but Leave days = 0. Code change
    # tbl_PPM_Encounter.loc[((tbl_PPM_Encounter.EncounterNumber.str.contains('[_]') == False) | ((tbl_PPM_Encounter['EpisodeOfCare'] != 'M') & (tbl_PPM_Encounter['Extra:WIP'] != '4'))) & (tbl_PPM_Encounter['StartDateTime'] ==tbl_PPM_Encounter['EndDateTime']), 'Extra:LeaveinCostingPeriod'] = 1
    tbl_PPM_Encounter.loc[
        (
            (tbl_PPM_Encounter.EncounterNumber.str.contains("[_]") == False)
            | (
                (tbl_PPM_Encounter["EpisodeOfCare"] != "M")
                & (tbl_PPM_Encounter["Extra:WIP"] != "4")
            )
        )
        & (tbl_PPM_Encounter["StartDateTime"] == tbl_PPM_Encounter["EndDateTime"]),
        "Extra:LOSinCostingPeriod",
    ] = 1
    tbl_PPM_Encounter["start_date_dt"] = start_date_dt
    tbl_PPM_Encounter["end_date_dt"] = end_date_dt
    condlist = [
        tbl_PPM_Encounter["StartDateTime"] < tbl_PPM_Encounter["start_date_dt"],
        (tbl_PPM_Encounter["StartDateTime"] > tbl_PPM_Encounter["end_date_dt"]),
    ]
    choicelist = [tbl_PPM_Encounter["start_date_dt"], tbl_PPM_Encounter["end_date_dt"]]
    tbl_PPM_Encounter["dummy_start_date"] = np.select(
        condlist, choicelist, tbl_PPM_Encounter["StartDateTime"]
    )
    """
    condlist =[(tbl_PPM_Encounter['EndDateTime'].isnull()) | (tbl_PPM_Encounter['EndDateTime']==''), pd.to_datetime(tbl_PPM_Encounter['EndDateTime'], format="%Y-%m-%d %H:%M:%S")>end_date_dt]
    choicelist = [end_date_dt+pd.DateOffset(1), end_date_dt+pd.DateOffset(1) ]
    tbl_PPM_Encounter['dummy_end_date'] = np.select(condlist, choicelist, tbl_PPM_Encounter['EndDateTime'])
    """
    # print("tbl_PPM_Encounter['EndDateTime']=",tbl_PPM_Encounter['EndDateTime'].dtypes, ". tbl_PPM_Encounter['end_date_dt']=", tbl_PPM_Encounter['end_date_dt'].dtypes, ". tbl_PPM_Encounter['EndDateTimeplus1']=", tbl_PPM_Encounter['EndDateTimeplus1'].dtypes)
    tbl_PPM_Encounter["dummy_end_date"] = np.where(
        tbl_PPM_Encounter["EndDateTime"] > tbl_PPM_Encounter["end_date_dt"],
        tbl_PPM_Encounter["EndDateTimeplus1"],
        tbl_PPM_Encounter["EndDateTime"],
    )
    # Nz([Extra:LeaveinCostingPeriod]
    # tbl_PPM_Encounter['Extra:LeaveinCostingPeriod'] = np.where((tbl_PPM_Encounter['Extra:LeaveinCostingPeriod'].isnull()) | (tbl_PPM_Encounter['Extra:LeaveinCostingPeriod']==''), 0, tbl_PPM_Encounter['Extra:LeaveinCostingPeriod'])
    tbl_PPM_Encounter["dummy_los"] = (
        tbl_PPM_Encounter["dummy_end_date"] - tbl_PPM_Encounter["dummy_start_date"]
    ).dt.days - (tbl_PPM_Encounter["Extra:LeaveinCostingPeriod"])
    # tbl_PPM_Encounter['dummy_los'] = tbl_PPM_Encounter['dummy_los'].astype(int, errors='ignore')
    # tbl_PPM_Encounter['Extra:LeaveinCostingPeriod'] = tbl_PPM_Encounter['Extra:LeaveinCostingPeriod'].astype(str)
    # print("tbl_PPM_Encounter['dummy_los'] =", tbl_PPM_Encounter['dummy_los'].dtypes, "tbl_PPM_Encounter['Extra:LeaveinCostingPeriod']=",tbl_PPM_Encounter['Extra:LeaveinCostingPeriod'].dtypes)
    # Resetting index with .reset_index() as an additional index col has crept into df
    tbl_PPM_Encounter = tbl_PPM_Encounter.reset_index()
    tbl_PPM_Encounter = tbl_PPM_Encounter[
        [
            "EncounterType",
            "EncounterNumber",
            "PostCode",
            "Suburb",
            "MaritalStatus",
            "PatientNumber",
            "EpisodeOfCare",
            "AttendingConsultant",
            "AdmissionCategory",
            "AdmissionElection",
            "DischargeElection",
            "AdmissionType",
            "AdmissionSource",
            "Hospital",
            "FinancialClass",
            "DischargeStatus",
            "DRG1",
            "DRG1Version",
            "DRG2",
            "DRG2Version",
            "LengthOfStay",
            "ICUHours",
            "MechVentHours",
            "StartDateTime",
            "EndDateTime",
            "Age",
            "HealthFund",
            "AdmissionWeight",
            "WeightedSeparation",
            "Extra:LGACode",
            "Extra:HospitalStayNumber",
            "Extra:LHDIdentifier",
            "Extra:LegalStatus",
            "Extra:DVANumber",
            "Extra:DVAType",
            "Extra:IntendedSameDay",
            "Extra:ReferralFurtherHealthcare",
            "Extra:UnplannedReadmission",
            "Extra:EpisodeSequenceNumber",
            "Extra:MedicareNumber",
            "Extra:DaysinPsychUnit",
            "Extra:UnplannedTheatre",
            "Extra:EDStatus",
            "Extra:ICUStatus",
            "Extra:SRGcurrent",
            "Extra:ESRGcurrent",
            "Extra:CW_A",
            "Extra:CW_B",
            "Extra:CW_C",
            "Extra:CW_D",
            "Extra:CW_E",
            "Extra:CW_F",
            "Extra:TrimPoint",
            "Extra:Outlierdays",
            "Extra:SurgeryIndicator",
            "Extra:AreaDOHRSCode",
            "Extra:FacilityTransferredto",
            "Extra:FacilityTransferredfrom",
            "Extra:MRN",
            "Extra:MDC",
            "Extra:MDC2",
            "Extra:FinancialProgram",
            "Extra:indicatorProcedurecode",
            "Extra:bookingIdentifier",
            "Extra:waitinglistcategory",
            "Extra:ClinicalURGfinal",
            "Extra:ReasonforRemoval",
            "Extra:DRG1_pccl",
            "Extra:EpisodeLeaveDays",
            "Extra:QualifiedBedDays",
            "Extra:IndigenousStatus",
            "Extra:MothersMRN",
            "Extra:MothersStayNumber",
            "Extra:MothersPersonIdentifier",
            "Extra:ElectionStatusSummary",
            "Extra:FacilityType",
            "Extra:MedicareEligibility",
            "Extra:LOSinCostingPeriod",
            "Extra:LeaveinCostingPeriod",
            "Extra:ExtractorVersion",
            "Extra:AICU1_Hours",
            "Extra:AICU3_Hours",
            "Extra:PICU_Hours",
            "Extra:NICU_Hours",
            "Extra:PSICU_Hours",
            "Extra:CCU_Hours",
            "Extra:AICU2_Hours",
            "AttendingConsultantSpecialty",
            "Extra:nwau",
            "Extra:nwau_PublicEquivModel",
            "Extra:nwau_base",
            "Extra:nwau_paed_incr",
            "Extra:nwau_indig_incr",
            "Extra:nwau_remote_incr",
            "Extra:nwau_icu_incr",
            "Extra:nwau_private_patient_service_incr",
            "Extra:nwau_private_patient_accom_incr",
            "Extra:AUID",
            "Extra:HITH_Hours",
            "Extra:HDU_Hours",
            "Extra:SCN_Hours",
            "Extra:SRG_Version",
            "Extra:Collabrtve_Care_Facility",
            "Extra:Contract_Status",
            "Extra:Collabrtve_Care_Role",
            "Extra:Collabrtve_Care_Type",
            "Extra:Radiotherapy_adj",
            "Extra:nwau_version",
            "Extra:LHD_of_Usual_Residence",
            "Extra:sp_psy_age_adj",
            "Extra:compensable_nwau",
            "Extra:SpecialtyPortal",
            "Extra:ExtractDate",
            "Extra:WIP",
            "Extra:StartDateTime_EpisodeTable",
            "Extra:EndDateTime_EpisodeATSTable",
            "Extra:EndDateTime_EpisodeTable",
            "Extra:LengthofStay_EpisodeTable",
            "Extra:LengthofStay_EpisodeATSTable",
            "Extra:EpisodeLeaveDays_EpisodeTable",
            "Extra:EpisodeLeaveDays_EpisodeATSTable",
            "Extra:EpisodeofCare_EpisodeTable",
            "Extra:EpisodeofCare_EpisodeATSTable",
            "Extra:MothersEncounterNumber",
            "DRG3",
            "DRG3Version",
            "Extra:SNAP_Class",
            "Extra:SNAP_ClassV4",
            "Extra:Dementia_Flag",
            "Extra:Delirium_Flag",
            "Extra:AMHCC_Class",
            "Extra:AMHCC_ClassVersion",
            "Extra:HON1",
            "Extra:HON2",
            "Extra:HON3",
            "Extra:HON4",
            "Extra:HON5",
            "Extra:HON6",
            "Extra:HON7",
            "Extra:HON8",
            "Extra:HON9",
            "Extra:HON10",
            "Extra:HON11",
            "Extra:HON12",
            "Extra:HON13",
            "Extra:HON14",
            "Extra:HON15",
            "Extra:HONOS1",
            "Extra:HONOS2",
            "Extra:HONOS3",
            "Extra:HONOS4",
            "Extra:HONOS5",
            "Extra:HONOS6",
            "Extra:HONOS7",
            "Extra:HONOS8",
            "Extra:HONOS9",
            "Extra:HONOS10",
            "Extra:HONOS11",
            "Extra:HONOS12",
            "Extra:HONOS65_1",
            "Extra:HONOS65_2",
            "Extra:HONOS65_3",
            "Extra:HONOS65_4",
            "Extra:HONOS65_5",
            "Extra:HONOS65_6",
            "Extra:HONOS65_7",
            "Extra:HONOS65_8",
            "Extra:HONOS65_9",
            "Extra:HONOS65_10",
            "Extra:HONOS65_11",
            "Extra:HONOS65_12",
            "Extra:HONOSCA1",
            "Extra:HONOSCA2",
            "Extra:HONOSCA3",
            "Extra:HONOSCA4",
            "Extra:HONOSCA5",
            "Extra:HONOSCA6",
            "Extra:HONOSCA7",
            "Extra:HONOSCA8",
            "Extra:HONOSCA9",
            "Extra:HONOSCA10",
            "Extra:HONOSCA11",
            "Extra:HONOSCA12",
            "Extra:HONOSCA13",
            "Extra:HONOSCA14",
            "Extra:HONOSCA15",
            "Extra:IHPA_LSP_01",
            "Extra:IHPA_LSP_02",
            "Extra:IHPA_LSP_03",
            "Extra:IHPA_LSP_04",
            "Extra:IHPA_LSP_05",
            "Extra:IHPA_LSP_06",
            "Extra:IHPA_LSP_07",
            "Extra:IHPA_LSP_08",
            "Extra:IHPA_LSP_09",
            "Extra:IHPA_LSP_10",
            "Extra:IHPA_LSP_11",
            "Extra:IHPA_LSP_12",
            "Extra:IHPA_LSP_13",
            "Extra:IHPA_LSP_14",
            "Extra:IHPA_LSP_15",
            "Extra:IHPA_LSP_16",
            "Extra:MHPhaseSeqNo",
            "Extra:Cost_Weight",
            "Extra:ProdType",
            "Extra:CaseType",
            "Extra:EpisType",
            "Extra:AssessOnly",
            "Extra:PCPhase",
            "Extra:PCSymptomScoreStart",
            "Extra:PCSeverityStart",
            "Extra:PCPsychSpiritualScoreStart",
            "Extra:PCFamilyCarerScoreStart",
            "Extra:MaintType",
            "Extra:CareFocus",
            "Extra:Impair",
            "Extra:RugBedBeg",
            "Extra:RugToilBeg",
            "Extra:RugXferBeg",
            "Extra:RugEatBeg",
            "Extra:FIMEatBeg",
            "Extra:FIMEatEnd",
            "Extra:FIMGroomBeg",
            "Extra:FIMGroomEnd",
            "Extra:FIMBathBeg",
            "Extra:FIMBathEnd",
            "Extra:FIMUpperBeg",
            "Extra:FIMUpperEnd",
            "Extra:FIMLowerBeg",
            "Extra:FIMLowerEnd",
            "Extra:FIMToiletBeg",
            "Extra:FIMToiletEnd",
            "Extra:FIMBladderBeg",
            "Extra:FIMBladderEnd",
            "Extra:FIMBowelBeg",
            "Extra:FIMBowelEnd",
            "Extra:FIMXferBeg",
            "Extra:FIMXferEnd",
            "Extra:FIMXferToilBeg",
            "Extra:FIMXferToilEnd",
            "Extra:FIMTubBeg",
            "Extra:FIMTubEnd",
            "Extra:FIMWalkBeg",
            "Extra:FIMWalkEnd",
            "Extra:FIMStairBeg",
            "Extra:FIMStairEnd",
            "Extra:FIMCompBeg",
            "Extra:FIMCompEnd",
            "Extra:FIMExpBeg",
            "Extra:FIMExpEnd",
            "Extra:FIMSocialBeg",
            "Extra:FIMSocialEnd",
            "Extra:FIMProbBeg",
            "Extra:FIMProbEnd",
            "Extra:FIMMemoryBeg",
            "Extra:FIMMemoryEnd",
            "Extra:HonActiveBeg",
            "Extra:HonActiveEnd",
            "Extra:HonInjuryBeg",
            "Extra:HonInjuryEnd",
            "Extra:HonDrinkBeg",
            "Extra:HonDrinkEnd",
            "Extra:HonCognitBeg",
            "Extra:HonCognitEnd",
            "Extra:HonDisabBeg",
            "Extra:HonDisabEnd",
            "Extra:HonHallucBeg",
            "Extra:HonHallucEnd",
            "Extra:HonDeprsBeg",
            "Extra:HonDeprsEnd",
            "Extra:HonOtherBeg",
            "Extra:HonOtherEnd",
            "Extra:HonRelatBeg",
            "Extra:HonRelatEnd",
            "Extra:HonADLBeg",
            "Extra:HonADLEnd",
            "Extra:HonLivingBeg",
            "Extra:HonLivingEnd",
            "Extra:HonOccupBeg",
            "Extra:HonOccupEnd",
            "EndDateTimeplus1",
            "start_date_dt",
            "end_date_dt",
            "dummy_start_date",
            "dummy_end_date",
            "dummy_los",
            "Extra:HLTH_ORG_OSP_OSP_ID",
            "Extra:MG_AUTH_OSP_OSP_ID",
            "Extra:SE_CBK_SK",
            "Extra:CL_ID_EUID",
            "Extra:CL_ID_IHI",
            "Extra:HLTH_ORG_OSP_TYP",
            "Extra:SRV_ENC_REC_ID",
            "Extra:FRML_DISCH_MODE_CD",
            "Extra:SE_SEP_MODE_NHDD_CD",
            "Extra:Responsible_Facility",
            "Extra:SE_TYP_CD",
            "Extra:SE_ADM_MODE_NHDD_CD",
            "Extra:DIM_RSP_ISP_SK",
            "Extra:AR_DRG_ECCS_RAW",
            "Extra:WAU_ADJ_PT_TX_REMT_AREA",
            "Extra:WAU_ADJ_DIALYSIS",
            "Extra:WAU_ADJ_COVID19",
            "Extra:WAU_ADJ_HAC",
            "Extra:ASGS_SA_L2_16_CD",
            "Extra:CL_URES_ADDR_ASGS21_SA_L2_CD",
        ]
    ]
    # tbl_PPM_Encounter.to_csv('./ExtractorDB/tbl_PPM_Encounter_testLOS_1.csv', index = False)
    # 22 oct - commenting this as LOSinCosting period is not correct.
    # tbl_PPM_Encounter.loc[((tbl_PPM_Encounter.EncounterNumber.str.contains('[_]') == False) | ((tbl_PPM_Encounter['EpisodeOfCare'] != 'M') & (tbl_PPM_Encounter['Extra:WIP'] != '4'))) & ~(tbl_PPM_Encounter['StartDateTime'] ==tbl_PPM_Encounter['EndDateTime']), 'Extra:LOSinCostingPeriod'] = tbl_PPM_Encounter['dummy_los']
    logging.info(
        "Query: Update LOS tbl_PPM_Encounter completed. tbl_PPM_Encounter has %s records.",
        len(tbl_PPM_Encounter),
    )
    # Access query: Update 0 LOS in Costing Period
    # UPDATE tbl_PPM_Encounter SET tbl_PPM_Encounter.[Extra:LOSinCostingPeriod] = "1" WHERE (((tbl_PPM_Encounter.[Extra:LOSinCostingPeriod])="0"));
    tbl_PPM_Encounter["Extra:LOSinCostingPeriod"] = np.where(
        tbl_PPM_Encounter["Extra:LOSinCostingPeriod"] == 0,
        1,
        tbl_PPM_Encounter["Extra:LOSinCostingPeriod"],
    )
    # tbl_PPM_Encounter['Extra:LOSinCostingPeriod'] = tbl_PPM_Encounter['Extra:LOSinCostingPeriod'].astype(int, errors='ignore')
    logging.info(
        "Query: Update 0 LOS in Costing Period completed. tbl_PPM_Encounter has %s records.",
        len(tbl_PPM_Encounter),
    )
    # BELow update query was already done during access query Encounter_AUID and Encounter_AUID_SNAP
    # Access query: Update_LOS_Less_Leave_On_PPM_Encounter
    # UPDATE tbl_PPM_Encounter SET tbl_PPM_Encounter.[Extra:LOSinCostingPeriod] = (VAL(tbl_PPM_Encounter.[Extra:LOSinCostingPeriod]) - VAL(tbl_PPM_Encounter.[Extra:LeaveinCostingPeriod])) WHERE tbl_PPM_Encounter.[Extra:LeaveinCostingPeriod] <> '' AND tbl_PPM_Encounter.[Extra:LOSinCostingPeriod] <> '' AND VAL(Nz(tbl_PPM_Encounter.[Extra:LeaveinCostingPeriod],'0')) > 0 AND VAL(Nz(tbl_PPM_Encounter.[Extra:LeaveinCostingPeriod],'0')) < VAL(Nz(tbl_PPM_Encounter.[Extra:LOSinCostingPeriod],'0'));
    """
    logging.info('Query: Update_LOS_Less_Leave_On_PPM_Encounter completed.  tbl_PPM_Encounter has %s records.',len(tbl_PPM_Encounter))
    tbl_PPM_Encounter['Extra:LOSinCostingPeriod'] = np.where((tbl_PPM_Encounter['Extra:LOSinCostingPeriod'] > 0) & (tbl_PPM_Encounter['Extra:LeaveinCostingPeriod']>0), tbl_PPM_Encounter['Extra:LOSinCostingPeriod']-tbl_PPM_Encounter['Extra:LeaveinCostingPeriod'], tbl_PPM_Encounter['Extra:LOSinCostingPeriod'])
    """
    tbl_PPM_Encounter["Extra:LOSinCostingPeriod"] = np.where(
        (tbl_PPM_Encounter["Extra:LOSinCostingPeriod"] < 0),
        (-1) * tbl_PPM_Encounter["Extra:LOSinCostingPeriod"],
        tbl_PPM_Encounter["Extra:LOSinCostingPeriod"],
    )
    # Access query: Update_DEG1Version_On_PPM_Encounter
    # UPDATE tbl_PPM_Encounter SET tbl_PPM_Encounter.DRG1Version = Int(Nz(tbl_PPM_Encounter.[DRG1Version],0)) WHERE tbl_PPM_Encounter.[DRG1Version] <> '' AND Val(Nz(tbl_PPM_Encounter.[DRG1Version],'0')) > 0;
    tbl_PPM_Encounter["DRG1Version"] = np.where(
        (tbl_PPM_Encounter["DRG1Version"] == "")
        | (tbl_PPM_Encounter["DRG1Version"].isnull()),
        "0",
        tbl_PPM_Encounter["DRG1Version"],
    )
    tbl_PPM_Encounter["DRG1Version"] = np.where(
        (
            (pd.notna(tbl_PPM_Encounter["DRG1Version"]))
            & (tbl_PPM_Encounter["DRG1Version"] != "")
        ),
        tbl_PPM_Encounter["DRG1Version"],
        0,
    )
    logging.info(
        "Query: Update_DEG1Version_On_PPM_Encounter completed. tbl_PPM_Encounter has %s records.",
        len(tbl_PPM_Encounter),
    )
    # Access query: Update_DEG2Version_On_PPM_Encounter
    # UPDATE tbl_PPM_Encounter SET tbl_PPM_Encounter.DRG2Version = Int(Nz(tbl_PPM_Encounter.[DRG2Version],0)) WHERE tbl_PPM_Encounter.[DRG2Version] <> '' AND Val(Nz(tbl_PPM_Encounter.[DRG2Version],'0')) > 0;
    tbl_PPM_Encounter["DRG2Version"] = np.where(
        (tbl_PPM_Encounter["DRG2Version"] == "")
        | (tbl_PPM_Encounter["DRG2Version"].isnull()),
        "0",
        tbl_PPM_Encounter["DRG2Version"],
    )
    tbl_PPM_Encounter["DRG2Version"] = np.where(
        (
            (pd.notna(tbl_PPM_Encounter["DRG2Version"]))
            & (tbl_PPM_Encounter["DRG2Version"] != "")
        ),
        tbl_PPM_Encounter["DRG2Version"],
        0,
    )
    logging.info(
        "Query: Update_DEG2Version_On_PPM_Encounter completed. tbl_PPM_Encounter has %s records.",
        len(tbl_PPM_Encounter),
    )
    # Access query: Update_DEG3Version_On_PPM_Encounter
    # UPDATE tbl_PPM_Encounter SET tbl_PPM_Encounter.DRG3Version = Int(Nz(tbl_PPM_Encounter.[DRG3Version],0)) WHERE tbl_PPM_Encounter.[DRG3Version] <> '' AND Val(Nz(tbl_PPM_Encounter.[DRG3Version],'0')) > 0;
    tbl_PPM_Encounter["DRG3Version"] = np.where(
        (tbl_PPM_Encounter["DRG3Version"] == "")
        | (tbl_PPM_Encounter["DRG3Version"].isnull()),
        "0",
        tbl_PPM_Encounter["DRG3Version"],
    )
    tbl_PPM_Encounter["DRG3Version"] = np.where(
        (
            (pd.notna(tbl_PPM_Encounter["DRG3Version"]))
            & (tbl_PPM_Encounter["DRG3Version"] != "")
        ),
        tbl_PPM_Encounter["DRG3Version"],
        0,
    )
    logging.info(
        "Query: Update_DEG3Version_On_PPM_Encounter completed. tbl_PPM_Encounter has %s records.",
        len(tbl_PPM_Encounter),
    )
    tbl_PPM_Encounter["DRG1Version"] = np.where(
        (tbl_PPM_Encounter["DRG1Version"] == 0)
        | (tbl_PPM_Encounter["DRG1Version"] == 0.0),
        "",
        tbl_PPM_Encounter["DRG1Version"].astype(str),
    )
    tbl_PPM_Encounter["DRG2Version"] = np.where(
        (tbl_PPM_Encounter["DRG2Version"] == 0)
        | (tbl_PPM_Encounter["DRG2Version"] == 0.0),
        "",
        tbl_PPM_Encounter["DRG2Version"].astype(str),
    )
    tbl_PPM_Encounter["DRG3Version"] = np.where(
        (tbl_PPM_Encounter["DRG3Version"] == 0)
        | (tbl_PPM_Encounter["DRG3Version"] == 0.0),
        "",
        tbl_PPM_Encounter["DRG3Version"].astype(str),
    )
    # tbl_PPM_Encounter.to_csv('./ExtractorDB/tbl_PPM_Encounter_Update_DEG3Version_On_PPM_Encounter.csv', index = False)
    # Access query: Make_tbl_PPM_Encounter_WIP2
    # SELECT tbl_PPM_Encounter.Hospital, tbl_PPM_Encounter.[Extra:HospitalStayNumber], tbl_PPM_Encounter.[Extra:EpisodeSequenceNumber], Min(DateValue([StartDateTime])) AS MinDateTime, Max(DateValue([EndDateTime])) AS MaxDateTime INTO tbl_PPM_Encounter_WIP2
    # FROM tbl_PPM_Encounter GROUP BY tbl_PPM_Encounter.Hospital, tbl_PPM_Encounter.[Extra:HospitalStayNumber], tbl_PPM_Encounter.[Extra:EpisodeSequenceNumber], tbl_PPM_Encounter.EncounterNumber HAVING (((tbl_PPM_Encounter.EncounterNumber) Like "*-M-*"));
    # tbl_PPM_Encounter_WIP2 = tbl_PPM_Encounter[(tbl_PPM_Encounter.EncounterNumber.str.contains('-M-') == True)][['Hospital', 'Extra:HospitalStayNumber', 'Extra:EpisodeSequenceNumber', 'EncounterNumber', 'StartDateTime', 'EndDateTime']]
    # 11 Jan 2024 - CREATED FACILITY CHANGE
    # tbl_PPM_Encounter_WIP2 = tbl_PPM_Encounter[(tbl_PPM_Encounter.EncounterNumber.str.contains('-M-') == True) | (tbl_PPM_Encounter['EpisodeOfCare']=='3')][['Hospital', 'Extra:HospitalStayNumber', 'Extra:EpisodeSequenceNumber', 'StartDateTime', 'EndDateTime']]
    tbl_PPM_Encounter_WIP2 = tbl_PPM_Encounter[
        (tbl_PPM_Encounter.EncounterNumber.str.contains("-M-") == True)
        | (tbl_PPM_Encounter["EpisodeOfCare"] == "3")
    ][
        [
            "Hospital",
            "Extra:HospitalStayNumber",
            "Extra:EpisodeSequenceNumber",
            "StartDateTime",
            "EndDateTime",
            "Extra:SE_CBK_SK",
        ]
    ]
    if len(tbl_PPM_Encounter_WIP2) > 0:
        tbl_PPM_Encounter_WIP2["StartDateTime"] = pd.to_datetime(
            tbl_PPM_Encounter_WIP2["StartDateTime"].astype(str).str[:10],
            errors="coerce",
            format="%Y-%m-%d",
        )
        tbl_PPM_Encounter_WIP2["EndDateTime"] = pd.to_datetime(
            tbl_PPM_Encounter_WIP2["EndDateTime"].astype(str).str[:10],
            errors="coerce",
            format="%Y-%m-%d",
        )
        # tbl_PPM_Encounter_WIP2 = tbl_PPM_Encounter_WIP2.groupby(['Hospital', 'Extra:HospitalStayNumber', 'Extra:EpisodeSequenceNumber', 'EncounterNumber'], as_index=False, dropna=False).agg(MinDateTime=("StartDateTime", "min"), MaxDateTime=("EndDateTime", "max")).reset_index()
        # tbl_PPM_Encounter_WIP2 = tbl_PPM_Encounter_WIP2[['Hospital', 'Extra:HospitalStayNumber', 'Extra:EpisodeSequenceNumber', 'EncounterNumber', 'MinDateTime', 'MaxDateTime']]
        # 11 Jan 2024 - CREATED FACILITY CHANGE
        # tbl_PPM_Encounter_WIP2 = tbl_PPM_Encounter_WIP2.groupby(['Hospital', 'Extra:HospitalStayNumber', 'Extra:EpisodeSequenceNumber'], as_index=False, dropna=False).agg(MinDateTime=("StartDateTime", "min"), MaxDateTime=("EndDateTime", "max")).reset_index()
        # tbl_PPM_Encounter_WIP2 = tbl_PPM_Encounter_WIP2[['Hospital', 'Extra:HospitalStayNumber', 'Extra:EpisodeSequenceNumber', 'MinDateTime', 'MaxDateTime']]
        tbl_PPM_Encounter_WIP2 = (
            tbl_PPM_Encounter_WIP2.groupby(
                [
                    "Hospital",
                    "Extra:HospitalStayNumber",
                    "Extra:EpisodeSequenceNumber",
                    "Extra:SE_CBK_SK",
                ],
                as_index=False,
                dropna=False,
            )
            .agg(
                MinDateTime=("StartDateTime", "min"), MaxDateTime=("EndDateTime", "max")
            )
            .reset_index()
        )
        tbl_PPM_Encounter_WIP2 = tbl_PPM_Encounter_WIP2[
            [
                "Hospital",
                "Extra:HospitalStayNumber",
                "Extra:EpisodeSequenceNumber",
                "Extra:SE_CBK_SK",
                "MinDateTime",
                "MaxDateTime",
            ]
        ]
    else:
        # tbl_PPM_Encounter_WIP2 = pd.DataFrame(columns=['Hospital', 'Extra:HospitalStayNumber', 'Extra:EpisodeSequenceNumber', 'EncounterNumber', 'MinDateTime', 'MaxDateTime'])
        # 11 Jan 2024 - CREATED FACILITY CHANGE
        # tbl_PPM_Encounter_WIP2 = pd.DataFrame(columns=['Hospital', 'Extra:HospitalStayNumber', 'Extra:EpisodeSequenceNumber', 'MinDateTime', 'MaxDateTime'])
        tbl_PPM_Encounter_WIP2 = pd.DataFrame(
            columns=[
                "Hospital",
                "Extra:HospitalStayNumber",
                "Extra:EpisodeSequenceNumber",
                "Extra:SE_CBK_SK",
                "MinDateTime",
                "MaxDateTime",
            ]
        )
    # replace end_date_dt with tbl_PPM_Encounter_WIP2['EndDateTimeplus1']
    tbl_PPM_Encounter_WIP2["end_date_dt"] = end_date
    tbl_PPM_Encounter_WIP2["EndDateTimeplus1"] = pd.to_datetime(
        tbl_PPM_Encounter_WIP2["end_date_dt"].astype(str).str[:10], format="%Y-%m-%d"
    ) + pd.DateOffset(1)
    tbl_PPM_Encounter_WIP2 = tbl_PPM_Encounter_WIP2.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    tbl_PPM_Encounter_WIP2 = tbl_PPM_Encounter_WIP2.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    tbl_PPM_Encounter_WIP2 = tbl_PPM_Encounter_WIP2.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    try:
        tbl_PPM_Encounter_WIP2.to_csv(
            "./ExtractorDB/tbl_PPM_Encounter_WIP2.csv", index=False
        )
    except Exception as e:
        logging.exception("Exception occurred")
        label_2_status = 0
        messagebox.showerror(
            "Export Error",
            "Error saving /ExtractorDB/tbl_PPM_Encounter_WIP2.csv\n" + str(e),
        )
        label_2_sub.configure(text="Failed (tbl_PPM_Encounter_WIP2)...", fg="red")
        main_screen.update()
        return  # stop export
    logging.info(
        "Query: Make_tbl_PPM_Encounter_WIP2 completed. tbl_PPM_Encounter_WIP2 has %s records. tbl_PPM_Encounter_WIP2 saved to ./ExtractorDB/tbl_PPM_Encounter_WIP2.csv",
        len(tbl_PPM_Encounter_WIP2),
    )
    tbl_PPM_Encounter_WIP2["MinDateTime"] = pd.to_datetime(
        tbl_PPM_Encounter_WIP2["MinDateTime"].astype(str).str[:19],
        errors="coerce",
        format="%Y-%m-%d %H:%M:%S",
    )
    tbl_PPM_Encounter_WIP2["MaxDateTime"] = pd.to_datetime(
        tbl_PPM_Encounter_WIP2["MaxDateTime"].astype(str).str[:19],
        errors="coerce",
        format="%Y-%m-%d %H:%M:%S",
    )
    tbl_PPM_Encounter["Extra:WIP2"] = ""
    # Access query: Update_WIP2_4
    # UPDATE tbl_ppm_encounter INNER JOIN tbl_PPM_Encounter_WIP2 ON (tbl_ppm_encounter.Hospital = tbl_PPM_Encounter_WIP2.Hospital) AND (tbl_ppm_encounter.[Extra:HospitalStayNumber] = tbl_PPM_Encounter_WIP2.[Extra:HospitalStayNumber]) AND (tbl_ppm_encounter.[Extra:EpisodeSequenceNumber] = tbl_PPM_Encounter_WIP2.[Extra:EpisodeSequenceNumber]) SET tbl_ppm_encounter.[Extra:WIP2] = "4"
    # WHERE (((tbl_PPM_Encounter_WIP2.MinDateTime) Between DateValue(Forms![Frm:1-ExtractSetUp]!Start_Date) And DateValue(Forms![Frm:1-ExtractSetUp]!End_Date)) And ((tbl_PPM_Encounter_WIP2.MaxDateTime) Between DateValue(Forms![Frm:1-ExtractSetUp]!Start_Date) And DateValue(Forms![Frm:1-ExtractSetUp]!End_Date)));
    # 11 Jan 2024 - CREATED FACILITY CHANGE
    # tbl_PPM_Encounter = pd.merge(tbl_PPM_Encounter, tbl_PPM_Encounter_WIP2[(tbl_PPM_Encounter_WIP2['MinDateTime'] >= start_date_dt) & (tbl_PPM_Encounter_WIP2['MinDateTime'] <= end_date_dt) & (tbl_PPM_Encounter_WIP2['MaxDateTime'] >= start_date_dt) & (tbl_PPM_Encounter_WIP2['MaxDateTime'] <= end_date_dt)], how='left', on=['Hospital', 'Extra:HospitalStayNumber', 'Extra:EpisodeSequenceNumber'], suffixes=('', '_drop'), indicator=True)
    tbl_PPM_Encounter = pd.merge(
        tbl_PPM_Encounter,
        tbl_PPM_Encounter_WIP2[
            (tbl_PPM_Encounter_WIP2["MinDateTime"] >= start_date_dt)
            & (tbl_PPM_Encounter_WIP2["MinDateTime"] <= end_date_dt)
            & (tbl_PPM_Encounter_WIP2["MaxDateTime"] >= start_date_dt)
            & (tbl_PPM_Encounter_WIP2["MaxDateTime"] <= end_date_dt)
        ],
        how="left",
        on=["Extra:SE_CBK_SK"],
        suffixes=("", "_drop"),
        indicator=True,
    )
    tbl_PPM_Encounter = tbl_PPM_Encounter.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    logging.info(
        "Update_WIP2_4 completed. %s records will be updated in tbl_PPM_Encounter. tbl_PPM_Encounter has %s records.",
        len(tbl_PPM_Encounter[tbl_PPM_Encounter["_merge"] == "both"]),
        len(tbl_PPM_Encounter),
    )
    tbl_PPM_Encounter["Extra:WIP2"] = np.where(
        tbl_PPM_Encounter["_merge"] == "both", "4", tbl_PPM_Encounter["Extra:WIP2"]
    )
    tbl_PPM_Encounter.drop(
        ["_merge", "EncounterNumber_drop", "MinDateTime", "MaxDateTime"],
        axis=1,
        inplace=True,
        errors="ignore",
    )
    # Access query: Update_WIP2_1
    # UPDATE tbl_ppm_encounter INNER JOIN tbl_PPM_Encounter_WIP2 ON (tbl_ppm_encounter.[Extra:EpisodeSequenceNumber] = tbl_PPM_Encounter_WIP2.[Extra:EpisodeSequenceNumber]) AND (tbl_ppm_encounter.[Extra:HospitalStayNumber] = tbl_PPM_Encounter_WIP2.[Extra:HospitalStayNumber]) AND (tbl_ppm_encounter.Hospital = tbl_PPM_Encounter_WIP2.Hospital) SET tbl_ppm_encounter.[Extra:WIP2] = "1"
    # WHERE (((tbl_PPM_Encounter_WIP2.MinDateTime)<DateValue(Forms![Frm:1-ExtractSetUp]!Start_Date)) And ((tbl_PPM_Encounter_WIP2.MaxDateTime) Between DateValue(Forms![Frm:1-ExtractSetUp]!Start_Date) And DateValue(Forms![Frm:1-ExtractSetUp]!End_Date)));
    # 11 Jan 2024 - CREATED FACILITY CHANGE
    # tbl_PPM_Encounter = pd.merge(tbl_PPM_Encounter, tbl_PPM_Encounter_WIP2[(tbl_PPM_Encounter_WIP2['MinDateTime'] < start_date_dt) & (tbl_PPM_Encounter_WIP2['MaxDateTime'] >= start_date_dt) & (tbl_PPM_Encounter_WIP2['MaxDateTime'] <= end_date_dt)], how='left', on=['Hospital', 'Extra:HospitalStayNumber', 'Extra:EpisodeSequenceNumber'], suffixes=('', '_drop'), indicator=True)
    tbl_PPM_Encounter = pd.merge(
        tbl_PPM_Encounter,
        tbl_PPM_Encounter_WIP2[
            (tbl_PPM_Encounter_WIP2["MinDateTime"] < start_date_dt)
            & (tbl_PPM_Encounter_WIP2["MaxDateTime"] >= start_date_dt)
            & (tbl_PPM_Encounter_WIP2["MaxDateTime"] <= end_date_dt)
        ],
        how="left",
        on=["Extra:SE_CBK_SK"],
        suffixes=("", "_drop"),
        indicator=True,
    )
    tbl_PPM_Encounter = tbl_PPM_Encounter.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    logging.info(
        "Update_WIP2_1 completed. %s records will be updated in tbl_PPM_Encounter. tbl_PPM_Encounter has %s records.",
        len(tbl_PPM_Encounter[tbl_PPM_Encounter["_merge"] == "both"]),
        len(tbl_PPM_Encounter),
    )
    tbl_PPM_Encounter["Extra:WIP2"] = np.where(
        tbl_PPM_Encounter["_merge"] == "both", "1", tbl_PPM_Encounter["Extra:WIP2"]
    )
    tbl_PPM_Encounter.drop(
        ["_merge", "EncounterNumber_drop", "MinDateTime", "MaxDateTime"],
        axis=1,
        inplace=True,
        errors="ignore",
    )
    # Access query: Update_WIP2_2
    # UPDATE tbl_ppm_encounter INNER JOIN tbl_PPM_Encounter_WIP2 ON (tbl_ppm_encounter.Hospital = tbl_PPM_Encounter_WIP2.Hospital) AND (tbl_ppm_encounter.[Extra:HospitalStayNumber] = tbl_PPM_Encounter_WIP2.[Extra:HospitalStayNumber]) AND (tbl_ppm_encounter.[Extra:EpisodeSequenceNumber] = tbl_PPM_Encounter_WIP2.[Extra:EpisodeSequenceNumber]) SET tbl_ppm_encounter.[Extra:WIP2] = "2"
    # WHERE (((tbl_PPM_Encounter_WIP2.MinDateTime) Between DateValue(Forms![Frm:1-ExtractSetUp]!Start_Date) And DateValue(Forms![Frm:1-ExtractSetUp]!End_Date)) And ((tbl_PPM_Encounter_WIP2.MaxDateTime)>DateValue(Forms![Frm:1-ExtractSetUp]!End_Date))) Or (((tbl_PPM_Encounter_WIP2.MinDateTime) Between DateValue(Forms![Frm:1-ExtractSetUp]!Start_Date) And DateValue(Forms![Frm:1-ExtractSetUp]!End_Date)) And ((tbl_PPM_Encounter_WIP2.MaxDateTime) Is Null));
    # 11 Jan 2024 - CREATED FACILITY CHANGE
    # tbl_PPM_Encounter = pd.merge(tbl_PPM_Encounter, tbl_PPM_Encounter_WIP2[((tbl_PPM_Encounter_WIP2['MinDateTime'] >= start_date_dt) & (tbl_PPM_Encounter_WIP2['MinDateTime'] <= end_date_dt) & (tbl_PPM_Encounter_WIP2['MaxDateTime']> end_date_dt)) | (((tbl_PPM_Encounter_WIP2['MinDateTime'] >= start_date_dt) & (tbl_PPM_Encounter_WIP2['MinDateTime'] <= end_date_dt)) & ((tbl_PPM_Encounter_WIP2['MaxDateTime'].isnull()) | (tbl_PPM_Encounter_WIP2['MaxDateTime']=='')))], how='left', on=['Hospital', 'Extra:HospitalStayNumber', 'Extra:EpisodeSequenceNumber'], suffixes=('', '_drop'), indicator=True)
    tbl_PPM_Encounter = pd.merge(
        tbl_PPM_Encounter,
        tbl_PPM_Encounter_WIP2[
            (
                (tbl_PPM_Encounter_WIP2["MinDateTime"] >= start_date_dt)
                & (tbl_PPM_Encounter_WIP2["MinDateTime"] <= end_date_dt)
                & (tbl_PPM_Encounter_WIP2["MaxDateTime"] > end_date_dt)
            )
            | (
                (
                    (tbl_PPM_Encounter_WIP2["MinDateTime"] >= start_date_dt)
                    & (tbl_PPM_Encounter_WIP2["MinDateTime"] <= end_date_dt)
                )
                & (
                    (tbl_PPM_Encounter_WIP2["MaxDateTime"].isnull())
                    | (tbl_PPM_Encounter_WIP2["MaxDateTime"] == "")
                )
            )
        ],
        how="left",
        on=["Extra:SE_CBK_SK"],
        suffixes=("", "_drop"),
        indicator=True,
    )
    tbl_PPM_Encounter = tbl_PPM_Encounter.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    logging.info(
        "Update_WIP2_2 completed. %s records will be updated in tbl_PPM_Encounter. tbl_PPM_Encounter has %s records.",
        len(tbl_PPM_Encounter[tbl_PPM_Encounter["_merge"] == "both"]),
        len(tbl_PPM_Encounter),
    )
    tbl_PPM_Encounter["Extra:WIP2"] = np.where(
        tbl_PPM_Encounter["_merge"] == "both", "2", tbl_PPM_Encounter["Extra:WIP2"]
    )
    tbl_PPM_Encounter.drop(
        ["_merge", "EncounterNumber_drop", "MinDateTime", "MaxDateTime"],
        axis=1,
        inplace=True,
        errors="ignore",
    )
    # Access query: Update_WIP2_3
    # UPDATE tbl_ppm_encounter INNER JOIN tbl_PPM_Encounter_WIP2 ON (tbl_ppm_encounter.Hospital = tbl_PPM_Encounter_WIP2.Hospital) AND (tbl_ppm_encounter.[Extra:HospitalStayNumber] = tbl_PPM_Encounter_WIP2.[Extra:HospitalStayNumber]) AND (tbl_ppm_encounter.[Extra:EpisodeSequenceNumber] = tbl_PPM_Encounter_WIP2.[Extra:EpisodeSequenceNumber]) SET tbl_ppm_encounter.[Extra:WIP2] = "3"
    # WHERE (((tbl_PPM_Encounter_WIP2.MinDateTime)<DateValue(Forms![Frm:1-ExtractSetUp]!Start_Date)) And ((tbl_PPM_Encounter_WIP2.MaxDateTime)>DateValue(Forms![Frm:1-ExtractSetUp]!End_Date))) Or (((tbl_PPM_Encounter_WIP2.MinDateTime)<DateValue(Forms![Frm:1-ExtractSetUp]!Start_Date)) And ((tbl_PPM_Encounter_WIP2.MaxDateTime) Is Null));
    # 11 Jan 2024 - CREATED FACILITY CHANGE
    # tbl_PPM_Encounter = pd.merge(tbl_PPM_Encounter, tbl_PPM_Encounter_WIP2[((tbl_PPM_Encounter_WIP2['MinDateTime'] < start_date_dt)  & (tbl_PPM_Encounter_WIP2['MaxDateTime'] > end_date_dt)) | ((tbl_PPM_Encounter_WIP2['MinDateTime'] < start_date_dt)  & ((tbl_PPM_Encounter_WIP2['MaxDateTime'].isnull()) | (tbl_PPM_Encounter_WIP2['MaxDateTime']=='')))], how='left', on=['Hospital', 'Extra:HospitalStayNumber', 'Extra:EpisodeSequenceNumber'], suffixes=('', '_drop'), indicator=True)
    tbl_PPM_Encounter = pd.merge(
        tbl_PPM_Encounter,
        tbl_PPM_Encounter_WIP2[
            (
                (tbl_PPM_Encounter_WIP2["MinDateTime"] < start_date_dt)
                & (tbl_PPM_Encounter_WIP2["MaxDateTime"] > end_date_dt)
            )
            | (
                (tbl_PPM_Encounter_WIP2["MinDateTime"] < start_date_dt)
                & (
                    (tbl_PPM_Encounter_WIP2["MaxDateTime"].isnull())
                    | (tbl_PPM_Encounter_WIP2["MaxDateTime"] == "")
                )
            )
        ],
        how="left",
        on=["Extra:SE_CBK_SK"],
        suffixes=("", "_drop"),
        indicator=True,
    )
    tbl_PPM_Encounter = tbl_PPM_Encounter.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    logging.info(
        "Update_WIP2_3 completed. %s records will be updated in tbl_PPM_Encounter. tbl_PPM_Encounter has %s records.",
        len(tbl_PPM_Encounter[tbl_PPM_Encounter["_merge"] == "both"]),
        len(tbl_PPM_Encounter),
    )
    tbl_PPM_Encounter["Extra:WIP2"] = np.where(
        tbl_PPM_Encounter["_merge"] == "both", "3", tbl_PPM_Encounter["Extra:WIP2"]
    )
    tbl_PPM_Encounter.drop(
        ["_merge", "EncounterNumber_drop", "MinDateTime", "MaxDateTime"],
        axis=1,
        inplace=True,
        errors="ignore",
    )
    # Access query: Update_WIP2_NonMH
    # UPDATE tbl_PPM_Encounter SET tbl_PPM_Encounter.[Extra:WIP2] = [tbl_PPM_Encounter].[Extra:WIP] WHERE (((tbl_PPM_Encounter.[Extra:WIP2]) Is Null));
    logging.info(
        "Update_WIP2_NonMH completed. %s records will be updated in tbl_PPM_Encounter. tbl_PPM_Encounter has %s records.",
        len(
            tbl_PPM_Encounter[
                (
                    tbl_PPM_Encounter["Extra:WIP2"].isnull()
                    | (tbl_PPM_Encounter["Extra:WIP2"] == "")
                )
            ]
        ),
        len(tbl_PPM_Encounter),
    )
    tbl_PPM_Encounter["Extra:WIP2"] = np.where(
        (
            tbl_PPM_Encounter["Extra:WIP2"].isnull()
            | (tbl_PPM_Encounter["Extra:WIP2"] == "")
        ),
        tbl_PPM_Encounter["Extra:WIP"],
        tbl_PPM_Encounter["Extra:WIP2"],
    )
    #############################DRG4#####################
    # Access query: Update_DRG4_On_PPM_Encounter
    # UPDATE tbl_dbo_episode_DRG INNER JOIN tbl_PPM_Encounter ON (tbl_dbo_episode_DRG.episode_sequence_number = tbl_PPM_Encounter.[Extra:EpisodeSequenceNumber]) AND (tbl_dbo_episode_DRG.facility_identifier = tbl_PPM_Encounter.Hospital) SET tbl_PPM_Encounter.[Extra:DRG4Version] = Round([tbl_dbo_episode_DRG].[4_an_drg_version],0), tbl_PPM_Encounter.[Extra:DRG4] = [tbl_dbo_episode_DRG].[4_an_drg]
    # WHERE (((tbl_PPM_Encounter.[Extra:HospitalStayNumber])="SN" & [tbl_dbo_episode_DRG].[stay_number]));
    # I put stay number also in JOIN fields
    tbl_dbo_episode_DRG["stay_number_DRG"] = np.where(
        (
            pd.notna(tbl_dbo_episode_DRG["stay_number"])
            & (tbl_dbo_episode_DRG["stay_number"] != "")
        ),
        "SN"
        + tbl_dbo_episode_DRG["stay_number"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0"),
        "",
    )
    #########################
    # 11 Jan 2025 - CREATED FACILITY CHANGE
    # ValueError: You are trying to merge on object and int64 columns
    tbl_PPM_Encounter["Extra:SE_CBK_SK"] = tbl_PPM_Encounter["Extra:SE_CBK_SK"].astype(
        "Int64"
    )
    ########################
    # 11 Jan 2024 - CREATED FACILITY CHANGE
    # tbl_PPM_Encounter = pd.merge(tbl_PPM_Encounter, tbl_dbo_episode_DRG[['stay_number_DRG', 'episode_sequence_number', 'facility_identifier', '4_an_drg_version', '4_an_drg']], how='left', right_on=['episode_sequence_number', 'facility_identifier', 'stay_number_DRG'], left_on=['Extra:EpisodeSequenceNumber', 'Hospital', 'Extra:HospitalStayNumber'], suffixes=('', '_drop'), indicator=True)
    tbl_PPM_Encounter = pd.merge(
        tbl_PPM_Encounter,
        tbl_dbo_episode_DRG[
            [
                "stay_number_DRG",
                "episode_sequence_number",
                "facility_identifier",
                "4_an_drg_version",
                "4_an_drg",
                "SE_CBK_SK",
            ]
        ],
        how="left",
        right_on=["SE_CBK_SK"],
        left_on=["Extra:SE_CBK_SK"],
        suffixes=("", "_drop"),
        indicator=True,
    )
    tbl_PPM_Encounter = tbl_PPM_Encounter.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    logging.info(
        "Update_DRG4_On_PPM_Encounter completed.  tbl_PPM_Encounter has %s records.",
        len(tbl_PPM_Encounter),
    )
    tbl_PPM_Encounter["Extra:DRG4Version"] = np.where(
        (tbl_PPM_Encounter["_merge"] == "both"),
        tbl_PPM_Encounter["4_an_drg_version"].astype("Int64", errors="ignore"),
        "",
    )
    tbl_PPM_Encounter["Extra:DRG4"] = np.where(
        (tbl_PPM_Encounter["_merge"] == "both"), tbl_PPM_Encounter["4_an_drg"], ""
    )
    tbl_PPM_Encounter.drop(
        ["_merge", "stay_number_DRG"], axis=1, inplace=True, errors="ignore"
    )
    # Access query: Update_DEG4Version_On_PPM_Encounter
    # UPDATE tbl_PPM_Encounter SET tbl_PPM_Encounter.[Extra:DRG4Version] = Int(Nz(tbl_PPM_Encounter.[Extra:DRG4Version],0)) WHERE tbl_PPM_Encounter.[Extra:DRG4Version] <> '' AND
    tbl_PPM_Encounter["Extra:DRG4Version"] = np.where(
        (tbl_PPM_Encounter["Extra:DRG4Version"] == "")
        | (tbl_PPM_Encounter["Extra:DRG4Version"].isnull()),
        "0",
        tbl_PPM_Encounter["Extra:DRG4Version"],
    )
    tbl_PPM_Encounter["Extra:DRG4Version"] = np.where(
        pd.notna(tbl_PPM_Encounter["Extra:DRG4Version"])
        & (tbl_PPM_Encounter["Extra:DRG4Version"] != ""),
        tbl_PPM_Encounter["Extra:DRG4Version"],
        0,
    )
    # tbl_PPM_Encounter['Extra:DRG4Version'] = tbl_PPM_Encounter['Extra:DRG4Version']#.astype(int, errors='ignore')
    tbl_PPM_Encounter["Extra:DRG4Version"] = np.where(
        tbl_PPM_Encounter["Extra:DRG4Version"] == 0,
        "",
        tbl_PPM_Encounter["Extra:DRG4Version"].astype(str),
    )
    logging.info(
        "Update_DEG4Version_On_PPM_Encounter completed. tbl_PPM_Encounter has %s records.",
        len(tbl_PPM_Encounter),
    )
    # Access query: Update_DRG4_On_PPM_Encounter_Uncoded
    # UPDATE tbl_PPM_Encounter SET tbl_PPM_Encounter.[Extra:DRG4] = "960Z", tbl_PPM_Encounter.[Extra:DRG4Version] = "9" WHERE (((tbl_PPM_Encounter.[Extra:DRG4]) Is Null) AND ((tbl_PPM_Encounter.[Extra:DRG4Version]) Is Null));
    tbl_PPM_Encounter["Extra:DRG4"] = np.where(
        (
            (tbl_PPM_Encounter["Extra:DRG4"].isnull())
            | (tbl_PPM_Encounter["Extra:DRG4"] == "")
        )
        & (
            (tbl_PPM_Encounter["Extra:DRG4Version"].isnull())
            | (tbl_PPM_Encounter["Extra:DRG4Version"] == "")
            | (tbl_PPM_Encounter["Extra:DRG4Version"] == "0")
            | (tbl_PPM_Encounter["Extra:DRG4Version"] == 0)
        ),
        "960Z",
        tbl_PPM_Encounter["Extra:DRG4"],
    )
    tbl_PPM_Encounter["Extra:DRG4Version"] = np.where(
        (
            (tbl_PPM_Encounter["Extra:DRG4"].isnull())
            | (tbl_PPM_Encounter["Extra:DRG4"] == "")
            | (tbl_PPM_Encounter["Extra:DRG4"] == "960Z")
        )
        & (
            (tbl_PPM_Encounter["Extra:DRG4Version"].isnull())
            | (tbl_PPM_Encounter["Extra:DRG4Version"] == "")
            | (tbl_PPM_Encounter["Extra:DRG4Version"] == "0")
            | (tbl_PPM_Encounter["Extra:DRG4Version"] == 0)
        ),
        "9",
        tbl_PPM_Encounter["Extra:DRG4Version"],
    )
    logging.info(
        "Update_DRG4_On_PPM_Encounter_Uncoded completed. tbl_PPM_Encounter has %s records.",
        len(tbl_PPM_Encounter),
    )
    ######################################################
    # Access query: Update_AdmittingSpecialtyPortal_On_PPM_Encounter
    # UPDATE tbl_PPM_Encounter INNER JOIN tbl_dbo_days_episode ON (tbl_PPM_Encounter.[Extra:EpisodeSequenceNumber] = tbl_dbo_days_episode.episode_sequence_number) AND (tbl_PPM_Encounter.Hospital = tbl_dbo_days_episode.facility_identifier) SET tbl_PPM_Encounter.[Extra:AdmittingSpecialtyPortal] = [tbl_dbo_days_episode].[facility_identifier] & "-" & [tbl_dbo_days_episode].[specialty_unit_code]
    # WHERE (((tbl_PPM_Encounter.StartDateTime)=Format([tbl_dbo_days_episode]![start_date] & " " & TimeValue([tbl_dbo_days_episode]![start_time]),"yyyy-mm-dd hh:nn:ss")) AND ((tbl_PPM_Encounter.[Extra:HospitalStayNumber])="SN" & [tbl_dbo_days_episode].[stay_number]));
    # Added stay number in join
    tbl_dbo_days_episode["episode_sequence_number_dbo_days_episode"] = (
        tbl_dbo_days_episode["episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    tbl_dbo_days_episode["facility_identifier_dbo_days_episode"] = tbl_dbo_days_episode[
        "facility_identifier"
    ]
    tbl_dbo_days_episode["stay_number_dbo_days_episode"] = (
        tbl_dbo_days_episode["stay_number"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0")
    )
    tbl_dbo_days_episode["stay_number_dbo_days_episode_dn_dummy"] = (
        "SN" + tbl_dbo_days_episode["stay_number_dbo_days_episode"]
    )
    tbl_dbo_days_episode["start_date_time_dummy_dbo_days_episode"] = (
        tbl_dbo_days_episode["start_date"].astype(str).str[:10]
        + " "
        + tbl_dbo_days_episode["start_time"].astype(str).str[-8:]
    )
    tbl_PPM_Encounter["StartDateTime"] = tbl_PPM_Encounter["StartDateTime"].astype(str)
    tbl_PPM_Encounter["Extra:EpisodeSequenceNumber_padded"] = (
        tbl_PPM_Encounter["Extra:EpisodeSequenceNumber"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    # 11 Jan 2024 - CREATED FACILITY CHANGE
    # tbl_PPM_Encounter = pd.merge(tbl_PPM_Encounter, tbl_dbo_days_episode[['episode_sequence_number_dbo_days_episode', 'facility_identifier_dbo_days_episode', 'specialty_unit_code', 'start_date', 'start_time', 'stay_number_dbo_days_episode', 'stay_number_dbo_days_episode_dn_dummy', 'start_date_time_dummy_dbo_days_episode']], how='left', left_on=['Extra:EpisodeSequenceNumber_padded', 'Hospital', 'Extra:HospitalStayNumber', 'StartDateTime'], right_on=['episode_sequence_number_dbo_days_episode', 'facility_identifier_dbo_days_episode', 'stay_number_dbo_days_episode_dn_dummy', 'start_date_time_dummy_dbo_days_episode'], suffixes=('', '_drop'), indicator=True)
    tbl_PPM_Encounter = pd.merge(
        tbl_PPM_Encounter,
        tbl_dbo_days_episode[
            [
                "episode_sequence_number_dbo_days_episode",
                "facility_identifier_dbo_days_episode",
                "specialty_unit_code",
                "start_date",
                "start_time",
                "stay_number_dbo_days_episode",
                "stay_number_dbo_days_episode_dn_dummy",
                "start_date_time_dummy_dbo_days_episode",
                "SE_CBK_SK",
            ]
        ],
        how="left",
        left_on=["Extra:SE_CBK_SK", "StartDateTime"],
        right_on=["SE_CBK_SK", "start_date_time_dummy_dbo_days_episode"],
        suffixes=("", "_drop"),
        indicator=True,
    )
    tbl_PPM_Encounter = tbl_PPM_Encounter.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    tbl_PPM_Encounter["Extra:AdmittingSpecialtyPortal"] = np.where(
        (tbl_PPM_Encounter["_merge"] == "both")
        & (
            tbl_PPM_Encounter["Extra:HospitalStayNumber"]
            == tbl_PPM_Encounter["stay_number_dbo_days_episode_dn_dummy"]
        )
        & (
            tbl_PPM_Encounter["StartDateTime"]
            == tbl_PPM_Encounter["start_date_time_dummy_dbo_days_episode"]
        ),
        tbl_PPM_Encounter["facility_identifier_dbo_days_episode"]
        .astype(str)
        .str.strip()
        + "-"
        + tbl_PPM_Encounter["specialty_unit_code"].astype(str).str.strip(),
        "",
    )
    # tbl_dbo_days_episode.drop(['episode_sequence_number_dbo_days_episode', 'facility_identifier_dbo_days_episode', 'stay_number_dbo_days_episode'], axis=1, inplace=True, errors='ignore')
    # tbl_PPM_Encounter.drop(['_merge', 'episode_sequence_number_dbo_days_episode', 'facility_identifier_dbo_days_episode', 'specialty_unit_code', 'start_date', 'start_time', 'stay_number_dbo_days_episode', 'stay_number_dbo_days_episode_dn_dummy', 'start_date_time_dummy_dbo_days_episode'], axis=1, inplace=True, errors='ignore')
    # Access query: Update_AdmittingSpecialtyPortal_On_PPM_Encounter_Phase
    # UPDATE (tbl_PPM_Encounter INNER JOIN tbl_dbo_days_episode ON (tbl_PPM_Encounter.Hospital = tbl_dbo_days_episode.facility_identifier) AND (tbl_PPM_Encounter.[Extra:EpisodeSequenceNumber] = tbl_dbo_days_episode.episode_sequence_number)) INNER JOIN tbl_dbo_episode_ats ON (tbl_dbo_days_episode.start_time = tbl_dbo_episode_ats.episode_start_time) AND (tbl_dbo_days_episode.start_date = tbl_dbo_episode_ats.episode_start_date) AND (tbl_dbo_days_episode.facility_identifier = tbl_dbo_episode_ats.facility_identifier) AND (tbl_dbo_days_episode.stay_number = tbl_dbo_episode_ats.stay_number) AND (tbl_dbo_days_episode.episode_sequence_number = tbl_dbo_episode_ats.episode_sequence_number) SET tbl_PPM_Encounter.[Extra:AdmittingSpecialtyPortal] = [tbl_dbo_days_episode].[facility_identifier] & "-" & [tbl_dbo_days_episode].[specialty_unit_code]
    # WHERE (((tbl_PPM_Encounter.[Extra:AdmittingSpecialtyPortal]) Is Null) AND ((tbl_PPM_Encounter.[Extra:HospitalStayNumber])="SN" & [tbl_dbo_days_episode].[stay_number]));
    # Added stay number in join
    tbl_dbo_episode_ats["facility_identifier_dbo_episode_ats"] = tbl_dbo_episode_ats[
        "facility_identifier"
    ]
    tbl_dbo_episode_ats["stay_number_dbo_episode_ats"] = (
        tbl_dbo_episode_ats["stay_number"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0")
    )
    tbl_dbo_episode_ats["episode_sequence_number_dbo_episode_ats"] = (
        tbl_dbo_episode_ats["episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    """
    tbl_PPM_Encounter[['Extra:EpisodeSequenceNumber_padded', 'Hospital', 'Extra:HospitalStayNumber']].to_csv('./ExtractorDB/tbl_PPM_Encounter_Update_AdmittingSpecialtyPortal_On_PPM_Encounter_Phase_1.csv', index = False)
    tbl_dbo_days_episode[['episode_sequence_number_dbo_days_episode', 'facility_identifier_dbo_days_episode', 'stay_number_dbo_days_episode_dn_dummy']].to_csv('./ExtractorDB/tbl_dbo_days_episode_Update_AdmittingSpecialtyPortal_On_PPM_Encounter_Phase.csv', index = False)
    tbl_PPM_Encounter = pd.merge(tbl_PPM_Encounter, tbl_dbo_days_episode[['episode_sequence_number_dbo_days_episode', 'facility_identifier_dbo_days_episode', 'specialty_unit_code', 'start_date', 'start_time', 'stay_number_dbo_days_episode', 'stay_number_dbo_days_episode_dn_dummy', 'start_date_time_dummy_dbo_days_episode']], how='left', left_on=['Extra:EpisodeSequenceNumber_padded', 'Hospital', 'Extra:HospitalStayNumber'], right_on=['episode_sequence_number_dbo_days_episode', 'facility_identifier_dbo_days_episode', 'stay_number_dbo_days_episode_dn_dummy'], suffixes=('', '_drop'), indicator=True)
    tbl_PPM_Encounter = tbl_PPM_Encounter.apply(lambda x: x.replace(regex=r'^nan$', value='') if x.dtype == 'object' else x)
    tbl_dbo_days_episode['start_date'] = tbl_dbo_days_episode['start_date'].astype(str).str[:10]
    tbl_dbo_days_episode['start_time'] = tbl_dbo_days_episode['start_time'].astype(str).str[-8:]
    """
    tbl_PPM_Encounter["start_date"] = (
        tbl_PPM_Encounter["start_date"].astype(str).str[:10]
    )
    tbl_PPM_Encounter["start_time"] = (
        tbl_PPM_Encounter["start_time"].astype(str).str[-8:]
    )
    tbl_dbo_episode_ats["episode_start_date"] = (
        tbl_dbo_episode_ats["episode_start_date"].astype(str).str[:10]
    )
    tbl_dbo_episode_ats["episode_start_time"] = (
        tbl_dbo_episode_ats["episode_start_time"].astype(str).str[-8:]
    )
    # tbl_PPM_Encounter['StartDateTime'] = tbl_PPM_Encounter['StartDateTime'].astype(str)
    """
    tbl_PPM_Encounter[['facility_identifier_dbo_days_episode', 'stay_number_dbo_days_episode', 'episode_sequence_number_dbo_days_episode', 'start_time', 'start_date']].to_csv('./ExtractorDB/tbl_PPM_Encounter_Update_AdmittingSpecialtyPortal_On_PPM_Encounter_Phase_1.csv', index = False)
    tbl_dbo_episode_ats[['facility_identifier_dbo_episode_ats', 'stay_number_dbo_episode_ats', 'episode_sequence_number_dbo_episode_ats', 'episode_start_time', 'episode_start_date']].to_csv('./ExtractorDB/tbl_dbo_episode_ats_Update_AdmittingSpecialtyPortal_On_PPM_Encounter_Phase.csv', index = False)
    """
    # 11 Jan 2024 - CREATED FACILITY CHANGE
    # tbl_PPM_Encounter = pd.merge(tbl_PPM_Encounter, tbl_dbo_episode_ats[['episode_start_time', 'episode_start_date', 'facility_identifier_dbo_episode_ats', 'stay_number_dbo_episode_ats', 'episode_sequence_number_dbo_episode_ats']], how='left', left_on=['start_time', 'start_date', 'facility_identifier_dbo_days_episode', 'stay_number_dbo_days_episode', 'episode_sequence_number_dbo_days_episode'], right_on=['episode_start_time', 'episode_start_date', 'facility_identifier_dbo_episode_ats', 'stay_number_dbo_episode_ats', 'episode_sequence_number_dbo_episode_ats'], suffixes=('', '_drop'), indicator="new_merge")
    tbl_PPM_Encounter = pd.merge(
        tbl_PPM_Encounter,
        tbl_dbo_episode_ats[
            [
                "episode_start_time",
                "episode_start_date",
                "facility_identifier_dbo_episode_ats",
                "stay_number_dbo_episode_ats",
                "episode_sequence_number_dbo_episode_ats",
                "SE_CBK_SK",
            ]
        ],
        how="left",
        left_on=["start_time", "start_date", "Extra:SE_CBK_SK"],
        right_on=["episode_start_time", "episode_start_date", "SE_CBK_SK"],
        suffixes=("", "_drop"),
        indicator="new_merge",
    )
    tbl_PPM_Encounter = tbl_PPM_Encounter.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    tbl_PPM_Encounter.to_csv(
        "./ExtractorDB/tbl_PPM_Encounter_Update_AdmittingSpecialtyPortal_On_PPM_Encounter_Phase_2.csv",
        index=False,
    )
    # comment _merge= both as in this query, inner join with dbo_episode is not on date and time
    # tbl_PPM_Encounter['Extra:AdmittingSpecialtyPortal'] = np.where((tbl_PPM_Encounter['new_merge']=='both') & (tbl_PPM_Encounter['_merge']=='both') & (tbl_PPM_Encounter['Extra:HospitalStayNumber']==tbl_PPM_Encounter['stay_number_dbo_days_episode_dn_dummy']) & ((tbl_PPM_Encounter['Extra:AdmittingSpecialtyPortal'].isnull())  | (tbl_PPM_Encounter['Extra:AdmittingSpecialtyPortal']=='')), tbl_PPM_Encounter['facility_identifier_dbo_days_episode'].astype(str).str.strip() + '-' + tbl_PPM_Encounter['specialty_unit_code'].astype(str).str.strip(), tbl_PPM_Encounter['Extra:AdmittingSpecialtyPortal'])
    tbl_PPM_Encounter["Extra:AdmittingSpecialtyPortal"] = np.where(
        (tbl_PPM_Encounter["new_merge"] == "both")
        & (
            tbl_PPM_Encounter["Extra:HospitalStayNumber"]
            == tbl_PPM_Encounter["stay_number_dbo_days_episode_dn_dummy"]
        )
        & (
            (tbl_PPM_Encounter["Extra:AdmittingSpecialtyPortal"].isnull())
            | (tbl_PPM_Encounter["Extra:AdmittingSpecialtyPortal"] == "")
        ),
        tbl_PPM_Encounter["facility_identifier_dbo_days_episode"]
        .astype(str)
        .str.strip()
        + "-"
        + tbl_PPM_Encounter["specialty_unit_code"].astype(str).str.strip(),
        tbl_PPM_Encounter["Extra:AdmittingSpecialtyPortal"],
    )
    tbl_dbo_days_episode.drop(
        [
            "episode_sequence_number_dbo_days_episode",
            "facility_identifier_dbo_days_episode",
            "stay_number_dbo_days_episode",
            "stay_number_dbo_days_episode_dn_dummy",
            "start_date_time_dummy_dbo_days_episode",
        ],
        axis=1,
        inplace=True,
        errors="ignore",
    )
    tbl_dbo_episode_ats.drop(
        [
            "facility_identifier_dbo_episode_ats",
            "stay_number_dbo_episode_ats",
            "episode_sequence_number_dbo_episode_ats",
        ],
        axis=1,
        inplace=True,
        errors="ignore",
    )
    tbl_PPM_Encounter.drop(
        [
            "_merge",
            "new_merge",
            "episode_sequence_number_dbo_days_episode",
            "facility_identifier_dbo_days_episode",
            "specialty_unit_code",
            "start_date",
            "start_time",
            "stay_number_dbo_days_episode",
            "episode_start_time",
            "episode_start_date",
            "facility_identifier_dbo_episode_ats",
            "stay_number_dbo_episode_ats",
            "episode_sequence_number_dbo_episode_ats",
        ],
        axis=1,
        inplace=True,
        errors="ignore",
    )
    # Access query: Update_AdmittingSpecialtyPortal_On_PPM_Encounter_spep2
    # UPDATE tbl_PPM_Encounter, SpecialityPortalMapping SET tbl_PPM_Encounter.[Extra:AdmittingSpecialtyPortal] = [SpecialityPortalMapping].[SpecialityPortal]
    # WHERE (((tbl_PPM_Encounter.[Extra:AdmittingSpecialtyPortal])=[SpecialityPortalMapping].[Clinic]));
    tbl_PPM_Encounter = pd.merge(
        tbl_PPM_Encounter,
        specialtyPortalMapping[["SpecialityPortal", "Clinic"]],
        how="left",
        left_on=["Extra:AdmittingSpecialtyPortal"],
        right_on=["Clinic"],
        suffixes=("", "_drop"),
        indicator=True,
    )
    tbl_PPM_Encounter = tbl_PPM_Encounter.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    logging.info(
        "Update_AdmittingSpecialtyPortal_On_PPM_Encounter_spep2 completed. %s records will be updated in tbl_PPM_Encounter. tbl_PPM_Encounter has %s records.",
        len(tbl_PPM_Encounter[(tbl_PPM_Encounter["_merge"] == "both")]),
        len(tbl_PPM_Encounter),
    )
    tbl_PPM_Encounter["Extra:AdmittingSpecialtyPortal"] = np.where(
        (tbl_PPM_Encounter["_merge"] == "both"),
        tbl_PPM_Encounter["SpecialityPortal"],
        tbl_PPM_Encounter["Extra:AdmittingSpecialtyPortal"],
    )
    tbl_PPM_Encounter.drop(
        ["_merge", "SpecialityPortal", "Clinic"], axis=1, inplace=True, errors="ignore"
    )
    # Some records did not have Extra:AdmittingSpecialtyPortal when they were expected to. Therefore this is a workaround to set value for this field for those records
    tbl_PPM_Encounter = pd.merge(
        tbl_PPM_Encounter,
        specialtyPortalMapping[["SpecialityPortal", "Clinic"]],
        how="left",
        left_on=["AttendingConsultantSpecialty"],
        right_on=["Clinic"],
        suffixes=("", "_drop"),
        indicator=True,
    )
    tbl_PPM_Encounter = tbl_PPM_Encounter.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    tbl_PPM_Encounter["Extra:AdmittingSpecialtyPortal"] = np.where(
        (tbl_PPM_Encounter["_merge"] == "both")
        & (
            (tbl_PPM_Encounter["Extra:AdmittingSpecialtyPortal"] == "")
            | (tbl_PPM_Encounter["Extra:AdmittingSpecialtyPortal"].isnull())
        )
        & (
            (tbl_PPM_Encounter["Extra:SpecialtyPortal"] != "")
            & pd.notna(tbl_PPM_Encounter["Extra:SpecialtyPortal"])
        ),
        tbl_PPM_Encounter["SpecialityPortal"],
        tbl_PPM_Encounter["Extra:AdmittingSpecialtyPortal"],
    )
    tbl_PPM_Encounter.drop(
        ["_merge", "SpecialityPortal", "Clinic"], axis=1, inplace=True, errors="ignore"
    )
    """
    tbl_PPM_Encounter['Extra:AdmittingSpecialtyPortal'] = np.where(((tbl_PPM_Encounter['Extra:AdmittingSpecialtyPortal']=='') | (tbl_PPM_Encounter['Extra:AdmittingSpecialtyPortal'].isnull())) & ((tbl_PPM_Encounter['Extra:SpecialtyPortal']!='') & pd.notna(tbl_PPM_Encounter['Extra:SpecialtyPortal'])), tbl_PPM_Encounter['Extra:SpecialtyPortal'], tbl_PPM_Encounter['Extra:AdmittingSpecialtyPortal'])
    """
    # Access query: Update_MH_CareType_SVHN
    # UPDATE tbl_PPM_Encounter SET tbl_PPM_Encounter.EpisodeOfCare = "M" WHERE (((tbl_PPM_Encounter.EncounterNumber) Like "*-M-*") AND ((tbl_PPM_Encounter.Hospital)="A212" Or (tbl_PPM_Encounter.Hospital)="D213"));
    # logging.info('Update_MH_CareType_SVHN completed. %s records will be updated in tbl_PPM_Encounter. tbl_PPM_Encounter has %s records.', len(tbl_PPM_Encounter[(tbl_PPM_Encounter.EncounterNumber.str.contains('-M-') == True) & (tbl_PPM_Encounter['Hospital'].isin(['A212', 'D213']))]),len(tbl_PPM_Encounter))
    tbl_PPM_Encounter["EpisodeOfCare"] = np.where(
        (tbl_PPM_Encounter.EncounterNumber.str.contains("-M-") == True)
        & (tbl_PPM_Encounter["Hospital"].isin(["A212", "D213"])),
        "M",
        tbl_PPM_Encounter["EpisodeOfCare"],
    )
    """ This step is redundant  as its done in snap app and query relates to snapversion s2??"""
    # Access query: Update SNAP LOS
    # cannot find this query
    """ Updates the NWAU in tbl_PPM_Encounter where encounters exist in the SNAP NWAU Table"""
    # Access query: SNAP NWAU Update Encounter tbl
    # UPDATE [SNAP NWAU] INNER JOIN tbl_PPM_Encounter ON [SNAP NWAU].EncounterNumber = tbl_PPM_Encounter.EncounterNumber SET tbl_PPM_Encounter.[Extra:nwau_base] = [sa_base_nwau], tbl_PPM_Encounter.[Extra:nwau_paed_incr] = [sa_paediatric_adj_nwau], tbl_PPM_Encounter.[Extra:nwau_indig_incr] = [sa_indigenous_adj_nwau], tbl_PPM_Encounter.[Extra:nwau_remote_incr] = [sa_remoteness_adj_nwau], tbl_PPM_Encounter.[Extra:nwau_private_patient_service_incr] = [sa_private_service_adj_nwau], tbl_PPM_Encounter.[Extra:nwau_private_patient_accom_incr] = [sa_private_accomm_adj_nwau], tbl_PPM_Encounter.[Extra:nwau] = [sa_nwau], tbl_PPM_Encounter.[Extra:nwau_PublicEquivModel] = [sa_public_equivalent_nwau], tbl_PPM_Encounter.[Extra:compensable_nwau] = IIf([SNAP NWAU]![payment type]="Compensable",[SNAP NWAU]!sa_nwau*0.89), tbl_PPM_Encounter.[Extra:nwau_version] = [sa_nwau_version];
    snap_NWAU = pd.DataFrame()
    file_SNAP_NWAU = "./ExtractorDB/SNAP_NWAU.csv"
    if os.path.isfile(file_SNAP_NWAU):
        try:
            snap_NWAU = read_csv_file(
                file_SNAP_NWAU,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error",
                "Error extracting SNAP_NWAU from ./ExtractorDB/SNAP_NWAU.csv.\n"
                + str(e),
            )
            label_2_status = 0
            label_2_sub.configure(text="Failed (SNAP_NWAU)...", fg="red")
            main_screen.update()
            return
        else:
            snap_NWAU = snap_NWAU.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            snap_NWAU = snap_NWAU.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            snap_NWAU = snap_NWAU.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            snap_NWAU = snap_NWAU.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
            logging.info("snap_NWAU=%s", len(snap_NWAU))
    else:
        messagebox.showerror(
            "File Error", "Error extracting SNAP_NWAU. File is missing."
        )
        label_2_status = 0
    snap_NWAU["sa_nwau"].fillna(0, inplace=True)
    # 11 Jan 2025 - CREATED FACILITY CHANGE
    snap_NWAU["SE_CBK_SK"] = snap_NWAU["SE_CBK_SK"].astype("Int64")
    # 11 Jan 2024 - CREATED FACILITY CHANGE    will not change as EncounterNumber is a unique field in both SNAP file and SNAP NW
    tbl_PPM_Encounter = pd.merge(
        tbl_PPM_Encounter,
        snap_NWAU,
        how="left",
        on=["EncounterNumber"],
        suffixes=("", "_drop"),
        indicator=True,
    )
    # tbl_PPM_Encounter = pd.merge(tbl_PPM_Encounter, snap_NWAU, how='left', left_on=['Extra:SE_CBK_SK'], right_on=['SE_CBK_SK'], suffixes=('', '_drop'), indicator=True)
    tbl_PPM_Encounter = tbl_PPM_Encounter.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    logging.info(
        "SNAP NWAU Update Encounter tbl in progress. %s records will be updated in tbl_PPM_Encounter. tbl_PPM_Encounter has %s records.",
        len(tbl_PPM_Encounter[tbl_PPM_Encounter["_merge"] == "both"]),
        len(tbl_PPM_Encounter),
    )
    tbl_PPM_Encounter["Extra:nwau_base"] = np.where(
        tbl_PPM_Encounter["_merge"] == "both",
        tbl_PPM_Encounter["sa_base_nwau"],
        tbl_PPM_Encounter["Extra:nwau_base"],
    )
    tbl_PPM_Encounter["Extra:nwau_paed_incr"] = np.where(
        tbl_PPM_Encounter["_merge"] == "both",
        tbl_PPM_Encounter["sa_paediatric_adj_nwau"],
        tbl_PPM_Encounter["Extra:nwau_paed_incr"],
    )
    tbl_PPM_Encounter["Extra:nwau_indig_incr"] = np.where(
        tbl_PPM_Encounter["_merge"] == "both",
        tbl_PPM_Encounter["sa_indigenous_adj_nwau"],
        tbl_PPM_Encounter["Extra:nwau_indig_incr"],
    )
    tbl_PPM_Encounter["Extra:nwau_remote_incr"] = np.where(
        tbl_PPM_Encounter["_merge"] == "both",
        tbl_PPM_Encounter["sa_remoteness_adj_nwau"],
        tbl_PPM_Encounter["Extra:nwau_remote_incr"],
    )
    tbl_PPM_Encounter["Extra:nwau_private_patient_service_incr"] = np.where(
        tbl_PPM_Encounter["_merge"] == "both",
        tbl_PPM_Encounter["sa_private_service_adj_nwau"],
        tbl_PPM_Encounter["Extra:nwau_private_patient_service_incr"],
    )
    tbl_PPM_Encounter["Extra:nwau_private_patient_accom_incr"] = np.where(
        tbl_PPM_Encounter["_merge"] == "both",
        tbl_PPM_Encounter["sa_private_accomm_adj_nwau"],
        tbl_PPM_Encounter["Extra:nwau_private_patient_accom_incr"],
    )
    # 19 Feb 2025 - V15 release . Radiotherapy not populated correctly for SNAP
    tbl_PPM_Encounter["Extra:Radiotherapy_adj"] = np.where(
        tbl_PPM_Encounter["_merge"] == "both",
        tbl_PPM_Encounter["sa_radiotherapy_adj_nwau"],
        tbl_PPM_Encounter["Extra:Radiotherapy_adj"],
    )
    tbl_PPM_Encounter["Extra:nwau"] = np.where(
        tbl_PPM_Encounter["_merge"] == "both",
        tbl_PPM_Encounter["sa_nwau"],
        tbl_PPM_Encounter["Extra:nwau"],
    )
    tbl_PPM_Encounter["Extra:nwau_PublicEquivModel"] = np.where(
        tbl_PPM_Encounter["_merge"] == "both",
        tbl_PPM_Encounter["sa_public_equivalent_nwau"],
        tbl_PPM_Encounter["Extra:nwau_PublicEquivModel"],
    )

    # NEW SNAP values - 16 June
    tbl_PPM_Encounter["Extra:WAU_ADJ_PT_TX_REMT_AREA"] = np.where(
        tbl_PPM_Encounter["_merge"] == "both",
        tbl_PPM_Encounter["sa_treatment_remoteness_adj_nwau"],
        tbl_PPM_Encounter["Extra:WAU_ADJ_PT_TX_REMT_AREA"],
    )
    tbl_PPM_Encounter["Extra:WAU_ADJ_DIALYSIS"] = np.where(
        tbl_PPM_Encounter["_merge"] == "both",
        tbl_PPM_Encounter["sa_dialysis_adj_nwau"],
        tbl_PPM_Encounter["Extra:WAU_ADJ_DIALYSIS"],
    )

    tbl_PPM_Encounter["Extra:nwau_version"] = np.where(
        tbl_PPM_Encounter["_merge"] == "both",
        tbl_PPM_Encounter["sa_nwau_version"],
        tbl_PPM_Encounter["Extra:nwau_version"],
    )
    # tbl_PPM_Encounter.loc[((tbl_PPM_Encounter['payment type'].str.upper()=='COMPENSABLE') & (tbl_PPM_Encounter['_merge'] =='both')), 'Extra:compensable_nwau'] = tbl_PPM_Encounter['sa_nwau']*0.89
    logging.info(
        "SNAP NWAU Update Encounter tbl completed. tbl_PPM_Encounter has %s records.",
        len(tbl_PPM_Encounter),
    )
    tbl_PPM_Encounter["sa_nwau"] = tbl_PPM_Encounter["sa_nwau"].fillna(0)
    tbl_PPM_Encounter["Extra:compensable_nwau"] = tbl_PPM_Encounter[
        "Extra:compensable_nwau"
    ].fillna(0)
    tbl_PPM_Encounter["sa_nwau"] = pd.to_numeric(
        tbl_PPM_Encounter["sa_nwau"], downcast="float"
    )
    tbl_PPM_Encounter["Extra:compensable_nwau"] = pd.to_numeric(
        tbl_PPM_Encounter["Extra:compensable_nwau"], downcast="float"
    )
    tbl_PPM_Encounter["sa_nwau"] = tbl_PPM_Encounter["sa_nwau"].astype(str)
    tbl_PPM_Encounter["Extra:compensable_nwau"] = tbl_PPM_Encounter[
        "Extra:compensable_nwau"
    ].astype(str)
    tbl_PPM_Encounter["Extra:compensable_nwau"] = np.where(
        (tbl_PPM_Encounter["Extra:compensable_nwau"].isnull())
        | (tbl_PPM_Encounter["Extra:compensable_nwau"] == "")
        | (tbl_PPM_Encounter["Extra:compensable_nwau"] == "nan"),
        0,
        tbl_PPM_Encounter["Extra:compensable_nwau"].astype(float),
    )
    tbl_PPM_Encounter["sa_nwau"] = np.where(
        (tbl_PPM_Encounter["sa_nwau"].isnull())
        | (tbl_PPM_Encounter["sa_nwau"] == "")
        | (tbl_PPM_Encounter["sa_nwau"] == "nan"),
        0,
        tbl_PPM_Encounter["sa_nwau"].astype(float),
    )
    tbl_PPM_Encounter["Extra:compensable_nwau"] = np.where(
        (
            (tbl_PPM_Encounter["payment type"].astype(str).str.upper() == "COMPENSABLE")
            & (tbl_PPM_Encounter["_merge"] == "both")
        ),
        tbl_PPM_Encounter["sa_nwau"] * 0.89,
        tbl_PPM_Encounter["Extra:compensable_nwau"],
    )

    tbl_PPM_Encounter.drop(["_merge"], axis=1, inplace=True, errors="ignore")

    """#  Exclude step?"""
    # Access query: Rec Encounter PPM
    # INSERT INTO Reconciliation ( Source, CountOfstay_number, Type ) SELECT "Encounter PPM" AS Source, Count(tbl_PPM_Encounter.EncounterNumber) AS CountOfEncounterNumber, IIf([episodeofcare] In ("1","5"),"Acute",IIf([tbl_PPM_Encounter]![DRG1Version]="S2","SNAP","Non-Acute")) AS Expr1 FROM tbl_PPM_Encounter GROUP BY "Encounter PPM", IIf([episodeofcare] In ("1","5"),"Acute",IIf([tbl_PPM_Encounter]![DRG1Version]="S2","SNAP","Non-Acute"));
    """ # Exclude step?"""
    # Access query: Rec Stay PPM
    # SELECT "Stay PPM" AS Source, Count(tbl_PPM_Encounter.PatientNumber) AS CountOfPatientNumber, tbl_PPM_Encounter.PatientNumber FROM tbl_PPM_Encounter GROUP BY "Stay PPM", tbl_PPM_Encounter.PatientNumber;
    """ # Exclude step?"""
    # Access query: Rec Stay PPM 01
    # INSERT INTO Reconciliation ( Source, CountOfstay_number ) SELECT [Rec Stay PPM].Source, Count([Rec Stay PPM].PatientNumber) AS CountOfPatientNumber1 FROM [Rec Stay PPM] GROUP BY [Rec Stay PPM].Source;
    """ # Delete all date in the PLA Table"""
    # Access query: qrydelete:PLATable
    # DELETE [PLA Table].* FROM [PLA Table];
    """ Appends data to the PLA Table based on the encounters in the tbl_PPM_Encounter to give there episode of care snap class days in psych hosprole, specrole and ward role (PLA role table)"""
    # query after initial steps
    file_pla_Role_Table = "./ExtractorDB/PLA_Role_Table.csv"
    if os.path.isfile(file_pla_Role_Table):
        try:
            pla_Role_Table = read_csv_file(
                file_pla_Role_Table,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error",
                "Error extracting PLA_Role_Table from ./ExtractorDB/PLA_Role_Table.csv.\n"
                + str(e),
            )
            label_2_status = 0
            label_2_sub.configure(text="Failed (PLA_Role_Table)...", fg="red")
            main_screen.update()
            return
        else:
            pla_Role_Table = pla_Role_Table.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            pla_Role_Table = pla_Role_Table.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            pla_Role_Table = pla_Role_Table.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            pla_Role_Table = pla_Role_Table.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
            logging.info("pla_Role_Table=%s", len(pla_Role_Table))
    else:
        messagebox.showerror(
            "File Error", "Error extracting PLA_Role_Table. File is missing."
        )
        label_2_status = 0
    # Access query: qry transfer max
    # SELECT [facility_identifier] & "-" & "I" & "-" & Format$([stay_number],"00000000") & "-" & IIf(Len([episode_sequence_number])=3,[episode_sequence_number],IIf(Len([episode_sequence_number])=2,"0" & [episode_sequence_number],"00" & [episode_sequence_number])) AS EncounterNumber, [start_date]+TimeValue([start_time]) AS startdatetime, tbl_dbo_days_episode.stay_number, tbl_dbo_days_episode.episode_sequence_number FROM tbl_dbo_days_episode GROUP BY [facility_identifier] & "-" & "I" & "-" & Format$([stay_number],"00000000") & "-" & IIf(Len([episode_sequence_number])=3,[episode_sequence_number],IIf(Len([episode_sequence_number])=2,"0" & [episode_sequence_number],"00" & [episode_sequence_number])), [start_date]+TimeValue([start_time]), tbl_dbo_days_episode.stay_number, tbl_dbo_days_episode.episode_sequence_number;
    # download OutputDaysEpisode
    file_OutputDaysEpisode = "./ExtractorDB/OutputDaysEpisode.csv"
    if os.path.isfile(file_OutputDaysEpisode):
        try:
            tbl_dbo_days_episode = read_csv_file(
                file_OutputDaysEpisode,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_dbo_days_episode from ./ExtractorDB/OutputDaysEpisode.csv.\n"
                + str(e),
            )
            label_2_status = 0
            return
        else:
            tbl_dbo_days_episode = tbl_dbo_days_episode[
                tbl_dbo_days_episode["facility_identifier"].isin(
                    facilities_included_list_global
                )
            ]
            tbl_dbo_days_episode = tbl_dbo_days_episode.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_days_episode = tbl_dbo_days_episode.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_dbo_days_episode = tbl_dbo_days_episode.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_dbo_days_episode = tbl_dbo_days_episode.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_days_episode["start_date"] = (
                tbl_dbo_days_episode["start_date"].astype(str).str[:10]
            )
            tbl_dbo_days_episode["start_time"] = (
                tbl_dbo_days_episode["start_time"].astype(str).str[-8:]
            )
            tbl_dbo_days_episode["end_date"] = (
                tbl_dbo_days_episode["end_date"].astype(str).str[:10]
            )
            tbl_dbo_days_episode["end_time"] = (
                tbl_dbo_days_episode["end_time"].astype(str).str[-8:]
            )
            tbl_dbo_days_episode["stay_number"] = (
                tbl_dbo_days_episode["stay_number"]
                .astype(str)
                .str.pad(8, side="left", fillchar="0")
            )
            tbl_dbo_days_episode["episode_sequence_number"] = (
                tbl_dbo_days_episode["episode_sequence_number"]
                .astype(str)
                .str.pad(3, side="left", fillchar="0")
            )
    else:
        tbl_dbo_days_episode = pd.DataFrame()
    qry_transfer_max = tbl_dbo_days_episode.copy()
    qry_transfer_max["stay_number"] = (
        qry_transfer_max["stay_number"].astype(str).str.strip()
    )
    qry_transfer_max["episode_sequence_number"] = (
        qry_transfer_max["episode_sequence_number"].astype(str).str.strip()
    )
    qry_transfer_max["stay_number"] = (
        qry_transfer_max["stay_number"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0")
    )
    qry_transfer_max["episode_sequence_number"] = (
        qry_transfer_max["episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    qry_transfer_max["EncounterNumber"] = (
        qry_transfer_max["facility_identifier"].astype(str).str.strip()
        + "-I-"
        + qry_transfer_max["stay_number"].astype(str).str.strip()
        + "-"
        + qry_transfer_max["episode_sequence_number"].astype(str).str.strip()
    )
    qry_transfer_max["startdatetime"] = (
        qry_transfer_max["start_date"].astype(str).str[:10]
        + " "
        + qry_transfer_max["start_time"].astype(str).str[-8:]
    )
    qry_transfer_max["startdatetime"] = pd.to_datetime(
        qry_transfer_max["startdatetime"], errors="coerce", format="%Y-%m-%d %H:%M:%S"
    )
    qry_transfer_max.sort_values(
        by=[
            "EncounterNumber",
            "startdatetime",
            "stay_number",
            "episode_sequence_number",
        ],
        inplace=True,
    )
    qry_transfer_max.drop_duplicates(
        subset=[
            "EncounterNumber",
            "startdatetime",
            "stay_number",
            "episode_sequence_number",
        ],
        keep="last",
        inplace=True,
    )
    # 11 Jan 2024 - CREATED FACILITY CHANGE
    # qry_transfer_max = qry_transfer_max[['EncounterNumber', 'startdatetime', 'stay_number', 'episode_sequence_number']]
    qry_transfer_max = qry_transfer_max[
        [
            "EncounterNumber",
            "startdatetime",
            "stay_number",
            "episode_sequence_number",
            "SE_CBK_SK",
        ]
    ]
    qry_transfer_max = qry_transfer_max.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    qry_transfer_max = qry_transfer_max.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    qry_transfer_max = qry_transfer_max.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    #########################
    # 11 Jan 2025 - CREATED FACILITY CHANGE
    # ValueError: You are trying to merge on object and int64 columns
    qry_transfer_max["SE_CBK_SK"] = qry_transfer_max["SE_CBK_SK"].astype("Int64")
    ########################
    try:
        qry_transfer_max.to_csv(
            "./ExtractorDB/qry_transfer_max.csv",
            index=False,
            na_rep="",
            float_format=str,
            decimal=str,
            date_format=str,
        )
    except Exception as e:
        logging.exception("Exception occurred")
        label_2_status = 0
        messagebox.showerror(
            "Export Error", "Error saving /ExtractorDB/qry_transfer_max.csv\n" + str(e)
        )
        label_2_sub.configure(text="Failed ()...", fg="red")
        main_screen.update()
        return  # stop export
    logging.info(
        "qry transfer max completed. %s records created ./ExtractorDB/qry_transfer_max.csv.",
        len(qry_transfer_max),
    )
    # Access query: qry transfer max 01
    # SELECT [qry transfer max].EncounterNumber, Max(tbl_dbo_days_episode.ward_identifier) AS maxofward, Max(tbl_dbo_days_episode.specialty_unit_code) AS maxofclinic, tbl_PPM_Encounter.Hospital FROM tbl_dbo_days_episode INNER JOIN ([qry transfer max] INNER JOIN tbl_PPM_Encounter ON [qry transfer max].EncounterNumber = tbl_PPM_Encounter.EncounterNumber) ON (tbl_dbo_days_episode.stay_number = [qry transfer max].stay_number) AND (tbl_dbo_days_episode.episode_sequence_number = [qry transfer max].episode_sequence_number) WHERE ((([qry transfer max].startdatetime)=[start_date]+TimeValue([start_time]))) GROUP BY [qry transfer max].EncounterNumber, tbl_PPM_Encounter.Hospital;
    # added this code as some of facility is are coming as null
    tbl_PPM_Encounter["facility_identifier"] = np.where(
        (tbl_PPM_Encounter["facility_identifier"].isnull())
        | (tbl_PPM_Encounter["facility_identifier"] == ""),
        tbl_PPM_Encounter["Hospital"],
        tbl_PPM_Encounter["facility_identifier"],
    )
    # qry_transfer_max01 = pd.merge(qry_transfer_max[qry_transfer_max['startdatetime']==start_date_dt], tbl_PPM_Encounter, how='inner', on=['EncounterNumber'], suffixes=('', '_drop'))
    # qry_transfer_max01 = pd.merge(qry_transfer_max, tbl_PPM_Encounter, how='inner', on=['EncounterNumber'], suffixes=('', '_drop'))
    qry_transfer_max01 = pd.merge(
        qry_transfer_max,
        tbl_PPM_Encounter,
        how="inner",
        left_on=["SE_CBK_SK"],
        right_on=["Extra:SE_CBK_SK"],
        suffixes=("", "_drop"),
    )
    # 24 Jan 2025
    qry_transfer_max01 = qry_transfer_max01[
        [
            "stay_number",
            "episode_sequence_number",
            "facility_identifier",
            "EncounterNumber",
            "SE_CBK_SK",
            "startdatetime",
            "Hospital",
        ]
    ]
    logging.info(
        "qry_transfer_max01 created first time. %s records created .",
        len(qry_transfer_max01),
    )
    # causing _ArrayMemoryError: Unable to allocate XX GiB for an array with shape because multiple rows in Days Episode for the same facility_id-stay_number-episode_sequence_number-startdatetime-enddatetime
    # qry_transfer_max01 = qry_transfer_max01.apply(lambda x: x.replace(regex=r'^nan$', value='') if x.dtype == 'object' else x)
    # I added facility identifier
    # 24 Jan 2025
    qry_transfer_max01 = pd.merge(
        tbl_dbo_days_episode[
            [
                "stay_number",
                "episode_sequence_number",
                "facility_identifier",
                "specialty_unit_code",
                "start_date",
                "start_time",
                "end_date",
                "end_time",
                "ward_identifier",
            ]
        ],
        qry_transfer_max01,
        how="inner",
        on=["stay_number", "episode_sequence_number", "facility_identifier"],
        suffixes=("", "_drop"),
    )
    # qry_transfer_max01 = pd.merge(tbl_dbo_days_episode, qry_transfer_max01, how='inner', on=['stay_number', 'episode_sequence_number', 'facility_identifier'], suffixes=('', '_drop'))
    logging.info(
        "qry_transfer_max01 created second time. %s records created .",
        len(qry_transfer_max01),
    )
    #  causing _ArrayMemoryError: Unable to allocate 9.24 GiB for an array with shape
    # qry_transfer_max01 = qry_transfer_max01.apply(lambda x: x.replace(regex=r'^nan$', value='') if x.dtype == 'object' else x)
    qry_transfer_max01["startdatetime_max01"] = (
        qry_transfer_max01["start_date"].astype(str).str[:10]
        + " "
        + qry_transfer_max01["start_time"].astype(str).str[-8:]
    )
    qry_transfer_max01["startdatetime"] = qry_transfer_max01["startdatetime"].astype(
        str
    )
    qry_transfer_max01 = qry_transfer_max01[
        qry_transfer_max01["startdatetime"] == qry_transfer_max01["startdatetime_max01"]
    ]
    qry_transfer_max01 = qry_transfer_max01.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    # 11 Jan 2024 - CREATED FACILITY CHANGE
    # qry_transfer_max01 = qry_transfer_max01.groupby(['EncounterNumber', 'Hospital'], as_index=False, dropna=False).agg(maxofward=("ward_identifier", "max"), maxofclinic=("specialty_unit_code", "max")).reset_index()
    # qry_transfer_max01 = qry_transfer_max01[['EncounterNumber', 'maxofward', 'maxofclinic', 'Hospital']]
    qry_transfer_max01 = (
        qry_transfer_max01.groupby(
            ["EncounterNumber", "Hospital", "SE_CBK_SK"], as_index=False, dropna=False
        )
        .agg(
            maxofward=("ward_identifier", "max"),
            maxofclinic=("specialty_unit_code", "max"),
        )
        .reset_index()
    )
    qry_transfer_max01 = qry_transfer_max01[
        ["EncounterNumber", "maxofward", "maxofclinic", "Hospital", "SE_CBK_SK"]
    ]
    qry_transfer_max01 = qry_transfer_max01.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    qry_transfer_max01 = qry_transfer_max01.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    qry_transfer_max01 = qry_transfer_max01.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    #########################
    # 11 Jan 2025 - CREATED FACILITY CHANGE
    # ValueError: You are trying to merge on object and int64 columns
    qry_transfer_max01["SE_CBK_SK"] = qry_transfer_max01["SE_CBK_SK"].astype("Int64")
    ########################
    try:
        qry_transfer_max01.to_csv(
            "./ExtractorDB/qry_transfer_max01.csv",
            index=False,
            na_rep="",
            float_format=str,
            decimal=str,
            date_format=str,
        )
    except Exception as e:
        logging.exception("Exception occurred")
        label_2_status = 0
        messagebox.showerror(
            "Export Error",
            "Error saving /ExtractorDB/qry_transfer_max01.csv\n" + str(e),
        )
        label_2_sub.configure(text="Failed ()...", fg="red")
        main_screen.update()
        return  # stop export
    logging.info(
        "qry transfer max 01 completed. %s records created ./ExtractorDB/qry_transfer_max01.csv.",
        len(qry_transfer_max01),
    )
    # Access query: qry update pla
    # INSERT INTO [PLA Table] ( EncounterNumber, EpisodeofCare, SNAPCLass, DaysinPsych, hosprole, specrole, wardrole ) SELECT tbl_PPM_Encounter.EncounterNumber, IIf([tbl_PPM_Encounter]![EpisodeOfCare] In ("0","1","2","3","4","5","6","7","8","9","M"),[tbl_PPM_Encounter]![EpisodeOfCare],"NA") AS EpisodeofCare, IIf([extra:Snap_class] Is Not Null,"Y","N") AS SNAPCLass, IIf([Extra:DaysinPsychUnit]>0,"Y","N") AS DaysinPsych, IIf([PLA Role Table]![roletype]='Hosp ID Role',[PLA Role Table]![role],'NA') AS hosprole, IIf([PLA Role Table_1]![roletype]='Attend Consultant Spec Role',[PLA Role Table_1]![role],'NA') AS specrole, IIf([PLA Role Table_2]![roletype]='WardRole',[PLA Role Table_2]![role],'NA') AS wardrole FROM (([PLA Role Table] RIGHT JOIN (tbl_PPM_Encounter LEFT JOIN [qry transfer max 01] ON tbl_PPM_Encounter.EncounterNumber = [qry transfer max 01].EncounterNumber) ON [PLA Role Table].HospID = tbl_PPM_Encounter.Hospital) LEFT JOIN [PLA Role Table] AS [PLA Role Table_1] ON ([qry transfer max 01].Hospital = [PLA Role Table_1].HospID) AND ([qry transfer max 01].MaxOfClinic = [PLA Role Table_1].Speciality)) LEFT JOIN [PLA Role Table] AS [PLA Role Table_2] ON ([qry transfer max 01].Hospital = [PLA Role Table_2].HospID) AND ([qry transfer max 01].MaxOfWard = [PLA Role Table_2].Ward) GROUP BY tbl_PPM_Encounter.EncounterNumber, IIf([tbl_PPM_Encounter]![EpisodeOfCare] In ("0","1","2","3","4","5","6","7","8","9","M"),[tbl_PPM_Encounter]![EpisodeOfCare],"NA"), IIf([extra:Snap_class] Is Not Null,"Y","N"), IIf([Extra:DaysinPsychUnit]>0,"Y","N"), IIf([PLA Role Table]![roletype]='Hosp ID Role',[PLA Role Table]![role],'NA'), IIf([PLA Role Table_1]![roletype]='Attend Consultant Spec Role',[PLA Role Table_1]![role],'NA'), IIf([PLA Role Table_2]![roletype]='WardRole',[PLA Role Table_2]![role],'NA');
    # 11 Jan 2024 - CREATED FACILITY CHANGE
    # df_qry_1 = pd.merge(tbl_PPM_Encounter[['EncounterNumber', 'EpisodeOfCare', 'Extra:SNAP_Class', 'Extra:DaysinPsychUnit']], qry_transfer_max01, how='left', on=['EncounterNumber'], suffixes=('', '_drop'))
    df_qry_1 = pd.merge(
        tbl_PPM_Encounter[
            [
                "EncounterNumber",
                "EpisodeOfCare",
                "Extra:SNAP_Class",
                "Extra:DaysinPsychUnit",
                "Extra:SE_CBK_SK",
            ]
        ],
        qry_transfer_max01,
        how="left",
        left_on=["Extra:SE_CBK_SK"],
        right_on=["SE_CBK_SK"],
        suffixes=("", "_drop"),
    )
    df_qry_1 = df_qry_1.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    df_qry_1.drop_duplicates(
        subset=[
            "EncounterNumber",
            "EpisodeOfCare",
            "Extra:SNAP_Class",
            "maxofward",
            "maxofclinic",
            "Hospital",
        ],
        keep="last",
        inplace=True,
    )
    df_qry_2 = pd.merge(
        pla_Role_Table[["RoleType", "Role", "HospID"]],
        df_qry_1,
        how="right",
        left_on=["HospID"],
        right_on=["Hospital"],
        suffixes=("", "_drop"),
    )
    df_qry_2 = df_qry_2.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    pla_Role_Table_1 = pla_Role_Table.copy()
    pla_Role_Table_1["role1"] = pla_Role_Table_1["Role"]
    pla_Role_Table_1["roletype1"] = pla_Role_Table_1["RoleType"]
    df_qry_3 = pd.merge(
        df_qry_2,
        pla_Role_Table_1[["roletype1", "role1", "HospID", "Speciality"]],
        how="left",
        left_on=["Hospital", "maxofclinic"],
        right_on=["HospID", "Speciality"],
        suffixes=("", "_drop"),
    )
    df_qry_3 = df_qry_3.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    df_qry_3.drop_duplicates(keep="last", inplace=True)
    pla_Role_Table_2 = pla_Role_Table.copy()
    pla_Role_Table_2["role2"] = pla_Role_Table_2["Role"]
    pla_Role_Table_2["roletype2"] = pla_Role_Table_2["RoleType"]
    pla_table = pd.merge(
        df_qry_3,
        pla_Role_Table_2[["roletype2", "role2", "HospID", "Ward"]],
        how="left",
        left_on=["Hospital", "maxofward"],
        right_on=["HospID", "Ward"],
        suffixes=("", "_drop"),
    )
    pla_table = pla_table.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    pla_table["EpisodeOfCare"] = np.where(
        pla_table["EpisodeOfCare"].isin(
            ["0", "1", "2", "3", "4", "5", "6", "7", "8", "9", "M"]
        ),
        pla_table["EpisodeOfCare"],
        "NA",
    )
    pla_table["SNAPCLass"] = np.where(
        pd.notna(pla_table["Extra:SNAP_Class"]) & (pla_table["Extra:SNAP_Class"] != ""),
        "Y",
        "N",
    )
    pla_table["DaysinPsych"] = np.where(
        pla_table["Extra:DaysinPsychUnit"].astype(int, errors="ignore") > 0, "Y", "N"
    )
    pla_table["hosprole"] = np.where(
        pla_table["RoleType"] == "Hosp ID Role", pla_table["Role"], "NA"
    )
    pla_table["specrole"] = np.where(
        pla_table["roletype1"] == "Attend Consultant Spec Role",
        pla_table["role1"],
        "NA",
    )
    pla_table["wardrole"] = np.where(
        pla_table["roletype2"] == "WardRole", pla_table["role2"], "NA"
    )
    pla_table = pla_table[
        [
            "EncounterNumber",
            "EpisodeOfCare",
            "SNAPCLass",
            "DaysinPsych",
            "hosprole",
            "specrole",
            "wardrole",
        ]
    ]
    pla_table.sort_values(
        by=[
            "EncounterNumber",
            "EpisodeOfCare",
            "SNAPCLass",
            "DaysinPsych",
            "hosprole",
            "specrole",
            "wardrole",
        ],
        inplace=True,
    )
    pla_table.drop_duplicates(
        subset=[
            "EncounterNumber",
            "EpisodeOfCare",
            "SNAPCLass",
            "DaysinPsych",
            "hosprole",
            "specrole",
            "wardrole",
        ],
        keep="last",
        inplace=True,
    )
    pla_table = pla_table.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    pla_table = pla_table.applymap(lambda x: x.strip() if isinstance(x, str) else x)
    pla_table = pla_table.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    try:
        pla_table.to_csv(
            "./ExtractorDB/PLA_Table.csv",
            index=False,
            na_rep="",
            float_format=str,
            decimal=str,
            date_format=str,
        )
    except Exception as e:
        logging.exception("Exception occurred")
        label_2_status = 0
        messagebox.showerror(
            "Export Error", "Error saving /ExtractorDB/PLA_Table.csv\n" + str(e)
        )
        label_2_sub.configure(text="Failed ()...", fg="red")
        main_screen.update()
        return  # stop export
    logging.info(
        "qry update pla completed. %s records created ./ExtractorDB/PLA_Table.csv.",
        len(pla_table),
    )
    """ Updates N_Z_financial class field in the tbl_PPM_encounter linking the data in the PLA Table and pla mapping 00 table (which is the mapping based on the pla role assignment sheet in collab space)"""
    # Access query: qry PLA Update tbl_PPM_encounter
    # UPDATE ([PLA Table] INNER JOIN tbl_PPM_Encounter ON [PLA Table].EncounterNumber = tbl_PPM_Encounter.EncounterNumber) INNER JOIN [PLA Mapping 00] ON ([PLA Mapping 00].episode_of_care_type = [PLA Table].EpisodeofCare) AND ([PLA Mapping 00].HospRole = [PLA Table].hosprole) AND ([PLA Mapping 00].PsychDays = [PLA Table].DaysinPsych) AND ([PLA Mapping 00].[Ward Role] = [PLA Table].wardrole) AND ([PLA Table].specrole = [PLA Mapping 00].[spec Role]) SET tbl_PPM_Encounter.[Extra:N_Z_FinancialProgram] = [PLA];
    file_PLA_Mapping_00 = "./Costing/PLA_Mapping_00.csv"
    if os.path.isfile(file_PLA_Mapping_00):
        try:
            df_PLA_Mapping_00 = read_csv_file(
                file_PLA_Mapping_00,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error",
                "Error extracting PLA_Mapping_00 from ./Costing/PLA_Mapping_00.csv.\n"
                + str(e),
            )
            label_2_status = 0
            label_2_sub.configure(text="Failed (PLA_Mapping_00)...", fg="red")
            main_screen.update()
            return
        else:
            df_PLA_Mapping_00 = df_PLA_Mapping_00.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            df_PLA_Mapping_00 = df_PLA_Mapping_00.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            df_PLA_Mapping_00 = df_PLA_Mapping_00.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            df_PLA_Mapping_00 = df_PLA_Mapping_00.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
            logging.info("df_PLA_Mapping_00=%s", len(df_PLA_Mapping_00))
    else:
        messagebox.showerror(
            "File Error", "Error extracting PLA_Mapping_00. File is missing."
        )
        label_2_status = 0
    df_query_1 = pd.merge(
        tbl_PPM_Encounter,
        pla_table,
        how="inner",
        on=["EncounterNumber"],
        suffixes=("", "_drop"),
    )
    df_query_1 = df_query_1.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    # df_query_1 = df_query_1[df_query_1['_merge'] == 'both']
    df_query_2 = pd.merge(
        df_query_1,
        df_PLA_Mapping_00,
        how="inner",
        left_on=["EpisodeOfCare", "hosprole", "DaysinPsych", "wardrole", "specrole"],
        right_on=[
            "episode_of_care_type",
            "HospRole",
            "PsychDays",
            "Ward Role",
            "spec Role",
        ],
        suffixes=("", "_drop"),
    )
    df_query_2 = df_query_2.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    tbl_PPM_Encounter = pd.merge(
        tbl_PPM_Encounter,
        df_query_2[["PLA", "EncounterNumber"]],
        how="left",
        on=["EncounterNumber"],
        suffixes=("", "_drop"),
        indicator=True,
    )
    tbl_PPM_Encounter = tbl_PPM_Encounter.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    logging.info(
        "Query: qry PLA Update tbl_PPM_Encounter completed. %s records will be updated in tbl_PPM_Encounter. tbl_PPM_Encounter has %s records.",
        len(
            tbl_PPM_Encounter[
                (
                    (tbl_PPM_Encounter["_merge"] == "both")
                    & (pd.notna(tbl_PPM_Encounter["PLA"]))
                    & (tbl_PPM_Encounter["PLA"] != "")
                )
            ]
        ),
        len(tbl_PPM_Encounter),
    )
    tbl_PPM_Encounter["Extra:N_Z_FinancialProgram"] = np.where(
        (
            (tbl_PPM_Encounter["_merge"] == "both")
            & (pd.notna(tbl_PPM_Encounter["PLA"]))
            & (tbl_PPM_Encounter["PLA"] != "")
        ),
        tbl_PPM_Encounter["PLA"],
        "",
    )
    tbl_PPM_Encounter.drop(["_merge"], axis=1, inplace=True, errors="ignore")
    tbl_PPM_Encounter.to_csv(
        "./ExtractorDB/tbl_PPM_Encounter_qry_PLA_Update_tbl_PPM_Encounter.csv",
        index=False,
    )
    """Updates N_Z_financial class field in the tbl_PPM_encounter linking the data in the PLA Table and PLA_AMHCC table  """
    # Access query: qry PLA Update tbl_PPM_encounter AMHCC
    # UPDATE tbl_PPM_Encounter INNER JOIN PLA_AMHCC ON tbl_PPM_Encounter.[Extra:AMHCC_Class] = PLA_AMHCC.ClassCode SET tbl_PPM_Encounter.[Extra:N_Z_FinancialProgram] = [PLA_AMHCC].[PLACode] WHERE (((tbl_PPM_Encounter.[Extra:N_Z_FinancialProgram])<>"31041"));
    file_PLA_AMHCC = "./Costing/PLA_AMHCC.CSV"
    if os.path.isfile(file_PLA_AMHCC):
        try:
            df_PLA_AMHCC = read_csv_file(
                file_PLA_AMHCC,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            label_2_status = 0
            messagebox.showerror(
                "File Error",
                "Error extracting PLA_AMHCC from ./Costing/PLA_AMHCC.csv.\n" + str(e),
            )
            label_2_sub.configure(text="Failed (PLA_AMHCC)...", fg="red")
            main_screen.update()
            return
        else:
            df_PLA_AMHCC.columns = [
                "ClassCode",
                "ClassDescription",
                "PLACode",
            ]  # necessary because original file has column names: ['ClassCode', 'ClassDescription', 'PLACode']
            df_PLA_AMHCC = df_PLA_AMHCC.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            df_PLA_AMHCC = df_PLA_AMHCC.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            df_PLA_AMHCC = df_PLA_AMHCC.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            df_PLA_AMHCC = df_PLA_AMHCC.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_PPM_Encounter = pd.merge(
                tbl_PPM_Encounter,
                df_PLA_AMHCC[["ClassCode", "PLACode"]],
                how="left",
                left_on="Extra:AMHCC_Class",
                right_on="ClassCode",
                suffixes=("", "_drop"),
                indicator=True,
            )
            tbl_PPM_Encounter = tbl_PPM_Encounter.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
            logging.info(
                "Query: qry PLA Update tbl_PPM_Encounter AMHCC completed. %s records will be updated in tbl_PPM_Encounter. tbl_PPM_Encounter has %s records.",
                len(
                    tbl_PPM_Encounter[
                        (tbl_PPM_Encounter["_merge"] == "both")
                        & (tbl_PPM_Encounter["Extra:N_Z_FinancialProgram"] != "31041")
                    ]
                ),
                len(tbl_PPM_Encounter),
            )
            tbl_PPM_Encounter["Extra:N_Z_FinancialProgram"] = np.where(
                (tbl_PPM_Encounter["_merge"] == "both")
                & (tbl_PPM_Encounter["Extra:N_Z_FinancialProgram"] != "31041"),
                tbl_PPM_Encounter["PLACode"],
                tbl_PPM_Encounter["Extra:N_Z_FinancialProgram"],
            )
            tbl_PPM_Encounter.to_csv(
                "./ExtractorDB/tbl_PPM_Encounter_qry_PLA_Update_tbl_PPM_Encounter_AMHCC.csv",
                index=False,
            )
    else:
        # Lai-Mun: 26 Oct : in the ABSENCE of AMHCC, use Inform8 logic : Inpatienttransformation-> PLA_By_Age_Processing()
        logging.exception(
            "./Costing/PLA_AMHCC.CSV is not present. Update subprogram by age criteria."
        )
        condlist = [
            tbl_PPM_Encounter["Age"].astype(float) < 18,
            tbl_PPM_Encounter["Age"].astype(float) >= 18
            and tbl_PPM_Encounter["Age"].astype(float) < 65,
            tbl_PPM_Encounter["Age"].astype(float) >= 65,
        ]
        choicelist = ["31011", "31021", "31031"]
        tbl_PPM_Encounter["Extra:N_Z_FinancialProgram"] = np.select(
            condlist, choicelist, tbl_PPM_Encounter["Extra:N_Z_FinancialProgram"]
        )
        tbl_PPM_Encounter.to_csv(
            "./ExtractorDB/tbl_PPM_Encounter_qry_PLA_Update_tbl_PPM_Encounter_no_AMHCC.csv",
            index=False,
        )
        """
        label_2_status = 0
        messagebox.showerror("File Error","./Costing/PLA_AMHCC.csv is missing.\n"+str(e))
        label_2_sub.configure(text="Failed (PLA_AMHCC)...",fg='red')
        main_screen.update()
        return
        """
    """ Updates the Extra:ElectionStatusSummary in the tbl_PPM_Encounter table based on the Finclass to ESS table.
    note this table needs to updated from the fintype mapping table in casemix (which hasnt been for a while) 
    [CasemixABF].[Lookup].[FinClassFinTypeMapping]
    Will be this in future
    [CasemixABF].[mapping].[FinClassFinTypeMapping]"""
    #########NOTE : For EDW , there is no Finclass.
    # Access query: qry update ESS
    # UPDATE tbl_PPM_Encounter INNER JOIN [Finclass to ESS] ON tbl_PPM_Encounter.FinancialClass = [Finclass to ESS].Finclass SET tbl_PPM_Encounter.[Extra:ElectionStatusSummary] = [FinClass_FinType] WHERE (((tbl_PPM_Encounter.[Extra:ElectionStatusSummary]) Is Null));
    file_FinclassToESS = "./Costing/FinclassToFinType.csv"
    if os.path.isfile(file_FinclassToESS):
        try:
            finclassToESS = read_csv_file(
                file_FinclassToESS,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            label_2_status = 0
            messagebox.showerror(
                "File Error",
                "Error extracting FinclassToFinType from ./Costing/FinclassToFinType.csv.\n"
                + str(e),
            )
            label_2_sub.configure(text="Failed (FinclassToFinType)...", fg="red")
            main_screen.update()
            return
        else:
            finclassToESS = finclassToESS[["Finclass", "FinType"]]
            finclassToESS = finclassToESS.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            finclassToESS = finclassToESS.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            finclassToESS = finclassToESS.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            finclassToESS = finclassToESS.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
            condlist = [
                finclassToESS["FinType"] == "COMPENSABLE",
                finclassToESS["FinType"] == "PUBLIC",
                finclassToESS["FinType"] == "PRIVATE",
            ]
            choicelist = ["Compensable", "Public", "Private"]
            finclassToESS["FinType"] = np.select(condlist, choicelist, "Null")
    else:
        label_2_status = 0
        messagebox.showerror(
            "File Error", "/Costing/FinclassToFinType.csv is missing.\n" + str(e)
        )
        label_2_sub.configure(text="Failed (FinclassToFinType)...", fg="red")
        main_screen.update()
        return
    tbl_PPM_Encounter = pd.merge(
        tbl_PPM_Encounter,
        finclassToESS,
        how="left",
        left_on="FinancialClass",
        right_on="Finclass",
        suffixes=("", "_drop"),
    )
    tbl_PPM_Encounter = tbl_PPM_Encounter.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    tbl_PPM_Encounter["Extra:LeaveinCostingPeriod"] = np.where(
        tbl_PPM_Encounter["Extra:LeaveinCostingPeriod"] == 0,
        "",
        tbl_PPM_Encounter["Extra:LeaveinCostingPeriod"].astype(str),
    )
    tbl_PPM_Encounter["Extra:nwau_paed_incr"] = np.where(
        tbl_PPM_Encounter["Extra:nwau_paed_incr"] == 0,
        "",
        tbl_PPM_Encounter["Extra:nwau_paed_incr"].astype(str),
    )
    tbl_PPM_Encounter["Extra:nwau_indig_incr"] = np.where(
        tbl_PPM_Encounter["Extra:nwau_indig_incr"] == 0,
        "",
        tbl_PPM_Encounter["Extra:nwau_indig_incr"].astype(str),
    )
    tbl_PPM_Encounter["Extra:nwau_remote_incr"] = np.where(
        tbl_PPM_Encounter["Extra:nwau_remote_incr"] == 0,
        "",
        tbl_PPM_Encounter["Extra:nwau_remote_incr"].astype(str),
    )
    tbl_PPM_Encounter["Extra:nwau_icu_incr"] = np.where(
        tbl_PPM_Encounter["Extra:nwau_icu_incr"] == 0,
        "",
        tbl_PPM_Encounter["Extra:nwau_icu_incr"].astype(str),
    )
    tbl_PPM_Encounter["Extra:nwau_private_patient_service_incr"] = np.where(
        tbl_PPM_Encounter["Extra:nwau_private_patient_service_incr"] == 0,
        "",
        tbl_PPM_Encounter["Extra:nwau_private_patient_service_incr"].astype(str),
    )
    tbl_PPM_Encounter["Extra:nwau_private_patient_accom_incr"] = np.where(
        tbl_PPM_Encounter["Extra:nwau_private_patient_accom_incr"] == 0,
        "",
        tbl_PPM_Encounter["Extra:nwau_private_patient_accom_incr"].astype(str),
    )
    # 19 Feb 2025 - V15 release . Radiotherapy not populated correctly for SNAP
    tbl_PPM_Encounter["Extra:Radiotherapy_adj"] = np.where(
        tbl_PPM_Encounter["Extra:Radiotherapy_adj"] == 0,
        "",
        tbl_PPM_Encounter["Extra:Radiotherapy_adj"].astype(str),
    )
    logging.info(
        "Query: qry update ESS completed. %s records will be updated in tbl_PPM_Encounter. tbl_PPM_Encounter has %s records.",
        len(
            tbl_PPM_Encounter[
                (tbl_PPM_Encounter["Extra:ElectionStatusSummary"].isnull())
                | (tbl_PPM_Encounter["Extra:ElectionStatusSummary"] == "")
            ]
        ),
        len(tbl_PPM_Encounter),
    )
    # Note: Extra:ElectionStatusSummary'] was set to 'Null' previously, when it is not public, pvt, compensable,
    tbl_PPM_Encounter["Extra:ElectionStatusSummary"] = np.where(
        (tbl_PPM_Encounter["Extra:ElectionStatusSummary"].isnull())
        | (tbl_PPM_Encounter["Extra:ElectionStatusSummary"] == "")
        | (tbl_PPM_Encounter["Extra:ElectionStatusSummary"] == "NULL")
        | (tbl_PPM_Encounter["Extra:ElectionStatusSummary"] == "nan"),
        tbl_PPM_Encounter["FinType"],
        tbl_PPM_Encounter["Extra:ElectionStatusSummary"],
    )
    ##############RANJIT : UNACCOUNTED COLUMNS - HOW ARE THESE POPULATED ???? ############################
    tbl_PPM_Encounter["Extra:nwau_cwt_type"] = ""
    tbl_PPM_Encounter["Extra:sla_ra06"] = ""
    tbl_PPM_Encounter["Extra:HospInsuranceonAdmit"] = ""
    tbl_PPM_Encounter["Extra:postcode_ra06"] = ""
    tbl_PPM_Encounter["Extra:hosp_ra06"] = ""
    tbl_PPM_Encounter["Extra:SNAPCareType"] = ""
    tbl_PPM_Encounter["Extra:MHCostingStudy"] = ""
    ######################################################################################################
    tbl_PPM_Encounter = tbl_PPM_Encounter[
        [
            "EncounterNumber",
            "PostCode",
            "Suburb",
            "MaritalStatus",
            "EncounterType",
            "PatientNumber",
            "EpisodeOfCare",
            "AttendingConsultant",
            "AttendingConsultantSpecialty",
            "AdmissionCategory",
            "AdmissionElection",
            "DischargeElection",
            "AdmissionType",
            "AdmissionSource",
            "Hospital",
            "FinancialClass",
            "DischargeStatus",
            "DRG1",
            "DRG1Version",
            "DRG2",
            "DRG2Version",
            "DRG3",
            "DRG3Version",
            "Extra:DRG4",
            "Extra:DRG4Version",
            "LengthOfStay",
            "ICUHours",
            "MechVentHours",
            "StartDateTime",
            "EndDateTime",
            "Age",
            "HealthFund",
            "AdmissionWeight",
            "WeightedSeparation",
            "Extra:LGACode",
            "Extra:HospitalStayNumber",
            "Extra:LHDIdentifier",
            "Extra:LegalStatus",
            "Extra:DVANumber",
            "Extra:DVAType",
            "Extra:IntendedSameDay",
            "Extra:ReferralFurtherHealthcare",
            "Extra:UnplannedReadmission",
            "Extra:EpisodeSequenceNumber",
            "Extra:MedicareNumber",
            "Extra:DaysinPsychUnit",
            "Extra:UnplannedTheatre",
            "Extra:EDStatus",
            "Extra:ICUStatus",
            "Extra:SRGcurrent",
            "Extra:ESRGcurrent",
            "Extra:CW_A",
            "Extra:CW_B",
            "Extra:CW_C",
            "Extra:CW_D",
            "Extra:CW_E",
            "Extra:CW_F",
            "Extra:TrimPoint",
            "Extra:Outlierdays",
            "Extra:SurgeryIndicator",
            "Extra:AreaDOHRSCode",
            "Extra:FinancialProgram",
            "Extra:FacilityTransferredto",
            "Extra:FacilityTransferredfrom",
            "Extra:MRN",
            "Extra:MDC",
            "Extra:indicatorProcedurecode",
            "Extra:bookingIdentifier",
            "Extra:waitinglistcategory",
            "Extra:ClinicalURGfinal",
            "Extra:ReasonforRemoval",
            "Extra:DRG1_pccl",
            "Extra:EpisodeLeaveDays",
            "Extra:QualifiedBedDays",
            "Extra:IndigenousStatus",
            "Extra:MothersMRN",
            "Extra:MothersStayNumber",
            "Extra:MothersPersonIdentifier",
            "Extra:WIP2",
            "Extra:WIP",
            "Extra:ElectionStatusSummary",
            "Extra:MedicareEligibility",
            "Extra:FacilityType",
            "Extra:LOSinCostingPeriod",
            "Extra:LeaveinCostingPeriod",
            "Extra:ProdType",
            "Extra:CaseType",
            "Extra:EpisType",
            "Extra:AssessOnly",
            "Extra:PCPhase",
            "Extra:PCSymptomScoreStart",
            "Extra:PCSeverityStart",
            "Extra:PCPsychSpiritualScoreStart",
            "Extra:PCFamilyCarerScoreStart",
            "Extra:MaintType",
            "Extra:CareFocus",
            "Extra:Impair",
            "Extra:RugBedBeg",
            "Extra:RugToilBeg",
            "Extra:RugXferBeg",
            "Extra:RugEatBeg",
            "Extra:Cost_Weight",
            "Extra:SNAP_Class",
            "Extra:FIMEatBeg",
            "Extra:FIMEatEnd",
            "Extra:FIMGroomBeg",
            "Extra:FIMGroomEnd",
            "Extra:FIMBathBeg",
            "Extra:FIMBathEnd",
            "Extra:FIMUpperBeg",
            "Extra:FIMUpperEnd",
            "Extra:FIMLowerBeg",
            "Extra:FIMLowerEnd",
            "Extra:FIMToiletBeg",
            "Extra:FIMToiletEnd",
            "Extra:FIMBladderBeg",
            "Extra:FIMBladderEnd",
            "Extra:FIMBowelBeg",
            "Extra:FIMBowelEnd",
            "Extra:FIMXferBeg",
            "Extra:FIMXferEnd",
            "Extra:FIMXferToilBeg",
            "Extra:FIMXferToilEnd",
            "Extra:FIMTubBeg",
            "Extra:FIMTubEnd",
            "Extra:FIMWalkBeg",
            "Extra:FIMWalkEnd",
            "Extra:FIMStairBeg",
            "Extra:FIMStairEnd",
            "Extra:FIMCompBeg",
            "Extra:FIMCompEnd",
            "Extra:FIMExpBeg",
            "Extra:FIMExpEnd",
            "Extra:FIMSocialBeg",
            "Extra:FIMSocialEnd",
            "Extra:FIMProbBeg",
            "Extra:FIMProbEnd",
            "Extra:FIMMemoryBeg",
            "Extra:FIMMemoryEnd",
            "Extra:HonActiveBeg",
            "Extra:HonActiveEnd",
            "Extra:HonInjuryBeg",
            "Extra:HonInjuryEnd",
            "Extra:HonDrinkBeg",
            "Extra:HonDrinkEnd",
            "Extra:HonCognitBeg",
            "Extra:HonCognitEnd",
            "Extra:HonDisabBeg",
            "Extra:HonDisabEnd",
            "Extra:HonHallucBeg",
            "Extra:HonHallucEnd",
            "Extra:HonDeprsBeg",
            "Extra:HonDeprsEnd",
            "Extra:HonOtherBeg",
            "Extra:HonOtherEnd",
            "Extra:HonRelatBeg",
            "Extra:HonRelatEnd",
            "Extra:HonADLBeg",
            "Extra:HonADLEnd",
            "Extra:HonLivingBeg",
            "Extra:HonLivingEnd",
            "Extra:HonOccupBeg",
            "Extra:HonOccupEnd",
            "Extra:ExtractorVersion",
            "Extra:nwau_cwt_type",
            "Extra:nwau_base",
            "Extra:nwau_paed_incr",
            "Extra:nwau_indig_incr",
            "Extra:nwau_remote_incr",
            "Extra:nwau_icu_incr",
            "Extra:nwau_private_patient_service_incr",
            "Extra:nwau_private_patient_accom_incr",
            "Extra:nwau",
            "Extra:nwau_PublicEquivModel",
            "Extra:sla_ra06",
            "Extra:AICU1_Hours",
            "Extra:AICU2_Hours",
            "Extra:AICU3_Hours",
            "Extra:PICU_Hours",
            "Extra:NICU_Hours",
            "Extra:PSICU_Hours",
            "Extra:CCU_Hours",
            "Extra:HospInsuranceonAdmit",
            "Extra:postcode_ra06",
            "Extra:hosp_ra06",
            "Extra:AUID",
            "Extra:SCN_Hours",
            "Extra:HDU_Hours",
            "Extra:HITH_Hours",
            "Extra:SRG_Version",
            "Extra:Contract_Status",
            "Extra:Collabrtve_Care_Role",
            "Extra:Collabrtve_Care_Facility",
            "Extra:Collabrtve_Care_Type",
            "Extra:LHD_of_Usual_Residence",
            "Extra:compensable_nwau",
            "Extra:SNAPCareType",
            "Extra:nwau_version",
            "Extra:sp_psy_age_adj",
            "Extra:MDC2",
            "Extra:MHCostingStudy",
            "Extra:Radiotherapy_adj",
            "Extra:N_Z_FinancialProgram",
            "Extra:SpecialtyPortal",
            "Extra:SNAP_ClassV4",
            "Extra:Dementia_Flag",
            "Extra:Delirium_Flag",
            "Extra:ExtractDate",
            "Extra:AMHCC_Class",
            "Extra:AMHCC_ClassVersion",
            "Extra:HON1",
            "Extra:HON2",
            "Extra:HON3",
            "Extra:HON4",
            "Extra:HON5",
            "Extra:HON6",
            "Extra:HON7",
            "Extra:HON8",
            "Extra:HON9",
            "Extra:HON10",
            "Extra:HON11",
            "Extra:HON12",
            "Extra:HON13",
            "Extra:HON14",
            "Extra:HON15",
            "Extra:HONOS1",
            "Extra:HONOS2",
            "Extra:HONOS3",
            "Extra:HONOS4",
            "Extra:HONOS5",
            "Extra:HONOS6",
            "Extra:HONOS7",
            "Extra:HONOS8",
            "Extra:HONOS9",
            "Extra:HONOS10",
            "Extra:HONOS11",
            "Extra:HONOS12",
            "Extra:HONOS65_1",
            "Extra:HONOS65_2",
            "Extra:HONOS65_3",
            "Extra:HONOS65_4",
            "Extra:HONOS65_5",
            "Extra:HONOS65_6",
            "Extra:HONOS65_7",
            "Extra:HONOS65_8",
            "Extra:HONOS65_9",
            "Extra:HONOS65_10",
            "Extra:HONOS65_11",
            "Extra:HONOS65_12",
            "Extra:HONOSCA1",
            "Extra:HONOSCA2",
            "Extra:HONOSCA3",
            "Extra:HONOSCA4",
            "Extra:HONOSCA5",
            "Extra:HONOSCA6",
            "Extra:HONOSCA7",
            "Extra:HONOSCA8",
            "Extra:HONOSCA9",
            "Extra:HONOSCA10",
            "Extra:HONOSCA11",
            "Extra:HONOSCA12",
            "Extra:HONOSCA13",
            "Extra:HONOSCA14",
            "Extra:HONOSCA15",
            "Extra:IHPA_LSP_01",
            "Extra:IHPA_LSP_02",
            "Extra:IHPA_LSP_03",
            "Extra:IHPA_LSP_04",
            "Extra:IHPA_LSP_05",
            "Extra:IHPA_LSP_06",
            "Extra:IHPA_LSP_07",
            "Extra:IHPA_LSP_08",
            "Extra:IHPA_LSP_09",
            "Extra:IHPA_LSP_10",
            "Extra:IHPA_LSP_11",
            "Extra:IHPA_LSP_12",
            "Extra:IHPA_LSP_13",
            "Extra:IHPA_LSP_14",
            "Extra:IHPA_LSP_15",
            "Extra:IHPA_LSP_16",
            "Extra:LengthofStay_EpisodeTable",
            "Extra:EpisodeLeaveDays_EpisodeTable",
            "Extra:EpisodeofCare_EpisodeTable",
            "Extra:StartDateTime_EpisodeTable",
            "Extra:EndDateTime_EpisodeTable",
            "Extra:EndDateTime_EpisodeATSTable",
            "Extra:LengthofStay_EpisodeATSTable",
            "Extra:EpisodeLeaveDays_EpisodeATSTable",
            "Extra:EpisodeofCare_EpisodeATSTable",
            "Extra:MothersEncounterNumber",
            "Extra:AdmittingSpecialtyPortal",
            "Extra:MHPhaseSeqNo",
            "Extra:HLTH_ORG_OSP_OSP_ID",
            "Extra:MG_AUTH_OSP_OSP_ID",
            "Extra:SE_CBK_SK",
            "Extra:CL_ID_EUID",
            "Extra:CL_ID_IHI",
            "Extra:HLTH_ORG_OSP_TYP",
            "Extra:SRV_ENC_REC_ID",
            "Extra:FRML_DISCH_MODE_CD",
            "Extra:SE_SEP_MODE_NHDD_CD",
            "Extra:Responsible_Facility",
            "Extra:SE_TYP_CD",
            "Extra:SE_ADM_MODE_NHDD_CD",
            "Extra:DIM_RSP_ISP_SK",
            "Extra:AR_DRG_ECCS_RAW",
            "Extra:WAU_ADJ_PT_TX_REMT_AREA",
            "Extra:WAU_ADJ_DIALYSIS",
            "Extra:WAU_ADJ_COVID19",
            "Extra:WAU_ADJ_HAC",
            "Extra:ASGS_SA_L2_16_CD",
            "Extra:CL_URES_ADDR_ASGS21_SA_L2_CD",
        ]
    ]
    tbl_PPM_Encounter = tbl_PPM_Encounter.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    tbl_PPM_Encounter = tbl_PPM_Encounter.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    tbl_PPM_Encounter = tbl_PPM_Encounter.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    tbl_PPM_Encounter.drop_duplicates(keep="last", inplace=True)
    tbl_PPM_Encounter.to_csv(
        "./ExtractorDB/tbl_PPM_Encounter_" + versionID_underscore + "_before_aecc.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    # Incorrect text formatting in HealthFund AQA-357
    tbl_PPM_Encounter["HealthFund"] = (
        tbl_PPM_Encounter["HealthFund"]
        .str.normalize("NFKD")
        .str.encode("ascii", errors="ignore")
        .str.decode("utf-8")
    )
    try:
        # Incorrect text formatting in HealthFund AQA-357
        tbl_PPM_Encounter.to_csv(
            "./Output/tbl_PPM_Encounter_" + versionID_underscore + ".csv",
            index=False,
            na_rep="",
            float_format=str,
            decimal=str,
            date_format=str,
            encoding="utf-8",
        )
    except Exception as e:
        logging.exception("Exception occurred")
        label_2_status = 0
        messagebox.showerror(
            "Export Error", "Error exporting tbl_PPM_Encounter\n" + str(e)
        )
        label_2_sub.configure(text="Failed ()...", fg="red")
        main_screen.update()
        return  # stop export
    # else:
    #    label_2_sub.configure(text="Completed",fg='green')
    #    main_screen.update()
    #### Pending Quality Checks - QualityChecks_X_EncounterType_Errors, QualityChecks_N_Z_FinancialProgramNotAssigned
    # Quality Check X_EncounterType_Errors:
    # Inform8 query: SELECT EncounterNumber, PatientNumber, EpisodeOfCare, EncounterType,  NO_facility_identifier (ats.facility_identifier) as Facility, Extra:NICU_Hours as Extra_NICU_Hours, Extra:QualifiedBedDays as Extra_QualifiedBedDays FROM ppmEncounter WHERE Extra:NICU_Hours != 0 && (Extra:QualifiedBedDays == "0" || Extra:QualifiedBedDays is Null) && EpisodeOfCare == "5" && EncounterType == "X"
    # LM - Modify query to check condition where Extra:NICU_Hours = 0 and Extra:QualifiedBedDays is non-Zero.
    qualityChecks_X_EncounterType_Errors_inform8 = tbl_PPM_Encounter[
        (
            (tbl_PPM_Encounter["EncounterType"] == "X")
            & (tbl_PPM_Encounter["EpisodeOfCare"] == "5")
            & (tbl_PPM_Encounter["Extra:NICU_Hours"].astype(float) != 0.0)
            & (tbl_PPM_Encounter["Extra:QualifiedBedDays"].astype(float) == 0.0)
        )
        | (
            (tbl_PPM_Encounter["EncounterType"] == "X")
            & (tbl_PPM_Encounter["EpisodeOfCare"].astype(str).str.strip() == "5")
            & (tbl_PPM_Encounter["Extra:QualifiedBedDays"].astype(float) != 0.0)
            & (tbl_PPM_Encounter["Extra:NICU_Hours"].astype(float) == 0.0)
        )
    ][
        [
            "EncounterNumber",
            "PatientNumber",
            "EpisodeOfCare",
            "EncounterType",
            "Hospital",
            "Extra:NICU_Hours",
            "Extra:QualifiedBedDays",
        ]
    ]
    qualityChecks_X_EncounterType_Errors_inform8.rename(
        columns={
            "Hospital": "Facility",
            "Extra:NICU_Hours": "Extra_NICU_Hours",
            "Extra:QualifiedBedDays": "Extra_QualifiedBedDays",
        },
        inplace=True,
    )
    qualityChecks_X_EncounterType_Errors_inform8 = (
        qualityChecks_X_EncounterType_Errors_inform8[
            [
                "EncounterNumber",
                "PatientNumber",
                "EpisodeOfCare",
                "EncounterType",
                "Facility",
                "Extra_NICU_Hours",
                "Extra_QualifiedBedDays",
            ]
        ]
    )
    try:
        qualityChecks_X_EncounterType_Errors_inform8.to_csv(
            "./Output/QualityChecks_X_EncounterType_Errors.csv",
            index=False,
            na_rep="",
            float_format=str,
            decimal=str,
            date_format=str,
        )
    except Exception as e:
        logging.exception("Exception occurred")
        label_2_status = 0
        messagebox.showerror(
            "Export Error",
            "Error exporting qualityChecks_X_EncounterType_Errors_inform8.csv\n"
            + str(e),
        )
        label_2_sub.configure(text="Failed ()...", fg="red")
        main_screen.update()
        return  # stop export
    # QualityChecks_N_Z_FinancialProgramNotAssigned:
    # Inform8 query: SELECT EncounterNumber, PatientNumber, EpisodeOfCare,  NO_facility_identifier as Facility, Extra_AMHCC_Class FROM ppmEncounter  WHERE Extra:N_Z_FinancialProgram is null or empty
    qualityChecks_N_Z_FinancialProgramNotAssigned_inform8 = tbl_PPM_Encounter[
        (tbl_PPM_Encounter["Extra:N_Z_FinancialProgram"] == "")
        | (tbl_PPM_Encounter["Extra:N_Z_FinancialProgram"].isnull())
    ][
        [
            "EncounterNumber",
            "PatientNumber",
            "EpisodeOfCare",
            "Hospital",
            "Extra:AMHCC_Class",
        ]
    ]
    qualityChecks_N_Z_FinancialProgramNotAssigned_inform8.rename(
        columns={"Hospital": "Facility"}, inplace=True
    )
    qualityChecks_N_Z_FinancialProgramNotAssigned_inform8 = (
        qualityChecks_N_Z_FinancialProgramNotAssigned_inform8[
            [
                "EncounterNumber",
                "PatientNumber",
                "EpisodeOfCare",
                "Facility",
                "Extra:AMHCC_Class",
            ]
        ]
    )
    try:
        # https://abft101.atlassian.net/browse/AQA-320
        # qualityChecks_N_Z_FinancialProgramNotAssigned_inform8.to_csv('./Output/QualityChecks_N_Z_FinancialProgramNotAssigned.csv', index=False, na_rep='', float_format=str, decimal=str, date_format=str)
        qualityChecks_N_Z_FinancialProgramNotAssigned_inform8.to_csv(
            "./Output/QualityChecks_SubProgramNotAssigned.csv",
            index=False,
            na_rep="",
            float_format=str,
            decimal=str,
            date_format=str,
        )
    except Exception as e:
        logging.exception("Exception occurred")
        label_2_status = 0
        messagebox.showerror(
            "Export Error",
            "Error exporting qualityChecks_N_Z_FinancialProgramNotAssigned_inform8.csv\n"
            + str(e),
        )
        label_2_sub.configure(text="Failed ()...", fg="red")
        main_screen.update()
        return  # stop export
    # Update Sub task status
    if label_2_status == 0:
        label_2_sub.configure(text="Failed", fg="red")
        main_screen.update()
    else:
        label_2_sub.configure(text="Completed", fg="green")
        main_screen.update()
    main_screen.update()
    logging.info(
        "Export Encounter IP completed. %s records written to ./Output/tbl_PPM_Encounter_%s.csv",
        len(tbl_PPM_Encounter),
        versionID_underscore,
    )
    ############### "3. Export Diagnosis Data"#################
    logging.info("Export Diagnosis Data started.")
    # Set default value of sub-task status to 1
    label_3_status = 1
    label_3_sub.configure(text="In Progress (Diagnosis)...", fg="blue")
    main_screen.update()
    file_tbl_PPM_ICD_diagnoses = "./ExtractorDB/tbl_PPM_ICD_diagnoses.csv"
    if os.path.isfile(file_tbl_PPM_ICD_diagnoses):
        try:
            tbl_PPM_ICD_diagnoses = read_csv_file(
                file_tbl_PPM_ICD_diagnoses,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            label_3_status = 0
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_PPM_ICD_diagnoses from ./ExtractorDB/tbl_PPM_ICD_diagnoses.csv.\n"
                + str(e),
            )
            label_3_sub.configure(text="Failed (tbl_PPM_ICD_diagnoses)...", fg="red")
            main_screen.update()
            return
        else:
            tbl_PPM_ICD_diagnoses = tbl_PPM_ICD_diagnoses.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_PPM_ICD_diagnoses = tbl_PPM_ICD_diagnoses.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_PPM_ICD_diagnoses = tbl_PPM_ICD_diagnoses.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_PPM_ICD_diagnoses = tbl_PPM_ICD_diagnoses.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
    else:
        tbl_PPM_ICD_diagnoses = pd.DataFrame()
    """ Deletes all exclude encounters in the tbl_PPM_ICD_diagnoses table where the encounter is in the tbl_ExcludedEncounters table"""
    # Access query: qry delete excluded encounters from diagnosis
    # DELETE DISTINCTROW tbl_PPM_ICD_diagnoses.EncounterNumber, tbl_PPM_ICD_diagnoses.* FROM tbl_ExcludedEncounters INNER JOIN tbl_PPM_ICD_diagnoses ON tbl_ExcludedEncounters.EncounterNumber = tbl_PPM_ICD_diagnoses.EncounterNumber;
    tbl_ExcludedEncounters_list = []
    file_tbl_ExcludedEncounters = "./ExtractorDB/tbl_ExcludedEncounters.csv"
    if os.path.isfile(file_tbl_ExcludedEncounters):
        try:
            tbl_ExcludedEncounters = read_csv_file(
                file_tbl_ExcludedEncounters,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            label_3_status = 0
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_ExcludedEncounters from ./ExtractorDB/tbl_ExcludedEncounters.csv.\n"
                + str(e),
            )
            label_3_sub.configure(text="Failed (tbl_ExcludedEncounters)...", fg="red")
            main_screen.update()
            return
        else:
            tbl_ExcludedEncounters_list = tbl_ExcludedEncounters[
                "EncounterNumber"
            ].tolist()
    else:
        tbl_ExcludedEncounters = pd.DataFrame()
    logging.info(
        "%s read from ./ExtractorDB/tbl_PPM_ICD_diagnoses.csv",
        len(tbl_PPM_ICD_diagnoses),
    )
    tbl_PPM_ICD_diagnoses = tbl_PPM_ICD_diagnoses[
        ~tbl_PPM_ICD_diagnoses["EncounterNumber"].isin(tbl_ExcludedEncounters_list)
    ]
    logging.info(
        "tbl_PPM_ICD_diagnoses has %s records after deleting all encounters in the tbl_PPM_ICD_diagnoses table where the encounter is in the tbl_ExcludedEncounters table.",
        len(tbl_PPM_ICD_diagnoses),
    )
    """ Deletes encounters in the tbl_PPM_ICD_diagnoses when they are not in the tbl_PPM_Encounter table  This is because the encounters have been excluded because of the inaptient encounter matched to snap encounter.. should includes these in excluded table for reconciliation ?"""
    # Access query: qrydelete:SNAP_diagnosis
    # DELETE DISTINCTROW tbl_PPM_ICD_diagnoses.*, tbl_PPM_Encounter.EncounterNumber FROM tbl_PPM_ICD_diagnoses LEFT JOIN tbl_PPM_Encounter ON tbl_PPM_ICD_diagnoses.EncounterNumber = tbl_PPM_Encounter.EncounterNumber WHERE (((tbl_PPM_Encounter.EncounterNumber) Is Null));
    tbl_PPM_Encounter_list = []
    file_tbl_PPM_Encounter_list = (
        "./Output/tbl_PPM_Encounter_" + versionID_underscore + ".csv"
    )
    if os.path.isfile(file_tbl_PPM_Encounter_list):
        try:
            tbl_PPM_Encounter = read_csv_file(
                file_tbl_PPM_Encounter_list,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            label_3_status = 0
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_PPM_Encounter from ./Output/tbl_PPM_Encounter.csv.\n"
                + str(e),
            )
            label_3_sub.configure(text="Failed (tbl_PPM_Encounter)...", fg="red")
            main_screen.update()
            return
        else:
            tbl_PPM_Encounter = tbl_PPM_Encounter.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_PPM_Encounter = tbl_PPM_Encounter.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_PPM_Encounter = tbl_PPM_Encounter.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_PPM_Encounter = tbl_PPM_Encounter.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_PPM_Encounter_list = tbl_PPM_Encounter["EncounterNumber"].tolist()
    else:
        tbl_PPM_Encounter = pd.DataFrame()
    # Note: unlike others, here keep encounters the tbl_PPM_ICD_diagnoses when they are in the tbl_PPM_Encounter table
    tbl_PPM_ICD_diagnoses = tbl_PPM_ICD_diagnoses[
        tbl_PPM_ICD_diagnoses["EncounterNumber"].isin(tbl_PPM_Encounter_list)
    ]
    # tbl_PPM_ICD_diagnoses = tbl_PPM_ICD_diagnoses[['EncounterNumber','DiagnosisCode','DiagnosisVersion','Sequence','ConditionOnset']]
    tbl_PPM_ICD_diagnoses = tbl_PPM_ICD_diagnoses[
        [
            "EncounterNumber",
            "DiagnosisCode",
            "DiagnosisVersion",
            "Sequence",
            "ConditionOnset",
            "HLTH_ORG_OSP_OSP_ID",
            "MG_AUTH_OSP_OSP_ID",
            "SE_CBK_SK",
            "EDW_Enc_Number",
        ]
    ]
    tbl_PPM_ICD_diagnoses = tbl_PPM_ICD_diagnoses.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    tbl_PPM_ICD_diagnoses = tbl_PPM_ICD_diagnoses.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    tbl_PPM_ICD_diagnoses = tbl_PPM_ICD_diagnoses.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    tbl_PPM_ICD_diagnoses.drop_duplicates(keep="last", inplace=True)
    #########################
    # 11 Jan 2025 - CREATED FACILITY CHANGE
    # ValueError: You are trying to merge on object and int64 columns
    tbl_PPM_ICD_diagnoses["SE_CBK_SK"] = tbl_PPM_ICD_diagnoses["SE_CBK_SK"].astype(
        "Int64"
    )
    ########################
    """Exports all data from tbl_PPM_ICD_diagnoses table as c:\costing\ tbl_PPM_ICD_diagnoses.txt """
    # Access query: tbl_PPM_ICD_diagnoses
    try:
        tbl_PPM_ICD_diagnoses.to_csv(
            "./Output/tbl_PPM_ICD_diagnoses_" + versionID_hash + ".csv",
            index=False,
            na_rep="",
            float_format=str,
            decimal=str,
            date_format=str,
        )
    except Exception as e:
        logging.exception("Exception occurred")
        label_3_status = 0
        messagebox.showerror(
            "Export Error", "Error exporting tbl_PPM_ICD_diagnoses\n" + str(e)
        )
        label_3_sub.configure(text="Failed ()...", fg="red")
        main_screen.update()
        return  # stop export
    # else:
    #    label_3_sub.configure(text="Completed",fg='green')
    #    main_screen.update()
    # Update Sub task status
    if label_3_status == 0:
        label_3_sub.configure(text="Failed", fg="red")
        main_screen.update()
    else:
        label_3_sub.configure(text="Completed", fg="green")
        main_screen.update()
    main_screen.update()
    logging.info(
        "Export Diagnosis Data completed. %s records written to ./Output/tbl_PPM_ICD_diagnoses_%s.csv",
        len(tbl_PPM_ICD_diagnoses),
        versionID_hash,
    )
    ############### "4. Export Procedure Data"#################
    logging.info("Export Procedure Data started.")
    # Set default value of sub-task status to 1
    label_4_status = 1
    label_4_sub.configure(text="In Progress (Procedures)...", fg="blue")
    main_screen.update()
    file_tbl_PPM_ICD_procedures = "./ExtractorDB/tbl_PPM_ICD_procedures.csv"
    if os.path.isfile(file_tbl_PPM_ICD_procedures):
        try:
            tbl_PPM_ICD_procedures = read_csv_file(
                file_tbl_PPM_ICD_procedures,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            label_4_status = 0
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_PPM_ICD_procedures from ./ExtractorDB/tbl_PPM_ICD_procedures.csv.\n"
                + str(e),
            )
            label_4_sub.configure(text="Failed (tbl_PPM_ICD_procedures)...", fg="red")
            main_screen.update()
            return
        else:
            tbl_PPM_ICD_procedures = tbl_PPM_ICD_procedures.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_PPM_ICD_procedures = tbl_PPM_ICD_procedures.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_PPM_ICD_procedures = tbl_PPM_ICD_procedures.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_PPM_ICD_procedures = tbl_PPM_ICD_procedures.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
    else:
        tbl_PPM_ICD_procedures = pd.DataFrame()
    """ Deletes all exclude encounters in the tbl_PPM_ICD_procedures table where the encounter is in the tbl_ExcludedEncounters table"""
    # Access query: qry delete excluded encounters from procedure
    # DELETE DISTINCTROW tbl_PPM_ICD_procedures.EncounterNumber, tbl_PPM_ICD_procedures.* FROM tbl_PPM_ICD_procedures INNER JOIN tbl_ExcludedEncounters ON tbl_PPM_ICD_procedures.EncounterNumber = tbl_ExcludedEncounters.EncounterNumber;
    tbl_ExcludedEncounters_list = []
    file_tbl_ExcludedEncounters = "./ExtractorDB/tbl_ExcludedEncounters.csv"
    if os.path.isfile(file_tbl_ExcludedEncounters):
        try:
            tbl_ExcludedEncounters = read_csv_file(
                file_tbl_ExcludedEncounters,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            label_4_status = 0
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_ExcludedEncounters from ./ExtractorDB/tbl_ExcludedEncounters.csv\n"
                + str(e),
            )
            label_4_sub.configure(text="Failed (tbl_ExcludedEncounters)...", fg="red")
            main_screen.update()
            return
        else:
            tbl_ExcludedEncounters_list = tbl_ExcludedEncounters[
                "EncounterNumber"
            ].tolist()
    else:
        tbl_ExcludedEncounters = pd.DataFrame()
    logging.info(
        "%s read from ./ExtractorDB/tbl_PPM_ICD_procedures.csv",
        len(tbl_PPM_ICD_procedures),
    )
    tbl_PPM_ICD_procedures = tbl_PPM_ICD_procedures[
        ~tbl_PPM_ICD_procedures["EncounterNumber"].isin(tbl_ExcludedEncounters_list)
    ]
    logging.info(
        "tbl_PPM_ICD_procedures has %s records after deleting all encounters in the tbl_PPM_ICD_procedures table where the encounter is in the tbl_ExcludedEncounters table.",
        len(tbl_PPM_ICD_procedures),
    )
    """Deletes encounters in the PPM_ICD_procedures when they are not in the tbl_PPM_ICD_procedures table  This is because the encounters have been excluded because of the inaptient encounter matched to snap encounter.. should includes these in excluded table for reconciliation ? """
    # Access query: qrydelete:SNAP_procedure
    # DELETE DISTINCTROW tbl_PPM_ICD_procedures.*, tbl_PPM_Encounter.EncounterNumber FROM tbl_PPM_ICD_procedures LEFT JOIN tbl_PPM_Encounter ON tbl_PPM_ICD_procedures.EncounterNumber = tbl_PPM_Encounter.EncounterNumber WHERE (((tbl_PPM_Encounter.EncounterNumber) Is Null));
    tbl_PPM_Encounter_list = []
    file_tbl_PPM_Encounter_list = (
        "./Output/tbl_PPM_Encounter_" + versionID_underscore + ".csv"
    )
    if os.path.isfile(file_tbl_PPM_Encounter_list):
        try:
            tbl_PPM_Encounter = read_csv_file(
                file_tbl_PPM_Encounter_list,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            label_4_status = 0
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_PPM_Encounter from ./Output/tbl_PPM_Encounter.csv.\n"
                + str(e),
            )
            label_4_sub.configure(text="Failed (tbl_PPM_Encounter)...", fg="red")
            main_screen.update()
            return
        else:
            tbl_PPM_Encounter_list = tbl_PPM_Encounter["EncounterNumber"].tolist()
    else:
        tbl_PPM_Encounter = pd.DataFrame()
    # delete from tbl_PPM_ICD_procedures where encounternumber is not in tbl_PPM_Encounter . => left join tbl_PPM_Encounter WHERE tbl_PPM_Encounter.EncounterNumber Is Null
    # i.e., keep encounters the tbl_PPM_ICD_procedures when they are in the tbl_PPM_Encounter table
    tbl_PPM_ICD_procedures = tbl_PPM_ICD_procedures[
        tbl_PPM_ICD_procedures["EncounterNumber"].isin(tbl_PPM_Encounter_list)
    ]
    logging.info(
        "Query: SNAP_procedure completed. tbl_PPM_ICD_procedures has %s records after deleting encounters in the tbl_PPM_ICD_procedures when they are not in the tbl_PPM_Encounter table. These encounters have been excluded because the inaptient encounter matched to snap encounter.",
        len(tbl_PPM_ICD_procedures),
    )
    # tbl_PPM_ICD_procedures = tbl_PPM_ICD_procedures[['EncounterNumber','ProcedureCode', 'ProcedureDateTime', 'ProcedureVersion', 'Sequence']]
    tbl_PPM_ICD_procedures = tbl_PPM_ICD_procedures[
        [
            "EncounterNumber",
            "ProcedureCode",
            "ProcedureDateTime",
            "ProcedureVersion",
            "Sequence",
            "HLTH_ORG_OSP_OSP_ID",
            "MG_AUTH_OSP_OSP_ID",
            "SE_CBK_SK",
            "EDW_Enc_Number",
        ]
    ]
    tbl_PPM_ICD_procedures["ProcedureDateTime"] = pd.to_datetime(
        tbl_PPM_ICD_procedures["ProcedureDateTime"], format="%Y-%m-%d %H:%M:%S"
    )
    tbl_PPM_ICD_procedures["ProcedureDateTime"] = tbl_PPM_ICD_procedures[
        "ProcedureDateTime"
    ].dt.strftime("%d/%m/%Y")
    """ Exports all data from tbl_ tbl_PPM_ICD_procedures table as c:\costing\ PPM_ICD_procedures.txt """
    # Access query: tbl_PPM_ICD_procedures
    # tbl_PPM_ICD_procedures = tbl_PPM_ICD_procedures[['EncounterNumber','ProcedureCode','ProcedureDateTime','ProcedureVersion','Sequence']]
    tbl_PPM_ICD_procedures = tbl_PPM_ICD_procedures[
        [
            "EncounterNumber",
            "ProcedureCode",
            "ProcedureDateTime",
            "ProcedureVersion",
            "Sequence",
            "HLTH_ORG_OSP_OSP_ID",
            "MG_AUTH_OSP_OSP_ID",
            "SE_CBK_SK",
            "EDW_Enc_Number",
        ]
    ]
    tbl_PPM_ICD_procedures = tbl_PPM_ICD_procedures.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    tbl_PPM_ICD_procedures = tbl_PPM_ICD_procedures.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    tbl_PPM_ICD_procedures = tbl_PPM_ICD_procedures.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    tbl_PPM_ICD_procedures["ProcedureDateTime"] = np.where(
        tbl_PPM_ICD_procedures["ProcedureDateTime"] == "nan",
        "",
        tbl_PPM_ICD_procedures["ProcedureDateTime"],
    )
    tbl_PPM_ICD_procedures.drop_duplicates(keep="last", inplace=True)
    #########################
    # 11 Jan 2025 - CREATED FACILITY CHANGE
    # ValueError: You are trying to merge on object and int64 columns
    tbl_PPM_ICD_procedures["SE_CBK_SK"] = tbl_PPM_ICD_procedures["SE_CBK_SK"].astype(
        "Int64"
    )
    ########################
    try:
        tbl_PPM_ICD_procedures.to_csv(
            "./Output/tbl_PPM_ICD_procedures_" + versionID_hash + ".csv",
            index=False,
            na_rep="",
            float_format=str,
            decimal=str,
            date_format=str,
        )
    except Exception as e:
        logging.exception("Exception occurred")
        label_4_status = 0
        messagebox.showerror(
            "Export Error", "Error exporting tbl_PPM_ICD_procedures\n" + str(e)
        )
        label_4_sub.configure(text="Failed (tbl_PPM_ICD_procedures)...", fg="red")
        main_screen.update()
        return  # stop export
    # else:
    #    label_4_sub.configure(text="Completed",fg='green')
    #    main_screen.update()
    logging.info(
        "%s records written to ./Output/tbl_PPM_ICD_procedures_%s.csv",
        len(tbl_PPM_ICD_procedures),
        versionID_hash,
    )
    ####################  tbl_ppm_ObstetEpi.txt ###########
    # Access query: qry ObsetEpi
    # SELECT tbl_PPM_Encounter.PatientNumber, tbl_PPM_Encounter.EncounterNumber, tbl_PPM_Encounter.Hospital, tbl_PPM_Encounter.AttendingConsultant, tbl_PPM_Encounter.AttendingConsultantSpecialty, tbl_PPM_Encounter.StartDateTime, tbl_PPM_Encounter.[Extra:MRN], tbl_PPM_Encounter.[Extra:AUID], tbl_PPM_ICD_diagnoses.DiagnosisCode, tbl_PPM_ICD_procedures.ProcedureCode, tbl_PPM_ICD_procedures.ProcedureDateTime, tbl_PPM_Encounter.EndDateTime
    # FROM tbl_PPM_ICD_procedures RIGHT JOIN (tbl_PPM_ICD_diagnoses RIGHT JOIN tbl_PPM_Encounter ON tbl_PPM_ICD_diagnoses.EncounterNumber = tbl_PPM_Encounter.EncounterNumber) ON tbl_PPM_ICD_procedures.EncounterNumber = tbl_PPM_Encounter.EncounterNumber
    # WHERE (((tbl_PPM_ICD_diagnoses.DiagnosisCode) Like 'Z37*') AND ((tbl_PPM_ICD_procedures.ProcedureCode) Like '92506*') AND ((tbl_PPM_Encounter.[Extra:WIP])="4" Or (tbl_PPM_Encounter.[Extra:WIP])="2")) OR (((tbl_PPM_ICD_diagnoses.DiagnosisCode) Like 'Z37*') AND ((tbl_PPM_ICD_procedures.ProcedureCode) Like '92507*') AND ((tbl_PPM_Encounter.[Extra:WIP])="4" Or (tbl_PPM_Encounter.[Extra:WIP])="2")) OR (((tbl_PPM_ICD_diagnoses.DiagnosisCode) Like 'Z37*') AND ((tbl_PPM_ICD_procedures.ProcedureCode) Like '92508*') AND ((tbl_PPM_Encounter.[Extra:WIP])="4" Or (tbl_PPM_Encounter.[Extra:WIP])="2"));
    # Access query: qry_append_obstet_epi
    # INSERT INTO Tbl_ppm_ObstetEpi ( EncounterNumber, patientnumber, AttendingConsultant, AttendingConsultantSpecialty, [extra:mrn], [extra:auid], startdatetime, hospital, DiagnosisCode, ProcedureCode, ProcedureDateTime, enddatetime )
    # SELECT Tbl_PPM_Encounter_V25.EncounterNumber, Tbl_PPM_Encounter_V25.patientnumber, Tbl_PPM_Encounter_V25.AttendingConsultant, Tbl_PPM_Encounter_V25.AttendingConsultantSpecialty, Tbl_PPM_Encounter_V25.[extra:mrn], Tbl_PPM_Encounter_V25.[extra:auid], Tbl_PPM_Encounter_V25.startdatetime, Tbl_PPM_Encounter_V25.hospital, Max(diagnosis_ICD10V12.diagnosis_code_curr) AS MaxOfdiagnosis_code_curr, Max(Procedure_ICD10V12.procedure_code_curr) AS MaxOfprocedure_code_curr, Procedure_ICD10V12.procedure_date, Tbl_PPM_Encounter_V25.enddatetime
    # FROM Procedure_ICD10V12 INNER JOIN (diagnosis_ICD10V12 INNER JOIN Tbl_PPM_Encounter_V25 ON diagnosis_ICD10V12.[EncounterNumber] = Tbl_PPM_Encounter_V25.EncounterNumber) ON Procedure_ICD10V12.EncounterNumber = Tbl_PPM_Encounter_V25.EncounterNumber
    # GROUP BY Tbl_PPM_Encounter_V25.EncounterNumber, Tbl_PPM_Encounter_V25.patientnumber, Tbl_PPM_Encounter_V25.AttendingConsultant, Tbl_PPM_Encounter_V25.AttendingConsultantSpecialty, Tbl_PPM_Encounter_V25.[extra:mrn], Tbl_PPM_Encounter_V25.[extra:auid], Tbl_PPM_Encounter_V25.startdatetime, Tbl_PPM_Encounter_V25.hospital, Procedure_ICD10V12.procedure_date, Tbl_PPM_Encounter_V25.enddatetime, Tbl_PPM_Encounter_V25.[extra:wip]
    # HAVING (((Max(Procedure_ICD10V12.procedure_code_curr)) Like '92506*') AND ((Tbl_PPM_Encounter_V25.[extra:wip]) In ("4","2"))) OR (((Max(Procedure_ICD10V12.procedure_code_curr)) Like '92507*') AND ((Tbl_PPM_Encounter_V25.[extra:wip]) In ("4","2"))) OR (((Max(Procedure_ICD10V12.procedure_code_curr)) Like '92508*') AND ((Tbl_PPM_Encounter_V25.[extra:wip]) In ("4","2")));
    # 11 Jan 2024 - CREATED FACILITY CHANGE
    # df_query1 = pd.merge(tbl_PPM_ICD_diagnoses[['EncounterNumber', 'DiagnosisCode']], tbl_PPM_Encounter[['PatientNumber', 'EncounterNumber', 'Hospital', 'AttendingConsultant', 'AttendingConsultantSpecialty', 'StartDateTime', 'Extra:MRN', 'Extra:AUID', 'EndDateTime', 'Extra:WIP']], how='right', on=['EncounterNumber'], suffixes=('', '_drop'))
    df_query1 = pd.merge(
        tbl_PPM_ICD_diagnoses[["EncounterNumber", "DiagnosisCode", "SE_CBK_SK"]],
        tbl_PPM_Encounter[
            [
                "PatientNumber",
                "EncounterNumber",
                "Hospital",
                "AttendingConsultant",
                "AttendingConsultantSpecialty",
                "StartDateTime",
                "Extra:MRN",
                "Extra:AUID",
                "EndDateTime",
                "Extra:WIP",
                "Extra:SE_CBK_SK",
            ]
        ],
        how="right",
        left_on=["SE_CBK_SK"],
        right_on=["Extra:SE_CBK_SK"],
        suffixes=("", "_drop"),
    )
    df_query1 = df_query1[
        [
            "PatientNumber",
            "EncounterNumber",
            "Hospital",
            "AttendingConsultant",
            "AttendingConsultantSpecialty",
            "StartDateTime",
            "Extra:MRN",
            "Extra:AUID",
            "EndDateTime",
            "Extra:WIP",
            "Extra:SE_CBK_SK",
            "DiagnosisCode",
        ]
    ]
    # df_query1 = df_query1.apply(lambda x: x.replace(regex=r'^nan$', value='') if x.dtype == 'object' else x)
    df_query1.drop_duplicates(keep="last", inplace=True)
    # 11 Jan 2024 - CREATED FACILITY CHANGE
    # obsetEpi = pd.merge(tbl_PPM_ICD_procedures[['EncounterNumber', 'ProcedureCode', 'ProcedureDateTime']], df_query1, how='right', on=['EncounterNumber'], suffixes=('', '_drop'))
    obsetEpi = pd.merge(
        tbl_PPM_ICD_procedures[
            ["EncounterNumber", "ProcedureCode", "ProcedureDateTime", "SE_CBK_SK"]
        ],
        df_query1,
        how="right",
        left_on=["SE_CBK_SK"],
        right_on=["Extra:SE_CBK_SK"],
        suffixes=("", "_drop"),
    )
    obsetEpi = obsetEpi[
        [
            "PatientNumber",
            "EncounterNumber",
            "Hospital",
            "AttendingConsultant",
            "AttendingConsultantSpecialty",
            "StartDateTime",
            "Extra:MRN",
            "Extra:AUID",
            "EndDateTime",
            "Extra:WIP",
            "DiagnosisCode",
            "ProcedureCode",
            "ProcedureDateTime",
        ]
    ]
    obsetEpi = obsetEpi.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    obsetEpi["Extra:WIP"] = obsetEpi["Extra:WIP"].astype(str)
    obsetEpi["DiagnosisCode"] = obsetEpi["DiagnosisCode"].astype(str)
    obsetEpi["ProcedureCode"] = obsetEpi["ProcedureCode"].astype(str)
    # new access update query does not check diagnosis code
    # Lai-Mun on 11/10/2023 on Teams - The Extraction Team - We deliver channel - "The Obstet should be RESTRICTED by diagnosis please. "
    obsetEpi = obsetEpi[
        (
            (obsetEpi.DiagnosisCode.astype(str).str.startswith(("Z37")) == True)
            & (obsetEpi.ProcedureCode.astype(str).str.startswith(("92506")) == True)
            & (obsetEpi["Extra:WIP"].isin(["4", "2"]))
        )
        | (
            (obsetEpi.DiagnosisCode.astype(str).str.startswith(("Z37")) == True)
            & (obsetEpi.ProcedureCode.astype(str).str.startswith(("92507")) == True)
            & (obsetEpi["Extra:WIP"].isin(["4", "2"]))
        )
        | (
            (obsetEpi.DiagnosisCode.astype(str).str.startswith(("Z37")) == True)
            & (obsetEpi.ProcedureCode.astype(str).str.startswith(("92508")) == True)
            & (obsetEpi["Extra:WIP"].isin(["4", "2"]))
        )
    ]
    """
    obsetEpi = obsetEpi[((obsetEpi.ProcedureCode.astype(str).str.startswith(('92506'))==True) & (obsetEpi['Extra:WIP'].isin(['4', '2']) )) | \
    ((obsetEpi.ProcedureCode.astype(str).str.startswith(('92507'))==True) & (obsetEpi['Extra:WIP'].isin(['4', '2']) ))  | \
    ((obsetEpi.ProcedureCode.astype(str).str.startswith(('92508'))==True) & (obsetEpi['Extra:WIP'].isin(['4', '2']) )) ]
    """
    obsetEpi["Extra:MRN"] = (
        obsetEpi["Extra:MRN"].astype(str).str.pad(10, side="left", fillchar="0")
    )
    obsetEpi["Extra:AUID"] = (
        obsetEpi["Extra:AUID"].astype(str).str.pad(10, side="left", fillchar="0")
    )
    obsetEpi = obsetEpi[
        [
            "PatientNumber",
            "EncounterNumber",
            "Hospital",
            "AttendingConsultant",
            "AttendingConsultantSpecialty",
            "StartDateTime",
            "Extra:MRN",
            "Extra:AUID",
            "DiagnosisCode",
            "ProcedureCode",
            "ProcedureDateTime",
            "EndDateTime",
        ]
    ]
    # obsetEpi['ProcedureDateTime'] = obsetEpi['ProcedureDateTime'].dt.strftime("%d/%m/%Y")
    obsetEpi = obsetEpi.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    obsetEpi = obsetEpi.applymap(lambda x: x.strip() if isinstance(x, str) else x)
    obsetEpi = obsetEpi.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    obsetEpi.drop_duplicates(keep="last", inplace=True)
    # https://abft101.atlassian.net/browse/AQA-348
    # obsetEpi=clear_neg_one(obsetEpi)
    try:
        obsetEpi.to_csv(
            "./Output/Tbl_ppm_ObstetEpi.txt",
            sep=",",
            index=False,
            na_rep="",
            float_format=str,
            decimal=str,
            date_format=str,
        )
    except Exception as e:
        logging.exception("Exception occurred")
        label_4_status = 0
        messagebox.showerror("Export Error", "Error exporting ObsetEpi\n" + str(e))
        label_4_sub.configure(text="Failed (ObsetEpi)...", fg="red")
        main_screen.update()
        return  # stop export
    # Update Sub task status
    if label_4_status == 0:
        label_4_sub.configure(text="Failed", fg="red")
        main_screen.update()
    else:
        logging.info(
            "Export Procedure Data completed. %s records written to ./Output/tbl_PPM_ICD_procedures_%s.csv",
            len(tbl_PPM_ICD_procedures),
            versionID_hash,
        )
        label_4_sub.configure(text="Completed", fg="green")
        main_screen.update()
    main_screen.update()
    logging.info(
        "Export Procedure Data completed. %s records written to ./Output/ObstetEpi.txt",
        len(obsetEpi),
    )
    ############### "5. Export Transfer Data"#################
    # Set default value of sub-task status to 1
    label_5_status = 1
    label_5_sub.configure(text="In Progress (Transfer)...", fg="blue")
    main_screen.update()
    # download OutputDaysEpisode
    file_OutputDaysEpisode = "./ExtractorDB/OutputDaysEpisode.csv"
    if os.path.isfile(file_OutputDaysEpisode):
        try:
            tbl_dbo_days_episode = read_csv_file(
                file_OutputDaysEpisode,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_dbo_days_episode from ./ExtractorDB/OutputDaysEpisode.csv.\n"
                + str(e),
            )
            label_5_sub.configure(text="Failed (tbl_dbo_days_episode)...", fg="red")
            label_5_status = 0
            return
        else:
            tbl_dbo_days_episode = tbl_dbo_days_episode.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_dbo_days_episode = tbl_dbo_days_episode.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_dbo_days_episode = tbl_dbo_days_episode.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_days_episode = tbl_dbo_days_episode.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_days_episode = tbl_dbo_days_episode[
                tbl_dbo_days_episode["facility_identifier"].isin(
                    facilities_included_list_global
                )
            ]
    else:
        tbl_dbo_days_episode = pd.DataFrame()
    # download OutputEpisodeAts
    file_OutputEpisodeAts = "./ExtractorDB/OutputEpisodeAts.csv"
    if os.path.isfile(file_OutputEpisodeAts):
        try:
            tbl_dbo_episode_ats = read_csv_file(
                file_OutputEpisodeAts,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_dbo_episode_ats from ./ExtractorDB/OutputEpisodeAts.csv.\n"
                + str(e),
            )
            label_5_sub.configure(text="Failed (tbl_dbo_episode_ats)...", fg="red")
            label_5_status = 0
            return
        else:
            tbl_dbo_episode_ats = tbl_dbo_episode_ats.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_dbo_episode_ats = tbl_dbo_episode_ats.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_dbo_episode_ats = tbl_dbo_episode_ats.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_episode_ats = tbl_dbo_episode_ats.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_episode_ats = tbl_dbo_episode_ats[
                tbl_dbo_episode_ats["facility_identifier"].isin(
                    facilities_included_list_global
                )
            ]
    else:
        tbl_dbo_episode_ats = pd.DataFrame()
    # download snapApp_CostingExtract
    file_snapApp_CostingExtract = "./ExtractorDB/snapApp_CostingExtract.csv"
    if os.path.isfile(file_snapApp_CostingExtract):
        try:
            snapApp_CostingExtract = read_csv_file(
                file_snapApp_CostingExtract,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            label_5_status = 0
            messagebox.showerror(
                "File Error",
                "Error extracting snapApp_CostingExtract from ./ExtractorDB/snapApp_CostingExtract.csv\n"
                + str(e),
            )
            label_5_sub.configure(text="Failed (snapApp_CostingExtract)...", fg="red")
            main_screen.update()
            return
        else:
            snapApp_CostingExtract = snapApp_CostingExtract.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            snapApp_CostingExtract = snapApp_CostingExtract.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            snapApp_CostingExtract = snapApp_CostingExtract.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            snapApp_CostingExtract = snapApp_CostingExtract.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
    else:
        snapApp_CostingExtract = pd.DataFrame()
    # download qrysnapApp_CostingExtract
    file_qrysnapApp_CostingExtract = "./ExtractorDB/qrysnapApp_CostingExtract.csv"
    if os.path.isfile(file_qrysnapApp_CostingExtract):
        try:
            qrysnapApp_CostingExtract = read_csv_file(
                file_qrysnapApp_CostingExtract,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            label_5_status = 0
            messagebox.showerror(
                "File Error",
                "Error extracting qrysnapApp_CostingExtract from ./ExtractorDB/qrysnapApp_CostingExtract.csv\n"
                + str(e),
            )
            label_5_sub.configure(
                text="Failed (qrysnapApp_CostingExtract)...", fg="red"
            )
            main_screen.update()
            return
        else:
            qrysnapApp_CostingExtract = qrysnapApp_CostingExtract.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            qrysnapApp_CostingExtract = qrysnapApp_CostingExtract.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            qrysnapApp_CostingExtract = qrysnapApp_CostingExtract.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            qrysnapApp_CostingExtract = qrysnapApp_CostingExtract.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
    else:
        qrysnapApp_CostingExtract = pd.DataFrame()
    # download tbl_ExcludedEncounters
    tbl_ExcludedEncounters_list = []
    file_tbl_ExcludedEncounters = "./ExtractorDB/tbl_ExcludedEncounters.csv"
    if os.path.isfile(file_tbl_ExcludedEncounters):
        try:
            tbl_ExcludedEncounters = read_csv_file(
                file_tbl_ExcludedEncounters,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            label_5_status = 0
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_ExcludedEncounters from ./ExtractorDB/tbl_ExcludedEncounters.csv.\n"
                + str(e),
            )
            label_5_sub.configure(text="Failed (tbl_ExcludedEncounters)...", fg="red")
            main_screen.update()
            return
        else:
            tbl_ExcludedEncounters = tbl_ExcludedEncounters[
                [
                    "facility_identifier",
                    "stay_number",
                    "episode_sequence_number",
                    "ed_identifier",
                    "SNAP_encounter",
                    "ReasonForExclusion",
                    "EncounterNumber",
                ]
            ]
            tbl_ExcludedEncounters_list = tbl_ExcludedEncounters[
                "EncounterNumber"
            ].tolist()
    else:
        tbl_ExcludedEncounters = pd.DataFrame()
    # download tbl_Patient_Contact_Details
    if (
        lhd_global == "X830"
        or lhd_global == "X840"
        or lhd_global == "X850"
        or lhd_global == "X860"
        or lhd_global == "X740"
    ):
        file_tbl_Patient_Contact_Details = "./ExtractorDB/OutputPatient.csv"
    else:
        file_tbl_Patient_Contact_Details = "./ExtractorDB/Patient_contact_details.csv"
    if os.path.isfile(file_tbl_Patient_Contact_Details):
        try:
            tbl_Patient_Contact_Details = read_csv_file(
                file_tbl_Patient_Contact_Details,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            label_5_status = 0
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_Patient_Contact_Details from "
                + file_tbl_Patient_Contact_Details
                + ".\n"
                + str(e),
            )
            label_5_sub.configure(
                text="Failed (tbl_Patient_Contact_Details)...", fg="red"
            )
            main_screen.update()
            return
        else:
            tbl_Patient_Contact_Details = tbl_Patient_Contact_Details.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_Patient_Contact_Details = tbl_Patient_Contact_Details.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_Patient_Contact_Details = tbl_Patient_Contact_Details.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_Patient_Contact_Details = tbl_Patient_Contact_Details.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
            # tbl_Patient_Contact_Details = tbl_Patient_Contact_Details[['facility_identifier' ,'area_identifier', 'person_area_uid', 'AUID', 'contact_identifier', 'mrn']]
    else:
        tbl_Patient_Contact_Details = pd.DataFrame()
    # download tbl_PPM_transfer_AMO
    file_tbl_PPM_transfer_AMO = "./Output/Tbl_PPM_transfer_AMO.csv"
    if os.path.isfile(file_tbl_PPM_transfer_AMO):
        try:
            tbl_PPM_transfer_AMO = read_csv_file(
                file_tbl_PPM_transfer_AMO,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            label_5_status = 0
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_PPM_transfer_AMO from ./Output/Tbl_PPM_transfer_AMO.csv.\n"
                + str(e),
            )
            label_5_sub.configure(text="Failed (tbl_PPM_transfer_AMO)...", fg="red")
            main_screen.update()
            return
        else:
            tbl_PPM_transfer_AMO = tbl_PPM_transfer_AMO.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_PPM_transfer_AMO = tbl_PPM_transfer_AMO.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_PPM_transfer_AMO = tbl_PPM_transfer_AMO.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_PPM_transfer_AMO = tbl_PPM_transfer_AMO.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
            # tbl_PPM_transfer_AMO = tbl_PPM_transfer_AMO[['facility_identifier', 'mo_code', 'Code', 'clinician_name', 'Consultant_Status', 'LHD']]
            tbl_PPM_transfer_AMO = tbl_PPM_transfer_AMO[
                [
                    "facility_identifier",
                    "mo_code",
                    "Code",
                    "clinician_name",
                    "Consultant_Status",
                    "LHD",
                    "HLTH_ORG_OSP_OSP_ID",
                    "MG_AUTH_OSP_OSP_ID",
                    "SE_CBK_SK",
                    "DIM_RSP_ISP_SK",
                ]
            ]
    else:
        tbl_PPM_transfer_AMO = pd.DataFrame()
    # download IntrerupCare - OBSOLETE
    """
    file_IntrerupCare = "./ExtractorDB/IntrerupCare.csv"
    if os.path.isfile(file_IntrerupCare):
        try:
            intrerupCare = read_csv_file(file_IntrerupCare, encoding = 'unicode_escape', dtype=str, keep_default_na=False, na_values='')
        except Exception as e:
            label_5_status = 0
            messagebox.showerror("File Error","Error extracting intrerupCare from ./ExtractorDB/IntrerupCare.csv.\n"+str(e))
            label_5_sub.configure(text="Failed (intrerupCare)...",fg='red')
            main_screen.update()
            return     
    else:
        intrerupCare = pd.DataFrame()   
    """
    #######################################
    tbl_dbo_episode_ats["episode_start_date"] = (
        tbl_dbo_episode_ats["episode_start_date"].astype(str).str[:10]
    )
    tbl_dbo_episode_ats["episode_start_time"] = (
        tbl_dbo_episode_ats["episode_start_time"].astype(str).str[-8:]
    )
    tbl_dbo_episode_ats["episode_end_date"] = (
        tbl_dbo_episode_ats["episode_end_date"].astype(str).str[:10]
    )
    tbl_dbo_episode_ats["episode_end_time"] = (
        tbl_dbo_episode_ats["episode_end_time"].astype(str).str[-8:]
    )
    tbl_dbo_episode_ats["stay_number"] = (
        tbl_dbo_episode_ats["stay_number"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0")
    )
    tbl_dbo_episode_ats["episode_sequence_number"] = (
        tbl_dbo_episode_ats["episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    tbl_dbo_days_episode["start_date"] = (
        tbl_dbo_days_episode["start_date"].astype(str).str[:10]
    )
    tbl_dbo_days_episode["start_time"] = (
        tbl_dbo_days_episode["start_time"].astype(str).str[-8:]
    )
    tbl_dbo_days_episode["end_date"] = (
        tbl_dbo_days_episode["end_date"].astype(str).str[:10]
    )
    tbl_dbo_days_episode["end_time"] = (
        tbl_dbo_days_episode["end_time"].astype(str).str[-8:]
    )
    tbl_dbo_days_episode["stay_number"] = (
        tbl_dbo_days_episode["stay_number"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0")
    )
    tbl_dbo_days_episode["episode_sequence_number"] = (
        tbl_dbo_days_episode["episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    tbl_Patient_Contact_Details["contact_identifier"] = (
        tbl_Patient_Contact_Details["contact_identifier"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0")
    )
    snapApp_CostingExtract["stay_number_cost"] = (
        snapApp_CostingExtract["stay_number_cost"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0")
    )
    snapApp_CostingExtract["sa_episode_sequence_number"] = (
        snapApp_CostingExtract["sa_episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    qrysnapApp_CostingExtract["stay_number_cost"] = (
        qrysnapApp_CostingExtract["stay_number_cost"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0")
    )
    qrysnapApp_CostingExtract["sa_episode_sequence_number"] = (
        qrysnapApp_CostingExtract["sa_episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    ########################################
    if (
        lhd_global == "X830"
        or lhd_global == "X840"
        or lhd_global == "X850"
        or lhd_global == "X860"
        or lhd_global == "X740"
        or lhd_global == "X170"
    ):
        """  Appends data to the tbl_PPM_transfer based on data in the tbl_dbo_episode_ats, tbl_dbo_days_episode where the encounters are not in the qrysnapApp_CostingExtract (?why does it use qry not table)"""
        # Access query: Append_to_tbl_PPM_transfer_AUID
        # cannot open query
        # INSERT INTO tbl_PPM_transfer ( Clinic, EncounterNumber, PatientNumber, StartDateTime, Ward, AttendingConsultant_Code, AttendingConsultant_SpecialtyCode, BedNumber, Unit, Leave )
        # SELECT Trim([tbl_dbo_DAYS_EPISODE]![facility_identifier] & "-" & [tbl_dbo_DAYS_EPISODE]![specialty_unit_code]) AS Expr1,
        # [tbl_dbo_episode_ats]![facility_identifier] & "-" & "I" & "-" & Format$([tbl_dbo_episode_ats]![stay_number],"00000000") & "-" & IIf(Len([tbl_dbo_episode_ats]![episode_sequence_number])=3,[tbl_dbo_episode_ats]![episode_sequence_number],IIf(Len([tbl_dbo_episode_ats]![episode_sequence_number])=2,"0" & [tbl_dbo_episode_ats]![episode_sequence_number],"00" & [tbl_dbo_episode_ats]![episode_sequence_number])) AS Expr2,
        # [tbl_dbo_episode_ats]![facility_identifier] & "-" & IIf([tbl_Patient_Contact_Details]![AUID] Is Not Null,[tbl_Patient_Contact_Details]![AUID],Right([tbl_dbo_episode_ats]![mrn],10)) AS Expr7,
        # Format([tbl_dbo_days_episode]![start_date] & " " & [tbl_dbo_days_episode]![start_time],"yyyy-mm-dd hh:nn:ss") AS Expr3,
        # IIf(Trim([tbl_dbo_DAYS_EPISODE]![ward_identifier])="MATERNITY-",[tbl_dbo_DAYS_EPISODE]![facility_identifier] & "-" & Left([tbl_dbo_DAYS_EPISODE]![ward_identifier],9),[tbl_dbo_DAYS_EPISODE]![facility_identifier] & "-" & Trim([tbl_dbo_DAYS_EPISODE]![ward_identifier])) AS Expr4,
        # Max([tbl_dbo_EPISODE_ATS]![facility_identifier] & "-" & Trim([tbl_dbo_DAYS_Episode]![mo_code])) AS Expr5,
        # tbl_PPM_transfer_AMO.Consultant_Status as AttendingConsultant_SpecialtyCode,
        # tbl_dbo_days_episode.local_bed_identifier,
        # tbl_dbo_days_episode.unit_type, IIf(tbl_dbo_days_episode.leave_type In ("L","H","O","T"),"T","F") AS Expr8
        # FROM ((((tbl_dbo_episode_ats INNER JOIN tbl_dbo_days_episode ON (tbl_dbo_episode_ats.episode_sequence_number = tbl_dbo_days_episode.episode_sequence_number) AND (tbl_dbo_episode_ats.stay_number = tbl_dbo_days_episode.stay_number) AND (tbl_dbo_episode_ats.facility_identifier = tbl_dbo_days_episode.facility_identifier))
        # LEFT JOIN tbl_PPM_transfer_AMO ON (tbl_dbo_days_episode.mo_code = tbl_PPM_transfer_AMO.mo_code) AND (tbl_dbo_days_episode.facility_identifier = tbl_PPM_transfer_AMO.facility_identifier))
        # LEFT JOIN qrysnapApp_CostingExtract ON (qrysnapApp_CostingExtract.FacilityCode = tbl_dbo_episode_ats.facility_identifier) AND (qrysnapApp_CostingExtract.stay_number_cost = tbl_dbo_episode_ats.stay_number) AND (qrysnapApp_CostingExtract.sa_episode_sequence_number = tbl_dbo_episode_ats.episode_sequence_number))
        # LEFT JOIN tbl_Patient_Contact_Details ON (tbl_dbo_episode_ats.facility_identifier = tbl_Patient_Contact_Details.facility_identifier) AND (tbl_dbo_episode_ats.stay_number = tbl_Patient_Contact_Details.contact_identifier))
        # LEFT JOIN IntrerupCare ON IntrerupCare.facility_identifier = tbl_dbo_episode_ats.facility_identifier AND IntrerupCare.stay_number = tbl_dbo_episode_ats.stay_number AND IntrerupCare.episode_sequence_number = tbl_dbo_episode_ats.episode_sequence_number
        # WHERE (((tbl_dbo_days_episode.start_date)<=[Forms]![Frm:1-ExtractSetUp]![End_Date]) AND ((tbl_dbo_days_episode.end_date)>=[Forms]![Frm:1-ExtractSetUp]![Start_Date] Or (tbl_dbo_days_episode.end_date) Is Null)) OR (((tbl_dbo_days_episode.start_date)<=[Forms]![Frm:1-ExtractSetUp]![End_Date]) AND ((tbl_dbo_days_episode.end_date)>=[Forms]![Frm:1-ExtractSetUp]![Start_Date] Or (tbl_dbo_days_episode.end_date) Is Null))
        # GROUP BY Trim([tbl_dbo_DAYS_EPISODE]![facility_identifier] & "-" & [tbl_dbo_DAYS_EPISODE]![specialty_unit_code]),
        # [tbl_dbo_episode_ats]![facility_identifier] & "-" & "I" & "-" & Format$([tbl_dbo_episode_ats]![stay_number],"00000000") & "-" & IIf(Len([tbl_dbo_episode_ats]![episode_sequence_number])=3,[tbl_dbo_episode_ats]![episode_sequence_number],IIf(Len([tbl_dbo_episode_ats]![episode_sequence_number])=2,"0" & [tbl_dbo_episode_ats]![episode_sequence_number],"00" & [tbl_dbo_episode_ats]![episode_sequence_number])),
        # [tbl_dbo_episode_ats]![facility_identifier] & "-" & IIf([tbl_Patient_Contact_Details]![AUID] Is Not Null,[tbl_Patient_Contact_Details]![AUID],Right([tbl_dbo_episode_ats]![mrn],10)),
        # Format([tbl_dbo_days_episode]![start_date] & " " & [tbl_dbo_days_episode]![start_time],"yyyy-mm-dd hh:nn:ss"),
        # IIf(Trim([tbl_dbo_DAYS_EPISODE]![ward_identifier])="MATERNITY-",[tbl_dbo_DAYS_EPISODE]![facility_identifier] & "-" & Left([tbl_dbo_DAYS_EPISODE]![ward_identifier],9),[tbl_dbo_DAYS_EPISODE]![facility_identifier] & "-" & Trim([tbl_dbo_DAYS_EPISODE]![ward_identifier])),
        # tbl_PPM_transfer_AMO.Consultant_Status,
        # tbl_dbo_days_episode.local_bed_identifier,
        # tbl_dbo_days_episode.unit_type, IIf(tbl_dbo_days_episode.leave_type In ("L","H","O","T"),"T","F"), qrysnapApp_CostingExtract.SNAPEpisodeID, IntrerupCare.facility_identifier
        # HAVING (((qrysnapApp_CostingExtract.SNAPEpisodeID) Is Null Or (qrysnapApp_CostingExtract.SNAPEpisodeID) Is Null AND (IntrerupCare.facility_identifier) Is Null));
        # Ranjit 28 June
        # df_query1 = pd.merge(tbl_dbo_episode_ats[['facility_identifier', 'stay_number', 'episode_sequence_number', 'mrn']], tbl_dbo_days_episode[['facility_identifier', 'stay_number', 'episode_sequence_number', 'specialty_unit_code', 'start_date', 'start_time', 'ward_identifier', 'mo_code', 'local_bed_identifier', 'unit_type', 'leave_type', 'end_date']], how='inner', on=['facility_identifier', 'stay_number', 'episode_sequence_number'], suffixes=('', '_drop'))
        df_query1 = pd.merge(
            tbl_dbo_episode_ats[
                [
                    "facility_identifier",
                    "stay_number",
                    "episode_sequence_number",
                    "mrn",
                    "HLTH_ORG_OSP_OSP_ID",
                    "MG_AUTH_OSP_OSP_ID",
                    "SE_CBK_SK",
                    "Responsible_Facility",
                ]
            ],
            tbl_dbo_days_episode[
                [
                    "facility_identifier",
                    "stay_number",
                    "episode_sequence_number",
                    "specialty_unit_code",
                    "start_date",
                    "start_time",
                    "ward_identifier",
                    "mo_code",
                    "local_bed_identifier",
                    "unit_type",
                    "leave_type",
                    "end_date",
                    "WARD_NM",
                    "BED_DESC",
                    "specialty_unit_code_desc",
                    "SINGLE_ROOM_IND_CD",
                    "DIM_RSP_ISP_SK",
                ]
            ],
            how="inner",
            on=["facility_identifier", "stay_number", "episode_sequence_number"],
            suffixes=("", "_drop"),
        )
        df_query1.drop_duplicates(keep="last", inplace=True)
        df_query1 = df_query1.apply(
            lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
        )
        df_query2 = pd.merge(
            df_query1,
            tbl_PPM_transfer_AMO[
                ["facility_identifier", "Consultant_Status", "mo_code"]
            ],
            how="left",
            left_on=["facility_identifier", "mo_code"],
            right_on=["facility_identifier", "mo_code"],
            suffixes=("", "_drop"),
        )
        df_query2 = df_query2.apply(
            lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
        )
        df_query2.drop_duplicates(keep="last", inplace=True)
        # 142 - 02 Feb 2025
        ####START#######
        """
        Sandra Thompson - 29 Jan 2025 , forwarded an email from Sharon Mc Farlane
        a.	We have discovered another issue with V1.14.  Because you changed the extractor to bring out the -1 in the transfer AMO table, if you have a doctor that is in the system with -1 and a correct one, the transfer table has duplicated all the records.  So one line for -1 doctor and one line for correct doctor.
        b.	It appears the only ones that populated the SE_CBK_SK in both SNSW and MLHD in the transfer_AMO table are the -1 new ones.  It did populate in August (whatever version that was).  The last three columns are all blank now.  It appears to be that if we populate the consultant status in the load file, it does not populate the last three columns.  We will test this theory and let you know.
        df_query2.drop_duplicates(subset=['A'], keep='last', inplace=True)
        """
        #
        # Sort the DataFrame based on columns 'A' and 'B'
        df_query2.sort_values(
            by=[
                "facility_identifier",
                "stay_number",
                "episode_sequence_number",
                "mrn",
                "HLTH_ORG_OSP_OSP_ID",
                "MG_AUTH_OSP_OSP_ID",
                "SE_CBK_SK",
                "specialty_unit_code",
                "start_date",
                "start_time",
                "ward_identifier",
                "mo_code",
                "local_bed_identifier",
                "unit_type",
                "leave_type",
                "end_date",
                "WARD_NM",
                "BED_DESC",
                "specialty_unit_code_desc",
                "SINGLE_ROOM_IND_CD",
                "Consultant_Status",
                "mo_code",
            ],
            inplace=True,
        )
        df_query2.drop_duplicates(
            subset=[
                "facility_identifier",
                "stay_number",
                "episode_sequence_number",
                "mrn",
                "HLTH_ORG_OSP_OSP_ID",
                "MG_AUTH_OSP_OSP_ID",
                "SE_CBK_SK",
                "specialty_unit_code",
                "start_date",
                "start_time",
                "ward_identifier",
                "mo_code",
                "local_bed_identifier",
                "unit_type",
                "leave_type",
                "end_date",
                "WARD_NM",
                "BED_DESC",
                "specialty_unit_code_desc",
                "SINGLE_ROOM_IND_CD",
                "mo_code",
            ],
            keep="last",
            inplace=True,
        )
        ####STOP#######
        df_query2["stay_number"] = df_query2["stay_number"].astype(str).str.strip()
        df_query2["episode_sequence_number"] = (
            df_query2["episode_sequence_number"].astype(str).str.strip()
        )
        df_query2["stay_number"] = (
            df_query2["stay_number"].astype(str).str.pad(8, side="left", fillchar="0")
        )
        df_query2["episode_sequence_number"] = (
            df_query2["episode_sequence_number"]
            .astype(str)
            .str.pad(3, side="left", fillchar="0")
        )
        # 11 Jan 2024 - CREATED FACILITY CHANGE
        # df_query3 = pd.merge(df_query2, qrysnapApp_CostingExtract[['FacilityCode', 'stay_number_cost', 'sa_episode_sequence_number']], how='left', left_on=['facility_identifier', 'stay_number', 'episode_sequence_number'], right_on=['FacilityCode', 'stay_number_cost', 'sa_episode_sequence_number'], suffixes=('', '_drop'), indicator=True)
        df_query3 = pd.merge(
            df_query2,
            qrysnapApp_CostingExtract[
                [
                    "FacilityCode",
                    "stay_number_cost",
                    "sa_episode_sequence_number",
                    "SE_CBK_SK",
                ]
            ],
            how="left",
            on=["SE_CBK_SK"],
            suffixes=("", "_drop"),
            indicator=True,
        )
        df_query3 = df_query3.apply(
            lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
        )
        df_query3.drop_duplicates(keep="last", inplace=True)
        # NOT in qrysnapApp_CostingExtract
        df_query3 = df_query3[df_query3["_merge"] == "left_only"]
        df_query3.drop(["_merge"], axis=1, inplace=True, errors="ignore")
        # InterupCare is obsolete
        # df_query4 = pd.merge(df_query3, tbl_Patient_Contact_Details[['facility_identifier', 'contact_identifier', 'AUID']], how='left', left_on=['facility_identifier', 'stay_number'], right_on=['facility_identifier', 'contact_identifier'], suffixes=('', '_drop'))
        # df_query5 = pd.merge(df_query4, intrerupCare[['facility_identifier', 'stay_number', 'episode_sequence_number']], how='left', on=['facility_identifier', 'stay_number', 'episode_sequence_number'], suffixes=('', '_drop'))
        # 11 Jan 2024 - CREATED FACILITY CHANGE
        # df_query5 = pd.merge(df_query3, tbl_Patient_Contact_Details[['facility_identifier', 'contact_identifier', 'AUID']], how='left', left_on=['facility_identifier', 'stay_number'], right_on=['facility_identifier', 'contact_identifier'], suffixes=('', '_drop'))
        df_query5 = pd.merge(
            df_query3,
            tbl_Patient_Contact_Details[
                ["facility_identifier", "contact_identifier", "AUID", "SE_CBK_SK"]
            ],
            how="left",
            left_on=["SE_CBK_SK", "stay_number"],
            right_on=["SE_CBK_SK", "contact_identifier"],
            suffixes=("", "_drop"),
        )
        df_query5.drop_duplicates(keep="last", inplace=True)
        df_query5 = df_query5.apply(
            lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
        )
        # end_date_dt = pd.to_datetime(end_date, format="%Y-%m-%d %H:%M:%S")
        # start_date_dt = pd.to_datetime(start_date, format="%Y-%m-%d %H:%M:%S")
        df_query5["end_date_dt"] = pd.to_datetime(end_date, format="%Y-%m-%d %H:%M:%S")
        df_query5["start_date_dt"] = pd.to_datetime(
            start_date, format="%Y-%m-%d %H:%M:%S"
        )
        # df_query5['start_date'] = pd.to_datetime(df_query5['start_date'], errors='coerce', format="%Y-%m-%d")
        # df_query5['end_date'] = pd.to_datetime(df_query5['end_date'], errors='coerce', format="%Y-%m-%d")
        # df_query5= df_query5[(df_query5['start_date'] <= df_query5['end_date_dt']) & ((df_query5['end_date'] >= start_date_dt) | (df_query5['end_date'].isnull()) | (df_query5['end_date']==''))]
        # Ranjit 11 Sep 2024 - End date 9999-12-31 in Days Episode causing below filter not to work and excluding some encounters https://abft101.atlassian.net/browse/AQA-139
        # therefore, I changed end_date to end_Date_dt
        # df_query5= df_query5[(pd.to_datetime(df_query5['start_date'].astype(str).str[:10], errors='coerce', format="%Y-%m-%d") <= df_query5['end_date_dt']) & ((pd.to_datetime(df_query5['end_date'].astype(str).str[:10], errors='coerce', format="%Y-%m-%d") >= df_query5['start_date_dt']) | (df_query5['end_date'].isnull()) | (df_query5['end_date']==''))]
        df_query5 = df_query5[
            (
                pd.to_datetime(
                    df_query5["start_date"].astype(str).str[:10],
                    errors="coerce",
                    format="%Y-%m-%d",
                )
                <= df_query5["end_date_dt"]
            )
            & (
                (
                    pd.to_datetime(
                        df_query5["end_date"].astype(str).str[:10],
                        errors="coerce",
                        format="%Y-%m-%d",
                    )
                    >= df_query5["start_date_dt"]
                )
                | (df_query5["end_date"].isnull())
                | (df_query5["end_date"] == "")
                | (df_query5["end_date"] == "9999-12-31")
            )
        ]
        df_query5["stay_number"] = df_query5["stay_number"].astype(str).str.strip()
        df_query5["episode_sequence_number"] = (
            df_query5["episode_sequence_number"].astype(str).str.strip()
        )
        df_query5["stay_number"] = (
            df_query5["stay_number"].astype(str).str.pad(8, side="left", fillchar="0")
        )
        df_query5["episode_sequence_number"] = (
            df_query5["episode_sequence_number"]
            .astype(str)
            .str.pad(3, side="left", fillchar="0")
        )
        df_query5["ward_identifier"] = (
            df_query5["ward_identifier"].astype(str).str.strip()
        )
        df_query5["mrn"] = df_query5["mrn"].astype(str).str.strip()
        df_query5["MRN_dummy"] = df_query5["mrn"].str[-10:]
        df_query5["MRN_dummy"] = np.where(
            df_query5["MRN_dummy"] == "",
            "",
            df_query5["MRN_dummy"].astype(str).str.pad(10, side="left", fillchar="0"),
        )
        df_query5["AUID"] = df_query5["AUID"].astype(str).str.strip()
        df_query5["AUID"] = df_query5["AUID"].astype(str).str.replace("nan", "")
        df_query5["AUID"] = np.where(
            df_query5["AUID"] == "",
            "",
            df_query5["AUID"].astype(str).str.pad(10, side="left", fillchar="0"),
        )
        df_query5["dummy_mrn_auid"] = np.where(
            (df_query5["AUID"] != ""), df_query5["AUID"], df_query5["MRN_dummy"]
        )
        df_query5["Clinic"] = (
            df_query5["facility_identifier"].astype(str).str.strip()
            + "-"
            + df_query5["specialty_unit_code"]
        )
        df_query5["EncounterNumber"] = (
            df_query5["facility_identifier"].astype(str).str.strip()
            + "-I-"
            + df_query5["stay_number"]
            + "-"
            + df_query5["episode_sequence_number"]
        )
        df_query5["PatientNumber"] = (
            df_query5["facility_identifier"].astype(str).str.strip()
            + "-"
            + df_query5["dummy_mrn_auid"].astype(str).str.strip()
        )
        df_query5["StartDateTime"] = (
            df_query5["start_date"].astype(str).str[:10]
            + " "
            + df_query5["start_time"].astype(str).str[-8:]
        )
        df_query5["StartDateTime"] = pd.to_datetime(
            df_query5["StartDateTime"], errors="coerce", format="%Y-%m-%d %H:%M:%S"
        )
        df_query5["Ward"] = np.where(
            df_query5["ward_identifier"].astype(str).str.strip() == "MATERNITY-",
            df_query5["facility_identifier"].astype(str).str.strip()
            + "-"
            + df_query5["ward_identifier"].str[:9],
            df_query5["facility_identifier"].astype(str).str.strip()
            + "-"
            + df_query5["ward_identifier"],
        )
        df_query5["AttendingConsultant_SpecialtyCode"] = df_query5["Consultant_Status"]
        df_query5["BedNumber"] = df_query5["local_bed_identifier"]
        df_query5["Unit"] = df_query5["unit_type"]
        df_query5["Leave"] = np.where(
            df_query5["leave_type"].isin(["L", "H", "O", "T"]), "T", "F"
        )
        df_query5["mo_code"] = np.where(
            df_query5["mo_code"] == "nan", "", df_query5["mo_code"]
        )
        df_query5["AttendingConsultant_Code_dummy"] = np.where(
            (df_query5["mo_code"] == "") | (df_query5["mo_code"].isnull()),
            "",
            df_query5["facility_identifier"].astype(str).str.strip()
            + "-"
            + df_query5["mo_code"].astype(str).str.strip(),
        )
        df_query5["Extra:HLTH_ORG_OSP_OSP_ID"] = df_query5["HLTH_ORG_OSP_OSP_ID"]
        df_query5["Extra:MG_AUTH_OSP_OSP_ID"] = df_query5["MG_AUTH_OSP_OSP_ID"]
        df_query5["Extra:SE_CBK_SK"] = df_query5["SE_CBK_SK"]
        df_query5["Extra:single_room_flag"] = df_query5["SINGLE_ROOM_IND_CD"]
        df_query5["Extra:Ward_NM"] = df_query5["WARD_NM"]
        df_query5["Extra:Bed_Desc"] = df_query5["BED_DESC"]
        df_query5["Extra:specialty_unit_code_desc"] = df_query5[
            "specialty_unit_code_desc"
        ]
        df_query5["Extra:DIM_RSP_ISP_SK"] = df_query5["DIM_RSP_ISP_SK"]
        df_query5["Extra:Responsible_Facility"] = df_query5["Responsible_Facility"]
        tbl_PPM_transfer = df_query5.copy()
        tbl_PPM_transfer.drop_duplicates(keep="last", inplace=True)
        # tbl_PPM_transfer = tbl_PPM_transfer[['Clinic', 'EncounterNumber', 'PatientNumber', 'StartDateTime', 'Ward', 'AttendingConsultant_Code_dummy', 'AttendingConsultant_SpecialtyCode', 'BedNumber', 'Unit', 'Leave']]
        tbl_PPM_transfer = tbl_PPM_transfer[
            [
                "Clinic",
                "EncounterNumber",
                "PatientNumber",
                "StartDateTime",
                "Ward",
                "AttendingConsultant_Code_dummy",
                "AttendingConsultant_SpecialtyCode",
                "BedNumber",
                "Unit",
                "Leave",
                "Extra:HLTH_ORG_OSP_OSP_ID",
                "Extra:MG_AUTH_OSP_OSP_ID",
                "Extra:SE_CBK_SK",
                "Extra:Ward_NM",
                "Extra:Bed_Desc",
                "Extra:specialty_unit_code_desc",
                "Extra:single_room_flag",
                "Extra:DIM_RSP_ISP_SK",
                "Extra:Responsible_Facility",
            ]
        ]
        # GROUP BY
        # tbl_PPM_transfer = tbl_PPM_transfer.groupby(['Clinic', 'EncounterNumber', 'PatientNumber', 'StartDateTime', 'Ward', 'AttendingConsultant_SpecialtyCode', 'BedNumber', 'Unit', 'Leave'], as_index=False, dropna=False).agg(AttendingConsultant_Code=("AttendingConsultant_Code_dummy", "max")).reset_index()
        # tbl_PPM_transfer = tbl_PPM_transfer[['Clinic', 'EncounterNumber', 'PatientNumber', 'StartDateTime', 'Ward', 'AttendingConsultant_Code', 'AttendingConsultant_SpecialtyCode', 'BedNumber', 'Unit', 'Leave']]
        tbl_PPM_transfer = (
            tbl_PPM_transfer.groupby(
                [
                    "Clinic",
                    "EncounterNumber",
                    "PatientNumber",
                    "StartDateTime",
                    "Ward",
                    "AttendingConsultant_SpecialtyCode",
                    "BedNumber",
                    "Unit",
                    "Leave",
                    "Extra:HLTH_ORG_OSP_OSP_ID",
                    "Extra:MG_AUTH_OSP_OSP_ID",
                    "Extra:SE_CBK_SK",
                    "Extra:Ward_NM",
                    "Extra:Bed_Desc",
                    "Extra:specialty_unit_code_desc",
                    "Extra:single_room_flag",
                    "Extra:DIM_RSP_ISP_SK",
                    "Extra:Responsible_Facility",
                ],
                as_index=False,
                dropna=False,
            )
            .agg(AttendingConsultant_Code=("AttendingConsultant_Code_dummy", "max"))
            .reset_index()
        )
        tbl_PPM_transfer = tbl_PPM_transfer[
            [
                "Clinic",
                "EncounterNumber",
                "PatientNumber",
                "StartDateTime",
                "Ward",
                "AttendingConsultant_Code",
                "AttendingConsultant_SpecialtyCode",
                "BedNumber",
                "Unit",
                "Leave",
                "Extra:HLTH_ORG_OSP_OSP_ID",
                "Extra:MG_AUTH_OSP_OSP_ID",
                "Extra:SE_CBK_SK",
                "Extra:Ward_NM",
                "Extra:Bed_Desc",
                "Extra:specialty_unit_code_desc",
                "Extra:single_room_flag",
                "Extra:DIM_RSP_ISP_SK",
                "Extra:Responsible_Facility",
            ]
        ]
        tbl_PPM_transfer.drop_duplicates(keep="last", inplace=True)
        logging.info(
            "Query: Append_to_tbl_PPM_transfer_AUID completed. tbl_PPM_transfer created with %s records.",
            len(tbl_PPM_transfer),
        )
    else:
        """ Appends data to the tbl_PPM_transfer based on data in the tbl_dbo_episode_ats, tbl_dbo_days_episode where the encounters are not in the qrysnapApp_CostingExtract (?why does it use qry not table) """
        # Access query: Append_to_tbl_PPM_transfer
        # INSERT INTO tbl_PPM_transfer ( Clinic, EncounterNumber, PatientNumber, StartDateTime, Ward, AttendingConsultant_Code, AttendingConsultant_SpecialtyCode, BedNumber, Unit, Leave )
        # SELECT Trim([tbl_dbo_DAYS_EPISODE]![facility_identifier] & "-" & [tbl_dbo_DAYS_EPISODE]![specialty_unit_code]) AS Expr1,
        # [tbl_dbo_episode_ats]![facility_identifier] & "-" & "I" & "-" & Format$([tbl_dbo_episode_ats]![stay_number],"00000000") & "-" & IIf(Len([tbl_dbo_episode_ats]![episode_sequence_number])=3,[tbl_dbo_episode_ats]![episode_sequence_number],IIf(Len([tbl_dbo_episode_ats]![episode_sequence_number])=2,"0" & [tbl_dbo_episode_ats]![episode_sequence_number],"00" & [tbl_dbo_episode_ats]![episode_sequence_number])) AS Expr2,
        # [tbl_dbo_EPISODE_ATS]![facility_identifier] & "-" & [tbl_dbo_episode_ats]![mrn] AS Expr7,
        # Format([tbl_dbo_DAYS_EPISODE]![start_date] & " " & [tbl_dbo_DAYS_EPISODE]![start_time],"yyyy-mm-dd hh:nn:ss") AS Expr3,
        # IIf(Trim([tbl_dbo_DAYS_EPISODE]![ward_identifier])="MATERNITY-",[tbl_dbo_DAYS_EPISODE]![facility_identifier] & "-" & Left([tbl_dbo_DAYS_EPISODE]![ward_identifier],9),[tbl_dbo_DAYS_EPISODE]![facility_identifier] & "-" & Trim([tbl_dbo_DAYS_EPISODE]![ward_identifier])) AS Expr4,
        # Max([tbl_dbo_EPISODE_ATS]![facility_identifier] & "-" & Trim([tbl_dbo_DAYS_Episode]![mo_code])) AS Expr5,
        # tbl_PPM_transfer_AMO.Consultant_Status as AttendingConsultant_SpecialtyCode,
        # tbl_dbo_days_episode.local_bed_identifier,
        # tbl_dbo_days_episode.unit_type, IIf(tbl_dbo_days_episode.leave_type In ("L","H","O","T"),"T","F") AS Expr8
        # FROM ((tbl_dbo_episode_ats LEFT JOIN tbl_dbo_days_episode ON (tbl_dbo_episode_ats.facility_identifier = tbl_dbo_days_episode.facility_identifier) AND (tbl_dbo_episode_ats.stay_number = tbl_dbo_days_episode.stay_number) AND (tbl_dbo_episode_ats.episode_sequence_number = tbl_dbo_days_episode.episode_sequence_number))
        # LEFT JOIN tbl_PPM_transfer_AMO ON (tbl_dbo_days_episode.facility_identifier = tbl_PPM_transfer_AMO.facility_identifier) AND (tbl_dbo_days_episode.mo_code = tbl_PPM_transfer_AMO.mo_code))
        # LEFT JOIN qrysnapApp_CostingExtract ON (qrysnapApp_CostingExtract.FacilityCode = tbl_dbo_episode_ats.facility_identifier) AND (qrysnapApp_CostingExtract.stay_number_cost = tbl_dbo_episode_ats.stay_number) AND (qrysnapApp_CostingExtract.sa_episode_sequence_number = tbl_dbo_episode_ats.episode_sequence_number)
        # WHERE (((tbl_dbo_days_episode.start_date)<=[Forms]![Frm:1-ExtractSetUp]![End_Date]) AND ((tbl_dbo_days_episode.end_date)>=[Forms]![Frm:1-ExtractSetUp]![Start_Date] Or (tbl_dbo_days_episode.end_date) Is Null)) OR (((tbl_dbo_days_episode.start_date)<=[Forms]![Frm:1-ExtractSetUp]![End_Date]) AND ((tbl_dbo_days_episode.end_date)>=[Forms]![Frm:1-ExtractSetUp]![Start_Date] Or (tbl_dbo_days_episode.end_date) Is Null))
        # GROUP BY Trim([tbl_dbo_DAYS_EPISODE]![facility_identifier] & "-" & [tbl_dbo_DAYS_EPISODE]![specialty_unit_code]),
        # [tbl_dbo_episode_ats]![facility_identifier] & "-" & "I" & "-" & Format$([tbl_dbo_episode_ats]![stay_number],"00000000") & "-" & IIf(Len([tbl_dbo_episode_ats]![episode_sequence_number])=3,[tbl_dbo_episode_ats]![episode_sequence_number],IIf(Len([tbl_dbo_episode_ats]![episode_sequence_number])=2,"0" & [tbl_dbo_episode_ats]![episode_sequence_number],"00" & [tbl_dbo_episode_ats]![episode_sequence_number])),
        # [tbl_dbo_EPISODE_ATS]![facility_identifier] & "-" & [tbl_dbo_episode_ats]![mrn],
        # Format([tbl_dbo_DAYS_EPISODE]![start_date] & " " & [tbl_dbo_DAYS_EPISODE]![start_time],"yyyy-mm-dd hh:nn:ss")
        # IIf(Trim([tbl_dbo_DAYS_EPISODE]![ward_identifier])="MATERNITY-",[tbl_dbo_DAYS_EPISODE]![facility_identifier] & "-" & Left([tbl_dbo_DAYS_EPISODE]![ward_identifier],9),[tbl_dbo_DAYS_EPISODE]![facility_identifier] & "-" & Trim([tbl_dbo_DAYS_EPISODE]![ward_identifier]))
        # tbl_PPM_transfer_AMO.Consultant_Status,
        # tbl_dbo_days_episode.local_bed_identifier,  tbl_dbo_days_episode.unit_type, IIf(tbl_dbo_days_episode.leave_type In ("L","H","O","T"),"T","F"),  tbl_dbo_episode_ats.episode_start_date, # tbl_dbo_episode_ats.episode_end_date, tbl_dbo_episode_ats.episode_of_care_type
        # HAVING (((tbl_dbo_episode_ats.episode_start_date)<=[Forms]![Frm:1-ExtractSetUp]![End_Date]) AND ((tbl_dbo_episode_ats.episode_end_date)>=[Forms]![Frm:1-ExtractSetUp]![Start_Date])) OR (((tbl_dbo_episode_ats.episode_start_date)<=[Forms]![Frm:1-ExtractSetUp]![End_Date]) AND ((tbl_dbo_episode_ats.episode_end_date) Is Null));
        # Note: also include qrysnapApp_CostingExtract.FacilityCode is Null in both clauses of HAVING.
        # Ranjit 28 June
        # df_query1 = pd.merge(tbl_dbo_episode_ats[['facility_identifier', 'stay_number', 'episode_sequence_number', 'mrn', 'episode_start_date', 'episode_end_date', 'episode_of_care_type']], tbl_dbo_days_episode[['facility_identifier', 'stay_number', 'episode_sequence_number', 'specialty_unit_code', 'start_date', 'start_time', 'ward_identifier', 'mo_code', 'local_bed_identifier', 'unit_type', 'leave_type', 'end_date']], how='left', on=['facility_identifier', 'stay_number', 'episode_sequence_number'], suffixes=('', '_drop'))
        df_query1 = pd.merge(
            tbl_dbo_episode_ats[
                [
                    "facility_identifier",
                    "stay_number",
                    "episode_sequence_number",
                    "mrn",
                    "episode_start_date",
                    "episode_end_date",
                    "episode_of_care_type",
                    "HLTH_ORG_OSP_OSP_ID",
                    "MG_AUTH_OSP_OSP_ID",
                    "SE_CBK_SK",
                    "Responsible_Facility",
                ]
            ],
            tbl_dbo_days_episode[
                [
                    "facility_identifier",
                    "stay_number",
                    "episode_sequence_number",
                    "specialty_unit_code",
                    "start_date",
                    "start_time",
                    "ward_identifier",
                    "mo_code",
                    "local_bed_identifier",
                    "unit_type",
                    "leave_type",
                    "end_date",
                    "WARD_NM",
                    "BED_DESC",
                    "specialty_unit_code_desc",
                    "SINGLE_ROOM_IND_CD",
                    "DIM_RSP_ISP_SK",
                ]
            ],
            how="left",
            on=["facility_identifier", "stay_number", "episode_sequence_number"],
            suffixes=("", "_drop"),
        )
        df_query1.drop_duplicates(keep="last", inplace=True)
        df_query1 = df_query1.apply(
            lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
        )
        df_query2 = pd.merge(
            df_query1,
            tbl_PPM_transfer_AMO[
                ["facility_identifier", "Consultant_Status", "mo_code"]
            ],
            how="left",
            left_on=["facility_identifier", "mo_code"],
            right_on=["facility_identifier", "mo_code"],
            suffixes=("", "_drop"),
        )
        df_query2 = df_query2.apply(
            lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
        )
        df_query2.drop_duplicates(keep="last", inplace=True)
        # 142 - 02 Feb 2025
        ####START#######
        """
        Sandra Thompson - 29 Jan 2025 , forwarded an email from Sharon Mc Farlane
        a.	We have discovered another issue with V1.14.  Because you changed the extractor to bring out the -1 in the transfer AMO table, if you have a doctor that is in the system with -1 and a correct one, the transfer table has duplicated all the records.  So one line for -1 doctor and one line for correct doctor.
        b.	It appears the only ones that populated the SE_CBK_SK in both SNSW and MLHD in the transfer_AMO table are the -1 new ones.  It did populate in August (whatever version that was).  The last three columns are all blank now.  It appears to be that if we populate the consultant status in the load file, it does not populate the last three columns.  We will test this theory and let you know.
        df_query2.drop_duplicates(subset=['A'], keep='last', inplace=True)
        """

        # Sort the DataFrame based on columns 'A' and 'B'
        df_query2.sort_values(
            by=[
                "facility_identifier",
                "stay_number",
                "episode_sequence_number",
                "mrn",
                "HLTH_ORG_OSP_OSP_ID",
                "MG_AUTH_OSP_OSP_ID",
                "SE_CBK_SK",
                "specialty_unit_code",
                "start_date",
                "start_time",
                "ward_identifier",
                "mo_code",
                "local_bed_identifier",
                "unit_type",
                "leave_type",
                "end_date",
                "WARD_NM",
                "BED_DESC",
                "specialty_unit_code_desc",
                "SINGLE_ROOM_IND_CD",
                "Consultant_Status",
                "mo_code",
            ],
            inplace=True,
        )
        df_query2.drop_duplicates(
            subset=[
                "facility_identifier",
                "stay_number",
                "episode_sequence_number",
                "mrn",
                "HLTH_ORG_OSP_OSP_ID",
                "MG_AUTH_OSP_OSP_ID",
                "SE_CBK_SK",
                "specialty_unit_code",
                "start_date",
                "start_time",
                "ward_identifier",
                "mo_code",
                "local_bed_identifier",
                "unit_type",
                "leave_type",
                "end_date",
                "WARD_NM",
                "BED_DESC",
                "specialty_unit_code_desc",
                "SINGLE_ROOM_IND_CD",
                "mo_code",
                "DIM_RSP_ISP_SK",
                "Responsible_Facility",
            ],
            keep="last",
            inplace=True,
        )
        ####STOP#######
        df_query2["stay_number"] = df_query2["stay_number"].astype(str).str.strip()
        df_query2["episode_sequence_number"] = (
            df_query2["episode_sequence_number"].astype(str).str.strip()
        )
        df_query2["stay_number"] = (
            df_query2["stay_number"].astype(str).str.pad(8, side="left", fillchar="0")
        )
        df_query2["episode_sequence_number"] = (
            df_query2["episode_sequence_number"]
            .astype(str)
            .str.pad(3, side="left", fillchar="0")
        )
        # 11 Jan 2024 - CREATED FACILITY CHANGE
        # df_query5 = pd.merge(df_query2, qrysnapApp_CostingExtract[['FacilityCode', 'stay_number_cost', 'sa_episode_sequence_number']], how='left', left_on=['facility_identifier', 'stay_number', 'episode_sequence_number'], right_on=['FacilityCode', 'stay_number_cost', 'sa_episode_sequence_number'], suffixes=('', '_drop'), indicator=True)
        df_query5 = pd.merge(
            df_query2,
            qrysnapApp_CostingExtract[
                [
                    "FacilityCode",
                    "stay_number_cost",
                    "sa_episode_sequence_number",
                    "SE_CBK_SK",
                ]
            ],
            how="left",
            on=["SE_CBK_SK"],
            suffixes=("", "_drop"),
            indicator=True,
        )
        df_query5 = df_query5.apply(
            lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
        )
        df_query5.drop_duplicates(keep="last", inplace=True)
        # NOT in qrysnapApp_CostingExtract
        df_query5 = df_query5[df_query5["_merge"] == "left_only"]
        df_query5.drop(["_merge"], axis=1, inplace=True, errors="ignore")
        df_query5["end_date_dt"] = pd.to_datetime(end_date, format="%Y-%m-%d %H:%M:%S")
        df_query5["start_date_dt"] = pd.to_datetime(
            start_date, format="%Y-%m-%d %H:%M:%S"
        )
        # df_query5['start_date'] = df_query5['start_date'], errors='coerce', format="%Y-%m-%d")
        # df_query5['end_date'] = pd.to_datetime(df_query5['end_date'], errors='coerce', format="%Y-%m-%d")
        # Ranjit 11 Sep 2024 - End date 9999-12-31 in Days Episode causing below filter not to work and excluding some encounters https://abft101.atlassian.net/browse/AQA-139
        # therefore, I changed end_date to end_Date_dt
        # df_query5= df_query5[(pd.to_datetime(df_query5['start_date'].astype(str).str[:10], errors='coerce', format="%Y-%m-%d") <= df_query5['end_date_dt']) & ((pd.to_datetime(df_query5['end_date'].astype(str).str[:10], errors='coerce', format="%Y-%m-%d") >= df_query5['start_date_dt']) | (df_query5['end_date'].isnull()) | (df_query5['end_date']==''))]
        df_query5 = df_query5[
            (
                pd.to_datetime(
                    df_query5["start_date"].astype(str).str[:10],
                    errors="coerce",
                    format="%Y-%m-%d",
                )
                <= df_query5["end_date_dt"]
            )
            & (
                (
                    pd.to_datetime(
                        df_query5["end_date"].astype(str).str[:10],
                        errors="coerce",
                        format="%Y-%m-%d",
                    )
                    >= df_query5["start_date_dt"]
                )
                | (df_query5["end_date"].isnull())
                | (df_query5["end_date"] == "")
                | (df_query5["end_date"] == "9999-12-31")
            )
        ]
        df_query5["stay_number"] = df_query5["stay_number"].astype(str).str.strip()
        df_query5["episode_sequence_number"] = (
            df_query5["episode_sequence_number"].astype(str).str.strip()
        )
        df_query5["stay_number"] = (
            df_query5["stay_number"].astype(str).str.pad(8, side="left", fillchar="0")
        )
        df_query5["episode_sequence_number"] = (
            df_query5["episode_sequence_number"]
            .astype(str)
            .str.pad(3, side="left", fillchar="0")
        )
        df_query5["ward_identifier"] = (
            df_query5["ward_identifier"].astype(str).str.strip()
        )
        df_query5["Clinic"] = (
            df_query5["facility_identifier"] + "-" + df_query5["specialty_unit_code"]
        )
        df_query5["EncounterNumber"] = (
            df_query5["facility_identifier"].astype(str).str.strip()
            + "-I-"
            + df_query5["stay_number"]
            + "-"
            + df_query5["episode_sequence_number"]
        )
        df_query5["mrn"] = df_query5["mrn"].astype(str).str.strip()
        df_query5["mrn_dummy"] = np.where(
            df_query5["mrn"] == "",
            "",
            df_query5["mrn"].astype(str).str.pad(10, side="left", fillchar="0"),
        )
        df_query5["PatientNumber"] = (
            df_query5["facility_identifier"].astype(str).str.strip()
            + "-"
            + df_query5["mrn_dummy"].astype(str).str.strip()
        )
        df_query5["StartDateTime"] = (
            df_query5["start_date"].astype(str).str[:10]
            + " "
            + df_query5["start_time"].astype(str).str[-8:]
        )
        df_query5["StartDateTime"] = pd.to_datetime(
            df_query5["StartDateTime"], errors="coerce", format="%Y-%m-%d %H:%M:%S"
        )
        df_query5["Ward"] = np.where(
            df_query5["ward_identifier"].astype(str).str.strip() == "MATERNITY-",
            df_query5["facility_identifier"].astype(str).str.strip()
            + "-"
            + df_query5["ward_identifier"].str[:9],
            df_query5["facility_identifier"].astype(str).str.strip()
            + "-"
            + df_query5["ward_identifier"],
        )
        df_query5["AttendingConsultant_SpecialtyCode"] = df_query5["Consultant_Status"]
        df_query5["BedNumber"] = df_query5["local_bed_identifier"]
        df_query5["Unit"] = df_query5["unit_type"]
        df_query5["Leave"] = np.where(
            df_query5["leave_type"].isin(["L", "H", "O", "T"]), "T", "F"
        )
        df_query5["mo_code"] = np.where(
            df_query5["mo_code"] == "nan", "", df_query5["mo_code"]
        )
        # df_query5['AttendingConsultant_Code_dummy'] =  df_query5['facility_identifier'].astype(str).str.strip() + "-" + df_query5['mo_code']
        df_query5["AttendingConsultant_Code_dummy"] = np.where(
            (df_query5["mo_code"] == "") | (df_query5["mo_code"].isnull()),
            "",
            df_query5["facility_identifier"].astype(str).str.strip()
            + "-"
            + df_query5["mo_code"].astype(str).str.strip(),
        )
        df_query5 = df_query5[
            (
                (
                    pd.to_datetime(
                        df_query5["episode_start_date"].astype(str).str[:10],
                        errors="coerce",
                        format="%Y-%m-%d",
                    )
                    <= df_query5["end_date_dt"]
                )
                & (
                    pd.to_datetime(
                        df_query5["episode_end_date"].astype(str).str[:10],
                        errors="coerce",
                        format="%Y-%m-%d",
                    )
                    >= df_query5["start_date_dt"]
                )
            )
            | (
                (
                    pd.to_datetime(
                        df_query5["episode_start_date"].astype(str).str[:10],
                        errors="coerce",
                        format="%Y-%m-%d",
                    )
                    <= df_query5["end_date_dt"]
                )
                & (
                    df_query5["episode_end_date"].isnull()
                    | (df_query5["episode_end_date"] == "")
                )
            )
        ]
        df_query5["Extra:HLTH_ORG_OSP_OSP_ID"] = df_query5["HLTH_ORG_OSP_OSP_ID"]
        df_query5["Extra:MG_AUTH_OSP_OSP_ID"] = df_query5["MG_AUTH_OSP_OSP_ID"]
        df_query5["Extra:SE_CBK_SK"] = df_query5["SE_CBK_SK"]
        df_query5["Extra:single_room_flag"] = df_query5["SINGLE_ROOM_IND_CD"]
        df_query5["Extra:Ward_NM"] = df_query5["WARD_NM"]
        df_query5["Extra:Bed_Desc"] = df_query5["BED_DESC"]
        df_query5["Extra:specialty_unit_code_desc"] = df_query5[
            "specialty_unit_code_desc"
        ]
        df_query5["Extra:DIM_RSP_ISP_SK"] = df_query5["DIM_RSP_ISP_SK"]
        df_query5["Extra:Responsible_Facility"] = df_query5["Responsible_Facility"]
        # df_query5['episode_start_date'] = pd.to_datetime(df_query5['episode_start_date'], errors='coerce', format="%Y-%m-%d")
        # df_query5['episode_end_date'] = pd.to_datetime(df_query5['episode_end_date'], errors='coerce', format="%Y-%m-%d")
        # df_query5 = df_query5[['Clinic', 'EncounterNumber', 'PatientNumber', 'StartDateTime', 'Ward', 'AttendingConsultant_Code_dummy', 'AttendingConsultant_SpecialtyCode', 'BedNumber', 'Unit', 'Leave', 'episode_start_date', 'episode_end_date', 'episode_of_care_type']]
        df_query5 = df_query5[
            [
                "Clinic",
                "EncounterNumber",
                "PatientNumber",
                "StartDateTime",
                "Ward",
                "AttendingConsultant_Code_dummy",
                "AttendingConsultant_SpecialtyCode",
                "BedNumber",
                "Unit",
                "Leave",
                "episode_start_date",
                "episode_end_date",
                "episode_of_care_type",
                "Extra:HLTH_ORG_OSP_OSP_ID",
                "Extra:MG_AUTH_OSP_OSP_ID",
                "Extra:SE_CBK_SK",
                "Extra:Ward_NM",
                "Extra:Bed_Desc",
                "Extra:specialty_unit_code_desc",
                "Extra:single_room_flag",
                "Extra:DIM_RSP_ISP_SK",
                "Extra:Responsible_Facility",
            ]
        ]
        tbl_PPM_transfer = df_query5.copy()
        # GROUP BY
        # tbl_PPM_transfer = tbl_PPM_transfer.groupby(['Clinic', 'EncounterNumber', 'PatientNumber', 'StartDateTime', 'Ward', 'AttendingConsultant_SpecialtyCode', 'BedNumber', 'Unit', 'Leave', 'episode_start_date', 'episode_end_date', 'episode_of_care_type'], as_index=False, dropna=False).agg(AttendingConsultant_Code=("AttendingConsultant_Code_dummy", "max")).reset_index()
        # tbl_PPM_transfer = tbl_PPM_transfer[['Clinic', 'EncounterNumber', 'PatientNumber', 'StartDateTime', 'Ward', 'AttendingConsultant_Code', 'AttendingConsultant_SpecialtyCode', 'BedNumber', 'Unit', 'Leave']]
        tbl_PPM_transfer = (
            tbl_PPM_transfer.groupby(
                [
                    "Clinic",
                    "EncounterNumber",
                    "PatientNumber",
                    "StartDateTime",
                    "Ward",
                    "AttendingConsultant_SpecialtyCode",
                    "BedNumber",
                    "Unit",
                    "Leave",
                    "episode_start_date",
                    "episode_end_date",
                    "episode_of_care_type",
                    "Extra:HLTH_ORG_OSP_OSP_ID",
                    "Extra:MG_AUTH_OSP_OSP_ID",
                    "Extra:SE_CBK_SK",
                    "Extra:Ward_NM",
                    "Extra:Bed_Desc",
                    "Extra:specialty_unit_code_desc",
                    "Extra:single_room_flag",
                    "Extra:DIM_RSP_ISP_SK",
                    "Extra:Responsible_Facility",
                ],
                as_index=False,
                dropna=False,
            )
            .agg(AttendingConsultant_Code=("AttendingConsultant_Code_dummy", "max"))
            .reset_index()
        )
        tbl_PPM_transfer = tbl_PPM_transfer[
            [
                "Clinic",
                "EncounterNumber",
                "PatientNumber",
                "StartDateTime",
                "Ward",
                "AttendingConsultant_Code",
                "AttendingConsultant_SpecialtyCode",
                "BedNumber",
                "Unit",
                "Leave",
                "Extra:HLTH_ORG_OSP_OSP_ID",
                "Extra:MG_AUTH_OSP_OSP_ID",
                "Extra:SE_CBK_SK",
                "Extra:Ward_NM",
                "Extra:Bed_Desc",
                "Extra:specialty_unit_code_desc",
                "Extra:single_room_flag",
                "Extra:DIM_RSP_ISP_SK",
                "Extra:Responsible_Facility",
            ]
        ]
        tbl_PPM_transfer.drop_duplicates(keep="last", inplace=True)
        logging.info(
            "Query: Append_to_tbl_PPM_transfer completed. tbl_PPM_transfer created with %s records.",
            len(tbl_PPM_transfer),
        )
    """  Appends data to the tbl_PPM_transfer based on data in the tbl_dbo_episode_ats, tbl_dbo_days_episode where the encounters are in the qrysnapApp_CostingExtract (?why does it use qry not table)"""
    # Access query: Append_to_tbl_PPM_transfer_SNAP_AUID
    # INSERT INTO tbl_PPM_transfer ( Clinic, EncounterNumber, PatientNumber, StartDateTime, Ward, AttendingConsultant_Code, AttendingConsultant_SpecialtyCode, BedNumber, Unit, Leave )
    # SELECT Trim([tbl_dbo_DAYS_EPISODE]![facility_identifier] & "-" & [tbl_dbo_DAYS_EPISODE]![specialty_unit_code]) AS Expr1, snapApp_CostingExtract.EncounterNumber, [tbl_dbo_days_episode]![facility_identifier] & "-" & Format(IIf([tbl_Patient_Contact_Details]![AUID] Is Not Null,[tbl_Patient_Contact_Details]![AUID],Right([snapApp_CostingExtract]![MRN],10)),"0000000000") AS Expr7, Format([tbl_dbo_days_episode]![start_date] & " " & [tbl_dbo_days_episode]![start_time],"yyyy-mm-dd hh:nn:ss") AS Expr3, IIf(Trim([tbl_dbo_DAYS_EPISODE]![ward_identifier])="MATERNITY-",[tbl_dbo_DAYS_EPISODE]![facility_identifier] & "-" & Left([tbl_dbo_DAYS_EPISODE]![ward_identifier],9),[tbl_dbo_DAYS_EPISODE]![facility_identifier] & "-" & Trim([tbl_dbo_DAYS_EPISODE]![ward_identifier])) AS Expr4, [tbl_dbo_days_episode]![facility_identifier] & "-" & Trim([tbl_dbo_DAYS_Episode]![mo_code]) AS Expr5, Max(tbl_PPM_transfer_AMO.Consultant_Status) AS MaxOfConsultant_Status, tbl_dbo_days_episode.local_bed_identifier, tbl_dbo_days_episode.unit_type, IIf([leave_type] In ("L","H","O","T"),"T","F") AS Expr8
    # FROM ((snapApp_CostingExtract LEFT JOIN tbl_Patient_Contact_Details ON (snapApp_CostingExtract.stay_number_cost = tbl_Patient_Contact_Details.contact_identifier) AND (snapApp_CostingExtract.FacilityCode = tbl_Patient_Contact_Details.facility_identifier)) INNER JOIN (tbl_dbo_days_episode LEFT JOIN tbl_PPM_transfer_AMO ON (tbl_dbo_days_episode.facility_identifier = tbl_PPM_transfer_AMO.facility_identifier) AND (tbl_dbo_days_episode.mo_code = tbl_PPM_transfer_AMO.mo_code)) ON (snapApp_CostingExtract.sa_episode_sequence_number = tbl_dbo_days_episode.episode_sequence_number) AND (snapApp_CostingExtract.stay_number_cost = tbl_dbo_days_episode.stay_number) AND (snapApp_CostingExtract.FacilityCode = tbl_dbo_days_episode.facility_identifier)) LEFT JOIN tbl_ExcludedEncounters ON snapApp_CostingExtract.EncounterNumber = tbl_ExcludedEncounters.SNAP_encounter
    # WHERE ((([start_date]+TimeValue([start_time])) Between DateValue([EncounterStart])+TimeValue([EncounterStart]) And IIf([EncounterEnd] Is Null,Now(),DateValue([EncounterEnd])+TimeValue([EncounterEnd]))) AND ((tbl_dbo_days_episode.start_date)<=[Forms]![Frm:1-ExtractSetUp]![End_Date]) AND ((tbl_dbo_days_episode.end_date)>=[Forms]![Frm:1-ExtractSetUp]![Start_Date] Or (tbl_dbo_days_episode.end_date) Is Null)) OR (((tbl_dbo_days_episode.start_date)<=[Forms]![Frm:1-ExtractSetUp]![End_Date]) AND ((tbl_dbo_days_episode.end_date)>=[Forms]![Frm:1-ExtractSetUp]![Start_Date] Or (tbl_dbo_days_episode.end_date) Is Null) AND ((IIf([end_date] Is Null,Now(),IIf([end_time] Is Null,Now(),[end_date]+TimeValue([end_time])))) Between DateValue([EncounterStart])+TimeValue([EncounterStart]) And IIf([EncounterEnd] Is Null,Now(),DateValue([EncounterEnd])+TimeValue([EncounterEnd])))) OR ((([start_date]+TimeValue([start_time]))<DateValue([EncounterStart])+TimeValue([EncounterStart])) AND ((IIf([end_date] Is Null,Now(),IIf([end_time] Is Null,Now(),[end_date]+TimeValue([end_time]))))>IIf([EncounterEnd] Is Null,Now(),DateValue([EncounterEnd])+TimeValue([EncounterEnd]))))
    # GROUP BY Trim([tbl_dbo_DAYS_EPISODE]![facility_identifier] & "-" & [tbl_dbo_DAYS_EPISODE]![specialty_unit_code]), snapApp_CostingExtract.EncounterNumber, [tbl_dbo_days_episode]![facility_identifier] & "-" & Format(IIf([tbl_Patient_Contact_Details]![AUID] Is Not Null,[tbl_Patient_Contact_Details]![AUID],Right([snapApp_CostingExtract]![MRN],10)),"0000000000"), Format([tbl_dbo_days_episode]![start_date] & " " & [tbl_dbo_days_episode]![start_time],"yyyy-mm-dd hh:nn:ss"), IIf(Trim([tbl_dbo_DAYS_EPISODE]![ward_identifier])="MATERNITY-",[tbl_dbo_DAYS_EPISODE]![facility_identifier] & "-" & Left([tbl_dbo_DAYS_EPISODE]![ward_identifier],9),[tbl_dbo_DAYS_EPISODE]![facility_identifier] & "-" & Trim([tbl_dbo_DAYS_EPISODE]![ward_identifier])), [tbl_dbo_days_episode]![facility_identifier] & "-" & Trim([tbl_dbo_DAYS_Episode]![mo_code]), tbl_dbo_days_episode.local_bed_identifier, tbl_dbo_days_episode.unit_type, IIf([leave_type] In ("L","H","O","T"),"T","F"), tbl_ExcludedEncounters.SNAP_encounter
    # HAVING (((tbl_ExcludedEncounters.SNAP_encounter) Is Null Or (tbl_ExcludedEncounters.SNAP_encounter) Is Null Or (tbl_ExcludedEncounters.SNAP_encounter) Is Null));
    # FROM
    snapApp_CostingExtract["stay_number_cost"] = (
        snapApp_CostingExtract["stay_number_cost"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0")
    )
    tbl_Patient_Contact_Details["contact_identifier"] = (
        tbl_Patient_Contact_Details["contact_identifier"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0")
    )
    snapApp_CostingExtract["area_identifier"] = (
        lhd_global  # for area_identifier check in Patient number generation
    )
    # 11 Jan 2024 - CREATED FACILITY CHANGE
    # df_query1 = pd.merge(snapApp_CostingExtract,tbl_Patient_Contact_Details[['contact_identifier', 'facility_identifier', 'AUID']], how='left', left_on=['stay_number_cost', 'FacilityCode'], right_on=['contact_identifier', 'facility_identifier'], suffixes=('', '_drop'))
    df_query1 = pd.merge(
        snapApp_CostingExtract,
        tbl_Patient_Contact_Details[
            ["contact_identifier", "facility_identifier", "AUID", "SE_CBK_SK"]
        ],
        how="left",
        left_on=["stay_number_cost", "SE_CBK_SK"],
        right_on=["contact_identifier", "SE_CBK_SK"],
        suffixes=("", "_drop"),
    )
    df_query1.drop_duplicates(keep="last", inplace=True)
    df_query1 = df_query1.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    # df_query2 = pd.merge(tbl_dbo_days_episode[['facility_identifier', 'specialty_unit_code', 'mo_code', 'start_date', 'start_time', 'ward_identifier', 'local_bed_identifier', 'unit_type', 'episode_sequence_number', 'stay_number', 'end_date', 'end_time', 'leave_type']], tbl_PPM_transfer_AMO[['facility_identifier', 'mo_code', 'Consultant_Status']], how='left', left_on=['facility_identifier', 'mo_code'], right_on=['facility_identifier', 'mo_code'], suffixes=('', '_drop'))
    df_query2 = pd.merge(
        tbl_dbo_days_episode[
            [
                "facility_identifier",
                "specialty_unit_code",
                "mo_code",
                "start_date",
                "start_time",
                "ward_identifier",
                "local_bed_identifier",
                "unit_type",
                "episode_sequence_number",
                "stay_number",
                "end_date",
                "end_time",
                "leave_type",
                "HLTH_ORG_OSP_OSP_ID",
                "MG_AUTH_OSP_OSP_ID",
                "SE_CBK_SK",
                "WARD_NM",
                "BED_DESC",
                "specialty_unit_code_desc",
                "SINGLE_ROOM_IND_CD",
                "DIM_RSP_ISP_SK",
                "Responsible_Facility",
            ]
        ],
        tbl_PPM_transfer_AMO[["facility_identifier", "mo_code", "Consultant_Status"]],
        how="left",
        left_on=["facility_identifier", "mo_code"],
        right_on=["facility_identifier", "mo_code"],
        suffixes=("", "_drop"),
    )
    df_query2 = df_query2.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    # 142 - 02 Feb 2025
    ####START#######
    """
    Sandra Thompson - 29 Jan 2025 , forwarded an email from Sharon Mc Farlane
    a.	We have discovered another issue with V1.14.  Because you changed the extractor to bring out the -1 in the transfer AMO table, if you have a doctor that is in the system with -1 and a correct one, the transfer table has duplicated all the records.  So one line for -1 doctor and one line for correct doctor.
    b.	It appears the only ones that populated the SE_CBK_SK in both SNSW and MLHD in the transfer_AMO table are the -1 new ones.  It did populate in August (whatever version that was).  The last three columns are all blank now.  It appears to be that if we populate the consultant status in the load file, it does not populate the last three columns.  We will test this theory and let you know.
    df_query2.drop_duplicates(subset=['A'], keep='last', inplace=True)
    """
    df_query2.drop_duplicates(keep="last", inplace=True)
    # Sort the DataFrame based on columns 'A' and 'B'
    df_query2.sort_values(
        by=[
            "facility_identifier",
            "specialty_unit_code",
            "mo_code",
            "start_date",
            "start_time",
            "ward_identifier",
            "local_bed_identifier",
            "unit_type",
            "episode_sequence_number",
            "stay_number",
            "end_date",
            "end_time",
            "leave_type",
            "HLTH_ORG_OSP_OSP_ID",
            "MG_AUTH_OSP_OSP_ID",
            "SE_CBK_SK",
            "WARD_NM",
            "BED_DESC",
            "specialty_unit_code_desc",
            "SINGLE_ROOM_IND_CD",
            "Consultant_Status",
        ],
        inplace=True,
    )
    df_query2.drop_duplicates(
        subset=[
            "facility_identifier",
            "specialty_unit_code",
            "mo_code",
            "start_date",
            "start_time",
            "ward_identifier",
            "local_bed_identifier",
            "unit_type",
            "episode_sequence_number",
            "stay_number",
            "end_date",
            "end_time",
            "leave_type",
            "HLTH_ORG_OSP_OSP_ID",
            "MG_AUTH_OSP_OSP_ID",
            "SE_CBK_SK",
            "WARD_NM",
            "BED_DESC",
            "specialty_unit_code_desc",
            "SINGLE_ROOM_IND_CD",
            "DIM_RSP_ISP_SK",
        ],
        keep="last",
        inplace=True,
    )
    ####STOP#######
    df_query2["Clinic"] = (
        df_query2["facility_identifier"].astype(str).str.strip()
        + "-"
        + df_query2["specialty_unit_code"].astype(str).str.strip()
    )
    df_query2.drop_duplicates(keep="last", inplace=True)
    # df_query3 = pd.merge(df_query1, df_query2, how='inner', left_on=['sa_episode_sequence_number', 'stay_number_cost', 'FacilityCode'], right_on=['episode_sequence_number', 'stay_number', 'facility_identifier'], suffixes=('', '_drop'))
    # tbl_PPM_Transfer_SNAP_AUID = pd.merge(df_query3,tbl_ExcludedEncounters[['SNAP_encounter']], how='left', left_on=['EncounterNumber'], right_on=['SNAP_encounter'], suffixes=('', '_drop'))
    df_query1["stay_number_cost"] = np.where(
        (
            pd.notna(df_query1["stay_number_cost"])
            & (df_query1["stay_number_cost"] != "")
        ),
        df_query1["stay_number_cost"].astype(str).str.pad(8, side="left", fillchar="0"),
        "",
    )
    df_query1["sa_episode_sequence_number"] = np.where(
        (
            pd.notna(df_query1["sa_episode_sequence_number"])
            & (df_query1["sa_episode_sequence_number"] != "")
        ),
        df_query1["sa_episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0"),
        "",
    )
    df_query2["stay_number"] = np.where(
        (pd.notna(df_query2["stay_number"]) & (df_query2["stay_number"] != "")),
        df_query2["stay_number"].astype(str).str.pad(8, side="left", fillchar="0"),
        "",
    )
    df_query2["episode_sequence_number"] = np.where(
        (
            pd.notna(df_query2["episode_sequence_number"])
            & (df_query2["episode_sequence_number"] != "")
        ),
        df_query2["episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0"),
        "",
    )
    # 11 Jan 2024 - CREATED FACILITY CHANGE
    # tbl_PPM_Transfer_SNAP_AUID = pd.merge(df_query1, df_query2, how='inner', left_on=['sa_episode_sequence_number', 'stay_number_cost', 'FacilityCode'], right_on=['episode_sequence_number', 'stay_number', 'facility_identifier'], suffixes=('', '_drop'))
    tbl_PPM_Transfer_SNAP_AUID = pd.merge(
        df_query1,
        df_query2,
        how="inner",
        left_on=["sa_episode_sequence_number", "stay_number_cost", "SE_CBK_SK"],
        right_on=["episode_sequence_number", "stay_number", "SE_CBK_SK"],
        suffixes=("", "_drop"),
    )
    tbl_PPM_Transfer_SNAP_AUID.drop_duplicates(keep="last", inplace=True)
    tbl_PPM_Transfer_SNAP_AUID = tbl_PPM_Transfer_SNAP_AUID.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    tbl_PPM_Transfer_SNAP_AUID["StartDateTime_dummy"] = (
        tbl_PPM_Transfer_SNAP_AUID["start_date"].astype(str).str[:10]
        + " "
        + tbl_PPM_Transfer_SNAP_AUID["start_time"].astype(str).str[-8:]
    )
    tbl_PPM_Transfer_SNAP_AUID["StartDateTime_dummy"] = pd.to_datetime(
        tbl_PPM_Transfer_SNAP_AUID["StartDateTime_dummy"],
        errors="coerce",
        format="%Y-%m-%d %H:%M:%S",
    )
    tbl_PPM_Transfer_SNAP_AUID["EncounterStart_dummy"] = pd.to_datetime(
        tbl_PPM_Transfer_SNAP_AUID["EncounterStart"],
        errors="coerce",
        format="%Y-%m-%d %H:%M:%S",
    )
    tbl_PPM_Transfer_SNAP_AUID["today_dummy"] = pd.Timestamp.today()
    tbl_PPM_Transfer_SNAP_AUID["today_dummy"] = pd.to_datetime(
        tbl_PPM_Transfer_SNAP_AUID["today_dummy"].astype(str).str[:19],
        errors="coerce",
        format="%Y-%m-%d %H:%M:%S",
    )
    tbl_PPM_Transfer_SNAP_AUID["EncounterEnd_dummy"] = np.where(
        (tbl_PPM_Transfer_SNAP_AUID["EncounterEnd"].isnull())
        | (tbl_PPM_Transfer_SNAP_AUID["EncounterEnd"] == ""),
        tbl_PPM_Transfer_SNAP_AUID["today_dummy"],
        pd.to_datetime(
            tbl_PPM_Transfer_SNAP_AUID["EncounterEnd"],
            errors="coerce",
            format="%Y-%m-%d %H:%M:%S",
        ),
    )
    tbl_PPM_Transfer_SNAP_AUID["end_date_dt"] = pd.to_datetime(
        end_date, format="%Y-%m-%d %H:%M:%S"
    )
    tbl_PPM_Transfer_SNAP_AUID["start_date_dt"] = pd.to_datetime(
        start_date, format="%Y-%m-%d %H:%M:%S"
    )
    tbl_PPM_Transfer_SNAP_AUID["end_date_time_dummy"] = np.where(
        (tbl_PPM_Transfer_SNAP_AUID["end_date"].isnull())
        | (tbl_PPM_Transfer_SNAP_AUID["end_date"] == "")
        | (tbl_PPM_Transfer_SNAP_AUID["end_time"] == "")
        | (tbl_PPM_Transfer_SNAP_AUID["end_time"].isnull()),
        tbl_PPM_Transfer_SNAP_AUID["today_dummy"],
        pd.to_datetime(
            (
                tbl_PPM_Transfer_SNAP_AUID["end_date"].astype(str).str[:10]
                + " "
                + tbl_PPM_Transfer_SNAP_AUID["end_time"].astype(str).str[-8:]
            ),
            errors="coerce",
            format="%Y-%m-%d %H:%M:%S",
        ),
    )
    tbl_PPM_Transfer_SNAP_AUID.to_csv(
        "./ExtractorDB/tbl_PPM_Transfer_SNAP_AUID_0.csv", index=False
    )
    # WHERE - 1
    # If the combination of [start_date] and [start_time] falls between the start and end of the encounter,
    # And the start date of the episode is on or before the specified end date,
    # And the end date of the episode is on or after the specified start date (or is null).

    # ((([start_date]+TimeValue([start_time])) Between DateValue([EncounterStart])+TimeValue([EncounterStart]) And IIf([EncounterEnd] Is Null,Now(),DateValue([EncounterEnd])+TimeValue([EncounterEnd]))) AND ((tbl_dbo_days_episode.start_date)<=[Forms]![Frm:1-ExtractSetUp]![End_Date]) AND ((tbl_dbo_days_episode.end_date)>=[Forms]![Frm:1-ExtractSetUp]![Start_Date] Or (tbl_dbo_days_episode.end_date) Is Null))

    # WHERE - 2
    # Or if the start date of the episode is on or before the specified end date,
    # And the end date of the episode is on or after the specified start date (or is null),
    # And the combination of [end_date] and [end_time] (or the current time if either is null) falls between the start and end of the encounter.

    # (((tbl_dbo_days_episode.start_date)<=[Forms]![Frm:1-ExtractSetUp]![End_Date]) AND ((tbl_dbo_days_episode.end_date)>=[Forms]![Frm:1-ExtractSetUp]![Start_Date] Or (tbl_dbo_days_episode.end_date) Is Null) AND ((IIf([end_date] Is Null,Now(),IIf([end_time] Is Null,Now(),[end_date]+TimeValue([end_time])))) Between DateValue([EncounterStart])+TimeValue([EncounterStart]) And IIf([EncounterEnd] Is Null,Now(),DateValue([EncounterEnd])+TimeValue([EncounterEnd]))))

    # WHERE - 3
    # Or if the combination of [start_date] and [start_time] is before the start of the encounter,
    # And the combination of [end_date] and [end_time] (or the current time if either is null) is after the end of the encounter.

    # ((([start_date]+TimeValue([start_time]))<DateValue([EncounterStart])+TimeValue([EncounterStart])) AND ((IIf([end_date] Is Null,Now(),IIf([end_time] Is Null,Now(),[end_date]+TimeValue([end_time]))))>IIf([EncounterEnd] Is Null,Now(),DateValue([EncounterEnd])+TimeValue([EncounterEnd]))))

    # Ranjit 11 Sep 2024 - End date 9999-12-31 in Days Episode causing below filter not to work and excluding some encounters https://abft101.atlassian.net/browse/AQA-139
    # therefore, I changed end_date to end_Date_dt
    """tbl_PPM_Transfer_SNAP_AUID = tbl_PPM_Transfer_SNAP_AUID[((tbl_PPM_Transfer_SNAP_AUID['StartDateTime_dummy'] >= tbl_PPM_Transfer_SNAP_AUID['EncounterStart_dummy']) & (tbl_PPM_Transfer_SNAP_AUID['StartDateTime_dummy'] <= tbl_PPM_Transfer_SNAP_AUID['EncounterEnd_dummy']) & (pd.to_datetime(tbl_PPM_Transfer_SNAP_AUID['start_date'].astype(str).str[:10], errors='coerce', format="%Y-%m-%d")<= tbl_PPM_Transfer_SNAP_AUID['end_date_dt']) & ((pd.to_datetime(tbl_PPM_Transfer_SNAP_AUID['end_date'].astype(str).str[:10], errors='coerce', format="%Y-%m-%d")>=tbl_PPM_Transfer_SNAP_AUID['start_date_dt']) | (tbl_PPM_Transfer_SNAP_AUID['end_date'].isnull()) | (tbl_PPM_Transfer_SNAP_AUID['end_date']==''))) | \
    ((pd.to_datetime(tbl_PPM_Transfer_SNAP_AUID['start_date'].astype(str).str[:10], errors='coerce', format="%Y-%m-%d")<= tbl_PPM_Transfer_SNAP_AUID['end_date_dt']) & ((pd.to_datetime(tbl_PPM_Transfer_SNAP_AUID['end_date'].astype(str).str[:10], errors='coerce', format="%Y-%m-%d")>=tbl_PPM_Transfer_SNAP_AUID['start_date_dt']) | (tbl_PPM_Transfer_SNAP_AUID['end_date'].isnull()) | (tbl_PPM_Transfer_SNAP_AUID['end_date']=='')) & ((tbl_PPM_Transfer_SNAP_AUID['end_date_time_dummy'] >= tbl_PPM_Transfer_SNAP_AUID['EncounterStart_dummy']) & (tbl_PPM_Transfer_SNAP_AUID['end_date_time_dummy'] <= tbl_PPM_Transfer_SNAP_AUID['EncounterEnd_dummy']))) | \
    ((tbl_PPM_Transfer_SNAP_AUID['StartDateTime_dummy'] < tbl_PPM_Transfer_SNAP_AUID['EncounterStart_dummy']) & (tbl_PPM_Transfer_SNAP_AUID['end_date_time_dummy'] > tbl_PPM_Transfer_SNAP_AUID['EncounterEnd_dummy']))] """
    ## Ranjit 12 December 2024 - Issue #114:
    """" Ranjit: Hi Lou, Below are my findings from the initial analysis:
    The issue is occurring because the time field is not captured in the input AMHCC file. As a result, the default time of 12:00:00 AM is used in the start time field. Therefore, if the /extractorDB/DaysEpisode.csv (i.e. Transfer file) has the same start date but the start time is after 12:00 AM, the encounter will be excluded from the transfer file.
    I checked this for one encounter with the number H214-M-05840772-001-001. I believe there are 24 AMHCC encounters impacted, including the two that you have highlighted. 
    The issue happens when Startdatetime = Enddatetime in the Input AMHCC file. Note that we are not capturing time field, therefore the startdatetime and enddatetime in the input AMHCC file are startdate and enddate respectively. All the 24 encounters have Startdatetime = Enddatetime in the Input AMHCC file.  """
    """tbl_PPM_Transfer_SNAP_AUID = tbl_PPM_Transfer_SNAP_AUID[((tbl_PPM_Transfer_SNAP_AUID['StartDateTime_dummy'] >= tbl_PPM_Transfer_SNAP_AUID['EncounterStart_dummy']) & (tbl_PPM_Transfer_SNAP_AUID['StartDateTime_dummy'] <= tbl_PPM_Transfer_SNAP_AUID['EncounterEnd_dummy']) & (pd.to_datetime(tbl_PPM_Transfer_SNAP_AUID['start_date'].astype(str).str[:10], errors='coerce', format="%Y-%m-%d")<= tbl_PPM_Transfer_SNAP_AUID['end_date_dt']) & ((pd.to_datetime(tbl_PPM_Transfer_SNAP_AUID['end_date'].astype(str).str[:10], errors='coerce', format="%Y-%m-%d")>=tbl_PPM_Transfer_SNAP_AUID['start_date_dt']) | (tbl_PPM_Transfer_SNAP_AUID['end_date'].isnull()) | (tbl_PPM_Transfer_SNAP_AUID['end_date']=='')  | (tbl_PPM_Transfer_SNAP_AUID['end_date']=='9999-12-31') )) | \
    ((pd.to_datetime(tbl_PPM_Transfer_SNAP_AUID['start_date'].astype(str).str[:10], errors='coerce', format="%Y-%m-%d")<= tbl_PPM_Transfer_SNAP_AUID['end_date_dt']) & ((pd.to_datetime(tbl_PPM_Transfer_SNAP_AUID['end_date'].astype(str).str[:10], errors='coerce', format="%Y-%m-%d")>=tbl_PPM_Transfer_SNAP_AUID['start_date_dt']) | (tbl_PPM_Transfer_SNAP_AUID['end_date'].isnull()) | (tbl_PPM_Transfer_SNAP_AUID['end_date']=='')  | (tbl_PPM_Transfer_SNAP_AUID['end_date']=='9999-12-31') ) & ((tbl_PPM_Transfer_SNAP_AUID['end_date_time_dummy'] >= tbl_PPM_Transfer_SNAP_AUID['EncounterStart_dummy']) & (tbl_PPM_Transfer_SNAP_AUID['end_date_time_dummy'] <= tbl_PPM_Transfer_SNAP_AUID['EncounterEnd_dummy']))) | \
    ((tbl_PPM_Transfer_SNAP_AUID['StartDateTime_dummy'] < tbl_PPM_Transfer_SNAP_AUID['EncounterStart_dummy']) & (tbl_PPM_Transfer_SNAP_AUID['end_date_time_dummy'] > tbl_PPM_Transfer_SNAP_AUID['EncounterEnd_dummy']))]"""
    tbl_PPM_Transfer_SNAP_AUID = tbl_PPM_Transfer_SNAP_AUID[
        (
            (
                tbl_PPM_Transfer_SNAP_AUID["StartDateTime_dummy"]
                >= tbl_PPM_Transfer_SNAP_AUID["EncounterStart_dummy"]
            )
            & (
                tbl_PPM_Transfer_SNAP_AUID["StartDateTime_dummy"]
                <= tbl_PPM_Transfer_SNAP_AUID["EncounterEnd_dummy"]
            )
            & (
                pd.to_datetime(
                    tbl_PPM_Transfer_SNAP_AUID["start_date"].astype(str).str[:10],
                    errors="coerce",
                    format="%Y-%m-%d",
                )
                <= tbl_PPM_Transfer_SNAP_AUID["end_date_dt"]
            )
            & (
                (
                    pd.to_datetime(
                        tbl_PPM_Transfer_SNAP_AUID["end_date"].astype(str).str[:10],
                        errors="coerce",
                        format="%Y-%m-%d",
                    )
                    >= tbl_PPM_Transfer_SNAP_AUID["start_date_dt"]
                )
                | (tbl_PPM_Transfer_SNAP_AUID["end_date"].isnull())
                | (tbl_PPM_Transfer_SNAP_AUID["end_date"] == "")
                | (tbl_PPM_Transfer_SNAP_AUID["end_date"] == "9999-12-31")
            )
        )
        | (
            (
                pd.to_datetime(
                    tbl_PPM_Transfer_SNAP_AUID["start_date"].astype(str).str[:10],
                    errors="coerce",
                    format="%Y-%m-%d",
                )
                <= tbl_PPM_Transfer_SNAP_AUID["end_date_dt"]
            )
            & (
                (
                    pd.to_datetime(
                        tbl_PPM_Transfer_SNAP_AUID["end_date"].astype(str).str[:10],
                        errors="coerce",
                        format="%Y-%m-%d",
                    )
                    >= tbl_PPM_Transfer_SNAP_AUID["start_date_dt"]
                )
                | (tbl_PPM_Transfer_SNAP_AUID["end_date"].isnull())
                | (tbl_PPM_Transfer_SNAP_AUID["end_date"] == "")
                | (tbl_PPM_Transfer_SNAP_AUID["end_date"] == "9999-12-31")
            )
            & (
                (
                    tbl_PPM_Transfer_SNAP_AUID["end_date_time_dummy"]
                    >= tbl_PPM_Transfer_SNAP_AUID["EncounterStart_dummy"]
                )
                & (
                    tbl_PPM_Transfer_SNAP_AUID["end_date_time_dummy"]
                    <= tbl_PPM_Transfer_SNAP_AUID["EncounterEnd_dummy"]
                )
            )
        )
        | (
            (
                tbl_PPM_Transfer_SNAP_AUID["StartDateTime_dummy"]
                < tbl_PPM_Transfer_SNAP_AUID["EncounterStart_dummy"]
            )
            & (
                tbl_PPM_Transfer_SNAP_AUID["end_date_time_dummy"]
                > tbl_PPM_Transfer_SNAP_AUID["EncounterEnd_dummy"]
            )
        )
        | (
            tbl_PPM_Transfer_SNAP_AUID["EncounterStart"]
            == tbl_PPM_Transfer_SNAP_AUID["EncounterEnd"]
        )
    ]

    tbl_PPM_Transfer_SNAP_AUID.to_csv(
        "./ExtractorDB/tbl_PPM_Transfer_SNAP_AUID_1.csv", index=False
    )

    # HAVING (tbl_ExcludedEncounters.SNAP_encounter) Is Null
    # tbl_PPM_Transfer_SNAP_AUID = tbl_PPM_Transfer_SNAP_AUID[(tbl_PPM_Transfer_SNAP_AUID['SNAP_encounter'].isnull()) | (tbl_PPM_Transfer_SNAP_AUID['SNAP_encounter']=='')]
    # snap_encounter_list = tbl_ExcludedEncounters['SNAP_encounter'].values.tolist()
    # Don't know if it must be SNAP_encounter which is either SNAP or AMHCC or XXX_XXXX in my file.
    snap_encounter_list = tbl_ExcludedEncounters["EncounterNumber"].values.tolist()
    tbl_PPM_Transfer_SNAP_AUID = tbl_PPM_Transfer_SNAP_AUID[
        ~(tbl_PPM_Transfer_SNAP_AUID["EncounterNumber"].isin(snap_encounter_list))
    ]
    # SELECT [tbl_dbo_days_episode]![facility_identifier] & "-" & Format(IIf([tbl_Patient_Contact_Details]![AUID] Is Not Null,[tbl_Patient_Contact_Details]![AUID],Right([snapApp_CostingExtract]![MRN],10)),"0000000000") AS Expr7
    tbl_PPM_Transfer_SNAP_AUID["mrn"] = (
        tbl_PPM_Transfer_SNAP_AUID["mrn"].astype(str).str.strip()
    )
    tbl_PPM_Transfer_SNAP_AUID["MRN_dummy"] = tbl_PPM_Transfer_SNAP_AUID["mrn"].str[
        -10:
    ]
    # tbl_PPM_Transfer_SNAP_AUID['MRN_dummy'] = tbl_PPM_Transfer_SNAP_AUID['MRN_dummy'].astype(str).str.pad(10, side ='left', fillchar ='0')
    tbl_PPM_Transfer_SNAP_AUID["MRN_dummy"] = np.where(
        tbl_PPM_Transfer_SNAP_AUID["MRN_dummy"] == "",
        "",
        tbl_PPM_Transfer_SNAP_AUID["MRN_dummy"]
        .astype(str)
        .str.pad(10, side="left", fillchar="0"),
    )
    tbl_PPM_Transfer_SNAP_AUID["AUID_dummy"] = (
        tbl_PPM_Transfer_SNAP_AUID["AUID"].astype(str).str.strip()
    )
    tbl_PPM_Transfer_SNAP_AUID["AUID"] = (
        tbl_PPM_Transfer_SNAP_AUID["AUID"].astype(str).str.replace("nan", "")
    )
    tbl_PPM_Transfer_SNAP_AUID["AUID_dummy"] = (
        tbl_PPM_Transfer_SNAP_AUID["AUID_dummy"].astype(str).str.replace("nan", "")
    )
    # extra padding for auid - not in access code
    # tbl_PPM_Transfer_SNAP_AUID['AUID_dummy'] = tbl_PPM_Transfer_SNAP_AUID['AUID_dummy'].astype(str).str.pad(10, side ='left', fillchar ='0')
    # tbl_PPM_Transfer_SNAP_AUID['dummy_mrn_auid'] = np.where((tbl_PPM_Transfer_SNAP_AUID['AUID']!=''), tbl_PPM_Transfer_SNAP_AUID['AUID_dummy'], tbl_PPM_Transfer_SNAP_AUID['MRN_dummy'])
    # tbl_PPM_Transfer_SNAP_AUID['dummy_mrn_auid'] = np.where((tbl_PPM_Transfer_SNAP_AUID['AUID_dummy']=='') | ((tbl_PPM_Transfer_SNAP_AUID['AUID_dummy']!='') & ~(tbl_PPM_Transfer_SNAP_AUID['area_identifier'].isin(['X830','X860','X840', 'X850']))), tbl_PPM_Transfer_SNAP_AUID['MRN_dummy'], tbl_PPM_Transfer_SNAP_AUID['AUID_dummy'].astype(str).str.pad(10, side ='left', fillchar ='0'))
    tbl_PPM_Transfer_SNAP_AUID["dummy_mrn_auid"] = np.where(
        (tbl_PPM_Transfer_SNAP_AUID["AUID_dummy"] == "")
        | (
            (tbl_PPM_Transfer_SNAP_AUID["AUID_dummy"] != "")
            & ~(
                tbl_PPM_Transfer_SNAP_AUID["area_identifier"].isin(
                    ["X830", "X860", "X840", "X850", "X740", "X170"]
                )
            )
        ),
        tbl_PPM_Transfer_SNAP_AUID["MRN_dummy"],
        tbl_PPM_Transfer_SNAP_AUID["AUID_dummy"],
    )
    tbl_PPM_Transfer_SNAP_AUID["PatientNumber"] = (
        tbl_PPM_Transfer_SNAP_AUID["facility_identifier"].astype(str).str.strip()
        + "-"
        + tbl_PPM_Transfer_SNAP_AUID["dummy_mrn_auid"].astype(str).str.strip()
    )
    tbl_PPM_Transfer_SNAP_AUID["StartDateTime"] = (
        tbl_PPM_Transfer_SNAP_AUID["start_date"].astype(str).str[:10]
        + " "
        + tbl_PPM_Transfer_SNAP_AUID["start_time"].astype(str).str[-8:]
    )
    tbl_PPM_Transfer_SNAP_AUID["StartDateTime"] = pd.to_datetime(
        tbl_PPM_Transfer_SNAP_AUID["StartDateTime"],
        errors="coerce",
        format="%Y-%m-%d %H:%M:%S",
    )
    tbl_PPM_Transfer_SNAP_AUID["Ward"] = np.where(
        tbl_PPM_Transfer_SNAP_AUID["ward_identifier"].astype(str).str.strip()
        == "MATERNITY-",
        tbl_PPM_Transfer_SNAP_AUID["facility_identifier"].astype(str).str.strip()
        + "-"
        + tbl_PPM_Transfer_SNAP_AUID["ward_identifier"].str[:9],
        tbl_PPM_Transfer_SNAP_AUID["facility_identifier"].astype(str).str.strip()
        + "-"
        + tbl_PPM_Transfer_SNAP_AUID["ward_identifier"].astype(str).str.strip(),
    )
    tbl_PPM_Transfer_SNAP_AUID["mo_code"] = np.where(
        tbl_PPM_Transfer_SNAP_AUID["mo_code"] == "nan",
        "",
        tbl_PPM_Transfer_SNAP_AUID["mo_code"],
    )
    # tbl_PPM_Transfer_SNAP_AUID['AttendingConsultant_Code'] = tbl_PPM_Transfer_SNAP_AUID['facility_identifier'].astype(str).str.strip()+ "-" + tbl_PPM_Transfer_SNAP_AUID['mo_code'].astype(str).str.strip()
    tbl_PPM_Transfer_SNAP_AUID["AttendingConsultant_Code"] = np.where(
        (tbl_PPM_Transfer_SNAP_AUID["mo_code"] == "")
        | (tbl_PPM_Transfer_SNAP_AUID["mo_code"].isnull()),
        "",
        tbl_PPM_Transfer_SNAP_AUID["facility_identifier"].astype(str).str.strip()
        + "-"
        + tbl_PPM_Transfer_SNAP_AUID["mo_code"].astype(str).str.strip(),
    )
    tbl_PPM_Transfer_SNAP_AUID["BedNumber"] = tbl_PPM_Transfer_SNAP_AUID[
        "local_bed_identifier"
    ]
    tbl_PPM_Transfer_SNAP_AUID["Unit"] = tbl_PPM_Transfer_SNAP_AUID["unit_type"]
    tbl_PPM_Transfer_SNAP_AUID["Leave"] = np.where(
        tbl_PPM_Transfer_SNAP_AUID["leave_type"].isin(["L", "H", "O", "T"]), "T", "F"
    )
    tbl_PPM_Transfer_SNAP_AUID["Extra:HLTH_ORG_OSP_OSP_ID"] = (
        tbl_PPM_Transfer_SNAP_AUID["HLTH_ORG_OSP_OSP_ID"]
    )
    tbl_PPM_Transfer_SNAP_AUID["Extra:MG_AUTH_OSP_OSP_ID"] = tbl_PPM_Transfer_SNAP_AUID[
        "MG_AUTH_OSP_OSP_ID"
    ]
    tbl_PPM_Transfer_SNAP_AUID["Extra:SE_CBK_SK"] = tbl_PPM_Transfer_SNAP_AUID[
        "SE_CBK_SK"
    ]
    tbl_PPM_Transfer_SNAP_AUID["Extra:single_room_flag"] = tbl_PPM_Transfer_SNAP_AUID[
        "SINGLE_ROOM_IND_CD"
    ]
    tbl_PPM_Transfer_SNAP_AUID["Extra:Ward_NM"] = tbl_PPM_Transfer_SNAP_AUID["WARD_NM"]
    tbl_PPM_Transfer_SNAP_AUID["Extra:Bed_Desc"] = tbl_PPM_Transfer_SNAP_AUID[
        "BED_DESC"
    ]
    tbl_PPM_Transfer_SNAP_AUID["Extra:specialty_unit_code_desc"] = (
        tbl_PPM_Transfer_SNAP_AUID["specialty_unit_code_desc"]
    )
    tbl_PPM_Transfer_SNAP_AUID["Extra:DIM_RSP_ISP_SK"] = tbl_PPM_Transfer_SNAP_AUID[
        "DIM_RSP_ISP_SK"
    ]
    tbl_PPM_Transfer_SNAP_AUID["Extra:Responsible_Facility"] = (
        tbl_PPM_Transfer_SNAP_AUID["Responsible_Facility"]
    )
    # GROUP BY
    tbl_PPM_Transfer_SNAP_AUID = tbl_PPM_Transfer_SNAP_AUID[
        [
            "Clinic",
            "EncounterNumber",
            "PatientNumber",
            "StartDateTime",
            "Ward",
            "AttendingConsultant_Code",
            "BedNumber",
            "Unit",
            "Leave",
            "Consultant_Status",
            "Extra:HLTH_ORG_OSP_OSP_ID",
            "Extra:MG_AUTH_OSP_OSP_ID",
            "Extra:SE_CBK_SK",
            "Extra:Ward_NM",
            "Extra:Bed_Desc",
            "Extra:specialty_unit_code_desc",
            "Extra:single_room_flag",
            "Extra:DIM_RSP_ISP_SK",
            "Extra:Responsible_Facility",
        ]
    ]
    tbl_PPM_Transfer_SNAP_AUID = (
        tbl_PPM_Transfer_SNAP_AUID.groupby(
            [
                "Clinic",
                "EncounterNumber",
                "PatientNumber",
                "StartDateTime",
                "Ward",
                "AttendingConsultant_Code",
                "BedNumber",
                "Unit",
                "Leave",
                "Extra:HLTH_ORG_OSP_OSP_ID",
                "Extra:MG_AUTH_OSP_OSP_ID",
                "Extra:SE_CBK_SK",
                "Extra:Ward_NM",
                "Extra:Bed_Desc",
                "Extra:specialty_unit_code_desc",
                "Extra:single_room_flag",
                "Extra:DIM_RSP_ISP_SK",
                "Extra:Responsible_Facility",
            ],
            as_index=False,
            dropna=False,
        )
        .agg(AttendingConsultant_SpecialtyCode=("Consultant_Status", "max"))
        .reset_index()
    )
    tbl_PPM_Transfer_SNAP_AUID = tbl_PPM_Transfer_SNAP_AUID[
        [
            "Clinic",
            "EncounterNumber",
            "PatientNumber",
            "StartDateTime",
            "Ward",
            "AttendingConsultant_Code",
            "AttendingConsultant_SpecialtyCode",
            "BedNumber",
            "Unit",
            "Leave",
            "Extra:HLTH_ORG_OSP_OSP_ID",
            "Extra:MG_AUTH_OSP_OSP_ID",
            "Extra:SE_CBK_SK",
            "Extra:Ward_NM",
            "Extra:Bed_Desc",
            "Extra:specialty_unit_code_desc",
            "Extra:single_room_flag",
            "Extra:DIM_RSP_ISP_SK",
            "Extra:Responsible_Facility",
        ]
    ]
    tbl_PPM_Transfer_SNAP_AUID.drop_duplicates(keep="last", inplace=True)
    logging.info(
        "Query: Append_to_tbl_PPM_transfer_SNAP_AUID completed. tbl_PPM_Transfer_SNAP_AUID created with %s records.",
        len(tbl_PPM_Transfer_SNAP_AUID),
    )
    tbl_PPM_Transfer_SNAP_AUID.to_csv(
        "./ExtractorDB/tbl_PPM_Transfer_SNAP_AUID_original.csv", index=False
    )
    ###################START #########################
    # 01 Feb 2025 - Issue 144, 147 - remove rows from transfer file that has  overlapping phases - Palliative care and AMHCC
    """ 
    # NEW CODE    
    tbl_dbo_days_episode_new = tbl_dbo_days_episode.copy()
    tbl_dbo_days_episode_new['StartDateTime'] = tbl_dbo_days_episode_new['start_date'].astype(str).str[:10]+ " "  + tbl_dbo_days_episode_new['start_time'].astype(str).str[-8:]
    tbl_dbo_days_episode_new['StartDateTime'] = pd.to_datetime(tbl_dbo_days_episode_new['StartDateTime'], errors='coerce', format="%Y-%m-%d %H:%M:%S")
    tbl_dbo_days_episode_new = tbl_dbo_days_episode_new[['SE_CBK_SK','StartDateTime']]

    tbl_PPM_Transfer_SNAP_AUID = pd.merge(tbl_PPM_Transfer_SNAP_AUID, tbl_dbo_days_episode_new, how = 'inner', left_on = ['SE_CBK_SK', 'StartDateTime'], right_on = ['SE_CBK_SK', 'StartDateTime'], suffixes=('', '_drop'))
    tbl_PPM_Transfer_SNAP_AUID.to_csv('./ExtractorDB/tbl_PPM_Transfer_SNAP_AUID_removed_overlap_phases.csv', index=False)
    """
    ################### concatenate all tbl_ppm_transfers
    len_tbl_PPM_transfer_dummy = len(tbl_PPM_transfer)
    tbl_PPM_transfer = pd.concat([tbl_PPM_transfer, tbl_PPM_Transfer_SNAP_AUID], axis=0)
    tbl_PPM_transfer.drop_duplicates(keep="last", inplace=True)
    logging.info(
        "tbl_PPM_transfer created with %s records, after concatenating %s records from tbl_PPM_transfer and  %s records from tbl_PPM_Transfer_SNAP_AUID.",
        len(tbl_PPM_transfer),
        len_tbl_PPM_transfer_dummy,
        len(tbl_PPM_Transfer_SNAP_AUID),
    )
    # I added this.
    tbl_ExcludedEncounters_list = tbl_ExcludedEncounters["EncounterNumber"].tolist()
    tbl_PPM_transfer = tbl_PPM_transfer[
        ~(tbl_PPM_transfer["EncounterNumber"].isin(tbl_ExcludedEncounters_list))
    ]
    logging.info(
        "tbl_PPM_transfer now has %s records, after excluding encounters.",
        len(tbl_PPM_transfer),
    )
    tbl_PPM_transfer = tbl_PPM_transfer.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    tbl_PPM_transfer = tbl_PPM_transfer.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    tbl_PPM_transfer = tbl_PPM_transfer.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    tbl_PPM_transfer = tbl_PPM_transfer.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    tbl_PPM_transfer.sort_values(
        by=[
            "Clinic",
            "EncounterNumber",
            "PatientNumber",
            "StartDateTime",
            "Ward",
            "AttendingConsultant_Code",
            "AttendingConsultant_SpecialtyCode",
            "BedNumber",
            "Unit",
            "Leave",
            "Extra:HLTH_ORG_OSP_OSP_ID",
            "Extra:MG_AUTH_OSP_OSP_ID",
            "Extra:SE_CBK_SK",
            "Extra:Ward_NM",
            "Extra:Bed_Desc",
            "Extra:specialty_unit_code_desc",
            "Extra:single_room_flag",
        ],
        inplace=True,
    )
    tbl_PPM_transfer.drop_duplicates(
        subset=[
            "Clinic",
            "EncounterNumber",
            "PatientNumber",
            "StartDateTime",
            "Ward",
            "AttendingConsultant_Code",
            "AttendingConsultant_SpecialtyCode",
            "BedNumber",
            "Unit",
            "Leave",
        ],
        keep="last",
        inplace=True,
    )
    tbl_PPM_transfer.drop_duplicates(keep="last", inplace=True)
    logging.info("tbl_PPM_transfer has %s records, after removing duplicate records")
    """ Updates the startdatetime in the tbl_ppm_transfer into to the encounterstartdatetime where  startdatetimes in transfer are before the startdatetimes in the encounter file """
    # Access query: Update_to_tbl_PPM_transfer_SNAP_AUID
    # UPDATE snapApp_CostingExtract INNER JOIN tbl_PPM_transfer ON snapApp_CostingExtract.EncounterNumber = tbl_PPM_transfer.EncounterNumber SET tbl_PPM_transfer.StartDateTime = Format([EncounterStart],"yyyy-mm-dd hh:nn:ss") WHERE (((DateValue([StartDateTime])+TimeValue([StartDateTime]))<DateValue([EncounterStart])+TimeValue([EncounterStart])) AND (((tbl_PPM_transfer.EncounterNumber) Like "*_*") OR ((tbl_PPM_transfer.EncounterNumber) Like "*-M-*")));
    # 11 Jan 2024 - CREATED FACILITY CHANGE
    # tbl_PPM_transfer = pd.merge(tbl_PPM_transfer, snapApp_CostingExtract[['EncounterNumber', 'EncounterStart']], how='left', on=['EncounterNumber'], suffixes=('', '_drop'), indicator=True)
    # 21 Feb 2025 - Transfer file for snap pal care and AMHCC 141, 144, 147, 157 , 170
    # tbl_PPM_transfer = pd.merge(tbl_PPM_transfer, snapApp_CostingExtract[['EncounterNumber', 'EncounterStart', 'SE_CBK_SK']], how='left', left_on=['Extra:SE_CBK_SK'], right_on=['SE_CBK_SK'], suffixes=('', '_drop'), indicator=True)
    # 25 Feb - fix Transfer overlapping
    # tbl_PPM_transfer = pd.merge(tbl_PPM_transfer, snapApp_CostingExtract[['EncounterNumber', 'EncounterStart', 'SE_CBK_SK']], how='left', left_on=['EncounterNumber', 'Extra:SE_CBK_SK'], right_on=['EncounterNumber', 'SE_CBK_SK'], suffixes=('', '_drop'), indicator=True)
    tbl_PPM_transfer = pd.merge(
        tbl_PPM_transfer,
        snapApp_CostingExtract[
            ["EncounterNumber", "EncounterStart", "EncounterEnd", "SE_CBK_SK"]
        ],
        how="left",
        left_on=["EncounterNumber", "Extra:SE_CBK_SK"],
        right_on=["EncounterNumber", "SE_CBK_SK"],
        suffixes=("", "_drop"),
        indicator=True,
    )
    tbl_PPM_transfer.drop_duplicates(keep="last", inplace=True)
    tbl_PPM_transfer = tbl_PPM_transfer.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    logging.info(
        "Query: Update_to_tbl_PPM_transfer_SNAP_AUID completed. %s records will be updated in tbl_PPM_transfer. tbl_PPM_transfer has %s records.",
        len(
            tbl_PPM_transfer[
                (tbl_PPM_transfer["_merge"] == "both")
                & (
                    pd.to_datetime(
                        tbl_PPM_transfer["StartDateTime"],
                        errors="coerce",
                        format="%Y-%m-%d %H:%M:%S",
                    )
                    < pd.to_datetime(
                        tbl_PPM_transfer["EncounterStart"],
                        errors="coerce",
                        format="%Y-%m-%d %H:%M:%S",
                    )
                )
                & (tbl_PPM_transfer.EncounterNumber.str.contains("_|-M-") == True)
            ]
        ),
        len(tbl_PPM_transfer),
    )
    # 25 Feb - fix Transfer overlapping
    tbl_PPM_transfer["delete_flag"] = np.where(
        (tbl_PPM_transfer["_merge"] == "both")
        & (
            pd.to_datetime(
                tbl_PPM_transfer["StartDateTime"],
                errors="coerce",
                format="%Y-%m-%d %H:%M:%S",
            )
            - pd.to_datetime(
                tbl_PPM_transfer["EncounterEnd"],
                errors="coerce",
                format="%Y-%m-%d %H:%M:%S",
            )
            > pd.Timedelta(days=1)
        )
        & (tbl_PPM_transfer.EncounterNumber.str.contains("_|-M-") == True),
        1,
        0,
    )
    tbl_PPM_transfer["StartDateTime"] = np.where(
        (tbl_PPM_transfer["_merge"] == "both")
        & (
            pd.to_datetime(
                tbl_PPM_transfer["StartDateTime"],
                errors="coerce",
                format="%Y-%m-%d %H:%M:%S",
            )
            < pd.to_datetime(
                tbl_PPM_transfer["EncounterStart"],
                errors="coerce",
                format="%Y-%m-%d %H:%M:%S",
            )
        )
        & (tbl_PPM_transfer.EncounterNumber.str.contains("_|-M-") == True),
        pd.to_datetime(
            tbl_PPM_transfer["EncounterStart"],
            errors="coerce",
            format="%Y-%m-%d %H:%M:%S",
        ),
        pd.to_datetime(
            tbl_PPM_transfer["StartDateTime"],
            errors="coerce",
            format="%Y-%m-%d %H:%M:%S",
        ),
    )
    # 25 Feb - fix Transfer overlapping
    # tbl_PPM_transfer.drop(['_merge'], axis=1, inplace=True, errors='ignore')
    index_names = tbl_PPM_transfer[(tbl_PPM_transfer["delete_flag"] == 1)].index
    tbl_PPM_transfer.drop(index_names, inplace=True)
    tbl_PPM_transfer.drop(
        ["_merge", "delete_flag", "EncounterEnd"], axis=1, inplace=True, errors="ignore"
    )
    """  Updates the Extra:SpecialtyPortal filed in the tbl_ppm_transfer table based on the clinic from the SpecialtyPortalMapping table"""
    # Access query: Update SpecialtyPortal
    # UPDATE tbl_PPM_transfer INNER JOIN SpecialityPortalMapping ON tbl_PPM_transfer.Clinic = SpecialityPortalMapping.Clinic SET tbl_PPM_transfer.[Extra:SpecialtyPortal] = [SpecialityPortal];
    file_SpecialtyPortalMapping = "./Output/SpecialityPortalMapping.csv"
    if os.path.isfile(file_SpecialtyPortalMapping):
        try:
            specialtyPortalMapping = read_csv_file(
                file_SpecialtyPortalMapping,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            label_5_status = 0
            messagebox.showerror(
                "File Error",
                "Error extracting SpecialtyPortalMapping from ./Output/SpecialityPortalMapping.csv\n"
                + str(e),
            )
            label_5_sub.configure(text="Failed (SpecialtyPortalMapping)...", fg="red")
            main_screen.update()
            return
        else:
            specialtyPortalMapping = specialtyPortalMapping.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            specialtyPortalMapping = specialtyPortalMapping.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            specialtyPortalMapping = specialtyPortalMapping.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            specialtyPortalMapping = specialtyPortalMapping.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
            #    specialtyPortalMapping = specialtyPortalMapping[['Clinic', 'SpecialityPortal']]
    else:
        specialtyPortalMapping = pd.DataFrame()
    tbl_PPM_transfer = pd.merge(
        tbl_PPM_transfer,
        specialtyPortalMapping[["Clinic", "SpecialityPortal"]],
        how="left",
        on=["Clinic"],
        suffixes=("", "_drop"),
        indicator=True,
    )
    tbl_PPM_transfer.drop_duplicates(keep="last", inplace=True)
    tbl_PPM_transfer = tbl_PPM_transfer.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    len_dummy = len(
        tbl_PPM_transfer[
            (tbl_PPM_transfer["_merge"] == "both")
            & pd.notna(tbl_PPM_transfer["SpecialityPortal"])
            & (tbl_PPM_transfer["SpecialityPortal"] != "")
        ]
    )
    tbl_PPM_transfer["Extra:SpecialtyPortal"] = np.where(
        (tbl_PPM_transfer["_merge"] == "both")
        & pd.notna(tbl_PPM_transfer["SpecialityPortal"])
        & (tbl_PPM_transfer["SpecialityPortal"] != ""),
        tbl_PPM_transfer["SpecialityPortal"],
        "",
    )
    logging.info(
        "Query: Update SpecialtyPortal completed. Extra:SpecialtyPortal field of %s records updated in tbl_PPM_transfer. tbl_PPM_transfer has %s records.",
        len_dummy,
        len(tbl_PPM_transfer),
    )
    tbl_PPM_transfer.drop(["_merge"], axis=1, inplace=True, errors="ignore")
    """ Deletes all data in the tbl_PPM_transfer  where the encounter exists in the tbl_ExcludedEncounters table """
    # Access query: qry delete excluded encounters from transfer
    # DELETE DISTINCTROW tbl_PPM_transfer.EncounterNumber, tbl_PPM_transfer.* FROM tbl_ExcludedEncounters INNER JOIN tbl_PPM_transfer ON tbl_ExcludedEncounters.EncounterNumber = tbl_PPM_transfer.EncounterNumber;
    tbl_ExcludedEncounters_list = tbl_ExcludedEncounters[
        "EncounterNumber"
    ].values.tolist()
    tbl_PPM_transfer = tbl_PPM_transfer[
        ~tbl_PPM_transfer["EncounterNumber"].isin(tbl_ExcludedEncounters_list)
    ]
    logging.info(
        "Query: qry delete excluded encounters from transfer completed. After deleting all data in the tbl_PPM_transfer where the encounter exists in the tbl_ExcludedEncounters,  table tbl_PPM_transfer has %s records.",
        len(tbl_PPM_transfer),
    )
    tbl_PPM_transfer.drop_duplicates(keep="last", inplace=True)
    # Access query:  Remove_Duplicate_Not_MH_Encounters
    # DELETE DISTINCTROW tbl_PPM_transfer_0.*
    # FROM tbl_PPM_transfer AS tbl_PPM_transfer_0 LEFT JOIN tbl_PPM_transfer AS tbl_PPM_transfer_1 ON ((tbl_PPM_transfer_0.PatientNumber)=[tbl_PPM_transfer_1].[PatientNumber]) AND ((tbl_PPM_transfer_0.StartDateTime)=[tbl_PPM_transfer_1].[StartDateTime])
    # WHERE ((tbl_PPM_transfer_0.EncounterNumber) Like "*" & "-I-" & "*") And ((tbl_PPM_transfer_0.Ward)=tbl_PPM_transfer_1.Ward) And ((tbl_PPM_transfer_1.EncounterNumber) Like "*" & "-M-" & "*");
    # tbl_PPM_transfer_0 = tbl_PPM_transfer.copy()
    tbl_PPM_transfer_1 = tbl_PPM_transfer[
        (tbl_PPM_transfer.EncounterNumber.str.contains("-M-") == True)
    ]
    tbl_PPM_transfer_1.rename(columns={"Ward": "Ward_1"}, inplace=True)
    tbl_PPM_transfer = pd.merge(
        tbl_PPM_transfer,
        tbl_PPM_transfer_1[["PatientNumber", "StartDateTime", "Ward_1"]],
        how="left",
        on=["PatientNumber", "StartDateTime"],
        suffixes=("", "_drop"),
        indicator=True,
    )
    tbl_PPM_transfer.drop_duplicates(keep="last", inplace=True)
    tbl_PPM_transfer = tbl_PPM_transfer.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    index_names = tbl_PPM_transfer[
        (tbl_PPM_transfer.EncounterNumber.str.contains("-I-") == True)
        & (tbl_PPM_transfer["_merge"] == "both")
        & (tbl_PPM_transfer["Ward"] == tbl_PPM_transfer["Ward_1"])
    ].index
    tbl_PPM_transfer.drop(index_names, inplace=True)
    logging.info(
        "Query: Remove_Duplicate_Not_MH_Encounters completed. tbl_PPM_transfer now has %s records.",
        len(tbl_PPM_transfer),
    )
    tbl_PPM_transfer.drop(["_merge", "Ward_1"], axis=1, inplace=True, errors="ignore")
    """ Exports data in transfer file to C:\costing\Tbl_PPM_transfer.txt with versionID"""
    # Access query:  tbl_PPM_Transfer
    """
    From: Kylie Hawkins <Kylie.Hawkins2@health.nsw.gov.au> 
    Sent: Wednesday, May 15, 2024 11:53 AM
    To: Ranjit Sukumaran <Ranjit.Sukumaran@health.nsw.gov.au>; Badari Lanka Venkata <Badari.LankaVenkata@health.nsw.gov.au>
    Subject: RE: Costing extractor columns
    ConsultantSpecialtyRollup
    Pretty sure it will need to be this but will confirm
    From: Kylie Hawkins 
    Sent: Wednesday, May 15, 2024 11:46 AM
    To: Ranjit Sukumaran <Ranjit.Sukumaran@health.nsw.gov.au>; Badari Lanka Venkata <Badari.LankaVenkata@health.nsw.gov.au>
    Subject: FW: Costing extractor columns
    Hi both
    We made this change recently. In training today they have told us we cannot use the Extra: fields in the Transfer file to build codes, so we now need to move again into one of their standard fields. Otherwise we will not be able to cost out medical hours. Can we talk about which field to put it in in the next day or so. I cannot remember which fields we already have populated and which are spare
    k
    From: Ranjit Sukumaran <Ranjit.Sukumaran@health.nsw.gov.au> 
    Sent: Tuesday, May 7, 2024 11:20 AM
    To: Kylie Hawkins <Kylie.Hawkins2@health.nsw.gov.au>
    Subject: RE: Costing extractor columns
    Hi Kylie,
    In the excel workbook, sheet : tbl_ppm_transfer,
    Please note that  Clinic has been removed and replaced with Extra:Clinic column
    Best regards
    Ranjit S
    From: Julia Heberle <Julia.Heberle@health.nsw.gov.au> 
    Sent: Tuesday, April 23, 2024 2:22 PM
    To: Kylie Hawkins <Kylie.Hawkins2@health.nsw.gov.au>; Ranjit Sukumaran <Ranjit.Sukumaran@health.nsw.gov.au>; Badari Lanka Venkata <Badari.LankaVenkata@health.nsw.gov.au>; Jeanette Friend <Jeanette.Friend@health.nsw.gov.au>; Tony Hutton <Tony.Hutton@health.nsw.gov.au>
    Subject: EDW Extractor request - transfer file
    Dear All,
    Can we please add this request to the list of EDW Extractor enhancement/requests. This has been raised by the Pilot sites
    -	In the transfer file, can we find another field for specialty details that are currently held in the Clinic field? This could be an Extra field or the Consultant specialty rollup field.
    Many thanks
    Kind regards
    Julia Heberle
    """
    tbl_PPM_transfer = tbl_PPM_transfer[
        [
            "Clinic",
            "EncounterNumber",
            "PatientNumber",
            "StartDateTime",
            "Ward",
            "AttendingConsultant_Code",
            "AttendingConsultant_SpecialtyCode",
            "BedNumber",
            "Unit",
            "Leave",
            "Extra:SpecialtyPortal",
            "Extra:HLTH_ORG_OSP_OSP_ID",
            "Extra:MG_AUTH_OSP_OSP_ID",
            "Extra:SE_CBK_SK",
            "Extra:Ward_NM",
            "Extra:Bed_Desc",
            "Extra:specialty_unit_code_desc",
            "Extra:single_room_flag",
            "Extra:DIM_RSP_ISP_SK",
            "Extra:Responsible_Facility",
        ]
    ]
    tbl_PPM_transfer.drop_duplicates(keep="last", inplace=True)
    tbl_PPM_transfer = tbl_PPM_transfer.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    tbl_PPM_transfer = tbl_PPM_transfer.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    tbl_PPM_transfer = tbl_PPM_transfer.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    tbl_PPM_transfer.drop_duplicates(keep="last", inplace=True)
    tbl_PPM_transfer["Unit"] = (
        tbl_PPM_transfer["Unit"].astype(str).str.pad(2, side="left", fillchar="0")
    )
    tbl_PPM_transfer_new = tbl_PPM_transfer.copy()
    tbl_PPM_transfer_new["Extra:Clinic_Orig"] = tbl_PPM_transfer_new["Clinic"]
    # tbl_PPM_transfer_new['Clinic'] = tbl_PPM_transfer_new['Clinic'] +"-"+ tbl_PPM_transfer_new['AttendingConsultant_SpecialtyCode']
    tbl_PPM_transfer_new["Clinic"] = np.where(
        (
            (tbl_PPM_transfer_new["AttendingConsultant_SpecialtyCode"] == "")
            | (tbl_PPM_transfer_new["AttendingConsultant_SpecialtyCode"].isnull())
        ),
        tbl_PPM_transfer_new["Clinic"],
        tbl_PPM_transfer_new["Clinic"]
        + "-"
        + tbl_PPM_transfer_new["AttendingConsultant_SpecialtyCode"],
    )
    tbl_PPM_transfer_new["Extra:BedNumber_Orig"] = tbl_PPM_transfer_new["BedNumber"]
    tbl_PPM_transfer_new["BedNumber"] = (
        tbl_PPM_transfer_new["Ward"].astype(str).str.strip()
        + "-"
        + tbl_PPM_transfer_new["Unit"].astype(str).str.strip()
        + "-"
        + tbl_PPM_transfer_new["Extra:BedNumber_Orig"].astype(str).str.strip()
    )
    # Add , 'Extra:single_room_flag' in the next two statements
    tbl_PPM_transfer_new = tbl_PPM_transfer_new[
        [
            "Clinic",
            "Extra:Clinic_Orig",
            "EncounterNumber",
            "PatientNumber",
            "StartDateTime",
            "BedNumber",
            "Ward",
            "AttendingConsultant_Code",
            "AttendingConsultant_SpecialtyCode",
            "Extra:BedNumber_Orig",
            "Unit",
            "Leave",
            "Extra:SpecialtyPortal",
            "Extra:HLTH_ORG_OSP_OSP_ID",
            "Extra:MG_AUTH_OSP_OSP_ID",
            "Extra:SE_CBK_SK",
            "Extra:Ward_NM",
            "Extra:Bed_Desc",
            "Extra:specialty_unit_code_desc",
            "Extra:single_room_flag",
            "Extra:DIM_RSP_ISP_SK",
        ]
    ]
    tbl_PPM_transfer_new.sort_values(
        by=[
            "Clinic",
            "Extra:Clinic_Orig",
            "EncounterNumber",
            "PatientNumber",
            "StartDateTime",
            "BedNumber",
            "Ward",
            "AttendingConsultant_Code",
            "AttendingConsultant_SpecialtyCode",
            "Extra:BedNumber_Orig",
            "Unit",
            "Leave",
            "Extra:SpecialtyPortal",
            "Extra:HLTH_ORG_OSP_OSP_ID",
            "Extra:MG_AUTH_OSP_OSP_ID",
            "Extra:SE_CBK_SK",
            "Extra:Ward_NM",
            "Extra:Bed_Desc",
            "Extra:specialty_unit_code_desc",
            "Extra:single_room_flag",
        ],
        inplace=True,
    )
    # remove
    # tbl_PPM_transfer_new.drop_duplicates(subset=['Clinic', 'Extra:Clinic_Orig', 'EncounterNumber', 'PatientNumber', 'StartDateTime', 'BedNumber', 'Ward', 'AttendingConsultant_SpecialtyCode', 'Extra:BedNumber_Orig', 'Unit', 'Leave', 'Extra:SpecialtyPortal', 'Extra:HLTH_ORG_OSP_OSP_ID', 'Extra:MG_AUTH_OSP_OSP_ID', 'Extra:SE_CBK_SK'], keep='last', inplace=True)
    tbl_PPM_transfer_new.drop_duplicates(keep="last", inplace=True)
    # https://abft101.atlassian.net/browse/AQA-348
    # tbl_PPM_transfer_new=clear_neg_one(tbl_PPM_transfer_new)
    try:
        tbl_PPM_transfer.to_csv(
            "./ExtractorDB/tbl_PPM_Transfer_" + versionID_hash + "_OLD_FORMAT.csv",
            index=False,
            na_rep="",
            float_format=str,
            decimal=str,
            date_format=str,
        )
        tbl_PPM_transfer_new.to_csv(
            "./Output/tbl_PPM_Transfer_" + versionID_hash + ".csv",
            index=False,
            na_rep="",
            float_format=str,
            decimal=str,
            date_format=str,
        )
    except Exception as e:
        logging.exception("Exception occurred")
        label_5_status = 0
        messagebox.showerror(
            "Export Error", "Error exporting tbl_PPM_Transfer\n" + str(e)
        )
        label_5_sub.configure(text="Failed ()...", fg="red")
        main_screen.update()
        return  # stop export
    # else:
    #    label_5_sub.configure(text="Completed",fg='green')
    #    main_screen.update()
    logging.info(
        "%s records saved to ./Output/tbl_PPM_Transfer_%s.csv",
        len(tbl_PPM_transfer),
        versionID_hash,
    )
    """  Step not required delete? In MH RVU Builder"""
    # Access query: qry mental health days episode
    # SELECT tbl_dbo_episode_ats.facility_identifier, tbl_dbo_episode_ats.stay_number, tbl_dbo_episode_ats.episode_sequence_number, tbl_dbo_days_episode.ward_identifier, tbl_dbo_days_episode.unit_type, tbl_dbo_days_episode.trans_type, tbl_dbo_days_episode.start_date, tbl_dbo_days_episode.start_time, tbl_dbo_days_episode.end_date, tbl_dbo_days_episode.end_time
    # FROM tbl_dbo_episode_ats INNER JOIN tbl_dbo_days_episode ON (tbl_dbo_days_episode.episode_sequence_number = tbl_dbo_episode_ats.episode_sequence_number) AND (tbl_dbo_days_episode.stay_number = tbl_dbo_episode_ats.stay_number) AND (tbl_dbo_episode_ats.facility_identifier = tbl_dbo_days_episode.facility_identifier)
    # WHERE (((tbl_dbo_days_episode.unit_type) In ("54","55","62","63","64","65","06","04","05","20","22","32","56","73","50")));
    qry_mental_health_days_episode = pd.merge(
        tbl_dbo_episode_ats[
            ["episode_sequence_number", "stay_number", "facility_identifier"]
        ],
        tbl_dbo_days_episode[
            tbl_dbo_days_episode["unit_type"].isin(
                [
                    "54",
                    "55",
                    "62",
                    "63",
                    "64",
                    "65",
                    "06",
                    "04",
                    "05",
                    "20",
                    "22",
                    "32",
                    "56",
                    "73",
                    "50",
                ]
            )
        ][
            [
                "trans_type",
                "ward_identifier",
                "unit_type",
                "start_date",
                "start_time",
                "end_date",
                "end_time",
                "episode_sequence_number",
                "stay_number",
                "facility_identifier",
            ]
        ],
        how="inner",
        on=["facility_identifier", "episode_sequence_number", "stay_number"],
        suffixes=("", "_drop"),
    )
    qry_mental_health_days_episode = qry_mental_health_days_episode.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    qry_mental_health_days_episode = qry_mental_health_days_episode[
        [
            "facility_identifier",
            "stay_number",
            "episode_sequence_number",
            "ward_identifier",
            "unit_type",
            "trans_type",
            "start_date",
            "start_time",
            "end_date",
            "end_time",
        ]
    ]
    qry_mental_health_days_episode = qry_mental_health_days_episode.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    qry_mental_health_days_episode = qry_mental_health_days_episode.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    qry_mental_health_days_episode = qry_mental_health_days_episode.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    qry_mental_health_days_episode.drop_duplicates(keep="last", inplace=True)
    try:
        qry_mental_health_days_episode.to_csv(
            "./ExtractorDB/qry_mental_health_days_episode.csv",
            index=False,
            na_rep="",
            float_format=str,
            decimal=str,
            date_format=str,
        )
    except Exception as e:
        logging.exception("Exception occurred")
        label_5_status = 0
        messagebox.showerror(
            "Export Error", "Error saving qry_mental_health_days_episode.csv\n" + str(e)
        )
        label_5_sub.configure(text="Failed ()...", fg="red")
        main_screen.update()
    logging.info(
        "Query: qry mental health days episode completed. %s records saved to ./ExtractorDB/qry_mental_health_days_episode.csv.",
        len(qry_mental_health_days_episode),
    )
    # Update Sub task status
    if label_5_status == 0:
        label_5_sub.configure(text="Failed", fg="red")
        main_screen.update()
    else:
        label_5_sub.configure(text="Completed", fg="green")
        main_screen.update()
    main_screen.update()
    logging.info("Export Transfer Data completed.")
    ############### "6. Export ED_Encounter Data"#################
    logging.info("Export ED_Encounter Data started.")
    # Set default value of sub-task status to 1
    label_6_status = 1
    label_6_sub.configure(text="In Progress (ED_Encounter)...", fg="blue")
    main_screen.update()
    # import tbl_ExcludedEncounters
    file_tbl_ExcludedEncounters = "./ExtractorDB/tbl_ExcludedEncounters.csv"
    if os.path.isfile(file_tbl_ExcludedEncounters):
        try:
            tbl_ExcludedEncounters = read_csv_file(
                file_tbl_ExcludedEncounters,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            label_6_status = 0
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_ExcludedEncounters from ./ExtractorDB/tbl_ExcludedEncounters.csv.\n"
                + str(e),
            )
            label_6_sub.configure(text="Failed (tbl_ExcludedEncounters)...", fg="red")
            main_screen.update()
            return
        else:
            tbl_ExcludedEncounters = tbl_ExcludedEncounters[
                [
                    "facility_identifier",
                    "stay_number",
                    "episode_sequence_number",
                    "ed_identifier",
                    "SNAP_encounter",
                    "ReasonForExclusion",
                    "EncounterNumber",
                ]
            ]
    else:
        tbl_ExcludedEncounters = pd.DataFrame()
    # import tbl_ppm_ED_Encounter_preclean
    file_tbl_ppm_ED_Encounter_preclean = "./ExtractorDB/PpmEdEncounterPreclean.csv"
    if os.path.isfile(file_tbl_ppm_ED_Encounter_preclean):
        try:
            tbl_ppm_ED_Encounter_preclean = read_csv_file(
                file_tbl_ppm_ED_Encounter_preclean,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            label_6_status = 0
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_ppm_ED_Encounter_preclean from ./ExtractorDB/PpmEdEncounterPreclean.csv.\n"
                + str(e),
            )
            label_6_sub.configure(
                text="Failed (tbl_ppm_ED_Encounter_preclean)...", fg="red"
            )
            main_screen.update()
            return
        else:
            tbl_ppm_ED_Encounter_preclean = tbl_ppm_ED_Encounter_preclean.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_ppm_ED_Encounter_preclean = tbl_ppm_ED_Encounter_preclean.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_ppm_ED_Encounter_preclean = tbl_ppm_ED_Encounter_preclean.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_ppm_ED_Encounter_preclean = tbl_ppm_ED_Encounter_preclean.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
    # import tbl_dbo_Facility
    file_tbl_dbo_Facility = "./ExtractorDB/OutputFacility.csv"
    if os.path.isfile(file_tbl_dbo_Facility):
        try:
            tbl_dbo_Facility = read_csv_file(
                file_tbl_dbo_Facility,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            label_6_status = 0
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_dbo_Facility from ./ExtractorDB/OutputFacility.csv.\n"
                + str(e),
            )
            label_6_sub.configure(text="Failed (tbl_dbo_Facility)...", fg="red")
            main_screen.update()
            return
        else:
            tbl_dbo_Facility = tbl_dbo_Facility.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_dbo_Facility = tbl_dbo_Facility.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_dbo_Facility = tbl_dbo_Facility.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_Facility = tbl_dbo_Facility.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_Facility.drop_duplicates(
                subset=[
                    "facility_identifier",
                    "area_identifier",
                    "facility_name",
                    "snap_upd_batch_run_no",
                ],
                keep="last",
                inplace=True,
            )
    # import ED_Diag_Slice
    file_ed_Diag_Slice = "./ExtractorDB/ED_Diag_Slice.csv"
    if os.path.isfile(file_ed_Diag_Slice):
        try:
            ed_Diag_Slice = read_csv_file(
                file_ed_Diag_Slice,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            label_6_status = 0
            messagebox.showerror(
                "File Error",
                "Error extracting ed_Diag_Slice from ./ExtractorDB/ED_Diag_Slice.csv.\n"
                + str(e),
            )
            label_6_sub.configure(text="Failed (ed_Diag_Slice)...", fg="red")
            main_screen.update()
            return
        else:
            ed_Diag_Slice = ed_Diag_Slice.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            ed_Diag_Slice = ed_Diag_Slice.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            ed_Diag_Slice = ed_Diag_Slice.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            ed_Diag_Slice = ed_Diag_Slice.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
            # 04 July - Ranjit - remove it
            ed_Diag_Slice.drop_duplicates(
                subset=["ed_visit_identifier", "facility_identifier"],
                keep="last",
                inplace=True,
            )
    # import tbl_EDRoleDelin
    file_tbl_EDRoleDelin = "./ExtractorDB/EDRoleDelin.csv"
    if os.path.isfile(file_tbl_EDRoleDelin):
        try:
            tbl_EDRoleDelin = read_csv_file(
                file_tbl_EDRoleDelin,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            label_6_status = 0
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_EDRoleDelin from ./ExtractorDB/EDRoleDelin.csv.\n"
                + str(e),
            )
            label_6_sub.configure(text="Failed (tbl_EDRoleDelin)...", fg="red")
            main_screen.update()
            return
        else:
            tbl_EDRoleDelin = tbl_EDRoleDelin.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_EDRoleDelin = tbl_EDRoleDelin.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_EDRoleDelin = tbl_EDRoleDelin.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_EDRoleDelin = tbl_EDRoleDelin.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
    # import ED_NWAU
    file_ed_NWAU = "./ExtractorDB/OutputEdNwau.csv"
    if os.path.isfile(file_ed_NWAU):
        try:
            ed_NWAU = read_csv_file(
                file_ed_NWAU,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            label_6_status = 0
            messagebox.showerror(
                "File Error",
                "Error extracting ED_NWAU from ./ExtractorDB/OutputEdNwau.csv.\n"
                + str(e),
            )
            label_6_sub.configure(text="Failed (ED_NWAU)...", fg="red")
            main_screen.update()
            return
        else:
            ed_NWAU = ed_NWAU.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            ed_NWAU = ed_NWAU.applymap(lambda x: x.strip() if isinstance(x, str) else x)
            ed_NWAU = ed_NWAU.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            ed_NWAU = ed_NWAU.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
            ed_NWAU.drop_duplicates(
                subset=["ed_visit_identifier", "facility_identifier"],
                keep="last",
                inplace=True,
            )
    # import tbl_ppm_ED_Patient
    file_tbl_ppm_ED_Patient = "./ExtractorDB/PpmEdPatient.csv"
    if os.path.isfile(file_tbl_ppm_ED_Patient):
        try:
            tbl_ppm_ED_Patient = read_csv_file(
                file_tbl_ppm_ED_Patient,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            label_6_status = 0
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_ppm_ED_Patient from ./ExtractorDB/PpmEdPatient.csv.\n"
                + str(e),
            )
            label_6_sub.configure(text="Failed (tbl_ppm_ED_Patient)...", fg="red")
            main_screen.update()
            return
        else:
            tbl_ppm_ED_Patient = tbl_ppm_ED_Patient.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_ppm_ED_Patient = tbl_ppm_ED_Patient.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_ppm_ED_Patient = tbl_ppm_ED_Patient.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_ppm_ED_Patient = tbl_ppm_ED_Patient.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
            # from Inform8 ExportEdPatientData
            tbl_ppm_ED_Patient.sort_values(by=["PatientNumber"], inplace=True)
            tbl_ppm_ED_Patient.drop_duplicates(
                subset=["PatientNumber"], keep="last", inplace=True
            )
    # import tbl_dbo_Ward_Episode
    file_tbl_dbo_Ward_Episode = "./ExtractorDB/OutputWardEpisode.csv"
    if os.path.isfile(file_tbl_dbo_Ward_Episode):
        try:
            tbl_dbo_Ward_Episode = read_csv_file(
                file_tbl_dbo_Ward_Episode,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            label_6_status = 0
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_dbo_Ward_Episode from ./ExtractorDB/OutputWardEpisode.csv.\n"
                + str(e),
            )
            label_6_sub.configure(text="Failed (tbl_dbo_Ward_Episode)...", fg="red")
            main_screen.update()
            return
        else:
            tbl_dbo_Ward_Episode = tbl_dbo_Ward_Episode.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_dbo_Ward_Episode = tbl_dbo_Ward_Episode.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_dbo_Ward_Episode = tbl_dbo_Ward_Episode.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_Ward_Episode = tbl_dbo_Ward_Episode.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
    # import tbl_PPM_Patient
    file_tbl_PPM_Patient = (
        "./ExtractorDB/tbl_PPM_IP_Patient_" + versionID_hash + ".csv"
    )  # "./ExtractorDB/tbl_PPM_Patient.csv"
    if os.path.isfile(file_tbl_PPM_Patient):
        try:
            tbl_PPM_Patient = read_csv_file(
                file_tbl_PPM_Patient,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            label_6_status = 0
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_PPM_Patient from ./ExtractorDB/tbl_PPM_Patient.csv.\n"
                + str(e),
            )
            label_6_sub.configure(text="Failed (tbl_PPM_Patient)...", fg="red")
            main_screen.update()
            return
        else:
            tbl_PPM_Patient = tbl_PPM_Patient.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_PPM_Patient = tbl_PPM_Patient.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_PPM_Patient = tbl_PPM_Patient.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_PPM_Patient = tbl_PPM_Patient.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
    # import tbl_PPM_Encounter
    file_tbl_PPM_Encounter = (
        "./Output/tbl_PPM_Encounter_" + versionID_underscore + ".csv"
    )  # "./ExtractorDB/tbl_PPM_Encounter.csv"
    if os.path.isfile(file_tbl_PPM_Encounter):
        try:
            tbl_PPM_Encounter = read_csv_file(
                file_tbl_PPM_Encounter,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            label_6_status = 0
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_PPM_Encounter from ./Output/tbl_PPM_Encounter_"
                + versionID_underscore
                + ".csv.\n"
                + str(e),
            )
            label_6_sub.configure(text="Failed (tbl_PPM_Encounter)...", fg="red")
            main_screen.update()
            return
        else:
            tbl_PPM_Encounter = tbl_PPM_Encounter.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_PPM_Encounter = tbl_PPM_Encounter.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_PPM_Encounter = tbl_PPM_Encounter.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_PPM_Encounter = tbl_PPM_Encounter.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
    # download tbl_Patient_Contact_Details
    if (
        lhd_global == "X830"
        or lhd_global == "X840"
        or lhd_global == "X850"
        or lhd_global == "X860"
        or lhd_global == "X740"
    ):
        file_tbl_Patient_Contact_Details = "./ExtractorDB/OutputPatient.csv"
    else:
        file_tbl_Patient_Contact_Details = "./ExtractorDB/Patient_contact_details.csv"
    if os.path.isfile(file_tbl_Patient_Contact_Details):
        try:
            tbl_Patient_Contact_Details = read_csv_file(
                file_tbl_Patient_Contact_Details,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            label_2_status = 0
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_Patient_Contact_Details from "
                + file_tbl_Patient_Contact_Details
                + ".\n"
                + str(e),
            )
            label_2_sub.configure(
                text="Failed (tbl_Patient_Contact_Details)...", fg="red"
            )
            main_screen.update()
            return
        else:
            tbl_Patient_Contact_Details = tbl_Patient_Contact_Details[
                [
                    "facility_identifier",
                    "area_identifier",
                    "person_area_uid",
                    "AUID",
                    "contact_identifier",
                    "mrn",
                ]
            ]
    else:
        tbl_Patient_Contact_Details = pd.DataFrame()
    """insert the encounter number in the tbl_ExcludedEncounters  for encounters with valid ed_visit_identifier"""
    # Access query: update tbl_excluded encounters ED Encounter
    # UPDATE tbl_ExcludedEncounters SET tbl_ExcludedEncounters.EncounterNumber = IIf([facility_identifier]="P202" And Len(Trim([ed_identifier]))>10,[facility_identifier] & "-E-" & [ed_identifier],IIf(Len(Trim([ed_identifier]))>=10,[facility_identifier] & "-" & "E" & "-" & Mid([ed_identifier],3,8),[facility_identifier] & "-" & "E" & "-" & Format$([ed_identifier],"00000000"))) WHERE (((tbl_ExcludedEncounters.Ed_identifier) Not Like "XX*"));
    # added check not Mode of Sep 99 Adminstrative Error
    tbl_ExcludedEncounters["ed_identifier"] = (
        tbl_ExcludedEncounters["ed_identifier"].astype(str).str.strip()
    )
    condlist = [
        (
            ~(
                tbl_ExcludedEncounters.ed_identifier.astype(str).str.startswith(("XX"))
                == True
            )
            & (tbl_ExcludedEncounters["facility_identifier"] == "P202")
            & (len(tbl_ExcludedEncounters["ed_identifier"]) > 10)
            & (
                tbl_ExcludedEncounters["ReasonForExclusion"]
                != "Mode of Sep 99 Adminstrative Error"
            )
        ),
        (
            ~(
                tbl_ExcludedEncounters.ed_identifier.astype(str).str.startswith(("XX"))
                == True
            )
            & (tbl_ExcludedEncounters["facility_identifier"] != "P202")
            & (len(tbl_ExcludedEncounters["ed_identifier"]) >= 10)
            & (
                tbl_ExcludedEncounters["ReasonForExclusion"]
                != "Mode of Sep 99 Adminstrative Error"
            )
        ),
        (
            ~(
                tbl_ExcludedEncounters.ed_identifier.astype(str).str.startswith(("XX"))
                == True
            )
            & (tbl_ExcludedEncounters["facility_identifier"] != "P202")
            & (len(tbl_ExcludedEncounters["ed_identifier"]) < 10)
            & (
                tbl_ExcludedEncounters["ReasonForExclusion"]
                != "Mode of Sep 99 Adminstrative Error"
            )
        ),
    ]
    choicelist = [
        tbl_ExcludedEncounters["facility_identifier"].astype(str).str.strip()
        + "-E-"
        + tbl_ExcludedEncounters["ed_identifier"].astype(str).str.strip(),
        tbl_ExcludedEncounters["facility_identifier"].astype(str).str.strip()
        + "-E-"
        + tbl_ExcludedEncounters["ed_identifier"].astype(str).str.slice(2, 10, 1),
        tbl_ExcludedEncounters["facility_identifier"].astype(str).str.strip()
        + "-E-"
        + tbl_ExcludedEncounters["ed_identifier"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0"),
    ]
    tbl_ExcludedEncounters["EncounterNumber"] = np.select(
        condlist, choicelist, tbl_ExcludedEncounters["EncounterNumber"]
    )
    tbl_ExcludedEncounters.drop_duplicates(keep="last", inplace=True)
    logging.info(
        "Query: update tbl_excluded encounters ED Encounter completed. tbl_ExcludedEncounters has %s records.",
        len(tbl_ExcludedEncounters),
    )
    """ Make a table ED_ENC_Latest which includes the maximum ed_visit_identifier (stu) for rows with same patientnumber startdatetime and endddattime and facility as there is duplicates in the tbl_ppm_ED_Encounter_preclean table """
    # Access query: Make-ED_ENC_Latest
    # SELECT tbl_ppm_ED_Encounter_preclean.PatientNumber, tbl_ppm_ED_Encounter_preclean.StartDateTime, Count(tbl_ppm_ED_Encounter_preclean.StartDateTime) AS CountOfStartDateTime, Max(tbl_ppm_ED_Encounter_preclean.Stu) AS MaxOfStu, tbl_ppm_ED_Encounter_preclean.Hospital INTO ED_ENC_Latest FROM tbl_ppm_ED_Encounter_preclean GROUP BY tbl_ppm_ED_Encounter_preclean.PatientNumber, tbl_ppm_ED_Encounter_preclean.StartDateTime, tbl_ppm_ED_Encounter_preclean.Hospital;
    ed_ENC_Latest = tbl_ppm_ED_Encounter_preclean[
        ["PatientNumber", "StartDateTime", "Stu", "Hospital"]
    ]
    ed_ENC_Latest = (
        ed_ENC_Latest.groupby(
            ["PatientNumber", "StartDateTime", "Hospital"], as_index=False, dropna=False
        )
        .agg(CountOfStartDateTime=("StartDateTime", "count"), MaxOfStu=("Stu", "max"))
        .reset_index()
    )
    ed_ENC_Latest = ed_ENC_Latest.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    ed_ENC_Latest = ed_ENC_Latest.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    ed_ENC_Latest = ed_ENC_Latest.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    ed_ENC_Latest.drop_duplicates(keep="last", inplace=True)
    ed_ENC_Latest = ed_ENC_Latest.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    try:
        ed_ENC_Latest.to_csv(
            "./ExtractorDB/ED_ENC_Latest.csv",
            index=False,
            na_rep="",
            float_format=str,
            decimal=str,
            date_format=str,
        )
    except Exception as e:
        logging.exception("Exception occurred")
        label_6_status = 0
        messagebox.showerror("Export Error", "Error saving ED_ENC_Latest\n" + str(e))
        label_6_sub.configure(text="Failed ()...", fg="red")
        main_screen.update()
        return  # stop export
    main_screen.update()
    logging.info(
        "Query: Make-ED_ENC_Latest completed. %s records saved to ./ExtractorDB/ED_ENC_Latest.csv.",
        len(ed_ENC_Latest),
    )
    """Updates invalid encounter numbers  in tbl_ppm_ED_Encounter_preclean with Left([EncounterNumber],7) & "00" & Right([Stu],7) """
    # Access query: UpdateENwdatesinEDEncounterExtract
    # UPDATE tbl_ppm_ED_Encounter_preclean SET tbl_ppm_ED_Encounter_preclean.EncounterNumber = Left([EncounterNumber],7) & "00" & Right([Stu],7) WHERE (((Right([EncounterNumber],8))=""));
    tbl_ppm_ED_Encounter_preclean["EncounterNumber"] = (
        tbl_ppm_ED_Encounter_preclean["EncounterNumber"].astype(str).str.strip()
    )
    tbl_ppm_ED_Encounter_preclean["Stu"] = (
        tbl_ppm_ED_Encounter_preclean["Stu"].astype(str).str.strip()
    )
    tbl_ppm_ED_Encounter_preclean["EncounterNumber"] = np.where(
        (tbl_ppm_ED_Encounter_preclean["EncounterNumber"].str[-8:] == "")
        | (tbl_ppm_ED_Encounter_preclean["EncounterNumber"].str[-8:].isnull()),
        tbl_ppm_ED_Encounter_preclean["EncounterNumber"].str[:7]
        + "00"
        + tbl_ppm_ED_Encounter_preclean["Stu"].str[-7:],
        tbl_ppm_ED_Encounter_preclean["EncounterNumber"],
    )
    tbl_ppm_ED_Encounter_preclean = tbl_ppm_ED_Encounter_preclean.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    tbl_ppm_ED_Encounter_preclean = tbl_ppm_ED_Encounter_preclean.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    tbl_ppm_ED_Encounter_preclean = tbl_ppm_ED_Encounter_preclean.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    tbl_ppm_ED_Encounter_preclean.drop_duplicates(keep="last", inplace=True)
    tbl_ppm_ED_Encounter_preclean = tbl_ppm_ED_Encounter_preclean.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    """
    try:
        tbl_ppm_ED_Encounter_preclean.to_csv('./ExtractorDB/tbl_ppm_ED_Encounter_preclean.csv', index=False, na_rep='', float_format=str, decimal=str, date_format=str)
    except Exception as e:
        logging.exception("Exception occurred")
        label_6_status = 0
        messagebox.showerror("Export Error","Error saving tbl_ppm_ED_Encounter_preclean\n"+str(e))
        label_6_sub.configure(text="Failed ()...",fg='red')
        main_screen.update()
        return # stop export
    main_screen.update()
    """
    logging.info(
        "Query: UpdateENwdatesinEDEncounterExtract completed. %s records saved to ./ExtractorDB/tbl_ppm_ED_Encounter_preclean.csv.",
        len(tbl_ppm_ED_Encounter_preclean),
    )
    """ Delete all data in the Tbl_excludedencounters_EDVisttype13 table"""
    # Access query: del Tbl_excludedencounters_EDVisttype13
    # DELETE tbl_ExcludedEncounters.[Reason For Exclusion] FROM tbl_ExcludedEncounters WHERE (((tbl_ExcludedEncounters.[Reason For Exclusion])="ED Visit Type 13 - Admitted Patient"));
    """
    index_names = tbl_ExcludedEncounters[(tbl_ExcludedEncounters['ReasonForExclusion'] == 'ED Visit Type 13 - Admitted Patient')].index
    tbl_ExcludedEncounters.drop(index_names, inplace = True)
    logging.info('Query: del Tbl_excludedencounters_EDVisttype13 completed. tbl_ExcludedEncounters now has %s records.',len(tbl_ExcludedEncounters))
    """
    """Appends data from the tbl_ppm_ED_Encounter_preclean as per appendix ED_NWAU table , eD_diag_SCT_slice and eD_diag _slice, tbl_EDRoleDelin when linked with the ED_ENC_Latest table and not in the tbl_ExcludedEncounters  """
    # Access query: Append_ENCOUNTER_ED_2ED_SNOW
    # INSERT INTO tbl_ppm_ED_Encounter ( EncounterNumber, PostCode, Suburb, EncounterType, PatientNumber, Hospital, LengthofStay, StartDateTime, EndDateTime, Age, WeightedSeparation, [Extra:InpatientStayNumber], [Extra:TriageCategory], [Extra:ModeofArrival], [Extra:EDVisitType], [Extra:EDDiagnosis], [Extra:ModeofSep], [Extra:EDTriageDateTime], [Extra:EDReferralSource], [Extra:IndigenousStatus], [Extra:MedicareNumber], [Extra:UDG], [Extra:ClinStartDTTM], [Extra:DepartureReadyDTTM], [Extra:EDDiagnosisType], [Extra:AdmWard], [Extra:EdCompStatus], [Extra:EmergRoleDelin], [Extra:nwau], [Extra:UDG_IPHA], [Extra:URG], [Extra:ED_Hosp_A233], [Extra:ED_visit_identifier], [Extra:Version_Id], [Extra:nwau_base], [Extra:nwau_indig_incr], [Extra:compensable_nwau], [Extra:nwau_urg_ed_diagnosis_mapped], [Extra:nwau_type], [Extra:MDB], [Extra:LHD_of_Usual_Residence], [Extra:nwau_version], DRG1, DRG1Version, [Extra:ExtractDate] )
    # SELECT tbl_ppm_ED_Encounter_preclean.EncounterNumber, tbl_ppm_ED_Encounter_preclean.PostCode, tbl_ppm_ED_Encounter_preclean.Suburb, tbl_ppm_ED_Encounter_preclean.EncounterType, tbl_ppm_ED_Encounter_preclean.PatientNumber, tbl_ppm_ED_Encounter_preclean.Hospital, tbl_ppm_ED_Encounter_preclean.LengthofStay, tbl_ppm_ED_Encounter_preclean.StartDateTime, tbl_ppm_ED_Encounter_preclean.EndDateTime, tbl_ppm_ED_Encounter_preclean.Age, tbl_ppm_ED_Encounter_preclean.WeightedSeparation, tbl_ppm_ED_Encounter_preclean.[Extra:InpatientStayNumber], tbl_ppm_ED_Encounter_preclean.[Extra:TriageCategory], tbl_ppm_ED_Encounter_preclean.[Extra:ModeofArrival], tbl_ppm_ED_Encounter_preclean.[Extra:EDVisitType], [ED_Diag_Slice]![ed_diagnosis_code] AS Expr1, tbl_ppm_ED_Encounter_preclean.[Extra:ModeofSep], tbl_ppm_ED_Encounter_preclean.[Extra:EDTriageDateTime], tbl_ppm_ED_Encounter_preclean.[Extra:EDReferralSource], tbl_ppm_ED_Encounter_preclean.[Extra:IndigenousStatus], tbl_ppm_ED_Encounter_preclean.[Extra:MedicareNumber], tbl_ppm_ED_Encounter_preclean.[Extra:UDG], tbl_ppm_ED_Encounter_preclean.[Extra:ClinStartDTTM], tbl_ppm_ED_Encounter_preclean.[Extra:DepartureReadyDTTM], ED_Diag_Slice.clinical_codeset, tbl_ppm_ED_Encounter_preclean.[Extra:AdmWard], tbl_ppm_ED_Encounter_preclean.[Extra:EdCompStatus], tbl_EDRoleDelin.EmergRoleDelin, IIf([tbl_EDRoleDelin]![EmergRoleDelin] In ("3B","4","5","6") And [URG] Not Like "E*",[nwau_final],[nwau_final_udg]) AS Expr6, ED_NWAU.UDG, ED_NWAU.URG, IIf([tbl_ppm_ED_Encounter_preclean]![Hospital] In ("A216","A231"),[tbl_ppm_ED_Encounter_preclean]![Hospital],Null) AS Expr5, "ED" & [Stu] AS Expr4, Replace([Forms]![Frm:1-ExtractSetUp]![fm_round],"V","") AS Expr2, IIf([tbl_EDRoleDelin]![EmergRoleDelin] In ("3B","4","5","6") And [URG] Not Like "E*",[nwau_base],[nwau_base_udg]) AS Expr7, IIf([tbl_EDRoleDelin]![EmergRoleDelin] In ("3A","4","5","6") And [URG] Not Like "E*",[indigenous_adj],[indigenous_adj_udg]) AS Expr8, IIf([tbl_EDRoleDelin]![EmergRoleDelin] In ("3A","4","5","6") And [URG] Not Like "E*",[compensable_nwau],[compensable_nwau_udg]) AS Expr9, ED_NWAU.nwau_urg_ed_diagnosis_mapped, IIf([tbl_EDRoleDelin]![EmergRoleDelin] In ("3B","4","5","6") And [URG] Not Like "E*","URG","UDG") AS Expr10, ED_NWAU.nwau_urg_mdb_value, tbl_ppm_ED_Encounter_preclean.[Extra:LHD_of_usual_residence], ED_NWAU.nwau_version, ED_NWAU.URG, IIf([nwau_version] Is Null,Null,Left([nwau_version],1) & "." & Right(Trim([nwau_version]),1)) AS Expr11, Format([getdate],"yyyy-mm-dd hh:nn:ss") AS Expr12
    # FROM tbl_ExcludedEncounters RIGHT JOIN (((((tbl_ppm_ED_Encounter_preclean INNER JOIN tbl_dbo_Facility ON tbl_ppm_ED_Encounter_preclean.Hospital = tbl_dbo_Facility.facility_identifier) LEFT JOIN ED_Diag_Slice ON (tbl_ppm_ED_Encounter_preclean.Hospital = ED_Diag_Slice.facility_identifier) AND (tbl_ppm_ED_Encounter_preclean.Stu = ED_Diag_Slice.ed_visit_identifier)) LEFT JOIN tbl_EDRoleDelin ON tbl_ppm_ED_Encounter_preclean.Hospital = tbl_EDRoleDelin.facility_identifier) INNER JOIN ED_ENC_Latest ON (tbl_ppm_ED_Encounter_preclean.PatientNumber = ED_ENC_Latest.PatientNumber) AND (tbl_ppm_ED_Encounter_preclean.StartDateTime = ED_ENC_Latest.StartDateTime) AND (tbl_ppm_ED_Encounter_preclean.Stu = ED_ENC_Latest.MaxOfStu) AND (tbl_ppm_ED_Encounter_preclean.Hospital = ED_ENC_Latest.Hospital)) LEFT JOIN ED_NWAU ON (tbl_ppm_ED_Encounter_preclean.Hospital = ED_NWAU.facility_identifier) AND (tbl_ppm_ED_Encounter_preclean.Stu = ED_NWAU.ed_visit_identifier)) ON tbl_ExcludedEncounters.EncounterNumber = tbl_ppm_ED_Encounter_preclean.EncounterNumber
    # GROUP BY tbl_ppm_ED_Encounter_preclean.EncounterNumber, tbl_ppm_ED_Encounter_preclean.PostCode, tbl_ppm_ED_Encounter_preclean.Suburb, tbl_ppm_ED_Encounter_preclean.EncounterType, tbl_ppm_ED_Encounter_preclean.PatientNumber, tbl_ppm_ED_Encounter_preclean.Hospital, tbl_ppm_ED_Encounter_preclean.LengthofStay, tbl_ppm_ED_Encounter_preclean.StartDateTime, tbl_ppm_ED_Encounter_preclean.EndDateTime, tbl_ppm_ED_Encounter_preclean.Age, tbl_ppm_ED_Encounter_preclean.WeightedSeparation, tbl_ppm_ED_Encounter_preclean.[Extra:InpatientStayNumber], tbl_ppm_ED_Encounter_preclean.[Extra:TriageCategory], tbl_ppm_ED_Encounter_preclean.[Extra:ModeofArrival], tbl_ppm_ED_Encounter_preclean.[Extra:EDVisitType], [ED_Diag_Slice]![ed_diagnosis_code], tbl_ppm_ED_Encounter_preclean.[Extra:ModeofSep], tbl_ppm_ED_Encounter_preclean.[Extra:EDTriageDateTime], tbl_ppm_ED_Encounter_preclean.[Extra:EDReferralSource], tbl_ppm_ED_Encounter_preclean.[Extra:IndigenousStatus], tbl_ppm_ED_Encounter_preclean.[Extra:MedicareNumber], tbl_ppm_ED_Encounter_preclean.[Extra:UDG], tbl_ppm_ED_Encounter_preclean.[Extra:ClinStartDTTM], tbl_ppm_ED_Encounter_preclean.[Extra:DepartureReadyDTTM], ED_Diag_Slice.clinical_codeset, tbl_ppm_ED_Encounter_preclean.[Extra:AdmWard], tbl_ppm_ED_Encounter_preclean.[Extra:EdCompStatus], tbl_EDRoleDelin.EmergRoleDelin, IIf([tbl_EDRoleDelin]![EmergRoleDelin] In ("3B","4","5","6") And [URG] Not Like "E*",[nwau_final],[nwau_final_udg]), ED_NWAU.UDG, IIf([tbl_ppm_ED_Encounter_preclean]![Hospital] In ("A216","A231"),[tbl_ppm_ED_Encounter_preclean]![Hospital],Null), "ED" & [Stu], Replace([Forms]![Frm:1-ExtractSetUp]![fm_round],"V",""), IIf([tbl_EDRoleDelin]![EmergRoleDelin] In ("3B","4","5","6") And [URG] Not Like "E*",[nwau_base],[nwau_base_udg]), IIf([tbl_EDRoleDelin]![EmergRoleDelin] In ("3A","4","5","6") And [URG] Not Like "E*",[indigenous_adj],[indigenous_adj_udg]), IIf([tbl_EDRoleDelin]![EmergRoleDelin] In ("3A","4","5","6") And [URG] Not Like "E*",[compensable_nwau],[compensable_nwau_udg]), ED_NWAU.nwau_urg_ed_diagnosis_mapped, IIf([tbl_EDRoleDelin]![EmergRoleDelin] In ("3B","4","5","6") And [URG] Not Like "E*","URG","UDG"), ED_NWAU.nwau_urg_mdb_value, tbl_ppm_ED_Encounter_preclean.[Extra:LHD_of_usual_residence], ED_NWAU.nwau_version, ED_NWAU.URG, IIf([nwau_version] Is Null,Null,Left([nwau_version],1) & "." & Right(Trim([nwau_version]),1)), Format([getdate],"yyyy-mm-dd hh:nn:ss"), DateValue([tbl_ppm_ED_Encounter_preclean]![StartDateTime]), DateValue([tbl_ppm_ED_Encounter_preclean]![EndDateTime]), ED_NWAU.URG, tbl_ExcludedEncounters.EncounterNumber
    # HAVING (((tbl_ppm_ED_Encounter_preclean.EndDateTime) Is Not Null And (tbl_ppm_ED_Encounter_preclean.EndDateTime)<>"") AND ((DateValue([tbl_ppm_ED_Encounter_preclean]![StartDateTime]))>=([Forms]![Frm:1-ExtractSetUp]![Start_Date])) AND ((tbl_ExcludedEncounters.EncounterNumber) Is Null)) OR (((tbl_ppm_ED_Encounter_preclean.EndDateTime) Is Not Null And (tbl_ppm_ED_Encounter_preclean.EndDateTime)<>"") AND ((DateValue([tbl_ppm_ED_Encounter_preclean]![StartDateTime]))<([Forms]![Frm:1-ExtractSetUp]![Start_Date])) AND ((DateValue([tbl_ppm_ED_Encounter_preclean]![EndDateTime]))<([Forms]![Frm:1-ExtractSetUp]![End_Date])) AND ((tbl_ExcludedEncounters.EncounterNumber) Is Null));
    # FROM
    df_query1 = pd.merge(
        tbl_ppm_ED_Encounter_preclean,
        tbl_dbo_Facility[["facility_identifier"]],
        how="inner",
        left_on=["Hospital"],
        right_on=["facility_identifier"],
        suffixes=("", "_drop"),
    )
    df_query1.drop_duplicates(keep="last", inplace=True)
    df_query1 = df_query1.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    df_query2 = pd.merge(
        df_query1,
        ed_Diag_Slice,
        how="left",
        left_on=["Hospital", "Stu"],
        right_on=["facility_identifier", "ed_visit_identifier"],
        suffixes=("", "_drop"),
    )
    df_query2 = df_query2.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    df_query2.drop_duplicates(keep="last", inplace=True)
    df_query3 = pd.merge(
        df_query2,
        tbl_EDRoleDelin[["EmergRoleDelin", "facility_identifier"]],
        how="left",
        left_on=["Hospital"],
        right_on=["facility_identifier"],
        suffixes=("", "_drop"),
    )
    df_query3 = df_query3.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    df_query3.drop_duplicates(keep="last", inplace=True)
    df_query4 = pd.merge(
        df_query3,
        ed_ENC_Latest[["PatientNumber", "StartDateTime", "MaxOfStu", "Hospital"]],
        how="inner",
        left_on=["PatientNumber", "StartDateTime", "Stu", "Hospital"],
        right_on=["PatientNumber", "StartDateTime", "MaxOfStu", "Hospital"],
        suffixes=("", "_drop"),
    )
    df_query4 = df_query4.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    df_query4.drop_duplicates(keep="last", inplace=True)
    df_query5 = pd.merge(
        df_query4,
        ed_NWAU,
        how="left",
        left_on=["Stu", "Hospital"],
        right_on=["ed_visit_identifier", "facility_identifier"],
        suffixes=("", "_drop"),
    )
    df_query5 = df_query5.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    df_query5.drop_duplicates(keep="last", inplace=True)
    tbl_ExcludedEncounters_dummy = tbl_ExcludedEncounters.copy()
    tbl_ExcludedEncounters_dummy["EncounterNumber_dummy"] = (
        tbl_ExcludedEncounters_dummy["EncounterNumber"]
    )
    tbl_ppm_ED_Encounter = pd.merge(
        tbl_ExcludedEncounters_dummy[["EncounterNumber_dummy"]],
        df_query5,
        how="right",
        left_on=["EncounterNumber_dummy"],
        right_on=["EncounterNumber"],
        suffixes=("", "_drop"),
        indicator=True,
    )
    tbl_ppm_ED_Encounter = tbl_ppm_ED_Encounter[
        tbl_ppm_ED_Encounter["_merge"] == "right_only"
    ]
    tbl_ppm_ED_Encounter.drop_duplicates(keep="last", inplace=True)
    tbl_ppm_ED_Encounter = tbl_ppm_ED_Encounter.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    tbl_ppm_ED_Encounter["Extra:AUID"] = (
        tbl_ppm_ED_Encounter["person_area_uid"].astype(str).str.replace("nan", "")
    )
    """
    tbl_ppm_ED_Encounter['EncounterNumber'] = tbl_ppm_ED_Encounter['EncounterNumber']
    tbl_ppm_ED_Encounter['PostCode'] = tbl_ppm_ED_Encounter['PostCode']
    tbl_ppm_ED_Encounter['Suburb'] = tbl_ppm_ED_Encounter['Suburb']
    tbl_ppm_ED_Encounter['EncounterType'] = tbl_ppm_ED_Encounter['EncounterType']
    tbl_ppm_ED_Encounter['PatientNumber'] = tbl_ppm_ED_Encounter['PatientNumber']
    tbl_ppm_ED_Encounter['Hospital'] = tbl_ppm_ED_Encounter['Hospital']
    tbl_ppm_ED_Encounter['LengthofStay'] = tbl_ppm_ED_Encounter['LengthofStay']
    tbl_ppm_ED_Encounter['StartDateTime'] = tbl_ppm_ED_Encounter['StartDateTime']
    tbl_ppm_ED_Encounter['EndDateTime'] = tbl_ppm_ED_Encounter['EndDateTime']
    tbl_ppm_ED_Encounter['Age'] = tbl_ppm_ED_Encounter['Age']
    tbl_ppm_ED_Encounter['WeightedSeparation'] = tbl_ppm_ED_Encounter['WeightedSeparation']
    tbl_ppm_ED_Encounter['Extra:EDVisitType'] = tbl_ppm_ED_Encounter['Extra:EDVisitType']
    tbl_ppm_ED_Encounter['Extra:ModeofSep'] = tbl_ppm_ED_Encounter['Extra:ModeofSep']
    """
    tbl_ppm_ED_Encounter["Extra:InpatientStayNumber"] = tbl_ppm_ED_Encounter[
        "Extra_InpatientStayNumber"
    ]
    tbl_ppm_ED_Encounter["Extra:ModeofArrival"] = tbl_ppm_ED_Encounter[
        "Extra_ModeofArrival"
    ]
    tbl_ppm_ED_Encounter["Extra:EDTriageDateTime"] = tbl_ppm_ED_Encounter[
        "Extra_EDTriageDateTime"
    ]
    tbl_ppm_ED_Encounter["Extra:EDReferralSource"] = tbl_ppm_ED_Encounter[
        "Extra_EDReferralSource"
    ]
    tbl_ppm_ED_Encounter["Extra:IndigenousStatus"] = tbl_ppm_ED_Encounter[
        "Extra_IndigenousStatus"
    ]
    tbl_ppm_ED_Encounter["Extra:MedicareNumber"] = tbl_ppm_ED_Encounter[
        "Extra_MedicareNumber"
    ]
    tbl_ppm_ED_Encounter["Extra:UDG"] = tbl_ppm_ED_Encounter["Extra_UDG"]
    tbl_ppm_ED_Encounter["Extra:ClinStartDTTM"] = tbl_ppm_ED_Encounter[
        "Extra_ClinStartDTTM"
    ]
    tbl_ppm_ED_Encounter["Extra:DepartureReadyDTTM"] = tbl_ppm_ED_Encounter[
        "Extra_DepartureReadyDTTM"
    ]
    tbl_ppm_ED_Encounter["Extra:AdmWard"] = tbl_ppm_ED_Encounter["Extra_AdmWard"]
    tbl_ppm_ED_Encounter["Extra:EdCompStatus"] = tbl_ppm_ED_Encounter[
        "Extra_EdCompStatus"
    ]
    tbl_ppm_ED_Encounter["Extra:nwau_urg_ed_diagnosis_mapped"] = tbl_ppm_ED_Encounter[
        "nwau_urg_ed_diagnosis_mapped"
    ]
    tbl_ppm_ED_Encounter["Extra:LHD_of_Usual_Residence"] = tbl_ppm_ED_Encounter[
        "Extra_LHD_of_usual_residence"
    ]
    tbl_ppm_ED_Encounter["nwau_version"] = (
        tbl_ppm_ED_Encounter["nwau_version"].astype(str).str.strip()
    )
    tbl_ppm_ED_Encounter["Extra:EmergRoleDelin"] = tbl_ppm_ED_Encounter[
        "EmergRoleDelin"
    ]
    tbl_ppm_ED_Encounter["Extra:nwau"] = np.where(
        tbl_ppm_ED_Encounter["EmergRoleDelin"].isin(["3B", "4", "5", "6"])
        & ~(tbl_ppm_ED_Encounter.URG.astype(str).str.startswith(("E")) == True),
        tbl_ppm_ED_Encounter["nwau_final"],
        tbl_ppm_ED_Encounter["nwau_final_UDG"],
    )
    tbl_ppm_ED_Encounter["Extra:UDG_IPHA"] = tbl_ppm_ED_Encounter["UDG"]
    tbl_ppm_ED_Encounter["Extra:URG"] = tbl_ppm_ED_Encounter["URG"]
    tbl_ppm_ED_Encounter["Extra:ED_Hosp_A233"] = np.where(
        tbl_ppm_ED_Encounter["Hospital"].isin(["A216", "A231"]),
        tbl_ppm_ED_Encounter["Hospital"],
        "",
    )
    tbl_ppm_ED_Encounter["Extra:ED_visit_identifier"] = "ED" + tbl_ppm_ED_Encounter[
        "Stu"
    ].astype(str)
    """tbl_ppm_ED_Encounter['Extra:Version_Id'] = versionID_dot #
    tbl_ppm_ED_Encounter['Extra:Version_Id'] = tbl_ppm_ED_Encounter['Extra:Version_Id'].astype(str).str.replace('V','')
    tbl_ppm_ED_Encounter['Extra:Version_Id'] = tbl_ppm_ED_Encounter['Extra:Version_Id'].astype(str).str.replace('V' ,'')"""
    tbl_ppm_ED_Encounter["Extra:ExtractorVersion"] = "1.17"
    tbl_ppm_ED_Encounter["Extra:nwau_base"] = np.where(
        tbl_ppm_ED_Encounter["EmergRoleDelin"].isin(["3B", "4", "5", "6"])
        & ~(tbl_ppm_ED_Encounter.URG.astype(str).str.startswith(("E")) == True),
        tbl_ppm_ED_Encounter["nwau_base"],
        tbl_ppm_ED_Encounter["nwau_base_UDG"],
    )
    tbl_ppm_ED_Encounter["Extra:nwau_indig_incr"] = np.where(
        tbl_ppm_ED_Encounter["EmergRoleDelin"].isin(["3B", "4", "5", "6"])
        & ~(tbl_ppm_ED_Encounter.URG.astype(str).str.startswith(("E")) == True),
        tbl_ppm_ED_Encounter["indigenous_adj"],
        tbl_ppm_ED_Encounter["indigenous_adj_UDG"],
    )
    tbl_ppm_ED_Encounter["Extra:compensable_nwau"] = np.where(
        tbl_ppm_ED_Encounter["EmergRoleDelin"].isin(["3A", "4", "5", "6"])
        & ~(tbl_ppm_ED_Encounter.URG.astype(str).str.startswith(("E")) == True),
        tbl_ppm_ED_Encounter["compensable_nwau"],
        tbl_ppm_ED_Encounter["compensable_nwau_UDG"],
    )
    tbl_ppm_ED_Encounter["Extra:nwau_type"] = np.where(
        tbl_ppm_ED_Encounter["EmergRoleDelin"].isin(["3B", "4", "5", "6"])
        & ~(tbl_ppm_ED_Encounter.URG.astype(str).str.startswith(("E")) == True),
        "URG",
        "UDG",
    )
    tbl_ppm_ED_Encounter["Extra:MDB"] = tbl_ppm_ED_Encounter["nwau_urg_mdb_value"]
    tbl_ppm_ED_Encounter["Extra:nwau_version"] = tbl_ppm_ED_Encounter["nwau_version"]
    tbl_ppm_ED_Encounter["DRG1"] = tbl_ppm_ED_Encounter["URG"]
    tbl_ppm_ED_Encounter["DRG1Version"] = np.where(
        (tbl_ppm_ED_Encounter["nwau_version"].isnull())
        | (tbl_ppm_ED_Encounter["nwau_version"] == ""),
        "",
        tbl_ppm_ED_Encounter["nwau_version"].astype(str).str[:1]
        + "."
        + tbl_ppm_ED_Encounter["nwau_version"].astype(str).str[-1:],
    )
    # tbl_ppm_ED_Encounter['Extra:ExtractDate'] = pd.to_datetime(pd.Timestamp.today()) #pd.to_datetime(date.today(), errors='coerce', format="%Y-%m-%d")
    tbl_ppm_ED_Encounter["Extra:ExtractDate"] = (
        pd.Timestamp.today()
    )  # pd.to_datetime(date.today(), errors='coerce', format="%Y-%m-%d")
    tbl_ppm_ED_Encounter["Extra:ExtractDate"] = pd.to_datetime(
        tbl_ppm_ED_Encounter["Extra:ExtractDate"].astype(str).str[:19],
        errors="coerce",
        format="%Y-%m-%d %H:%M:%S",
    )
    tbl_ppm_ED_Encounter["Extra:EDDiagnosis"] = tbl_ppm_ED_Encounter[
        "ed_diagnosis_code"
    ]
    tbl_ppm_ED_Encounter["Extra:EDDiagnosisType"] = tbl_ppm_ED_Encounter[
        "clinical_codeset"
    ]
    tbl_ppm_ED_Encounter["Extra:EDDiagnosis2"] = tbl_ppm_ED_Encounter[
        "ed_diagnosis_code2"
    ]
    tbl_ppm_ED_Encounter["Extra:EDDiagnosisType2"] = tbl_ppm_ED_Encounter[
        "ed_diagnosis_type2"
    ]
    tbl_ppm_ED_Encounter["Extra:EDDiagnosis3"] = tbl_ppm_ED_Encounter[
        "ed_diagnosis_code3"
    ]
    tbl_ppm_ED_Encounter["Extra:EDDiagnosisType3"] = tbl_ppm_ED_Encounter[
        "ed_diagnosis_type3"
    ]
    # for silly groupby when already 'StartDateTime', 'EndDateTime',  are in groupby
    tbl_ppm_ED_Encounter["StartDateTime_dummy"] = (
        tbl_ppm_ED_Encounter["StartDateTime"].astype(str).str[:10]
    )
    tbl_ppm_ED_Encounter["EndDateTime_dummy"] = (
        tbl_ppm_ED_Encounter["EndDateTime"].astype(str).str[:10]
    )
    tbl_ppm_ED_Encounter["start_date_dt"] = pd.to_datetime(
        start_date, errors="coerce", format="%Y-%m-%d %H:%M:%S"
    )
    tbl_ppm_ED_Encounter["end_date_dt"] = pd.to_datetime(
        end_date, errors="coerce", format="%Y-%m-%d %H:%M:%S"
    )
    tbl_ppm_ED_Encounter["Extra:HLTH_ORG_OSP_OSP_ID"] = tbl_ppm_ED_Encounter[
        "HLTH_ORG_OSP_OSP_ID"
    ]
    tbl_ppm_ED_Encounter["Extra:MG_AUTH_OSP_OSP_ID"] = tbl_ppm_ED_Encounter[
        "MG_AUTH_OSP_OSP_ID"
    ]
    tbl_ppm_ED_Encounter["Extra:SE_CBK_SK"] = tbl_ppm_ED_Encounter["SE_CBK_SK"]
    tbl_ppm_ED_Encounter["Extra:CL_ID_EUID"] = tbl_ppm_ED_Encounter["CL_ID_EUID"]
    tbl_ppm_ED_Encounter["Extra:CL_ID_IHI"] = tbl_ppm_ED_Encounter["CL_ID_IHI"]
    tbl_ppm_ED_Encounter["Extra:FST_BILL_CATEGORY_CD"] = tbl_ppm_ED_Encounter[
        "FST_BILL_CATEGORY_CD"
    ]
    tbl_ppm_ED_Encounter["Extra:EDW_Pat_Number"] = tbl_ppm_ED_Encounter[
        "EDW_Pat_Number"
    ]
    tbl_ppm_ED_Encounter["Extra:EDW_Enc_Number"] = tbl_ppm_ED_Encounter[
        "EDW_Enc_Number"
    ]
    tbl_ppm_ED_Encounter["Extra:SRV_ENC_REC_ID"] = tbl_ppm_ED_Encounter[
        "SRV_ENC_REC_ID"
    ]
    tbl_ppm_ED_Encounter["Extra:FST_FIN_CLASS_CD"] = tbl_ppm_ED_Encounter[
        "FST_FIN_CLASS_CD"
    ]
    tbl_ppm_ED_Encounter["Extra:WAU_ADJ_PT_TX_REMT_AREA"] = tbl_ppm_ED_Encounter[
        "WAU_ADJ_PT_TX_REMT_AREA"
    ]
    tbl_ppm_ED_Encounter["Extra:EDDiag_ver"] = tbl_ppm_ED_Encounter["EDDiag_ver"]
    tbl_ppm_ED_Encounter["Extra:EDINTERVENTION_VER"] = tbl_ppm_ED_Encounter[
        "EDINTERVENTION_VER"
    ]
    tbl_ppm_ED_Encounter["Extra:EDINTERVENTION_CD"] = tbl_ppm_ED_Encounter[
        "EDINTERVENTION_CD"
    ]
    tbl_ppm_ED_Encounter["Extra:WAU_ADJ_PT_RES_REMT_AREA"] = tbl_ppm_ED_Encounter[
        "remoteness_area_adj"
    ]
    tbl_ppm_ED_Encounter["Extra:ASGS_SA_L2_16_CD"] = tbl_ppm_ED_Encounter[
        "ASGS_SA_L2_16_CD"
    ]
    tbl_ppm_ED_Encounter["Extra:CL_URES_ADDR_ASGS21_SA_L2_CD"] = tbl_ppm_ED_Encounter[
        "CL_URES_ADDR_ASGS21_SA_L2_CD"
    ]
    tbl_ppm_ED_Encounter["Extra:AP_SE_CBK_SK"] = tbl_ppm_ED_Encounter["AP_SE_CBK_SK"]
    tbl_ppm_ED_Encounter["Extra:IP_SRV_ENC_REC_ID"] = tbl_ppm_ED_Encounter[
        "IP_SRV_ENC_REC_ID"
    ]
    # HAVING (((tbl_ppm_ED_Encounter_preclean.EndDateTime) Is Not Null And (tbl_ppm_ED_Encounter_preclean.EndDateTime)<>"") AND ((DateValue([tbl_ppm_ED_Encounter_preclean]![StartDateTime]))>=([Forms]![Frm:1-ExtractSetUp]![Start_Date])) AND ((tbl_ExcludedEncounters.EncounterNumber) Is Null)) OR (((tbl_ppm_ED_Encounter_preclean.EndDateTime) Is Not Null And (tbl_ppm_ED_Encounter_preclean.EndDateTime)<>"") AND ((DateValue([tbl_ppm_ED_Encounter_preclean]![StartDateTime]))<([Forms]![Frm:1-ExtractSetUp]![Start_Date])) AND ((DateValue([tbl_ppm_ED_Encounter_preclean]![EndDateTime]))<([Forms]![Frm:1-ExtractSetUp]![End_Date])) AND ((tbl_ExcludedEncounters.EncounterNumber) Is Null))
    # Commenting this. to include null end date encounters
    """tbl_ppm_ED_Encounter = tbl_ppm_ED_Encounter[(((tbl_ppm_ED_Encounter['EndDateTime'].astype(str).str[:19]!='') & (pd.notna(tbl_ppm_ED_Encounter['EndDateTime']))) & \
    (pd.to_datetime(tbl_ppm_ED_Encounter['StartDateTime'].astype(str).str[:19], errors='coerce', format="%Y-%m-%d %H:%M:%S") >= tbl_ppm_ED_Encounter['start_date_dt']) & ((tbl_ppm_ED_Encounter['EncounterNumber_dummy'].isnull()) | (tbl_ppm_ED_Encounter['EncounterNumber_dummy']==''))) | \
    (((tbl_ppm_ED_Encounter['EndDateTime'].astype(str).str[:19]!='') & (pd.notna(tbl_ppm_ED_Encounter['EndDateTime']))) & (pd.to_datetime(tbl_ppm_ED_Encounter['StartDateTime'].astype(str).str[:19], errors='coerce', format="%Y-%m-%d %H:%M:%S") < tbl_ppm_ED_Encounter['start_date_dt']) & \
    (pd.to_datetime(tbl_ppm_ED_Encounter['EndDateTime'].astype(str).str[:19], errors='coerce', format="%Y-%m-%d %H:%M:%S") < tbl_ppm_ED_Encounter['end_date_dt']) & ((tbl_ppm_ED_Encounter['EncounterNumber_dummy'].isnull()) | (tbl_ppm_ED_Encounter['EncounterNumber_dummy']=='')))]"""
    tbl_ExcludedEncounters_list = tbl_ExcludedEncounters[
        "EncounterNumber"
    ].values.tolist()
    tbl_ppm_ED_Encounter = tbl_ppm_ED_Encounter[
        ~tbl_ppm_ED_Encounter["EncounterNumber"].isin(tbl_ExcludedEncounters_list)
    ]
    tbl_ppm_ED_Encounter.sort_values(
        by=[
            "EncounterNumber",
            "PostCode",
            "Suburb",
            "EncounterType",
            "PatientNumber",
            "Hospital",
            "LengthofStay",
            "StartDateTime",
            "EndDateTime",
            "Age",
            "WeightedSeparation",
            "Extra:InpatientStayNumber",
            "Extra:TriageCategory",
            "Extra:ModeofArrival",
            "Extra:EDVisitType",
            "Extra:EDDiagnosis",
            "Extra:ModeofSep",
            "Extra:EDTriageDateTime",
            "Extra:EDReferralSource",
            "Extra:IndigenousStatus",
            "Extra:MedicareNumber",
            "Extra:UDG",
            "Extra:ClinStartDTTM",
            "Extra:DepartureReadyDTTM",
            "Extra:EDDiagnosisType",
            "Extra:AdmWard",
            "Extra:EdCompStatus",
            "Extra:EmergRoleDelin",
            "Extra:nwau",
            "Extra:UDG_IPHA",
            "Extra:URG",
            "Extra:ED_Hosp_A233",
            "Extra:ED_visit_identifier",
            "Extra:ExtractorVersion",
            "Extra:nwau_base",
            "Extra:nwau_indig_incr",
            "Extra:compensable_nwau",
            "Extra:nwau_urg_ed_diagnosis_mapped",
            "Extra:nwau_type",
            "Extra:MDB",
            "Extra:LHD_of_Usual_Residence",
            "Extra:nwau_version",
            "DRG1",
            "DRG1Version",
            "Extra:ExtractDate",
            "Extra:WAU_ADJ_PT_TX_REMT_AREA",
            "Extra:WAU_ADJ_PT_RES_REMT_AREA",
            "Extra:EDDiag_ver",
            "Extra:EDINTERVENTION_VER",
            "Extra:EDINTERVENTION_CD",
            "Extra:ASGS_SA_L2_16_CD",
            "Extra:CL_URES_ADDR_ASGS21_SA_L2_CD",
            "Extra:AP_SE_CBK_SK",
            "Extra:IP_SRV_ENC_REC_ID",
        ],
        inplace=True,
    )
    tbl_ppm_ED_Encounter.drop_duplicates(
        subset=[
            "EncounterNumber",
            "PostCode",
            "Suburb",
            "EncounterType",
            "PatientNumber",
            "Hospital",
            "LengthofStay",
            "StartDateTime",
            "EndDateTime",
            "Age",
            "WeightedSeparation",
            "Extra:InpatientStayNumber",
            "Extra:TriageCategory",
            "Extra:ModeofArrival",
            "Extra:EDVisitType",
            "Extra:EDDiagnosis",
            "Extra:ModeofSep",
            "Extra:EDTriageDateTime",
            "Extra:EDReferralSource",
            "Extra:IndigenousStatus",
            "Extra:MedicareNumber",
            "Extra:UDG",
            "Extra:ClinStartDTTM",
            "Extra:DepartureReadyDTTM",
            "Extra:EDDiagnosisType",
            "Extra:AdmWard",
            "Extra:EdCompStatus",
            "Extra:EmergRoleDelin",
            "Extra:nwau",
            "Extra:UDG_IPHA",
            "Extra:URG",
            "Extra:ED_Hosp_A233",
            "Extra:ED_visit_identifier",
            "Extra:ExtractorVersion",
            "Extra:nwau_base",
            "Extra:nwau_indig_incr",
            "Extra:compensable_nwau",
            "Extra:nwau_urg_ed_diagnosis_mapped",
            "Extra:nwau_type",
            "Extra:MDB",
            "Extra:LHD_of_Usual_Residence",
            "Extra:nwau_version",
            "DRG1",
            "DRG1Version",
            "Extra:ExtractDate",
            "Extra:AUID",
        ],
        keep="last",
        inplace=True,
    )
    tbl_ppm_ED_Encounter = tbl_ppm_ED_Encounter[
        [
            "EncounterNumber",
            "PostCode",
            "Suburb",
            "EncounterType",
            "PatientNumber",
            "Hospital",
            "LengthofStay",
            "StartDateTime",
            "EndDateTime",
            "Age",
            "WeightedSeparation",
            "Extra:InpatientStayNumber",
            "Extra:TriageCategory",
            "Extra:ModeofArrival",
            "Extra:EDVisitType",
            "Extra:EDDiagnosis",
            "Extra:ModeofSep",
            "Extra:EDTriageDateTime",
            "Extra:EDReferralSource",
            "Extra:IndigenousStatus",
            "Extra:MedicareNumber",
            "Extra:UDG",
            "Extra:ClinStartDTTM",
            "Extra:DepartureReadyDTTM",
            "Extra:EDDiagnosisType",
            "Extra:EDDiagnosis2",
            "Extra:EDDiagnosisType2",
            "Extra:EDDiagnosis3",
            "Extra:EDDiagnosisType3",
            "Extra:AdmWard",
            "Extra:EdCompStatus",
            "Extra:EmergRoleDelin",
            "Extra:nwau",
            "Extra:UDG_IPHA",
            "Extra:URG",
            "Extra:ED_Hosp_A233",
            "Extra:ED_visit_identifier",
            "Extra:ExtractorVersion",
            "Extra:nwau_base",
            "Extra:nwau_indig_incr",
            "Extra:compensable_nwau",
            "Extra:nwau_urg_ed_diagnosis_mapped",
            "Extra:nwau_type",
            "Extra:MDB",
            "Extra:LHD_of_Usual_Residence",
            "Extra:nwau_version",
            "DRG1",
            "DRG1Version",
            "Extra:ExtractDate",
            "Extra:AUID",
            "Extra:HLTH_ORG_OSP_OSP_ID",
            "Extra:MG_AUTH_OSP_OSP_ID",
            "Extra:SE_CBK_SK",
            "Extra:CL_ID_EUID",
            "Extra:CL_ID_IHI",
            "Extra:FST_BILL_CATEGORY_CD",
            "Extra:FST_FIN_CLASS_CD",
            "Extra:EDW_Pat_Number",
            "Extra:EDW_Enc_Number",
            "Extra:SRV_ENC_REC_ID",
            "Extra:WAU_ADJ_PT_TX_REMT_AREA",
            "Extra:WAU_ADJ_PT_RES_REMT_AREA",
            "Extra:EDDiag_ver",
            "Extra:EDINTERVENTION_VER",
            "Extra:EDINTERVENTION_CD",
            "Extra:ASGS_SA_L2_16_CD",
            "Extra:CL_URES_ADDR_ASGS21_SA_L2_CD",
            "Extra:AP_SE_CBK_SK",
            "Extra:IP_SRV_ENC_REC_ID",
        ]
    ]
    tbl_ppm_ED_Encounter.drop_duplicates(keep="last", inplace=True)
    logging.info(
        "After deleting duplicates, tbl_ppm_ED_Encounter now has %s records.",
        len(tbl_ppm_ED_Encounter),
    )
    logging.info(
        "Query: Append_ENCOUNTER_ED_2ED_SNOW completed. tbl_ppm_ED_Encounter now has %s records.",
        len(tbl_ppm_ED_Encounter),
    )
    tbl_ppm_ED_Encounter.to_csv(
        "./ExtractorDB/tbl_ppm_ED_Encounter_Append_ENCOUNTER_ED_2ED_SNOW.csv",
        index=False,
    )
    """ Where the ed patient is not in the ED Encounter file the patient number is updated to the word delete"""
    # Access query: qry update ed patients not linked to ed encounters (inform8: ExportEDEncounterData -> RemoveFromTbl_ppm_ED_Patient_allPatientsWithoutAnED_Encounter)
    # UPDATE tbl_ppm_ED_Encounter RIGHT JOIN tbl_ppm_ED_Patient ON tbl_ppm_ED_Encounter.PatientNumber = tbl_ppm_ED_Patient.PatientNumber SET tbl_ppm_ED_Patient.PatientNumber = "delete" WHERE (((tbl_ppm_ED_Encounter.PatientNumber) Is Null));
    """
    tbl_ppm_ED_Encounter_list = tbl_ppm_ED_Encounter['PatientNumber'].values.tolist()
    logging.info('Query: qry update ed patients not linked to ed encounters completed. %s records marked for DELETE in tbl_ppm_ED_Patient. tbl_ppm_ED_Patient has %s records.', len(tbl_ppm_ED_Patient[~tbl_ppm_ED_Patient['PatientNumber'].isin(tbl_ppm_ED_Encounter_list)]),len(tbl_ppm_ED_Patient))
    tbl_ppm_ED_Patient['PatientNumber'] = np.where(~tbl_ppm_ED_Patient['PatientNumber'].isin(tbl_ppm_ED_Encounter_list), 'delete', tbl_ppm_ED_Patient['PatientNumber'])
    """
    tbl_ppm_ED_Encounter["PatientNumber_dummy"] = tbl_ppm_ED_Encounter["PatientNumber"]
    tbl_ppm_ED_Patient = pd.merge(
        tbl_ppm_ED_Encounter[["PatientNumber", "PatientNumber_dummy"]],
        tbl_ppm_ED_Patient,
        how="right",
        on=["PatientNumber"],
        suffixes=("", "_drop"),
        indicator=True,
    )
    tbl_ppm_ED_Patient["Reason"] = np.where(
        tbl_ppm_ED_Patient["_merge"] == "right_only",
        "ED Patient is not in ED Encounter",
        "",
    )
    tbl_ppm_ED_Patient[tbl_ppm_ED_Patient["_merge"] == "right_only"][
        [
            "PatientNumber",
            "Gender",
            "indigenous_status",
            "EthnicOrigin",
            "DateOfBirth",
            "Reason",
        ]
    ].to_csv(
        "./ExtractorDB/tbl_PPM_ED_Patient_marked_for_delete.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    tbl_ppm_ED_Patient["PatientNumber"] = np.where(
        tbl_ppm_ED_Patient["_merge"] == "right_only",
        "delete",
        tbl_ppm_ED_Patient["PatientNumber"],
    )
    tbl_ppm_ED_Patient.drop(
        ["PatientNumber_dummy", "Reason", "_merge"],
        inplace=True,
        axis=1,
        errors="ignore",
    )
    tbl_ppm_ED_Encounter.drop(
        ["PatientNumber_dummy"], inplace=True, axis=1, errors="ignore"
    )
    logging.info(
        "Query: qry update ed patients not linked to ed encounters completed. tbl_ppm_ED_Patient has %s records marked for delete.",
        len(tbl_ppm_ED_Patient[tbl_ppm_ED_Patient["PatientNumber"] == "delete"]),
    )
    """Deletes all patients in tbl_PPm_ed_patient table where patientnumber = delete """
    # Access query: qry delete ed patients not linked to ed encounters
    # DELETE tbl_ppm_ED_Patient.PatientNumber FROM tbl_ppm_ED_Patient WHERE (((tbl_ppm_ED_Patient.PatientNumber)="delete"));
    """file_tbl_ppm_ED_Patient = "./ExtractorDB/PpmEdPatient.csv"
    if os.path.isfile(file_tbl_ppm_ED_Patient):
        try:
            tbl_ppm_ED_Patient = read_csv_file(file_tbl_ppm_ED_Patient, encoding = 'unicode_escape', dtype=str, keep_default_na=False, na_values='')
        except Exception as e:
            logging.exception("Exception occurred")
            label_6_status = 0
            messagebox.showerror("File Error","Error extracting tbl_ppm_ED_Patient from ./ExtractorDB/PpmEdPatient.csv.\n"+str(e))
            label_6_sub.configure(text="Failed (tbl_ppm_ED_Patient)...",fg='red')
            main_screen.update()
            return
    else:
        tbl_ppm_ED_Patient = pd.DataFrame(columns=['PatientNumber', 'Gender', 'indigenous_status', 'EthnicOrigin', 'DateOfBirth', 'mrn_for_matching'])"""
    index_names = tbl_ppm_ED_Patient[
        (tbl_ppm_ED_Patient["PatientNumber"] == "delete")
    ].index
    tbl_ppm_ED_Patient.drop(index_names, inplace=True)
    tbl_ppm_ED_Patient.drop_duplicates(keep="last", inplace=True)
    tbl_ppm_ED_Patient = tbl_ppm_ED_Patient[
        tbl_ppm_ED_Patient["PatientNumber"] != "delete"
    ]
    tbl_ppm_ED_Patient = tbl_ppm_ED_Patient.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    tbl_ppm_ED_Patient = tbl_ppm_ED_Patient.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    tbl_ppm_ED_Patient = tbl_ppm_ED_Patient.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    tbl_ppm_ED_Patient = tbl_ppm_ED_Patient.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    tbl_ppm_ED_Patient = tbl_ppm_ED_Patient.drop_duplicates(keep="last")
    # AQA-280 - Add AUID
    tbl_ppm_ED_Patient = tbl_ppm_ED_Patient[
        [
            "PatientNumber",
            "Gender",
            "indigenous_status",
            "EthnicOrigin",
            "DateOfBirth",
            "AUID",
        ]
    ]
    try:
        tbl_ppm_ED_Patient.to_csv(
            "./ExtractorDB/tbl_PPM_ED_Patient.csv",
            index=False,
            na_rep="",
            float_format=str,
            decimal=str,
            date_format=str,
        )
    except Exception as e:
        logging.exception("Exception occurred")
        label_6_status = 0
        messagebox.showerror(
            "Export Error", "Error exporting tbl_ppm_ED_Patient\n" + str(e)
        )
        label_6_sub.configure(text="Failed ()...", fg="red")
        main_screen.update()
        return  # stop export
    main_screen.update()
    logging.info(
        "After deleting encounters marked for delete, tbl_ppm_ED_Patient now has %s records and exported to ./ExtractorDB/tbl_PPM_ED_Patient.csv",
        len(tbl_ppm_ED_Patient),
    )
    """ Links the  tbl_ppm_ED_Encounter table and the tbl_dbo_Ward_Episode by staynumber and updates [Extra:AdmWard] as the ward where the ward_sequence_number = 2 as the ward_sequence_number = 1 should be the ed department (must use ward table as days_episode table has all transfer movements and ward table only has movement in wards).
    This is not required as update to stay_number is done at a later step? """
    # commenting this query as it is not found in Inform8
    # Access query: Update EDAdmWard
    # UPDATE tbl_ppm_ED_Encounter INNER JOIN tbl_dbo_Ward_Episode ON (tbl_ppm_ED_Encounter.Hospital = tbl_dbo_Ward_Episode.facility_identifier) AND (tbl_ppm_ED_Encounter.[Extra:InpatientStayNumber] = tbl_dbo_Ward_Episode.stay_number) SET tbl_ppm_ED_Encounter.[Extra:AdmWard] = [tbl_dbo_Ward_Episode]![dbo_WARD_EPISODE_unit_type] & "-" & [tbl_dbo_Ward_Episode]![ward_identifier] WHERE (((tbl_dbo_Ward_Episode.dbo_WARD_EPISODE_ward_sequence_number)=2));
    """
    tbl_ppm_ED_Encounter['Extra:InpatientStayNumber'] = np.where((tbl_ppm_ED_Encounter['Extra:InpatientStayNumber'].isnull()) | (tbl_ppm_ED_Encounter['Extra:InpatientStayNumber']==''),'',tbl_ppm_ED_Encounter['Extra:InpatientStayNumber'].astype(str).str.pad(8, side ='left', fillchar ='0'))
    tbl_dbo_Ward_Episode['stay_number'] = tbl_dbo_Ward_Episode['stay_number'].astype(str).str.pad(8, side ='left', fillchar ='0')
    tbl_ppm_ED_Encounter = pd.merge(tbl_ppm_ED_Encounter, tbl_dbo_Ward_Episode[tbl_dbo_Ward_Episode['dbo_WARD_EPISODE_ward_sequence_number'].astype(int, errors='ignore')==2][['facility_identifier', 'stay_number', 'dbo_WARD_EPISODE_unit_type', 'ward_identifier']], how='left', left_on=['Hospital', 'Extra:InpatientStayNumber'], right_on=['facility_identifier', 'stay_number'], suffixes=('', '_drop'), indicator=True)
    tbl_ppm_ED_Encounter = tbl_ppm_ED_Encounter.apply(lambda x: x.replace(regex=r'^nan$', value='') if x.dtype == 'object' else x)
    tbl_ppm_ED_Encounter['Extra:AdmWard'] = np.where((tbl_ppm_ED_Encounter['_merge']=='both') & (pd.notna(tbl_ppm_ED_Encounter['facility_identifier'])) & (tbl_ppm_ED_Encounter['facility_identifier']!='') & (pd.notna(tbl_ppm_ED_Encounter['stay_number'])) & (tbl_ppm_ED_Encounter['stay_number']!=''), tbl_ppm_ED_Encounter['dbo_WARD_EPISODE_unit_type'].astype(str).str.strip()+ "-" +  tbl_ppm_ED_Encounter['ward_identifier'].astype(str).str.strip(),tbl_ppm_ED_Encounter['Extra:AdmWard'])
    tbl_ppm_ED_Encounter.drop(['facility_identifier', 'stay_number', '_merge'], axis=1, inplace=True, errors='ignore')
    tbl_ppm_ED_Encounter = tbl_ppm_ED_Encounter.drop_duplicates( keep='last')
    logging.info('Query: Update EDAdmWard completed. tbl_ppm_ED_Encounter has %s records.', len(tbl_ppm_ED_Encounter))
    """
    """ Updates the Extra:WIP field in the the  tbl_ppm_ED_Encounter table:
    when arrival date prior to start date on form then 1 
    if departure date after end date on form then 2  
    if arrival date prior to start date on form then and departure date after end date on form then 3 (this should never occur unless source data is incorrect)
    else 4
    """
    # Access query: update_WIP_Encounter_ED
    # UPDATE tbl_ppm_ED_Encounter SET tbl_ppm_ED_Encounter.[Extra:WIP] = IIf(DateValue([StartDateTime])<(DateValue([Forms]![Frm:1-ExtractSetUp]![Start_Date])) And DateValue([endDateTime])<DateValue([Forms]![Frm:1-ExtractSetUp]![end_Date])+1,1,IIf(DateValue([StartDateTime])>=(DateValue([Forms]![Frm:1-ExtractSetUp]![Start_Date])) And DateValue([endDateTime])>=DateValue([Forms]![Frm:1-ExtractSetUp]![end_Date])+1 Or DateValue([StartDateTime])>=DateValue([Forms]![Frm:1-ExtractSetUp]![Start_Date]) And [enddatetime]="2012-07-01 00:00:00",2,IIf(DateValue([StartDateTime])<(DateValue([Forms]![Frm:1-ExtractSetUp]![Start_Date])) And DateValue([endDateTime])>=(DateValue([Forms]![Frm:1-ExtractSetUp]![end_Date])) Or DateValue([StartDateTime])<(DateValue([Forms]![Frm:1-ExtractSetUp]![Start_Date])) And [enddatetime]="2012-07-01 00:00:00",3,4)));
    end_date_dt = pd.to_datetime(end_date, format="%Y-%m-%d %H:%M:%S")
    start_date_dt = pd.to_datetime(start_date, format="%Y-%m-%d %H:%M:%S")
    tbl_ppm_ED_Encounter["StartDateTime"] = pd.to_datetime(
        tbl_ppm_ED_Encounter["StartDateTime"].astype(str).str[:19],
        errors="coerce",
        format="%Y-%m-%d %H:%M:%S",
    )
    tbl_ppm_ED_Encounter["EndDateTime"] = pd.to_datetime(
        tbl_ppm_ED_Encounter["EndDateTime"].astype(str).str[:19],
        errors="coerce",
        format="%Y-%m-%d %H:%M:%S",
    )
    tbl_ppm_ED_Encounter["end_date_dt"] = end_date_dt
    tbl_ppm_ED_Encounter["end_date_dt"] = pd.to_datetime(
        tbl_ppm_ED_Encounter["end_date_dt"].astype(str).str[:10],
        errors="coerce",
        format="%Y-%m-%d",
    )
    tbl_ppm_ED_Encounter["start_date_dt"] = start_date_dt
    condlist = [
        (tbl_ppm_ED_Encounter["StartDateTime"] < tbl_ppm_ED_Encounter["start_date_dt"])
        & (
            tbl_ppm_ED_Encounter["EndDateTime"]
            < (tbl_ppm_ED_Encounter["end_date_dt"] + pd.DateOffset(1))
        ),
        ~(
            (
                tbl_ppm_ED_Encounter["StartDateTime"]
                < tbl_ppm_ED_Encounter["start_date_dt"]
            )
            & (
                tbl_ppm_ED_Encounter["EndDateTime"]
                < (tbl_ppm_ED_Encounter["end_date_dt"] + pd.DateOffset(1))
            )
        )
        & (
            (
                (
                    tbl_ppm_ED_Encounter["StartDateTime"]
                    >= tbl_ppm_ED_Encounter["start_date_dt"]
                )
                & (
                    tbl_ppm_ED_Encounter["EndDateTime"]
                    >= (tbl_ppm_ED_Encounter["end_date_dt"] + pd.DateOffset(1))
                )
            )
            | (
                (
                    tbl_ppm_ED_Encounter["StartDateTime"]
                    >= tbl_ppm_ED_Encounter["start_date_dt"]
                )
                & (
                    tbl_ppm_ED_Encounter["EndDateTime"]
                    == pd.to_datetime(
                        "2012-07-01 00:00:00",
                        errors="coerce",
                        format="%Y-%m-%d %H:%M:%S",
                    )
                )
            )
        ),
        ~(
            (
                tbl_ppm_ED_Encounter["StartDateTime"]
                < tbl_ppm_ED_Encounter["start_date_dt"]
            )
            & (
                tbl_ppm_ED_Encounter["EndDateTime"]
                < (tbl_ppm_ED_Encounter["end_date_dt"] + pd.DateOffset(1))
            )
        )
        & ~(
            (
                (
                    tbl_ppm_ED_Encounter["StartDateTime"]
                    >= tbl_ppm_ED_Encounter["start_date_dt"]
                )
                & (
                    tbl_ppm_ED_Encounter["EndDateTime"]
                    >= (tbl_ppm_ED_Encounter["end_date_dt"] + pd.DateOffset(1))
                )
            )
            | (
                (tbl_ppm_ED_Encounter["StartDateTime"] >= start_date_dt)
                & (
                    tbl_ppm_ED_Encounter["EndDateTime"]
                    == pd.to_datetime(
                        "2012-07-01 00:00:00",
                        errors="coerce",
                        format="%Y-%m-%d %H:%M:%S",
                    )
                )
            )
        )
        & (
            (
                (
                    tbl_ppm_ED_Encounter["StartDateTime"]
                    < tbl_ppm_ED_Encounter["start_date_dt"]
                )
                & (
                    tbl_ppm_ED_Encounter["EndDateTime"]
                    >= tbl_ppm_ED_Encounter["end_date_dt"]
                )
            )
            | (
                (
                    tbl_ppm_ED_Encounter["StartDateTime"]
                    < tbl_ppm_ED_Encounter["start_date_dt"]
                )
                & (
                    tbl_ppm_ED_Encounter["EndDateTime"]
                    == pd.to_datetime(
                        "2012-07-01 00:00:00",
                        errors="coerce",
                        format="%Y-%m-%d %H:%M:%S",
                    )
                )
            )
        ),
    ]
    choicelist = ["1", "2", "3"]
    tbl_ppm_ED_Encounter["Extra:WIP"] = np.select(condlist, choicelist, "4")
    logging.info(
        "Query: update_WIP_Encounter_ED completed. Updated the Extra:WIP field in the the  tbl_ppm_ED_Encounter table. tbl_ppm_ED_Encounter has %s records.",
        len(tbl_ppm_ED_Encounter),
    )
    """ Obsolete query used in rec delete"""
    """
    # Access query: Make-CountPNs
    # INSERT INTO CountPNs ( PatientNumber, CountOfPatientNumber ) SELECT tbl_ppm_ED_Encounter.PatientNumber, Count(tbl_ppm_ED_Encounter.PatientNumber) AS CountOfPatientNumber FROM tbl_ppm_ED_Encounter GROUP BY tbl_ppm_ED_Encounter.PatientNumber;
    countPNs = tbl_ppm_ED_Encounter[['PatientNumber']]
    countPNs = tbl_ppm_ED_Encounter.groupby(['PatientNumber'], as_index=False, dropna=False).agg(CountOfPatientNumber=("PatientNumber", "count")).reset_index()
    countPNs = countPNs.applymap(str)#.apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    countPNs = countPNs.applymap(lambda x: x.strip() if isinstance(x, str) else x)
    countPNs = countPNs.apply(lambda x: x.replace(regex=r'^NaT$', value='') if x.dtype == 'object' else x)
    countPNs = countPNs.apply(lambda x: x.replace(regex=r'^nan$', value='') if x.dtype == 'object' else x)
    try:
        countPNs.to_csv('./ExtractorDB/CountPNs.csv', index=False, na_rep='', float_format=str, decimal=str, date_format=str)
    except Exception as e:
        logging.exception("Exception occurred")
        label_6_status = 0
        messagebox.showerror("Export Error","Error saving CountPNs\n"+str(e))
        label_6_sub.configure(text="Failed ()...",fg='red')
        main_screen.update()
        return # stop export
    main_screen.update() 
    logging.info('Query:  Make-CountPNs completed. %s records saved to ./ExtractorDB/countPNs.csv.', len(countPNs))
    """
    """ Updates the [Extra:N_Z_FinancialProgram] based on the PLA assignment worksheet collab space"""
    # Access query: qry update ed pla
    # UPDATE tbl_ppm_ED_Encounter SET tbl_ppm_ED_Encounter.[Extra:N_Z_FinancialProgram] = IIf([Extra:ModeofSep] In ('01','1','10','11'),'21021','21012');
    # Ranjit - 11 Oct mode of separation in EDW is different from HIE.
    # query:  select distinct replace(ltrim(replace(ED_MOS_HIE_CD,'0',' ')),' ','0') as HIE_ModeofSep_code, ED_MOS_HIE as HIE_ModeofSep_descr ,ED_MOS_CD as EDW_ModeofSep_codee, ED_MOS as EDW_ModeofSep_descr  from CRT.v_FACT_ED_SE_FLAT order by replace(ltrim(replace(ED_MOS_HIE_CD,'0',' ')),' ','0')
    # len_dummy = len(tbl_ppm_ED_Encounter[tbl_ppm_ED_Encounter['Extra:ModeofSep'].isin(['01','1','10','11'])])
    # tbl_ppm_ED_Encounter['Extra:N_Z_FinancialProgram'] = np.where(tbl_ppm_ED_Encounter['Extra:ModeofSep'].isin(['01','1','10','11']), '21021', '21012')
    len_dummy = len(
        tbl_ppm_ED_Encounter[
            tbl_ppm_ED_Encounter["Extra:ModeofSep"].isin(
                ["01.03", "01", "01.05", "01.04"]
            )
        ]
    )
    tbl_ppm_ED_Encounter["Extra:N_Z_FinancialProgram"] = np.where(
        tbl_ppm_ED_Encounter["Extra:ModeofSep"].isin(
            ["01.03", "01", "01.05", "01.04", "1.03", "1", "1.0", "1.05", "1.04"]
        ),
        "21021",
        "21012",
    )
    tbl_ppm_ED_Encounter = tbl_ppm_ED_Encounter.drop_duplicates(keep="last")
    logging.info(
        "Query: qry update ed pla completed. %s records updated in tbl_ppm_ED_Encounter. tbl_ppm_ED_Encounter has %s records.",
        len_dummy,
        len(tbl_ppm_ED_Encounter),
    )
    if lhd_global == "X720":
        """Updates the EncounterNumber in the tbl_ppm_ED_Encounter when the Hospital "A216" Or "A231" change it to "A233" """
        # Access query: X720_update_ED_Enc
        # UPDATE tbl_ppm_ED_Encounter SET tbl_ppm_ED_Encounter.EncounterNumber = "A233" & Right([EncounterNumber],11), tbl_ppm_ED_Encounter.PatientNumber = "A233" & Right([PatientNumber],11), tbl_ppm_ED_Encounter.Hospital = "A233" WHERE (((tbl_ppm_ED_Encounter.Hospital)="A216" Or (tbl_ppm_ED_Encounter.Hospital)="A231") AND ((Left([EncounterNumber],4))="A216" Or (Left([EncounterNumber],4))="A231"));
        tbl_ppm_ED_Encounter["EncounterNumber"] = (
            tbl_ppm_ED_Encounter["EncounterNumber"].astype(str).str.strip()
        )
        tbl_ppm_ED_Encounter["PatientNumber"] = (
            tbl_ppm_ED_Encounter["PatientNumber"].astype(str).str.strip()
        )
        tbl_ppm_ED_Encounter["Hospital"] = (
            tbl_ppm_ED_Encounter["Hospital"].astype(str).str.strip()
        )
        len_dummy = len(
            tbl_ppm_ED_Encounter[
                (
                    (
                        (tbl_ppm_ED_Encounter["Hospital"] == "A231")
                        | (tbl_ppm_ED_Encounter["Hospital"] == "A216")
                    )
                    & (
                        (tbl_ppm_ED_Encounter["EncounterNumber"].str[:4] == "A216")
                        | (tbl_ppm_ED_Encounter["EncounterNumber"].str[:4] == "A231")
                    )
                )
            ]
        )
        tbl_ppm_ED_Encounter["EncounterNumber"] = np.where(
            (
                (
                    (tbl_ppm_ED_Encounter["Hospital"] == "A231")
                    | (tbl_ppm_ED_Encounter["Hospital"] == "A216")
                )
                & (
                    (tbl_ppm_ED_Encounter["EncounterNumber"].str[:4] == "A216")
                    | (tbl_ppm_ED_Encounter["EncounterNumber"].str[:4] == "A231")
                )
            ),
            "A233" + tbl_ppm_ED_Encounter["EncounterNumber"].str[-11:],
            tbl_ppm_ED_Encounter["EncounterNumber"],
        )
        tbl_ppm_ED_Encounter["PatientNumber"] = np.where(
            (
                (
                    (tbl_ppm_ED_Encounter["Hospital"] == "A231")
                    | (tbl_ppm_ED_Encounter["Hospital"] == "A216")
                )
                & (
                    (tbl_ppm_ED_Encounter["EncounterNumber"].str[:4] == "A216")
                    | (tbl_ppm_ED_Encounter["EncounterNumber"].str[:4] == "A231")
                )
            ),
            "A233" + tbl_ppm_ED_Encounter["PatientNumber"].str[-11:],
            tbl_ppm_ED_Encounter["PatientNumber"],
        )
        tbl_ppm_ED_Encounter["Hospital"] = np.where(
            (
                (
                    (tbl_ppm_ED_Encounter["Hospital"] == "A231")
                    | (tbl_ppm_ED_Encounter["Hospital"] == "A216")
                )
                & (
                    (tbl_ppm_ED_Encounter["EncounterNumber"].str[:4] == "A216")
                    | (tbl_ppm_ED_Encounter["EncounterNumber"].str[:4] == "A231")
                )
            ),
            "A233",
            tbl_ppm_ED_Encounter["Hospital"],
        )
        logging.info(
            "Query: qry X720_update_ED_Enc completed. %s records updated in tbl_ppm_ED_Encounter. tbl_ppm_ED_Encounter has %s records.",
            len_dummy,
            len(tbl_ppm_ED_Encounter),
        )
    ##################UNACCOUNTED COLUMNS #########
    tbl_ppm_ED_Encounter["Extra:hosp_ra06"] = ""
    tbl_ppm_ED_Encounter["Extra:postcode_ra06"] = ""
    tbl_ppm_ED_Encounter["Extra:sla_ra06"] = ""
    tbl_ppm_ED_Encounter["EncounterType"] = "E"
    ########################################################
    cleanup_memory(df_query1)
    cleanup_memory(df_query2)
    cleanup_memory(df_query3)
    cleanup_memory(df_query4)
    cleanup_memory(df_query5)
    # tbl_ppm_ED_Encounter.to_csv('./ExtractorDB/tbl_ppm_ED_Encounter_0.csv', index = False)
    """ Cannot see this: (Call)"""
    # Access query: Run_Update_EDENT_IP_Data_Click
    #
    ##################### MACRO: Update-ED_IP-Data  ##################
    # access query: 1_Upd IPStay for ED Encounter Admtd in IP ENCOUNTER
    # access query: 1_Upd IPStay for ED Encounter Admtd in IP ENCOUNTER b
    # access query: Update EDAdmWard
    # access query: 1_Upd IPStay for ED Encounter Admtd in IP ENCOUNTER EVT 13
    # access query: 1_Upd IPStay for ED Encounter Admtd in IP ENCOUNTER EVT 13 b
    ##################### IMPLEMENTED BELOW ##################
    # tbl_ppm_ED_Encounter.to_csv('./ExtractorDB/tbl_ppm_ED_Encounter_InpatientstayN_1.csv', index = False)
    """ Updates the [Extra:InpatientStayNumber] and [Extra:InpatientEncounterNumber] field in the tbl_ppm_ED_Encounter table when the ed encounter is admitted (extra:modeofsep ="1" Or "2" Or "3" Or "10" Or "11" Or "12" Or "13") and the startdatetime in  tbl_ppm_ED_Encounter table equals the startdatetime  in the tbl_PPM_Encounter table or is one day after the the startdatetime  in the tbl_PPM_Encounter table when linked by the mrn in the tbl_ppm_patient table """
    # Access query:1_Upd IPStay for ED Encounter Admtd in IP ENCOUNTER
    # UPDATE tbl_ppm_ED_Encounter INNER JOIN (tbl_PPM_Patient INNER JOIN tbl_PPM_Encounter ON tbl_PPM_Patient.PatientNumber = tbl_PPM_Encounter.PatientNumber) ON tbl_ppm_ED_Encounter.PatientNumber = tbl_PPM_Patient.mrn_for_matching SET tbl_ppm_ED_Encounter.[Extra:InpatientStayNumber] = [tbl_PPM_Encounter]![Extra:HospitalStayNumber], tbl_ppm_ED_Encounter.[Extra:InpatientEncounterNumber] = [tbl_PPM_Encounter]![EncounterNumber] WHERE (((DateValue(Left([tbl_ppm_ED_Encounter]![StartDateTime],10)))=DateValue(Left([tbl_PPM_Encounter]![StartDateTime],10))) AND ((tbl_ppm_ED_Encounter.[Extra:ModeofSep])="1" Or (tbl_ppm_ED_Encounter.[Extra:ModeofSep])="2" Or (tbl_ppm_ED_Encounter.[Extra:ModeofSep])="3" Or (tbl_ppm_ED_Encounter.[Extra:ModeofSep])="10" Or (tbl_ppm_ED_Encounter.[Extra:ModeofSep])="11" Or (tbl_ppm_ED_Encounter.[Extra:ModeofSep])="12" Or (tbl_ppm_ED_Encounter.[Extra:ModeofSep])="13")) OR (((DateValue(Left([tbl_ppm_ED_Encounter]![StartDateTime],10)))=DateValue(Left(([tbl_PPM_Encounter]![StartDateTime]),10))+1) AND ((tbl_ppm_ED_Encounter.[Extra:ModeofSep])="1" Or (tbl_ppm_ED_Encounter.[Extra:ModeofSep])="2" Or (tbl_ppm_ED_Encounter.[Extra:ModeofSep])="3" Or (tbl_ppm_ED_Encounter.[Extra:ModeofSep])="10" Or (tbl_ppm_ED_Encounter.[Extra:ModeofSep])="11" Or (tbl_ppm_ED_Encounter.[Extra:ModeofSep])="12" Or (tbl_ppm_ED_Encounter.[Extra:ModeofSep])="13"));
    # Inform8 query: UpdateWhenAdmitted1()....namespace Extractor.Exports, public class ExportEdEncounterData
    # query: ppmpatient (ppp) inner join ppmedencounter (ede) on ppmedencounter.patientnumber = ppmpatient.mrn_for_matching)  inner join ppmEncounter (enc) on ppmEncounter.patientnumber = ppmpatient.patientnumber where ppmedencounter.Extra:ModeOfSep is in (1,3,10,11,12,13)
    # if (ppmedencounter.StartDateTime==ppmEncounter.StartDateTime) or (ppmedencounter.StartDateTime==ppmEncounter.StartDateTime+1) then
    # if not (ppmEncounter.StartDateTime< ppmedencounter.StartDateTime)
    # update
    #   ppmedencounter.Extra:InpatientEncounterNumber = ppm.EnncounterNumber,
    #   ppmedencounter.Extra:InpatientStayNumber = ppmEncounter.Extra:HospitalStayNumber,
    #   ppmedencounter.Extra:AUID = ppmEncounter.Extra:AUID
    tbl_ppm_ED_Encounter_copy = tbl_ppm_ED_Encounter.copy()
    tbl_PPM_Encounter["StartDateTime_enc"] = tbl_PPM_Encounter["StartDateTime"]
    tbl_PPM_Encounter["StartDateTime_plus1_enc"] = pd.to_datetime(
        tbl_PPM_Encounter["StartDateTime"].astype(str).str[:10],
        errors="coerce",
        format="%Y-%m-%d",
    )
    tbl_PPM_Encounter["StartDateTime_plus1_enc"] = tbl_PPM_Encounter[
        "StartDateTime_plus1_enc"
    ] + pd.DateOffset(1)
    tbl_PPM_Encounter["StartDateTime_plus1_enc"] = tbl_PPM_Encounter[
        "StartDateTime_plus1_enc"
    ].astype(str)
    tbl_PPM_Encounter["EncounterNumber_enc"] = tbl_PPM_Encounter["EncounterNumber"]
    # 05 Feb 2025 - Issue 140 - ED Encounters prior to IP START
    tbl_PPM_Encounter["StartDateTime_minus1_enc"] = pd.to_datetime(
        tbl_PPM_Encounter["StartDateTime"].astype(str).str[:10],
        errors="coerce",
        format="%Y-%m-%d",
    )
    tbl_PPM_Encounter["StartDateTime_minus1_enc"] = tbl_PPM_Encounter[
        "StartDateTime_minus1_enc"
    ] - pd.DateOffset(1)
    tbl_PPM_Encounter["StartDateTime_minus1_enc"] = tbl_PPM_Encounter[
        "StartDateTime_minus1_enc"
    ].astype(str)

    tbl_PPM_Encounter_patient_merge = pd.merge(
        tbl_PPM_Patient[["PatientNumber"]],
        tbl_PPM_Encounter[
            [
                "PatientNumber",
                "Extra:HospitalStayNumber",
                "EncounterNumber_enc",
                "StartDateTime_enc",
                "StartDateTime_plus1_enc",
                "StartDateTime_minus1_enc",
            ]
        ],
        how="inner",
        on=["PatientNumber"],
        suffixes=("", "_drop"),
    )
    tbl_PPM_Encounter_patient_merge = tbl_PPM_Encounter_patient_merge.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    tbl_ppm_ED_Encounter_copy = pd.merge(
        tbl_PPM_Encounter_patient_merge,
        tbl_ppm_ED_Encounter_copy,
        how="inner",
        on=["PatientNumber"],
        suffixes=("", "_drop"),
    )
    tbl_ppm_ED_Encounter_copy = tbl_ppm_ED_Encounter_copy.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    tbl_ppm_ED_Encounter_copy["Extra:InpatientStayNumber"] = np.where(
        (
            (
                (
                    tbl_ppm_ED_Encounter_copy["StartDateTime"].astype(str).str[:10]
                    == tbl_ppm_ED_Encounter_copy["StartDateTime_enc"]
                    .astype(str)
                    .str[:10]
                )
                | (
                    tbl_ppm_ED_Encounter_copy["StartDateTime"].astype(str).str[:10]
                    == tbl_ppm_ED_Encounter_copy["StartDateTime_plus1_enc"]
                    .astype(str)
                    .str[:10]
                )
                | (
                    tbl_ppm_ED_Encounter_copy["StartDateTime"].astype(str).str[:10]
                    == tbl_ppm_ED_Encounter_copy["StartDateTime_minus1_enc"]
                    .astype(str)
                    .str[:10]
                )
            )
            & (  # tbl_ppm_ED_Encounter_copy['Extra:ModeofSep'].isin(['1', '2', '3', '10', '11', '12', '13']))), tbl_ppm_ED_Encounter_copy['Extra:HospitalStayNumber'], tbl_ppm_ED_Encounter_copy['Extra:InpatientStayNumber'])
                tbl_ppm_ED_Encounter_copy["Extra:ModeofSep"].isin(
                    [
                        "01.03",
                        "01",
                        "01.01",
                        "04",
                        "01.06",
                        "01.05",
                        "01.04",
                        "01.02",
                        "01.07",
                        "1.03",
                        "1",
                        "1.0",
                        "1.01",
                        "4",
                        "4.0",
                        "1.06",
                        "1.05",
                        "1.04",
                        "1.02",
                        "1.07",
                    ]
                )
            )
        ),
        tbl_ppm_ED_Encounter_copy["Extra:HospitalStayNumber"],
        tbl_ppm_ED_Encounter_copy["Extra:InpatientStayNumber"],
    )
    tbl_ppm_ED_Encounter_copy["Extra:InpatientEncounterNumber"] = np.where(
        (
            (
                (
                    tbl_ppm_ED_Encounter_copy["StartDateTime"].astype(str).str[:10]
                    == tbl_ppm_ED_Encounter_copy["StartDateTime_enc"]
                    .astype(str)
                    .str[:10]
                )
                | (
                    tbl_ppm_ED_Encounter_copy["StartDateTime"].astype(str).str[:10]
                    == tbl_ppm_ED_Encounter_copy["StartDateTime_plus1_enc"]
                    .astype(str)
                    .str[:10]
                )
                | (
                    tbl_ppm_ED_Encounter_copy["StartDateTime"].astype(str).str[:10]
                    == tbl_ppm_ED_Encounter_copy["StartDateTime_minus1_enc"]
                    .astype(str)
                    .str[:10]
                )
            )
            & (  # tbl_ppm_ED_Encounter_copy['Extra:ModeofSep'].isin(['1', '2', '3', '10', '11', '12', '13']))), tbl_ppm_ED_Encounter_copy['EncounterNumber_enc'], '')
                tbl_ppm_ED_Encounter_copy["Extra:ModeofSep"].isin(
                    [
                        "01.03",
                        "01",
                        "01.01",
                        "04",
                        "01.06",
                        "01.05",
                        "01.04",
                        "01.02",
                        "01.07",
                        "1.03",
                        "1",
                        "1.0",
                        "1.01",
                        "4",
                        "4.0",
                        "1.06",
                        "1.05",
                        "1.04",
                        "1.02",
                        "1.07",
                    ]
                )
            )
        ),
        tbl_ppm_ED_Encounter_copy["EncounterNumber_enc"],
        "",
    )
    ########### STOP ###########
    # tbl_ppm_ED_Encounter_copy.to_csv('./ExtractorDB/tbl_ppm_ED_Encounter_InpatientstayN_2.csv', index = False)

    # tbl_ppm_ED_Encounter_copy['flag'] = np.where((((tbl_ppm_ED_Encounter_copy['StartDateTime'].astype(str).str[:10] == tbl_ppm_ED_Encounter_copy['StartDateTime_enc'].astype(str).str[:10]) | (tbl_ppm_ED_Encounter_copy['StartDateTime'].astype(str).str[:10] == tbl_ppm_ED_Encounter_copy['StartDateTime_plus1_enc'].astype(str).str[:10])) & (tbl_ppm_ED_Encounter_copy['Extra:ModeofSep'].isin(['1', '2', '3', '10', '11', '12', '13']))), 1, 0)
    ############################## 18 Nov 2024: Issue 64- AQA-328 : Fix InpatientStayNumber ##################
    # tbl_ppm_ED_Encounter_copy['flag'] = np.where((((tbl_ppm_ED_Encounter_copy['StartDateTime'].astype(str).str[:10] == tbl_ppm_ED_Encounter_copy['StartDateTime_enc'].astype(str).str[:10]) | (tbl_ppm_ED_Encounter_copy['StartDateTime'].astype(str).str[:10] == tbl_ppm_ED_Encounter_copy['StartDateTime_plus1_enc'].astype(str).str[:10])) & (tbl_ppm_ED_Encounter_copy['Extra:ModeofSep'].isin(['01.03', '01', '01.01', '04', '01.06', '01.05', '01.04', '01.02', '01.07', '1.03', '1', '1.0', '1.01', '4', '4.0', '1.06', '1.05', '1.04', '1.02', '1.07']))), 1, 0)
    # tbl_ppm_ED_Encounter_copy = tbl_ppm_ED_Encounter_copy[tbl_ppm_ED_Encounter_copy['flag']==1]
    tbl_ppm_ED_Encounter_copy["flag_sameStay"] = np.where(
        (
            tbl_ppm_ED_Encounter_copy["Extra:ModeofSep"].isin(
                [
                    "01.03",
                    "01",
                    "01.01",
                    "04",
                    "01.06",
                    "01.05",
                    "01.04",
                    "01.02",
                    "01.07",
                    "1.03",
                    "1",
                    "1.0",
                    "1.01",
                    "4",
                    "4.0",
                    "1.06",
                    "1.05",
                    "1.04",
                    "1.02",
                    "1.07",
                ]
            )
        )
        & (
            tbl_ppm_ED_Encounter_copy["EncounterNumber"].str[-10:].str.lstrip("0")
            == tbl_ppm_ED_Encounter_copy["Extra:HospitalStayNumber"]
            .str[-8:]
            .str.lstrip("0")
        )
        & (
            (tbl_ppm_ED_Encounter_copy["Extra:HospitalStayNumber"] != "")
            & (tbl_ppm_ED_Encounter_copy["Extra:InpatientStayNumber"] != "")
        ),
        1,
        0,
    )

    tbl_ppm_ED_Encounter_copy["Extra:InpatientStayNumber"] = np.where(
        (
            tbl_ppm_ED_Encounter_copy["EncounterNumber"].str[-10:].str.lstrip("0")
            == tbl_ppm_ED_Encounter_copy["Extra:HospitalStayNumber"]
            .str[-8:]
            .str.lstrip("0")
        )
        & (
            (tbl_ppm_ED_Encounter_copy["Extra:HospitalStayNumber"] != "")
            & (tbl_ppm_ED_Encounter_copy["Extra:InpatientStayNumber"] != "")
        )
        & (tbl_ppm_ED_Encounter_copy["flag_sameStay"] == 1),
        tbl_ppm_ED_Encounter_copy["Extra:HospitalStayNumber"],
        tbl_ppm_ED_Encounter_copy["Extra:InpatientStayNumber"],
    )

    tbl_ppm_ED_Encounter_copy["Extra:InpatientEncounterNumber"] = np.where(
        (
            tbl_ppm_ED_Encounter_copy["EncounterNumber"].str[-10:].str.lstrip("0")
            == tbl_ppm_ED_Encounter_copy["Extra:HospitalStayNumber"]
            .str[-8:]
            .str.lstrip("0")
        )
        & (
            (tbl_ppm_ED_Encounter_copy["Extra:HospitalStayNumber"] != "")
            & (tbl_ppm_ED_Encounter_copy["Extra:InpatientEncounterNumber"] != "")
        )
        & (tbl_ppm_ED_Encounter_copy["flag_sameStay"] == 1),
        tbl_ppm_ED_Encounter_copy["EncounterNumber_enc"],
        tbl_ppm_ED_Encounter_copy["Extra:InpatientEncounterNumber"],
    )

    tbl_ppm_ED_Encounter_copy["flag"] = np.where(
        (
            (
                tbl_ppm_ED_Encounter_copy["StartDateTime"].astype(str).str[:10]
                == tbl_ppm_ED_Encounter_copy["StartDateTime_plus1_enc"]
                .astype(str)
                .str[:10]
            )
            & (
                tbl_ppm_ED_Encounter_copy["Extra:ModeofSep"].isin(
                    [
                        "01.03",
                        "01",
                        "01.01",
                        "04",
                        "01.06",
                        "01.05",
                        "01.04",
                        "01.02",
                        "01.07",
                        "1.03",
                        "1",
                        "1.0",
                        "1.01",
                        "4",
                        "4.0",
                        "1.06",
                        "1.05",
                        "1.04",
                        "1.02",
                        "1.07",
                    ]
                )
            )
        ),
        1,
        0,
    )

    tbl_ppm_ED_Encounter_copy["flag_SameDay"] = np.where(
        (
            (
                tbl_ppm_ED_Encounter_copy["StartDateTime"].astype(str).str[:10]
                == tbl_ppm_ED_Encounter_copy["StartDateTime_enc"].astype(str).str[:10]
            )
            & (
                tbl_ppm_ED_Encounter_copy["Extra:ModeofSep"].isin(
                    [
                        "01.03",
                        "01",
                        "01.01",
                        "04",
                        "01.06",
                        "01.05",
                        "01.04",
                        "01.02",
                        "01.07",
                        "1.03",
                        "1",
                        "1.0",
                        "1.01",
                        "4",
                        "4.0",
                        "1.06",
                        "1.05",
                        "1.04",
                        "1.02",
                        "1.07",
                    ]
                )
            )
        ),
        1,
        0,
    )

    tbl_ppm_ED_Encounter_copy_stay = tbl_ppm_ED_Encounter_copy[
        tbl_ppm_ED_Encounter_copy["flag_sameStay"] == 1
    ]
    tbl_ppm_ED_Encounter_copy_list_stay = tbl_ppm_ED_Encounter_copy_stay[
        "EncounterNumber"
    ].tolist()

    tbl_ppm_ED_Encounter_copy_a = tbl_ppm_ED_Encounter_copy[
        (tbl_ppm_ED_Encounter_copy["flag_SameDay"] == 1)
        & (
            ~tbl_ppm_ED_Encounter_copy["EncounterNumber"].isin(
                tbl_ppm_ED_Encounter_copy_list_stay
            )
        )
    ]
    tbl_ppm_ED_Encounter_copy_list_a = tbl_ppm_ED_Encounter_copy_a[
        "EncounterNumber"
    ].tolist()

    tbl_ppm_ED_Encounter_copy_b = tbl_ppm_ED_Encounter_copy[
        (
            ~tbl_ppm_ED_Encounter_copy["EncounterNumber"].isin(
                tbl_ppm_ED_Encounter_copy_list_a
            )
        )
        & (
            ~tbl_ppm_ED_Encounter_copy["EncounterNumber"].isin(
                tbl_ppm_ED_Encounter_copy_list_stay
            )
        )
    ]
    tbl_ppm_ED_Encounter_copy_b = tbl_ppm_ED_Encounter_copy[
        tbl_ppm_ED_Encounter_copy["flag"] == 1
    ]
    tbl_ppm_ED_Encounter_copy = pd.concat(
        [
            tbl_ppm_ED_Encounter_copy_stay,
            tbl_ppm_ED_Encounter_copy_a,
            tbl_ppm_ED_Encounter_copy_b,
        ],
        axis=0,
    )

    ###########################################################
    tbl_ppm_ED_Encounter_copy_list = tbl_ppm_ED_Encounter_copy[
        "EncounterNumber"
    ].tolist()
    tbl_ppm_ED_Encounter_non_copy = tbl_ppm_ED_Encounter[
        ~tbl_ppm_ED_Encounter["EncounterNumber"].isin(tbl_ppm_ED_Encounter_copy_list)
    ]
    tbl_ppm_ED_Encounter_copy.drop(
        [
            "Extra:HospitalStayNumber",
            "EncounterNumber_enc",
            "StartDateTime_enc",
            "StartDateTime_plus1_enc",
            "flag",
            "flag_SameDay",
            "flag_sameStay",
        ],
        axis=1,
        inplace=True,
        errors="ignore",
    )
    tbl_ppm_ED_Encounter_copy.drop_duplicates(keep="last", inplace=True)
    tbl_ppm_ED_Encounter = pd.concat(
        [tbl_ppm_ED_Encounter_non_copy, tbl_ppm_ED_Encounter_copy], axis=0
    )
    tbl_ppm_ED_Encounter = tbl_ppm_ED_Encounter.drop_duplicates(
        subset=["EncounterNumber"], keep="first"
    )
    logging.info(
        "Query: 1_Upd IPStay for ED Encounter Admtd in IP ENCOUNTER completed.  tbl_ppm_ED_Encounter has %s records.",
        len(tbl_ppm_ED_Encounter),
    )
    # tbl_ppm_ED_Encounter.to_csv('./ExtractorDB/tbl_ppm_ED_Encounter_2.csv', index = False)
    """For [Extra:EDVisitType] = 13 Updates the [Extra:InpatientStayNumber] and [Extra:InpatientEncounterNumber] field in the tbl_ppm_ED_Encounter table where the startdatetime in the tbl_ppm_ED_Encounter is between the startdatetime and enddatetime in the tbl_PPM_Encounter where encounter type = I
    No link by MRN
    In case mrn is redirected 
    """
    # Access query: 1_Upd IPStay for ED Encounter Admtd in IP ENCOUNTER b
    # UPDATE tbl_ppm_ED_Encounter INNER JOIN tbl_PPM_Encounter ON tbl_ppm_ED_Encounter.PatientNumber = tbl_PPM_Encounter.PatientNumber SET tbl_ppm_ED_Encounter.[Extra:InpatientStayNumber] = [tbl_PPM_Encounter]![Extra:HospitalStayNumber], tbl_ppm_ED_Encounter.[Extra:InpatientEncounterNumber] = [tbl_PPM_Encounter]![EncounterNumber] WHERE (((tbl_ppm_ED_Encounter.[Extra:InpatientEncounterNumber]) Is Null) AND ((DateValue(Left([tbl_ppm_ED_Encounter]![StartDateTime],10)))=DateValue(Left([tbl_PPM_Encounter]![StartDateTime],10))) AND ((tbl_PPM_Encounter.[Extra:EDStatus])="1" Or (tbl_PPM_Encounter.[Extra:EDStatus])="2" Or (tbl_PPM_Encounter.[Extra:EDStatus])="4" Or (tbl_PPM_Encounter.[Extra:EDStatus])="5")) OR (((tbl_ppm_ED_Encounter.[Extra:InpatientEncounterNumber]) Is Null) AND ((DateValue(Left([tbl_ppm_ED_Encounter]![StartDateTime],10)))=DateValue(Left(([tbl_PPM_Encounter]![StartDateTime]),10))+1) AND ((tbl_PPM_Encounter.[Extra:EDStatus])="1" Or (tbl_PPM_Encounter.[Extra:EDStatus])="2" Or (tbl_PPM_Encounter.[Extra:EDStatus])="4" Or (tbl_PPM_Encounter.[Extra:EDStatus])="5"));
    # Inform8 query:UpdateWhenAdmitted2()
    # query: ppmencounter inner join ppmedencounter on ppmencounter.patientnumber = ppmedencounter.patientnumber  where ppmencounter.Exta:ED_Status is in (1,2,4,5) and ppmedencounter.Extra:InpatientEncounterNumber is null or empty
    # if (ppmedencounter.StartDateTime==ppmEncounter.StartDateTime) or (ppmedencounter.StartDateTime==ppmEncounter.StartDateTime+1) then
    # if not (ppmEncounter.StartDateTime< ppmedencounter.StartDateTime)
    # update
    #   ppmedencounter.Extra:InpatientEncounterNumber = ppmencounter.EncounterNumber,
    #   ppmedencounter.Extra:InpatientStayNumber = ppmEncounter.Extra:HospitalStayNumber,
    #   ppmedencounter.Extra:AUID = ppmEncounter.Extra:AUID
    tbl_ppm_ED_Encounter_copy = tbl_ppm_ED_Encounter.copy()
    # 05 Feb 2025 - Issue 140 - ED Encounters prior to IP START
    tbl_ppm_ED_Encounter_copy = pd.merge(
        tbl_PPM_Encounter[
            [
                "PatientNumber",
                "Extra:HospitalStayNumber",
                "EncounterNumber_enc",
                "StartDateTime_enc",
                "StartDateTime_plus1_enc",
                "Extra:EDStatus",
                "StartDateTime_minus1_enc",
            ]
        ],
        tbl_ppm_ED_Encounter_copy,
        how="inner",
        on=["PatientNumber"],
        suffixes=("", "_drop"),
    )
    tbl_ppm_ED_Encounter_copy = tbl_ppm_ED_Encounter_copy.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )

    tbl_ppm_ED_Encounter_copy["Extra:InpatientStayNumber"] = np.where(
        (
            (
                (tbl_ppm_ED_Encounter_copy["Extra:InpatientEncounterNumber"].isnull())
                | (tbl_ppm_ED_Encounter_copy["Extra:InpatientEncounterNumber"] == "")
            )
            & (
                (
                    tbl_ppm_ED_Encounter_copy["StartDateTime"].astype(str).str[:10]
                    == tbl_ppm_ED_Encounter_copy["StartDateTime_enc"]
                    .astype(str)
                    .str[:10]
                )
                | (
                    tbl_ppm_ED_Encounter_copy["StartDateTime"].astype(str).str[:10]
                    == tbl_ppm_ED_Encounter_copy["StartDateTime_plus1_enc"]
                    .astype(str)
                    .str[:10]
                )
                | (
                    tbl_ppm_ED_Encounter_copy["StartDateTime"].astype(str).str[:10]
                    == tbl_ppm_ED_Encounter_copy["StartDateTime_minus1_enc"]
                    .astype(str)
                    .str[:10]
                )
            )
            & (tbl_ppm_ED_Encounter_copy["Extra:EDStatus"].isin(["1", "2", "4", "5"]))
        ),
        tbl_ppm_ED_Encounter_copy["Extra:HospitalStayNumber"],
        tbl_ppm_ED_Encounter_copy["Extra:InpatientStayNumber"],
    )
    tbl_ppm_ED_Encounter_copy["Extra:InpatientEncounterNumber"] = np.where(
        (
            (
                (tbl_ppm_ED_Encounter_copy["Extra:InpatientEncounterNumber"].isnull())
                | (tbl_ppm_ED_Encounter_copy["Extra:InpatientEncounterNumber"] == "")
            )
            & (
                (
                    tbl_ppm_ED_Encounter_copy["StartDateTime"].astype(str).str[:10]
                    == tbl_ppm_ED_Encounter_copy["StartDateTime_enc"]
                    .astype(str)
                    .str[:10]
                )
                | (
                    tbl_ppm_ED_Encounter_copy["StartDateTime"].astype(str).str[:10]
                    == tbl_ppm_ED_Encounter_copy["StartDateTime_plus1_enc"]
                    .astype(str)
                    .str[:10]
                )
                | (
                    tbl_ppm_ED_Encounter_copy["StartDateTime"].astype(str).str[:10]
                    == tbl_ppm_ED_Encounter_copy["StartDateTime_minus1_enc"]
                    .astype(str)
                    .str[:10]
                )
            )
            & (tbl_ppm_ED_Encounter_copy["Extra:EDStatus"].isin(["1", "2", "4", "5"]))
        ),
        tbl_ppm_ED_Encounter_copy["EncounterNumber_enc"],
        tbl_ppm_ED_Encounter_copy["Extra:InpatientStayNumber"],
    )

    # Sort by all columns
    tbl_ppm_ED_Encounter_copy = tbl_ppm_ED_Encounter_copy.sort_values(
        by=list(tbl_ppm_ED_Encounter_copy.columns)
    )

    # Drop duplicates based on all columns, keeping the last occurrence
    tbl_ppm_ED_Encounter_copy = tbl_ppm_ED_Encounter_copy.drop_duplicates(keep="last")
    ########### STOP ###########

    tbl_ppm_ED_Encounter_copy_fix_inpatient = tbl_ppm_ED_Encounter_copy[
        [
            "EncounterNumber",
            "Extra:InpatientStayNumber",
            "Extra:InpatientEncounterNumber",
        ]
    ]
    tbl_ppm_ED_Encounter_copy_fix_inpatient = (
        tbl_ppm_ED_Encounter_copy_fix_inpatient.rename(
            columns={
                "Extra:InpatientStayNumber": "Extra:InpatientStayNumber_fix",
                "Extra:InpatientEncounterNumber": "Extra:InpatientEncounterNumber_fix",
            }
        )
    )
    tbl_ppm_ED_Encounter = pd.merge(
        tbl_ppm_ED_Encounter,
        tbl_ppm_ED_Encounter_copy_fix_inpatient,
        how="left",
        on=["EncounterNumber"],
        suffixes=("", "_drop"),
    )
    tbl_ppm_ED_Encounter["Extra:InpatientStayNumber"] = np.where(
        (
            (tbl_ppm_ED_Encounter["Extra:InpatientStayNumber"].isnull())
            | (tbl_ppm_ED_Encounter["Extra:InpatientStayNumber"] == "")
        ),
        tbl_ppm_ED_Encounter["Extra:InpatientStayNumber_fix"],
        tbl_ppm_ED_Encounter["Extra:InpatientStayNumber"],
    )
    tbl_ppm_ED_Encounter["Extra:InpatientEncounterNumber"] = np.where(
        (
            (tbl_ppm_ED_Encounter["Extra:InpatientEncounterNumber"].isnull())
            | (tbl_ppm_ED_Encounter["Extra:InpatientEncounterNumber"] == "")
        ),
        tbl_ppm_ED_Encounter["Extra:InpatientEncounterNumber_fix"],
        tbl_ppm_ED_Encounter["Extra:InpatientEncounterNumber"],
    )
    # tbl_ppm_ED_Encounter.to_csv('./ExtractorDB/tbl_ppm_ED_Encounter_2.csv', index = False)
    tbl_ppm_ED_Encounter = tbl_ppm_ED_Encounter.drop(
        columns=["Extra:InpatientEncounterNumber_fix", "Extra:InpatientStayNumber_fix"]
    )
    # tbl_ppm_ED_Encounter_copy.to_csv('./ExtractorDB/tbl_ppm_ED_Encounter_InpatientstayN_3.csv', index = False)
    ############################## 18 Nov 2024: Issue 64- AQA-328 : Fix InpatientStayNumber ##################
    # tbl_ppm_ED_Encounter_copy['flag'] = np.where((((tbl_ppm_ED_Encounter_copy['Extra:InpatientEncounterNumber'].isnull()) | (tbl_ppm_ED_Encounter_copy['Extra:InpatientEncounterNumber']=='')) & ((tbl_ppm_ED_Encounter_copy['StartDateTime'].astype(str).str[:10] == tbl_ppm_ED_Encounter_copy['StartDateTime_enc'].astype(str).str[:10]) | (tbl_ppm_ED_Encounter_copy['StartDateTime'].astype(str).str[:10] == tbl_ppm_ED_Encounter_copy['StartDateTime_plus1_enc'].astype(str).str[:10])) & (tbl_ppm_ED_Encounter_copy['Extra:EDStatus'].isin(['1', '2', '4', '5']))) , 1, 0)
    # tbl_ppm_ED_Encounter_copy = tbl_ppm_ED_Encounter_copy[tbl_ppm_ED_Encounter_copy['flag']==1]
    tbl_ppm_ED_Encounter_copy["flag"] = np.where(
        (
            (
                (tbl_ppm_ED_Encounter_copy["Extra:InpatientEncounterNumber"].isnull())
                | (tbl_ppm_ED_Encounter_copy["Extra:InpatientEncounterNumber"] == "")
            )
            & (
                tbl_ppm_ED_Encounter_copy["StartDateTime"].astype(str).str[:10]
                == tbl_ppm_ED_Encounter_copy["StartDateTime_plus1_enc"]
                .astype(str)
                .str[:10]
            )
            & (tbl_ppm_ED_Encounter_copy["Extra:EDStatus"].isin(["1", "2", "4", "5"]))
        ),
        1,
        0,
    )
    tbl_ppm_ED_Encounter_copy["flag_SameDay"] = np.where(
        (
            (
                (tbl_ppm_ED_Encounter_copy["Extra:InpatientEncounterNumber"].isnull())
                | (tbl_ppm_ED_Encounter_copy["Extra:InpatientEncounterNumber"] == "")
            )
            & (
                tbl_ppm_ED_Encounter_copy["StartDateTime"].astype(str).str[:10]
                == tbl_ppm_ED_Encounter_copy["StartDateTime_enc"].astype(str).str[:10]
            )
            & (tbl_ppm_ED_Encounter_copy["Extra:EDStatus"].isin(["1", "2", "4", "5"]))
        ),
        1,
        0,
    )

    tbl_ppm_ED_Encounter_copy["flag_sameStay"] = np.where(
        (
            (
                (tbl_ppm_ED_Encounter_copy["Extra:InpatientEncounterNumber"].isnull())
                | (tbl_ppm_ED_Encounter_copy["Extra:InpatientEncounterNumber"] == "")
            )
            & (
                tbl_ppm_ED_Encounter_copy["EncounterNumber"].str[-10:].str.lstrip("0")
                == tbl_ppm_ED_Encounter_copy["Extra:HospitalStayNumber"]
                .str[-8:]
                .str.lstrip("0")
            )
            & (
                (tbl_ppm_ED_Encounter_copy["Extra:HospitalStayNumber"] != "")
                & (tbl_ppm_ED_Encounter_copy["Extra:InpatientStayNumber"] != "")
            )
            & (tbl_ppm_ED_Encounter_copy["Extra:EDStatus"].isin(["1", "2", "4", "5"]))
        ),
        1,
        0,
    )

    tbl_ppm_ED_Encounter_copy_stay = tbl_ppm_ED_Encounter_copy[
        tbl_ppm_ED_Encounter_copy["flag_sameStay"] == 1
    ]
    tbl_ppm_ED_Encounter_copy_list_stay = tbl_ppm_ED_Encounter_copy_stay[
        "EncounterNumber"
    ].tolist()

    tbl_ppm_ED_Encounter_copy_a = tbl_ppm_ED_Encounter_copy[
        (tbl_ppm_ED_Encounter_copy["flag_SameDay"] == 1)
        & (
            ~tbl_ppm_ED_Encounter_copy["EncounterNumber"].isin(
                tbl_ppm_ED_Encounter_copy_list_stay
            )
        )
    ]
    tbl_ppm_ED_Encounter_copy_list_a = tbl_ppm_ED_Encounter_copy_a[
        "EncounterNumber"
    ].tolist()

    tbl_ppm_ED_Encounter_copy_b = tbl_ppm_ED_Encounter_copy[
        (
            ~tbl_ppm_ED_Encounter_copy["EncounterNumber"].isin(
                tbl_ppm_ED_Encounter_copy_list_a
            )
        )
        & (
            ~tbl_ppm_ED_Encounter_copy["EncounterNumber"].isin(
                tbl_ppm_ED_Encounter_copy_list_stay
            )
        )
    ]
    tbl_ppm_ED_Encounter_copy_b = tbl_ppm_ED_Encounter_copy[
        tbl_ppm_ED_Encounter_copy["flag"] == 1
    ]
    tbl_ppm_ED_Encounter_copy = pd.concat(
        [
            tbl_ppm_ED_Encounter_copy_stay,
            tbl_ppm_ED_Encounter_copy_a,
            tbl_ppm_ED_Encounter_copy_b,
        ],
        axis=0,
    )

    tbl_ppm_ED_Encounter_copy["Extra:InpatientStayNumber"] = np.where(
        (
            tbl_ppm_ED_Encounter_copy["EncounterNumber"].str[-10:].str.lstrip("0")
            == tbl_ppm_ED_Encounter_copy["Extra:HospitalStayNumber"]
            .str[-8:]
            .str.lstrip("0")
        )
        & (
            (tbl_ppm_ED_Encounter_copy["Extra:HospitalStayNumber"] != "")
            & (tbl_ppm_ED_Encounter_copy["Extra:InpatientStayNumber"] != "")
        ),
        tbl_ppm_ED_Encounter_copy["Extra:HospitalStayNumber"],
        tbl_ppm_ED_Encounter_copy["Extra:InpatientStayNumber"],
    )
    tbl_ppm_ED_Encounter_copy["Extra:InpatientEncounterNumber"] = np.where(
        (
            tbl_ppm_ED_Encounter_copy["EncounterNumber"].str[-10:].str.lstrip("0")
            == tbl_ppm_ED_Encounter_copy["Extra:HospitalStayNumber"]
            .str[-8:]
            .str.lstrip("0")
        )
        & (
            (tbl_ppm_ED_Encounter_copy["Extra:HospitalStayNumber"] != "")
            & (tbl_ppm_ED_Encounter_copy["Extra:InpatientEncounterNumber"] != "")
        ),
        tbl_ppm_ED_Encounter_copy["EncounterNumber_enc"],
        tbl_ppm_ED_Encounter_copy["Extra:InpatientEncounterNumber"],
    )
    ###########################################################

    tbl_ppm_ED_Encounter_copy = tbl_ppm_ED_Encounter_copy[
        tbl_ppm_ED_Encounter_copy["flag"] == 1
    ]
    tbl_ppm_ED_Encounter_copy_list = tbl_ppm_ED_Encounter_copy[
        "EncounterNumber"
    ].tolist()
    tbl_ppm_ED_Encounter_non_copy = tbl_ppm_ED_Encounter[
        ~tbl_ppm_ED_Encounter["EncounterNumber"].isin(tbl_ppm_ED_Encounter_copy_list)
    ]
    tbl_ppm_ED_Encounter_copy.drop(
        [
            "Extra:HospitalStayNumber",
            "EncounterNumber_enc",
            "StartDateTime_enc",
            "StartDateTime_plus1_enc",
            "flag",
            "Extra:EDStatus",
            "flag_SameDay",
            "flag_sameStay",
        ],
        axis=1,
        inplace=True,
        errors="ignore",
    )
    tbl_ppm_ED_Encounter_copy.drop_duplicates(keep="last", inplace=True)
    # tbl_ppm_ED_Encounter_non_copy.to_csv('./ExtractorDB/tbl_ppm_ED_Encounter_non_copy.csv', index = False)
    # tbl_ppm_ED_Encounter_copy.to_csv('./ExtractorDB/tbl_ppm_ED_Encounter_InpatientstayN_4.csv', index = False)
    tbl_ppm_ED_Encounter = pd.concat(
        [tbl_ppm_ED_Encounter_non_copy, tbl_ppm_ED_Encounter_copy], axis=0
    )
    # tbl_ppm_ED_Encounter.to_csv('./ExtractorDB/tbl_ppm_ED_Encounter_copy_non_copy_merge_before_dup.csv', index = False)
    # Prioritize rows with values in Extra:InpatientStayNumber by sorting
    tbl_ppm_ED_Encounter = tbl_ppm_ED_Encounter.sort_values(
        by=["EncounterNumber", "Extra:InpatientStayNumber"], ascending=[True, False]
    )
    tbl_ppm_ED_Encounter = tbl_ppm_ED_Encounter.drop_duplicates(
        subset=["EncounterNumber"], keep="first"
    )
    tbl_ppm_ED_Encounter.to_csv(
        "./ExtractorDB/tbl_ppm_ED_Encounter_copy_non_copy_merge_after_dup.csv",
        index=False,
    )
    logging.info(
        "Query: 1_Upd IPStay for ED Encounter Admtd in IP ENCOUNTER b completed. tbl_ppm_ED_Encounter has %s records.",
        len(tbl_ppm_ED_Encounter),
    )
    """ Updates the [Extra:AdmWard] in the tbl_ppm_ED_Encounter table when the [Extra:InpatientStayNumber] in tbl_ppm_ED_Encounter table equals the stay_number in the tbl_dbo_Ward_Episode where the dbo_WARD_EPISODE_ward_sequence_number - 2 as the ward_sequence_number = 1 should be the ed department (must use ward table as days_episode table has all transfer movements and ward table only has movement in wards)"""
    # Access query: Update EDAdmWard
    # UPDATE tbl_ppm_ED_Encounter INNER JOIN tbl_dbo_Ward_Episode ON (tbl_ppm_ED_Encounter.Hospital = tbl_dbo_Ward_Episode.facility_identifier) AND (tbl_ppm_ED_Encounter.[Extra:InpatientStayNumber] = tbl_dbo_Ward_Episode.stay_number) SET tbl_ppm_ED_Encounter.[Extra:AdmWard] = [tbl_dbo_Ward_Episode]![dbo_WARD_EPISODE_unit_type] & "-" & [tbl_dbo_Ward_Episode]![ward_identifier] WHERE (((tbl_dbo_Ward_Episode.dbo_WARD_EPISODE_ward_sequence_number)=2));

    # AQA - 277: ED Encounter file: Extra:AdmWard is blank
    tbl_dbo_Ward_Episode["stay_number_pad"] = np.where(
        (
            pd.notna(tbl_dbo_Ward_Episode["stay_number"])
            & (tbl_dbo_Ward_Episode["stay_number"] != "")
        ),
        tbl_dbo_Ward_Episode["stay_number"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0"),
        "",
    )
    tbl_dbo_Ward_Episode["stay_number_pad"] = np.where(
        (
            pd.notna(tbl_dbo_Ward_Episode["stay_number_pad"])
            & (tbl_dbo_Ward_Episode["stay_number_pad"] != "")
        ),
        "SN" + tbl_dbo_Ward_Episode["stay_number_pad"].astype(str).str.strip(),
        "",
    )
    # tbl_ppm_ED_Encounter = pd.merge(tbl_ppm_ED_Encounter, tbl_dbo_Ward_Episode[tbl_dbo_Ward_Episode['dbo_WARD_EPISODE_ward_sequence_number'].astype(int, errors='ignore')==2][['facility_identifier', 'stay_number', 'dbo_WARD_EPISODE_unit_type', 'ward_identifier', 'dbo_WARD_EPISODE_ward_sequence_number']], how='left', left_on=['Hospital', 'Extra:InpatientStayNumber'], right_on =['facility_identifier', 'stay_number'], suffixes=('', '_drop'), indicator=True)
    tbl_ppm_ED_Encounter = pd.merge(
        tbl_ppm_ED_Encounter,
        tbl_dbo_Ward_Episode[
            tbl_dbo_Ward_Episode["dbo_WARD_EPISODE_ward_sequence_number"].astype(
                int, errors="ignore"
            )
            == 2
        ][
            [
                "facility_identifier",
                "stay_number",
                "dbo_WARD_EPISODE_unit_type",
                "ward_identifier",
                "dbo_WARD_EPISODE_ward_sequence_number",
                "stay_number_pad",
            ]
        ],
        how="left",
        left_on=["Hospital", "Extra:InpatientStayNumber"],
        right_on=["facility_identifier", "stay_number_pad"],
        suffixes=("", "_drop"),
        indicator=True,
    )

    tbl_ppm_ED_Encounter.drop_duplicates(keep="last", inplace=True)
    tbl_ppm_ED_Encounter = tbl_ppm_ED_Encounter.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    tbl_ppm_ED_Encounter = tbl_ppm_ED_Encounter.drop_duplicates(keep="last")
    tbl_ppm_ED_Encounter["Extra:AdmWard"] = np.where(
        (tbl_ppm_ED_Encounter["_merge"] == "both"),
        tbl_ppm_ED_Encounter["dbo_WARD_EPISODE_unit_type"].astype(str).str.strip()
        + "-"
        + tbl_ppm_ED_Encounter["ward_identifier"].astype(str).str.strip(),
        tbl_ppm_ED_Encounter["Extra:AdmWard"],
    )
    logging.info(
        "Query: Update EDAdmWard completed. tbl_ppm_ED_Encounter has %s records.",
        len(tbl_ppm_ED_Encounter),
    )
    tbl_ppm_ED_Encounter.drop(
        ["_merge", "dbo_WARD_EPISODE_unit_type_drop", "ward_identifier_drop"],
        axis=1,
        inplace=True,
        errors="ignore",
    )
    tbl_ppm_ED_Encounter = tbl_ppm_ED_Encounter.drop_duplicates(keep="last")
    logging.info(
        "Query: Update EDAdmWard completed. tbl_ppm_ED_Encounter has %s records.",
        len(tbl_ppm_ED_Encounter),
    )
    #################################SEP 10##############################################
    # Ranjit - 11 Oct mode of separation in EDW is different from HIE.
    # query:  select distinct replace(ltrim(replace(ED_MOS_HIE_CD,'0',' ')),' ','0') as HIE_ModeofSep_code, ED_MOS_HIE as HIE_ModeofSep_descr ,ED_MOS_CD as EDW_ModeofSep_codee, ED_MOS as EDW_ModeofSep_descr  from CRT.v_FACT_ED_SE_FLAT order by replace(ltrim(replace(ED_MOS_HIE_CD,'0',' ')),' ','0')
    # tbl_ppm_ED_Encounter['Extra:ModeofSep'] = np.where((tbl_ppm_ED_Encounter['Extra:ModeofSep']=='') | (tbl_ppm_ED_Encounter['Extra:ModeofSep'].isnull()), '99', tbl_ppm_ED_Encounter['Extra:ModeofSep'])
    tbl_ppm_ED_Encounter["Extra:ModeofSep"] = np.where(
        (tbl_ppm_ED_Encounter["Extra:ModeofSep"] == "")
        | (tbl_ppm_ED_Encounter["Extra:ModeofSep"].isnull()),
        "98",
        tbl_ppm_ED_Encounter["Extra:ModeofSep"],
    )
    tbl_ppm_ED_Encounter["DRG1Version"] = np.where(
        tbl_ppm_ED_Encounter["DRG1Version"] == "n.n",
        "",
        tbl_ppm_ED_Encounter["DRG1Version"],
    )
    tbl_ppm_ED_Encounter = tbl_ppm_ED_Encounter.drop_duplicates(keep="last")
    ###################################################################################################
    """ For [Extra:EDVisitType] = 13 Updates the [Extra:InpatientStayNumber] and [Extra:InpatientEncounterNumber] field in the tbl_ppm_ED_Encounter table where the startdatetime in the tbl_ppm_ED_Encounter is between the startdatetime and enddatetime in the tbl_PPM_Encounter where encounter type = I when linked by the mrn in the tbl_ppm_patient table"""
    # Access query: 1_Upd IPStay for ED Encounter Admtd in IP ENCOUNTER EVT 13
    # UPDATE tbl_ppm_ED_Encounter INNER JOIN (tbl_PPM_Patient INNER JOIN tbl_PPM_Encounter ON tbl_PPM_Patient.PatientNumber = tbl_PPM_Encounter.PatientNumber) ON tbl_ppm_ED_Encounter.PatientNumber = tbl_PPM_Patient.mrn_for_matching SET tbl_ppm_ED_Encounter.[Extra:InpatientStayNumber] = [tbl_PPM_Encounter]![Extra:HospitalStayNumber], tbl_ppm_ED_Encounter.[Extra:InpatientEncounterNumber] = [tbl_PPM_Encounter]![EncounterNumber] WHERE (((DateValue(Left([tbl_ppm_ED_Encounter]![StartDateTime],10))) Between DateValue(Left([tbl_PPM_Encounter]![StartDateTime],10)) And DateValue(Left([tbl_PPM_Encounter]![EndDateTime],10))) AND ((tbl_ppm_ED_Encounter.[Extra:EDVisitType])="13") AND ((tbl_PPM_Encounter.EncounterType)="I"));
    # Inform8 query: UpdateWhenAdmitted3()....namespace Extractor.Exports, public class ExportEdEncounterData
    # query: pppmpatient (ppp) inner join ppmedencounter (ede) on ppmedencounter.patientnumber = ppmpatient.mrn_for_matching)  inner join ppmEncounter (enc) on ppmEncounter.patientnumber = ppmpatient.patientnumber where  ppmedencounter.Extra:EDVisitType == "13" && ppmencounter.EncounterType == "I" && string.IsNullOrEmpty(<>ppmedencounter.Extra:InpatientEncounterNumber) && IsNullOrEmpty(<>ppmedencounter.Extra:InpatientStayNumber)
    # if ppmedencounter.StartDateTime >= ppmEncounter.StartDateTime && ppmedencounter.StartDateTime<=ppmEncounter.EndDatTime
    # update
    #   ppmedencounter.Extra:InpatientEncounterNumber = ppm.EnncounterNumber,
    #   ppmedencounter.Extra:InpatientStayNumber = ppmEncounter.Extra:HospitalStayNumber,
    #   ppmedencounter.Extra:AUID = ppmEncounter.Extra:AUID
    tbl_ppm_ED_Encounter_copy = tbl_ppm_ED_Encounter.copy()
    tbl_PPM_Encounter["StartDateTime_enc"] = pd.to_datetime(
        tbl_PPM_Encounter["StartDateTime"].astype(str).str[:10],
        errors="coerce",
        format="%Y-%m-%d",
    )
    tbl_PPM_Encounter["EndDateTime_enc"] = pd.to_datetime(
        tbl_PPM_Encounter["EndDateTime"].astype(str).str[:10],
        errors="coerce",
        format="%Y-%m-%d",
    )
    tbl_PPM_Encounter["EncounterNumber_enc"] = tbl_PPM_Encounter["EncounterNumber"]
    tbl_PPM_Encounter["EncounterType_enc"] = tbl_PPM_Encounter["EncounterType"]
    tbl_PPM_Encounter_patient_merge = pd.merge(
        tbl_PPM_Patient[["PatientNumber"]],
        tbl_PPM_Encounter[
            [
                "PatientNumber",
                "Extra:HospitalStayNumber",
                "EncounterNumber_enc",
                "StartDateTime_enc",
                "EndDateTime_enc",
                "EncounterType_enc",
            ]
        ],
        how="inner",
        on=["PatientNumber"],
        suffixes=("", "_drop"),
    )
    tbl_PPM_Encounter_patient_merge = tbl_PPM_Encounter_patient_merge.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    tbl_ppm_ED_Encounter_copy = pd.merge(
        tbl_PPM_Encounter_patient_merge,
        tbl_ppm_ED_Encounter_copy,
        how="inner",
        on=["PatientNumber"],
        suffixes=("", "_drop"),
    )
    tbl_ppm_ED_Encounter_copy = tbl_ppm_ED_Encounter_copy.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    tbl_ppm_ED_Encounter_copy["Extra:InpatientStayNumber_dummy"] = (
        tbl_ppm_ED_Encounter_copy["Extra:InpatientStayNumber"]
    )
    tbl_ppm_ED_Encounter_copy["Extra:InpatientEncounterNumber_dummy"] = (
        tbl_ppm_ED_Encounter_copy["Extra:InpatientEncounterNumber"]
    )
    tbl_ppm_ED_Encounter_copy["flag"] = np.where(
        (
            (tbl_ppm_ED_Encounter_copy["Extra:InpatientStayNumber_dummy"].isnull())
            | (tbl_ppm_ED_Encounter_copy["Extra:InpatientStayNumber_dummy"] == "")
        )
        & (
            (tbl_ppm_ED_Encounter_copy["Extra:InpatientEncounterNumber_dummy"].isnull())
            | (tbl_ppm_ED_Encounter_copy["Extra:InpatientEncounterNumber_dummy"] == "")
        )
        & (
            pd.to_datetime(
                tbl_ppm_ED_Encounter_copy["StartDateTime"].astype(str).str[:10],
                errors="coerce",
                format="%Y-%m-%d",
            )
            >= tbl_ppm_ED_Encounter_copy["StartDateTime_enc"]
        )
        & (
            pd.to_datetime(
                tbl_ppm_ED_Encounter_copy["StartDateTime"].astype(str).str[:10],
                errors="coerce",
                format="%Y-%m-%d",
            )
            <= tbl_ppm_ED_Encounter_copy["EndDateTime_enc"]
        )
        & (tbl_ppm_ED_Encounter_copy["Extra:EDVisitType"].astype(str) == "13")
        & (tbl_ppm_ED_Encounter_copy["EncounterType_enc"] == "I"),
        1,
        0,
    )
    tbl_ppm_ED_Encounter_copy["Extra:InpatientStayNumber"] = np.where(
        (
            (tbl_ppm_ED_Encounter_copy["Extra:InpatientStayNumber_dummy"].isnull())
            | (tbl_ppm_ED_Encounter_copy["Extra:InpatientStayNumber_dummy"] == "")
        )
        & (
            (tbl_ppm_ED_Encounter_copy["Extra:InpatientEncounterNumber_dummy"].isnull())
            | (tbl_ppm_ED_Encounter_copy["Extra:InpatientEncounterNumber_dummy"] == "")
        )
        & (
            pd.to_datetime(
                tbl_ppm_ED_Encounter_copy["StartDateTime"].astype(str).str[:10],
                errors="coerce",
                format="%Y-%m-%d",
            )
            >= tbl_ppm_ED_Encounter_copy["StartDateTime_enc"]
        )
        & (
            pd.to_datetime(
                tbl_ppm_ED_Encounter_copy["StartDateTime"].astype(str).str[:10],
                errors="coerce",
                format="%Y-%m-%d",
            )
            <= tbl_ppm_ED_Encounter_copy["EndDateTime_enc"]
        )
        & (tbl_ppm_ED_Encounter_copy["Extra:EDVisitType"].astype(str) == "13")
        & (tbl_ppm_ED_Encounter_copy["EncounterType_enc"] == "I"),
        tbl_ppm_ED_Encounter_copy["Extra:HospitalStayNumber"],
        tbl_ppm_ED_Encounter_copy["Extra:InpatientStayNumber"],
    )
    tbl_ppm_ED_Encounter_copy["Extra:InpatientEncounterNumber"] = np.where(
        (
            (tbl_ppm_ED_Encounter_copy["Extra:InpatientStayNumber_dummy"].isnull())
            | (tbl_ppm_ED_Encounter_copy["Extra:InpatientStayNumber_dummy"] == "")
        )
        & (
            (tbl_ppm_ED_Encounter_copy["Extra:InpatientEncounterNumber_dummy"].isnull())
            | (tbl_ppm_ED_Encounter_copy["Extra:InpatientEncounterNumber_dummy"] == "")
        )
        & (
            pd.to_datetime(
                tbl_ppm_ED_Encounter_copy["StartDateTime"].astype(str).str[:10],
                errors="coerce",
                format="%Y-%m-%d",
            )
            >= tbl_ppm_ED_Encounter_copy["StartDateTime_enc"]
        )
        & (
            pd.to_datetime(
                tbl_ppm_ED_Encounter_copy["StartDateTime"].astype(str).str[:10],
                errors="coerce",
                format="%Y-%m-%d",
            )
            <= tbl_ppm_ED_Encounter_copy["EndDateTime_enc"]
        )
        & (tbl_ppm_ED_Encounter_copy["Extra:EDVisitType"].astype(str) == "13")
        & (tbl_ppm_ED_Encounter_copy["EncounterType_enc"] == "I"),
        tbl_ppm_ED_Encounter_copy["EncounterNumber_enc"],
        tbl_ppm_ED_Encounter_copy["Extra:InpatientEncounterNumber"],
    )
    tbl_ppm_ED_Encounter_copy = tbl_ppm_ED_Encounter_copy[
        tbl_ppm_ED_Encounter_copy["flag"] == 1
    ]
    tbl_ppm_ED_Encounter_copy_list = tbl_ppm_ED_Encounter_copy[
        "EncounterNumber"
    ].tolist()
    tbl_ppm_ED_Encounter_non_copy = tbl_ppm_ED_Encounter[
        ~tbl_ppm_ED_Encounter["EncounterNumber"].isin(tbl_ppm_ED_Encounter_copy_list)
    ]
    tbl_ppm_ED_Encounter_copy.drop(
        [
            "Extra:InpatientStayNumber_dummy",
            "Extra:InpatientEncounterNumber_dummy",
            "Extra:HospitalStayNumber",
            "EncounterNumber_enc",
            "StartDateTime_enc",
            "EndDateTime_enc",
            "EncounterType_enc",
            "flag",
        ],
        axis=1,
        inplace=True,
        errors="ignore",
    )
    tbl_ppm_ED_Encounter_copy.drop_duplicates(keep="last", inplace=True)
    tbl_ppm_ED_Encounter = pd.concat(
        [tbl_ppm_ED_Encounter_non_copy, tbl_ppm_ED_Encounter_copy], axis=0
    )
    tbl_ppm_ED_Encounter = tbl_ppm_ED_Encounter.drop_duplicates(
        subset=["EncounterNumber"], keep="first"
    )
    logging.info(
        "Query: 1_Upd IPStay for ED Encounter Admtd in IP ENCOUNTER EVT 13 completed. tbl_ppm_ED_Encounter has %s records.",
        len(tbl_ppm_ED_Encounter),
    )
    """ For [Extra:EDVisitType] = 13 Updates the [Extra:InpatientStayNumber] and [Extra:InpatientEncounterNumber] field in the tbl_ppm_ED_Encounter table where the startdatetime in the tbl_ppm_ED_Encounter is between the startdatetime and enddatetime in the tbl_PPM_Encounter where encounter type = I
    No link by MRN
    In case mrn is redirected 
    """
    # Access query: 1_Upd IPStay for ED Encounter Admtd in IP ENCOUNTER EVT 13 b
    # UPDATE tbl_PPM_Encounter INNER JOIN tbl_ppm_ED_Encounter ON tbl_PPM_Encounter.PatientNumber = tbl_ppm_ED_Encounter.PatientNumber SET tbl_ppm_ED_Encounter.[Extra:InpatientStayNumber] = [tbl_PPM_Encounter]![Extra:HospitalStayNumber], tbl_ppm_ED_Encounter.[Extra:InpatientEncounterNumber] = [tbl_PPM_Encounter]![EncounterNumber] WHERE (((tbl_ppm_ED_Encounter.[Extra:InpatientStayNumber]) Is Null) AND ((tbl_ppm_ED_Encounter.[Extra:InpatientEncounterNumber]) Is Null) AND ((DateValue(Left([tbl_ppm_ED_Encounter]![StartDateTime],10))) Between DateValue(Left([tbl_PPM_Encounter]![StartDateTime],10)) And DateValue(Left([tbl_PPM_Encounter]![EndDateTime],10))) AND ((tbl_ppm_ED_Encounter.[Extra:EDVisitType])="13") AND ((tbl_PPM_Encounter.EncounterType)="I"));
    # Inform8 query:UpdateWhenAdmitted4()
    # query: ppmencounter inner join ppmedencounter on ppmencounter.patientnumber = ppmedencounter.patientnumber  where ppmedencounter.Extra:EDVisitType == "13" && ppmencounter.EncounterType == "I" && string.IsNullOrEmpty(ppmedencounter.Extra:InpatientEncounterNumber) && IsNullOrEmpty(ppmedencounter.Extra:InpatientStayNumber)
    # if ppmedencounter.StartDateTime >= ppmEncounter.StartDateTime && ppmedencounter.StartDateTime<=ppmEncounter.EndDatTime
    # update
    #   ppmedencounter.Extra:InpatientEncounterNumber = ppmencounter.EncounterNumber,
    #   ppmedencounter.Extra:InpatientStayNumber = ppmEncounter.Extra:HospitalStayNumber,
    #   ppmedencounter.Extra:AUID = ppmEncounter.Extra:AUID
    tbl_ppm_ED_Encounter_copy = tbl_ppm_ED_Encounter.copy()
    tbl_ppm_ED_Encounter_copy = pd.merge(
        tbl_PPM_Encounter[
            [
                "PatientNumber",
                "Extra:HospitalStayNumber",
                "EncounterNumber_enc",
                "StartDateTime_enc",
                "EndDateTime_enc",
                "EncounterType_enc",
            ]
        ],
        tbl_ppm_ED_Encounter_copy,
        how="inner",
        on=["PatientNumber"],
        suffixes=("", "_drop"),
    )
    tbl_ppm_ED_Encounter_copy = tbl_ppm_ED_Encounter_copy.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    tbl_ppm_ED_Encounter_copy["Extra:InpatientStayNumber_dummy"] = (
        tbl_ppm_ED_Encounter_copy["Extra:InpatientStayNumber"]
    )
    tbl_ppm_ED_Encounter_copy["Extra:InpatientEncounterNumber_dummy"] = (
        tbl_ppm_ED_Encounter_copy["Extra:InpatientEncounterNumber"]
    )
    tbl_ppm_ED_Encounter_copy["flag"] = np.where(
        (
            (
                (tbl_ppm_ED_Encounter_copy["Extra:InpatientStayNumber_dummy"].isnull())
                | (tbl_ppm_ED_Encounter_copy["Extra:InpatientStayNumber_dummy"] == "")
            )
            & (
                (
                    tbl_ppm_ED_Encounter_copy[
                        "Extra:InpatientEncounterNumber_dummy"
                    ].isnull()
                )
                | (
                    tbl_ppm_ED_Encounter_copy["Extra:InpatientEncounterNumber_dummy"]
                    == ""
                )
            )
            & (
                pd.to_datetime(
                    tbl_ppm_ED_Encounter_copy["StartDateTime"].astype(str).str[:10],
                    errors="coerce",
                    format="%Y-%m-%d",
                )
                >= tbl_ppm_ED_Encounter_copy["StartDateTime_enc"]
            )
            & (
                pd.to_datetime(
                    tbl_ppm_ED_Encounter_copy["StartDateTime"].astype(str).str[:10],
                    errors="coerce",
                    format="%Y-%m-%d",
                )
                <= tbl_ppm_ED_Encounter_copy["EndDateTime_enc"]
            )
        )
        & (tbl_ppm_ED_Encounter_copy["Extra:EDVisitType"].astype(str) == "13")
        & (tbl_ppm_ED_Encounter_copy["EncounterType_enc"] == "I"),
        1,
        0,
    )
    tbl_ppm_ED_Encounter_copy["Extra:InpatientStayNumber"] = np.where(
        (
            (
                (tbl_ppm_ED_Encounter_copy["Extra:InpatientStayNumber_dummy"].isnull())
                | (tbl_ppm_ED_Encounter_copy["Extra:InpatientStayNumber_dummy"] == "")
            )
            & (
                (
                    tbl_ppm_ED_Encounter_copy[
                        "Extra:InpatientEncounterNumber_dummy"
                    ].isnull()
                )
                | (
                    tbl_ppm_ED_Encounter_copy["Extra:InpatientEncounterNumber_dummy"]
                    == ""
                )
            )
            & (
                pd.to_datetime(
                    tbl_ppm_ED_Encounter_copy["StartDateTime"].astype(str).str[:10],
                    errors="coerce",
                    format="%Y-%m-%d",
                )
                >= tbl_ppm_ED_Encounter_copy["StartDateTime_enc"]
            )
            & (
                pd.to_datetime(
                    tbl_ppm_ED_Encounter_copy["StartDateTime"].astype(str).str[:10],
                    errors="coerce",
                    format="%Y-%m-%d",
                )
                <= tbl_ppm_ED_Encounter_copy["EndDateTime_enc"]
            )
        )
        & (tbl_ppm_ED_Encounter_copy["Extra:EDVisitType"].astype(str) == "13")
        & (tbl_ppm_ED_Encounter_copy["EncounterType_enc"] == "I"),
        tbl_ppm_ED_Encounter_copy["Extra:HospitalStayNumber"],
        tbl_ppm_ED_Encounter_copy["Extra:InpatientStayNumber"],
    )
    tbl_ppm_ED_Encounter_copy["Extra:InpatientEncounterNumber"] = np.where(
        (
            (
                (tbl_ppm_ED_Encounter_copy["Extra:InpatientStayNumber_dummy"].isnull())
                | (tbl_ppm_ED_Encounter_copy["Extra:InpatientStayNumber_dummy"] == "")
            )
            & (
                (
                    tbl_ppm_ED_Encounter_copy[
                        "Extra:InpatientEncounterNumber_dummy"
                    ].isnull()
                )
                | (
                    tbl_ppm_ED_Encounter_copy["Extra:InpatientEncounterNumber_dummy"]
                    == ""
                )
            )
            & (
                pd.to_datetime(
                    tbl_ppm_ED_Encounter_copy["StartDateTime"].astype(str).str[:10],
                    errors="coerce",
                    format="%Y-%m-%d",
                )
                >= tbl_ppm_ED_Encounter_copy["StartDateTime_enc"]
            )
            & (
                pd.to_datetime(
                    tbl_ppm_ED_Encounter_copy["StartDateTime"].astype(str).str[:10],
                    errors="coerce",
                    format="%Y-%m-%d",
                )
                <= tbl_ppm_ED_Encounter_copy["EndDateTime_enc"]
            )
        )
        & (tbl_ppm_ED_Encounter_copy["Extra:EDVisitType"].astype(str) == "13")
        & (tbl_ppm_ED_Encounter_copy["EncounterType_enc"] == "I"),
        tbl_ppm_ED_Encounter_copy["EncounterNumber_enc"],
        tbl_ppm_ED_Encounter_copy["Extra:InpatientStayNumber"],
    )
    tbl_ppm_ED_Encounter_copy = tbl_ppm_ED_Encounter_copy[
        tbl_ppm_ED_Encounter_copy["flag"] == 1
    ]
    tbl_ppm_ED_Encounter_copy_list = tbl_ppm_ED_Encounter_copy[
        "EncounterNumber"
    ].tolist()
    tbl_ppm_ED_Encounter_non_copy = tbl_ppm_ED_Encounter[
        ~tbl_ppm_ED_Encounter["EncounterNumber"].isin(tbl_ppm_ED_Encounter_copy_list)
    ]
    tbl_ppm_ED_Encounter_copy.drop(
        [
            "Extra:InpatientStayNumber_dummy",
            "Extra:InpatientEncounterNumber_dummy",
            "Extra:HospitalStayNumber",
            "EncounterNumber_enc",
            "StartDateTime_enc",
            "EndDateTime_enc",
            "EncounterType_enc",
            "flag",
        ],
        axis=1,
        inplace=True,
        errors="ignore",
    )
    tbl_ppm_ED_Encounter_copy.drop_duplicates(keep="last", inplace=True)
    tbl_ppm_ED_Encounter = pd.concat(
        [tbl_ppm_ED_Encounter_non_copy, tbl_ppm_ED_Encounter_copy], axis=0
    )
    tbl_ppm_ED_Encounter = tbl_ppm_ED_Encounter.drop_duplicates(
        subset=["EncounterNumber"], keep="first"
    )
    logging.info(
        "Query: 1_Upd IPStay for ED Encounter Admtd in IP ENCOUNTER EVT 13 b completed.  tbl_ppm_ED_Encounter has %s records.",
        len(tbl_ppm_ED_Encounter),
    )
    """ Appends ed encounters from the tbl_ppm_ED_Encounter where [Extra:EDVisitType] = 13 and [Extra:InpatientEncounterNumber] is not null ( these encounters services will be attached to inpatient encounter ) to the tbl_ExcludedEncounters table """
    # Access query: qry Append Excluded Encounter EVT13
    # INSERT INTO tbl_ExcludedEncounters ( facility_identifier, Ed_identifier, [Reason For Exclusion], EncounterNumber ) SELECT tbl_ppm_ED_Encounter.Hospital, Replace([Extra:ED_visit_identifier],"ED","") AS Expr2, "ED Visit Type 13 - Admitted Patient" AS Expr1, tbl_ppm_ED_Encounter.EncounterNumber FROM tbl_ppm_ED_Encounter WHERE (((tbl_ppm_ED_Encounter.[Extra:EDVisitType])="13") AND ((tbl_ppm_ED_Encounter.[Extra:InpatientEncounterNumber]) Is Not Null));
    qry_Append_Excluded_Encounter_EVT13 = pd.DataFrame()
    qry_Append_Excluded_Encounter_EVT13 = tbl_ppm_ED_Encounter[
        (tbl_ppm_ED_Encounter["Extra:EDVisitType"].astype(str) == "13")
        & (pd.notna(tbl_ppm_ED_Encounter["Extra:InpatientEncounterNumber"]))
        & (tbl_ppm_ED_Encounter["Extra:InpatientEncounterNumber"] != "")
    ][["Hospital", "Extra:ED_visit_identifier", "EncounterNumber"]]
    qry_Append_Excluded_Encounter_EVT13.to_csv(
        "./ExtractorDB/tbl_ppm_ED_Encounter_EVT13_excluded.csv", index=False
    )
    qry_Append_Excluded_Encounter_EVT13["facility_identifier"] = (
        qry_Append_Excluded_Encounter_EVT13["Hospital"]
    )
    qry_Append_Excluded_Encounter_EVT13["ed_identifier"] = (
        qry_Append_Excluded_Encounter_EVT13["Extra:ED_visit_identifier"]
        .astype(str)
        .str.replace("ED", "")
    )
    qry_Append_Excluded_Encounter_EVT13["ed_identifier"] = (
        qry_Append_Excluded_Encounter_EVT13["ed_identifier"]
        .astype(str)
        .str.replace("ED", "")
    )
    qry_Append_Excluded_Encounter_EVT13["ReasonForExclusion"] = (
        "ED Visit Type 13 - Admitted Patient"
    )
    qry_Append_Excluded_Encounter_EVT13["stay_number"] = "XXXXXXXX"
    qry_Append_Excluded_Encounter_EVT13["episode_sequence_number"] = 0
    qry_Append_Excluded_Encounter_EVT13["SNAP_encounter"] = "XXXX_XXXXXXXX"
    qry_Append_Excluded_Encounter_EVT13 = qry_Append_Excluded_Encounter_EVT13[
        [
            "facility_identifier",
            "stay_number",
            "episode_sequence_number",
            "ed_identifier",
            "SNAP_encounter",
            "ReasonForExclusion",
            "EncounterNumber",
        ]
    ]
    tbl_ExcludedEncounters = pd.concat(
        [tbl_ExcludedEncounters, qry_Append_Excluded_Encounter_EVT13], axis=0
    )
    logging.info(
        "Query: qry Append Excluded Encounter EVT13 completed. %s ed encounters from the tbl_ppm_ED_Encounter where [Extra:EDVisitType] = 13 and [Extra:InpatientEncounterNumber] is not null will be inserted to tbl_ppm_ED_Encounter. tbl_ExcludedEncounters now has %s records.",
        len(qry_Append_Excluded_Encounter_EVT13),
        len(tbl_ExcludedEncounters),
    )
    # exclude encounters - # Comment this step
    # tbl_excludedencounters_list = tbl_ExcludedEncounters['EncounterNumber'].tolist()
    # tbl_ppm_ED_Encounter = tbl_ppm_ED_Encounter[~(tbl_ppm_ED_Encounter['EncounterNumber'].isin(tbl_excludedencounters_list))]
    """ Appends encounters to the tbl_ppm_ed_encounter EVT13 that have been appended to excluded table with same criteria"""
    # Access query: append tbl_ppm_Ed_encounter EVT13
    # INSERT INTO [tbl_ppm_ed_encounter EVT13] ( EncounterNumber, PostCode, Suburb, EncounterType, PatientNumber, Hospital, LengthofStay, StartDateTime, EndDateTime, Age, WeightedSeparation, [Extra:InpatientStayNumber], [Extra:TriageCategory], [Extra:ModeofArrival], [Extra:EDVisitType], [Extra:EDDiagnosis], [Extra:ModeofSep], [Extra:EDTriageDateTime], [Extra:EDReferralSource], [Extra:IndigenousStatus], [Extra:MedicareNumber], [Extra:EmergRoleDelin], [Extra:UDG], [Extra:URG], [Extra:ClinStartDTTM], [Extra:DepartureReadyDTTM], [Extra:EDDiagnosisType], [Extra:AdmWard], [Extra:EdCompStatus], [Extra:Version_Id], [Extra:nwau], [Extra:sla_ra06], [Extra:EDDiagnosis2], [Extra:EDDiagnosisType2], [Extra:EDDiagnosis3], [Extra:EDDiagnosisType3], [Extra:InpatientEncounterNumber], [Extra:postcode_ra06], [Extra:hosp_ra06], [Extra:MDB], [Extra:UDG_IPHA], [Extra:ED_visit_identifier], [Extra:ED_Hosp_A233], [Extra:LHD_of_Usual_Residence], [Extra:compensable_nwau], [Extra:nwau_base], [Extra:nwau_indig_incr], [Extra:nwau_version], [Extra:nwau_urg_ed_diagnosis_mapped], [Extra:nwau_type], [Extra:WIP], DRG1, DRG1Version, [Extra:N_Z_FinancialProgram] )
    # SELECT tbl_ppm_ED_Encounter.EncounterNumber, tbl_ppm_ED_Encounter.PostCode, tbl_ppm_ED_Encounter.Suburb, tbl_ppm_ED_Encounter.EncounterType, tbl_ppm_ED_Encounter.PatientNumber, tbl_ppm_ED_Encounter.Hospital, tbl_ppm_ED_Encounter.LengthofStay, tbl_ppm_ED_Encounter.StartDateTime, tbl_ppm_ED_Encounter.EndDateTime, tbl_ppm_ED_Encounter.Age, tbl_ppm_ED_Encounter.WeightedSeparation, tbl_ppm_ED_Encounter.[Extra:InpatientStayNumber], tbl_ppm_ED_Encounter.[Extra:TriageCategory], tbl_ppm_ED_Encounter.[Extra:ModeofArrival], tbl_ppm_ED_Encounter.[Extra:EDVisitType], tbl_ppm_ED_Encounter.[Extra:EDDiagnosis], tbl_ppm_ED_Encounter.[Extra:ModeofSep], tbl_ppm_ED_Encounter.[Extra:EDTriageDateTime], tbl_ppm_ED_Encounter.[Extra:EDReferralSource], tbl_ppm_ED_Encounter.[Extra:IndigenousStatus], tbl_ppm_ED_Encounter.[Extra:MedicareNumber], tbl_ppm_ED_Encounter.[Extra:EmergRoleDelin], tbl_ppm_ED_Encounter.[Extra:UDG], tbl_ppm_ED_Encounter.[Extra:URG], tbl_ppm_ED_Encounter.[Extra:ClinStartDTTM], tbl_ppm_ED_Encounter.[Extra:DepartureReadyDTTM], tbl_ppm_ED_Encounter.[Extra:EDDiagnosisType], tbl_ppm_ED_Encounter.[Extra:AdmWard], tbl_ppm_ED_Encounter.[Extra:EdCompStatus], tbl_ppm_ED_Encounter.[Extra:Version_Id], tbl_ppm_ED_Encounter.[Extra:nwau], tbl_ppm_ED_Encounter.[Extra:sla_ra06], tbl_ppm_ED_Encounter.[Extra:EDDiagnosis2], tbl_ppm_ED_Encounter.[Extra:EDDiagnosisType2], tbl_ppm_ED_Encounter.[Extra:EDDiagnosis3], tbl_ppm_ED_Encounter.[Extra:EDDiagnosisType3], tbl_ppm_ED_Encounter.[Extra:InpatientEncounterNumber], tbl_ppm_ED_Encounter.[Extra:postcode_ra06], tbl_ppm_ED_Encounter.[Extra:hosp_ra06], tbl_ppm_ED_Encounter.[Extra:MDB], tbl_ppm_ED_Encounter.[Extra:UDG_IPHA], tbl_ppm_ED_Encounter.[Extra:ED_visit_identifier], tbl_ppm_ED_Encounter.[Extra:ED_Hosp_A233], tbl_ppm_ED_Encounter.[Extra:LHD_of_Usual_Residence], tbl_ppm_ED_Encounter.[Extra:compensable_nwau], tbl_ppm_ED_Encounter.[Extra:nwau_base], tbl_ppm_ED_Encounter.[Extra:nwau_indig_incr], tbl_ppm_ED_Encounter.[Extra:nwau_version], tbl_ppm_ED_Encounter.[Extra:nwau_urg_ed_diagnosis_mapped], tbl_ppm_ED_Encounter.[Extra:nwau_type], tbl_ppm_ED_Encounter.[Extra:WIP], tbl_ppm_ED_Encounter.DRG1, tbl_ppm_ED_Encounter.DRG1Version, tbl_ppm_ED_Encounter.[Extra:N_Z_FinancialProgram]
    # FROM tbl_ppm_ED_Encounter  WHERE (((tbl_ppm_ED_Encounter.[Extra:EDVisitType])="13") AND ((tbl_ppm_ED_Encounter.[Extra:InpatientEncounterNumber]) Is Not Null));
    tbl_ppm_ed_encounter_EVT13 = tbl_ppm_ED_Encounter[
        (tbl_ppm_ED_Encounter["Extra:EDVisitType"] == "13")
        & (pd.notna(tbl_ppm_ED_Encounter["Extra:InpatientEncounterNumber"]))
        & (tbl_ppm_ED_Encounter["Extra:InpatientEncounterNumber"] != "")
    ]
    tbl_ppm_ed_encounter_EVT13 = tbl_ppm_ed_encounter_EVT13[
        [
            "EncounterNumber",
            "PostCode",
            "Suburb",
            "EncounterType",
            "PatientNumber",
            "Hospital",
            "LengthofStay",
            "StartDateTime",
            "EndDateTime",
            "Age",
            "WeightedSeparation",
            "Extra:InpatientStayNumber",
            "Extra:TriageCategory",
            "Extra:ModeofArrival",
            "Extra:EDVisitType",
            "Extra:EDDiagnosis",
            "Extra:ModeofSep",
            "Extra:EDTriageDateTime",
            "Extra:EDReferralSource",
            "Extra:IndigenousStatus",
            "Extra:MedicareNumber",
            "Extra:EmergRoleDelin",
            "Extra:UDG",
            "Extra:URG",
            "Extra:ClinStartDTTM",
            "Extra:DepartureReadyDTTM",
            "Extra:EDDiagnosisType",
            "Extra:EDDiagnosis2",
            "Extra:EDDiagnosisType2",
            "Extra:EDDiagnosis3",
            "Extra:EDDiagnosisType3",
            "Extra:AdmWard",
            "Extra:EdCompStatus",
            "Extra:ExtractorVersion",
            "Extra:nwau",
            "Extra:sla_ra06",
            "Extra:InpatientEncounterNumber",
            "Extra:postcode_ra06",
            "Extra:hosp_ra06",
            "Extra:MDB",
            "Extra:UDG_IPHA",
            "Extra:ED_visit_identifier",
            "Extra:ED_Hosp_A233",
            "Extra:LHD_of_Usual_Residence",
            "Extra:compensable_nwau",
            "Extra:nwau_base",
            "Extra:nwau_indig_incr",
            "Extra:nwau_version",
            "Extra:nwau_urg_ed_diagnosis_mapped",
            "Extra:nwau_type",
            "Extra:WIP",
            "DRG1",
            "DRG1Version",
            "Extra:N_Z_FinancialProgram",
            "Extra:AUID",
            "Extra:HLTH_ORG_OSP_OSP_ID",
            "Extra:MG_AUTH_OSP_OSP_ID",
            "Extra:SE_CBK_SK",
            "Extra:CL_ID_EUID",
            "Extra:CL_ID_IHI",
            "Extra:FST_BILL_CATEGORY_CD",
            "Extra:FST_FIN_CLASS_CD",
            "Extra:EDW_Pat_Number",
            "Extra:EDW_Enc_Number",
            "Extra:SRV_ENC_REC_ID",
            "Extra:WAU_ADJ_PT_TX_REMT_AREA",
            "Extra:WAU_ADJ_PT_RES_REMT_AREA",
            "Extra:EDDiag_ver",
            "Extra:EDINTERVENTION_VER",
            "Extra:EDINTERVENTION_CD",
            "Extra:ASGS_SA_L2_16_CD",
            "Extra:CL_URES_ADDR_ASGS21_SA_L2_CD",
            "Extra:AP_SE_CBK_SK",
            "Extra:IP_SRV_ENC_REC_ID",
        ]
    ]
    tbl_ppm_ed_encounter_EVT13 = tbl_ppm_ed_encounter_EVT13.drop_duplicates(keep="last")
    logging.info(
        "Query: append tbl_ppm_Ed_encounter EVT13 completed. tbl_ppm_ed_encounter_EVT13 now has %s records.",
        len(tbl_ppm_ed_encounter_EVT13),
    )
    """ Deletes encounters from the tbl_ppm_ED_Encounter where Extra:EDVisitType] = 13 and [Extra:InpatientEncounterNumber] is not null"""
    # Access query: qrydelete EDVisitType13
    # DELETE tbl_ppm_ED_Encounter.*, tbl_ppm_ED_Encounter.[Extra:EDVisitType], tbl_ppm_ED_Encounter.[Extra:InpatientEncounterNumber] FROM tbl_ppm_ED_Encounter WHERE (((tbl_ppm_ED_Encounter.[Extra:EDVisitType])="13") AND ((tbl_ppm_ED_Encounter.[Extra:InpatientEncounterNumber]) Is Not Null));
    """
    index_names = tbl_ppm_ED_Encounter[(tbl_ppm_ED_Encounter['Extra:EDVisitType'].astype(str) == '13') & (pd.notna(tbl_ppm_ED_Encounter['Extra:InpatientEncounterNumber'])) & (tbl_ppm_ED_Encounter['Extra:InpatientEncounterNumber']!='')].index
    tbl_ppm_ED_Encounter.drop(index_names, inplace = True)
    """
    tbl_ppm_ED_Encounter = tbl_ppm_ED_Encounter[
        ~(
            (tbl_ppm_ED_Encounter["Extra:EDVisitType"] == "13")
            & (pd.notna(tbl_ppm_ED_Encounter["Extra:InpatientEncounterNumber"]))
            & (tbl_ppm_ED_Encounter["Extra:InpatientEncounterNumber"] != "")
        )
    ]
    logging.info(
        "Query: qrydelete EDVisitType13 completed. tbl_ppm_ED_Encounter now has %s records.",
        len(tbl_ppm_ED_Encounter),
    )
    """ Deletes encounters from the table tbl_ExcludedEncounters where reason for exclusion = "Duplicate ED Encounter with same patientnumber, Start and End Date Time as another Encounter" this step could be changed from max table query adjustment add min and max ed_visit_id  in table ??"""
    # Access query: del tbl_exclude encounters duplicate ed encounter
    # DELETE tbl_ExcludedEncounters.[Reason For Exclusion] FROM tbl_ExcludedEncounters WHERE (((tbl_ExcludedEncounters.[Reason For Exclusion])="Duplicate ED Encounter with same patientnumber, Start and End Date Time as another Encounter"));
    """
    index_names = tbl_ExcludedEncounters[(tbl_ExcludedEncounters['ReasonForExclusion'] == 'Duplicate ED Encounter with same patientnumber, Start and End Date Time as another Encounter')].index
    tbl_ExcludedEncounters.drop(index_names, inplace = True)
    logging.info('Query: del tbl_exclude encounters duplicate ed encounter completed. tbl_ExcludedEncounters now has %s records.', len(tbl_ExcludedEncounters))
    tbl_ppm_ED_Encounter = tbl_ppm_ED_Encounter.drop_duplicates( keep='last')
    """
    # tbl_ppm_ED_Encounter.to_csv('./ExtractorDB/tbl_ppm_ED_Encounter_6.csv', index = False)
    # Access query: qry append tbl excluded encounters duplicate ED Encounters
    # INSERT INTO tbl_ExcludedEncounters ( EncounterNumber, facility_identifier, Ed_identifier, [Reason For Exclusion] ) SELECT tbl_ppm_ED_Encounter_preclean.EncounterNumber, tbl_ppm_ED_Encounter_preclean.Hospital, tbl_ppm_ED_Encounter_preclean.Stu, "Duplicate ED Encounter with same patientnumber, Start and End Date Time as another Encounter" AS Expr1 FROM (tbl_ppm_ED_Encounter_preclean LEFT JOIN tbl_ppm_ED_Encounter ON tbl_ppm_ED_Encounter_preclean.EncounterNumber = tbl_ppm_ED_Encounter.EncounterNumber) LEFT JOIN tbl_ExcludedEncounters ON tbl_ppm_ED_Encounter_preclean.EncounterNumber = tbl_ExcludedEncounters.EncounterNumber WHERE (((tbl_ppm_ED_Encounter.EncounterNumber) Is Null) AND ((tbl_ExcludedEncounters.EncounterNumber) Is Null));
    tbl_ppm_ED_Encounter_exc = pd.concat(
        [tbl_ppm_ed_encounter_EVT13, tbl_ppm_ED_Encounter], axis=0
    )
    tbl_ppm_ED_Encounter_list = tbl_ppm_ED_Encounter_exc["EncounterNumber"].tolist()
    tbl_ppm_ED_Encounter_preclean_copy = tbl_ppm_ED_Encounter_preclean[
        ~tbl_ppm_ED_Encounter_preclean["EncounterNumber"].isin(
            tbl_ppm_ED_Encounter_list
        )
    ]
    qry_append_tbl_excluded_encounters_duplicate_ED_Encounters = pd.DataFrame()
    qry_append_tbl_excluded_encounters_duplicate_ED_Encounters = (
        tbl_ppm_ED_Encounter_preclean_copy[["EncounterNumber", "Hospital", "Stu"]]
    )
    qry_append_tbl_excluded_encounters_duplicate_ED_Encounters[
        "facility_identifier"
    ] = qry_append_tbl_excluded_encounters_duplicate_ED_Encounters["Hospital"]
    qry_append_tbl_excluded_encounters_duplicate_ED_Encounters["ed_identifier"] = (
        qry_append_tbl_excluded_encounters_duplicate_ED_Encounters["Stu"]
    )
    qry_append_tbl_excluded_encounters_duplicate_ED_Encounters["ReasonForExclusion"] = (
        "Duplicate ED Encounter with same patientnumber, Start and End Date Time as another Encounter"
    )
    qry_append_tbl_excluded_encounters_duplicate_ED_Encounters["stay_number"] = (
        "XXXXXXXX"
    )
    qry_append_tbl_excluded_encounters_duplicate_ED_Encounters[
        "episode_sequence_number"
    ] = 0
    qry_append_tbl_excluded_encounters_duplicate_ED_Encounters["SNAP_encounter"] = (
        "XXXX_XXXXXXXX"
    )
    qry_append_tbl_excluded_encounters_duplicate_ED_Encounters.to_csv(
        "./ExtractorDB/qry_append_tbl_excluded_encounters_duplicate_ED_Encounters.csv",
        index=False,
    )
    qry_append_tbl_excluded_encounters_duplicate_ED_Encounters = (
        qry_append_tbl_excluded_encounters_duplicate_ED_Encounters[
            [
                "facility_identifier",
                "stay_number",
                "episode_sequence_number",
                "ed_identifier",
                "SNAP_encounter",
                "ReasonForExclusion",
                "EncounterNumber",
            ]
        ]
    )
    tbl_ExcludedEncounters_list_to_exclude_dup = tbl_ExcludedEncounters[
        "EncounterNumber"
    ].tolist()
    qry_append_tbl_excluded_encounters_duplicate_ED_Encounters = (
        qry_append_tbl_excluded_encounters_duplicate_ED_Encounters[
            ~qry_append_tbl_excluded_encounters_duplicate_ED_Encounters[
                "EncounterNumber"
            ].isin(tbl_ExcludedEncounters_list_to_exclude_dup)
        ]
    )
    if len(qry_append_tbl_excluded_encounters_duplicate_ED_Encounters) > 0:
        tbl_ExcludedEncounters = pd.concat(
            [
                tbl_ExcludedEncounters,
                qry_append_tbl_excluded_encounters_duplicate_ED_Encounters,
            ],
            axis=0,
        )
        tbl_ExcludedEncounters = tbl_ExcludedEncounters.drop_duplicates(keep="last")
    logging.info(
        "Query: qry append tbl excluded encounters duplicate ED Encounters completed. %s encounters with Duplicate ED Encounter with same patientnumber, Start and End Date Time as another Encounter will be inserted to tbl_ExcludedEncounters. tbl_ExcludedEncounters now has %s records.",
        len(qry_append_tbl_excluded_encounters_duplicate_ED_Encounters),
        len(tbl_ExcludedEncounters),
    )
    """ Export tbl_ppm_ED_Encounter table as c:\costing\ tbl_ppm_ED_Encounter + versionID + .csv"""
    # Access query: tbl_ppm_ED_Encounter
    tbl_ppm_ED_Encounter = tbl_ppm_ED_Encounter[
        [
            "EncounterNumber",
            "PostCode",
            "Suburb",
            "EncounterType",
            "PatientNumber",
            "Hospital",
            "LengthofStay",
            "StartDateTime",
            "EndDateTime",
            "Age",
            "WeightedSeparation",
            "Extra:InpatientStayNumber",
            "Extra:TriageCategory",
            "Extra:ModeofArrival",
            "Extra:EDVisitType",
            "Extra:EDDiagnosis",
            "Extra:ModeofSep",
            "Extra:EDTriageDateTime",
            "Extra:EDReferralSource",
            "Extra:IndigenousStatus",
            "Extra:MedicareNumber",
            "Extra:EmergRoleDelin",
            "Extra:UDG",
            "Extra:URG",
            "Extra:ClinStartDTTM",
            "Extra:DepartureReadyDTTM",
            "Extra:EDDiagnosisType",
            "Extra:EDDiagnosis2",
            "Extra:EDDiagnosisType2",
            "Extra:EDDiagnosis3",
            "Extra:EDDiagnosisType3",
            "Extra:AdmWard",
            "Extra:EdCompStatus",
            "Extra:ExtractorVersion",
            "Extra:nwau",
            "Extra:sla_ra06",
            "Extra:InpatientEncounterNumber",
            "Extra:postcode_ra06",
            "Extra:hosp_ra06",
            "Extra:MDB",
            "Extra:UDG_IPHA",
            "Extra:ED_visit_identifier",
            "Extra:ED_Hosp_A233",
            "Extra:LHD_of_Usual_Residence",
            "Extra:compensable_nwau",
            "Extra:nwau_base",
            "Extra:nwau_indig_incr",
            "Extra:nwau_version",
            "Extra:nwau_urg_ed_diagnosis_mapped",
            "Extra:nwau_type",
            "Extra:WIP",
            "DRG1",
            "DRG1Version",
            "Extra:N_Z_FinancialProgram",
            "Extra:ExtractDate",
            "Extra:AUID",
            "Extra:HLTH_ORG_OSP_OSP_ID",
            "Extra:MG_AUTH_OSP_OSP_ID",
            "Extra:SE_CBK_SK",
            "Extra:CL_ID_EUID",
            "Extra:CL_ID_IHI",
            "Extra:FST_BILL_CATEGORY_CD",
            "Extra:FST_FIN_CLASS_CD",
            "Extra:EDW_Pat_Number",
            "Extra:EDW_Enc_Number",
            "Extra:SRV_ENC_REC_ID",
            "Extra:WAU_ADJ_PT_TX_REMT_AREA",
            "Extra:WAU_ADJ_PT_RES_REMT_AREA",
            "Extra:EDDiag_ver",
            "Extra:EDINTERVENTION_VER",
            "Extra:EDINTERVENTION_CD",
            "Extra:ASGS_SA_L2_16_CD",
            "Extra:CL_URES_ADDR_ASGS21_SA_L2_CD",
            "Extra:AP_SE_CBK_SK",
            "Extra:IP_SRV_ENC_REC_ID",
        ]
    ]
    tbl_ppm_ED_Encounter = tbl_ppm_ED_Encounter.drop_duplicates(keep="last")
    tbl_ppm_ED_Encounter = tbl_ppm_ED_Encounter.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    tbl_ppm_ED_Encounter = tbl_ppm_ED_Encounter.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    tbl_ppm_ED_Encounter = tbl_ppm_ED_Encounter.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    tbl_ppm_ED_Encounter = tbl_ppm_ED_Encounter.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    # exclude encounters
    tbl_excludedencounters_list = tbl_ExcludedEncounters["EncounterNumber"].tolist()
    tbl_ppm_ED_Encounter = tbl_ppm_ED_Encounter[
        ~(tbl_ppm_ED_Encounter["EncounterNumber"].isin(tbl_excludedencounters_list))
    ]
    try:
        tbl_ppm_ED_Encounter.to_csv(
            "./Output/tbl_ppm_ED_Encounter_" + versionID_underscore + ".csv",
            index=False,
            na_rep="",
            float_format=str,
            decimal=str,
            date_format=str,
        )
    except Exception as e:
        logging.exception("Exception occurred")
        label_6_status = 0
        messagebox.showerror(
            "Export Error", "Error exporting tbl_ppm_ED_Encounter\n" + str(e)
        )
        label_6_sub.configure(text="Failed ()...", fg="red")
        main_screen.update()
        return  # stop export
    logging.info(
        "%s records saved to ./Output/tbl_ppm_ED_Encounter_%s.csv.",
        len(tbl_ppm_ED_Encounter),
        versionID_underscore,
    )
    ###############################################################################
    tbl_ppm_ed_encounter_EVT13["Extra:EDReferralSource"] = (
        tbl_ppm_ed_encounter_EVT13["Extra:EDReferralSource"]
        .astype(str)
        .str.pad(2, side="left", fillchar="0")
    )
    tbl_ppm_ed_encounter_EVT13["Extra:UDG_IPHA"] = (
        tbl_ppm_ed_encounter_EVT13["Extra:UDG_IPHA"]
        .astype(str)
        .str.pad(2, side="left", fillchar="0")
    )
    ###############################################################################
    """Export all data from tbl_ppm_ed_encounter EVT13 as c:\costing\tbl_ppm_ed_encounter EVT13.csv """
    # Access query: tbl_ppm_ed_encounter EVT13
    tbl_ppm_ed_encounter_EVT13 = tbl_ppm_ed_encounter_EVT13[
        [
            "EncounterNumber",
            "PostCode",
            "Suburb",
            "EncounterType",
            "PatientNumber",
            "Hospital",
            "LengthofStay",
            "StartDateTime",
            "EndDateTime",
            "Age",
            "WeightedSeparation",
            "Extra:InpatientStayNumber",
            "Extra:TriageCategory",
            "Extra:ModeofArrival",
            "Extra:EDVisitType",
            "Extra:EDDiagnosis",
            "Extra:ModeofSep",
            "Extra:EDTriageDateTime",
            "Extra:EDReferralSource",
            "Extra:IndigenousStatus",
            "Extra:MedicareNumber",
            "Extra:EmergRoleDelin",
            "Extra:UDG",
            "Extra:URG",
            "Extra:ClinStartDTTM",
            "Extra:DepartureReadyDTTM",
            "Extra:EDDiagnosisType",
            "Extra:EDDiagnosis2",
            "Extra:EDDiagnosisType2",
            "Extra:EDDiagnosis3",
            "Extra:EDDiagnosisType3",
            "Extra:AdmWard",
            "Extra:EdCompStatus",
            "Extra:ExtractorVersion",
            "Extra:nwau",
            "Extra:sla_ra06",
            "Extra:InpatientEncounterNumber",
            "Extra:postcode_ra06",
            "Extra:hosp_ra06",
            "Extra:MDB",
            "Extra:UDG_IPHA",
            "Extra:ED_visit_identifier",
            "Extra:ED_Hosp_A233",
            "Extra:LHD_of_Usual_Residence",
            "Extra:compensable_nwau",
            "Extra:nwau_base",
            "Extra:nwau_indig_incr",
            "Extra:nwau_version",
            "Extra:nwau_urg_ed_diagnosis_mapped",
            "Extra:nwau_type",
            "Extra:WIP",
            "DRG1",
            "DRG1Version",
            "Extra:N_Z_FinancialProgram",
            "Extra:AUID",
            "Extra:HLTH_ORG_OSP_OSP_ID",
            "Extra:MG_AUTH_OSP_OSP_ID",
            "Extra:SE_CBK_SK",
            "Extra:CL_ID_EUID",
            "Extra:CL_ID_IHI",
            "Extra:FST_BILL_CATEGORY_CD",
            "Extra:FST_FIN_CLASS_CD",
            "Extra:EDW_Pat_Number",
            "Extra:EDW_Enc_Number",
            "Extra:SRV_ENC_REC_ID",
            "Extra:WAU_ADJ_PT_TX_REMT_AREA",
            "Extra:WAU_ADJ_PT_RES_REMT_AREA",
            "Extra:EDDiag_ver",
            "Extra:EDINTERVENTION_VER",
            "Extra:EDINTERVENTION_CD",
            "Extra:ASGS_SA_L2_16_CD",
            "Extra:CL_URES_ADDR_ASGS21_SA_L2_CD",
            "Extra:AP_SE_CBK_SK",
            "Extra:IP_SRV_ENC_REC_ID",
        ]
    ]
    tbl_ppm_ed_encounter_EVT13 = tbl_ppm_ed_encounter_EVT13.drop_duplicates(keep="last")
    tbl_ppm_ed_encounter_EVT13 = tbl_ppm_ed_encounter_EVT13.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    tbl_ppm_ed_encounter_EVT13 = tbl_ppm_ed_encounter_EVT13.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    tbl_ppm_ed_encounter_EVT13 = tbl_ppm_ed_encounter_EVT13.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    tbl_ppm_ed_encounter_EVT13 = tbl_ppm_ed_encounter_EVT13.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    #### commenting this
    # tbl_excludedencounters_list = tbl_ExcludedEncounters['EncounterNumber'].tolist()
    # tbl_ppm_ed_encounter_EVT13 = tbl_ppm_ed_encounter_EVT13[~(tbl_ppm_ed_encounter_EVT13['EncounterNumber'].isin(tbl_excludedencounters_list))]
    try:
        # tbl_ppm_ed_encounter_EVT13.to_csv('./Output/tbl_ppm_ED_Encounter_'+versionID_underscore+'EVT13.csv', index=False, na_rep='', float_format=str, decimal=str, date_format=str)
        tbl_ppm_ed_encounter_EVT13.to_csv(
            "./ExtractorDB/tbl_ppm_ED_Encounter_EVT13_"
            + versionID_underscore
            + "_OLD_FORMAT.csv",
            index=False,
            na_rep="",
            float_format=str,
            decimal=str,
            date_format=str,
        )
    except Exception as e:
        logging.exception("Exception occurred")
        label_6_status = 0
        messagebox.showerror(
            "Export Error", "Error exporting tbl_ppm_ed_encounter_EVT13\n" + str(e)
        )
        label_6_sub.configure(text="Failed ()...", fg="red")
        main_screen.update()
        return  # stop export
    logging.info(
        "%s records saved to ./Output/tbl_ppm_ED_Encounter_%sEVT13.csv.",
        len(tbl_ppm_ed_encounter_EVT13),
        versionID_underscore,
    )
    """ Create tbl_ppm_ED_Service.txt."""
    # Access query: Append to tbl_ppm_ED_Service
    # INSERT INTO tbl_ppm_ED_Service ( PatientNumber, EncounterNumber, [Extra:InpatientStayNumber], ServiceCode, Quantity, ServicingDepartment, StartDateTime, EndDateTime, ActualCharge, Hospital, Duration )
    # SELECT tbl_ppm_ED_Encounter.PatientNumber, tbl_ppm_ED_Encounter.EncounterNumber, tbl_ppm_ED_Encounter.[Extra:InpatientStayNumber], tbl_ppm_ED_Encounter.[Extra:UDG], 1 AS Expr1, "Emergency" AS Expr2, IIf(DateValue([StartDateTime])<DateValue([Forms]![Frm:1-extractSetUp]![Start_Date]),Format(DateValue([Forms]![Frm:1-extractSetUp]![Start_Date]),"dd-mm-yyyy hh:nn:ss"),[startdatetime]) AS Expr5, IIf(DateValue([endDateTime])>=DateValue([Forms]![Frm:1-extractSetUp]![end_Date]),Format(DateValue([Forms]![Frm:1-extractSetUp]![end_Date]),"dd-mm-yyyy"+" 23:59:59"),[enddatetime]) AS Expr4, tbl_ppm_ED_Encounter.WeightedSeparation, tbl_ppm_ED_Encounter.Hospital,
    # IIf([tbl_ppm_ED_Encounter]![EndDateTime]="" And [tbl_ppm_ED_Encounter]![Extra:DepartureReadyDTTM]="",Null,IIf(DateValue([tbl_ppm_ED_Encounter]![EndDateTime])="",DateDiff("n",DateValue([tbl_ppm_ED_Encounter]![StartDateTime])+TimeValue([tbl_ppm_ED_Encounter]![StartDateTime]),DateValue([tbl_ppm_ED_Encounter]![Extra:DepartureReadyDTTM])+TimeValue([tbl_ppm_ED_Encounter]![Extra:DepartureReadyDTTM])),DateDiff("n",DateValue([tbl_ppm_ED_Encounter]![StartDateTime])+TimeValue([tbl_ppm_ED_Encounter]![StartDateTime]),DateValue([tbl_ppm_ED_Encounter]![EndDateTime])+TimeValue([tbl_ppm_ED_Encounter]![EndDateTime])))) AS Expr3
    # FROM tbl_ppm_ED_Encounter
    # GROUP BY tbl_ppm_ED_Encounter.PatientNumber, tbl_ppm_ED_Encounter.EncounterNumber, tbl_ppm_ED_Encounter.[Extra:InpatientStayNumber], tbl_ppm_ED_Encounter.[Extra:UDG], 1, "Emergency", IIf(DateValue([StartDateTime])<DateValue([Forms]![Frm:1-extractSetUp]![Start_Date]),Format(DateValue([Forms]![Frm:1-extractSetUp]![Start_Date]),"dd-mm-yyyy hh:nn:ss"),[startdatetime]), IIf(DateValue([endDateTime])>=DateValue([Forms]![Frm:1-extractSetUp]![end_Date]),Format(DateValue([Forms]![Frm:1-extractSetUp]![end_Date]),"dd-mm-yyyy"+" 23:59:59"),[enddatetime]), tbl_ppm_ED_Encounter.WeightedSeparation, tbl_ppm_ED_Encounter.Hospital, IIf([tbl_ppm_ED_Encounter]![EndDateTime]="" And [tbl_ppm_ED_Encounter]![Extra:DepartureReadyDTTM]="",Null,IIf(DateValue([tbl_ppm_ED_Encounter]![EndDateTime])="",DateDiff("n",DateValue([tbl_ppm_ED_Encounter]![StartDateTime])+TimeValue([tbl_ppm_ED_Encounter]![StartDateTime]),DateValue([tbl_ppm_ED_Encounter]![Extra:DepartureReadyDTTM])+TimeValue([tbl_ppm_ED_Encounter]![Extra:DepartureReadyDTTM])),DateDiff("n",DateValue([tbl_ppm_ED_Encounter]![StartDateTime])+TimeValue([tbl_ppm_ED_Encounter]![StartDateTime]),DateValue([tbl_ppm_ED_Encounter]![EndDateTime])+TimeValue([tbl_ppm_ED_Encounter]![EndDateTime])))), tbl_ppm_ED_Encounter.[Extra:DepartureReadyDTTM], tbl_ppm_ED_Encounter.EndDateTime;
    """
    tbl_ppm_ED_Service = tbl_ppm_ED_Encounter[['PatientNumber', 'EncounterNumber', 'Extra:InpatientStayNumber', 'Extra:UDG', 'StartDateTime', 'EndDateTime', 'WeightedSeparation', 'Hospital', 'Extra:DepartureReadyDTTM', 'Extra:WIP']]
    tbl_ppm_ED_Service.loc[((tbl_ppm_ED_Service['EndDateTime'].isnull()) | (tbl_ppm_ED_Service['EndDateTime']=='')), 'Duration'] = 0
    tbl_ppm_ED_Service['ServiceCode'] = tbl_ppm_ED_Service['Extra:UDG']
    tbl_ppm_ED_Service['Quantity'] = 1
    tbl_ppm_ED_Service['ServicingDepartment'] = 'Emergency'
    tbl_ppm_ED_Service['start_date_dt'] = pd.to_datetime(start_date, format="%Y-%m-%d %H:%M:%S")
    tbl_ppm_ED_Service['end_date_dt'] = pd.to_datetime(end_date, format="%Y-%m-%d %H:%M:%S")
    tbl_ppm_ED_Service['EndDateTime_dummy'] = tbl_ppm_ED_Service['EndDateTime']
    tbl_ppm_ED_Service['StartDateTime'] = pd.to_datetime(tbl_ppm_ED_Service['StartDateTime'].astype(str), errors='coerce', format="%Y-%m-%d %H:%M:%S")
    tbl_ppm_ED_Service['EndDateTime'] = pd.to_datetime(tbl_ppm_ED_Service['EndDateTime'].astype(str), errors='coerce', format="%Y-%m-%d %H:%M:%S")
    tbl_ppm_ED_Service['StartDateTime'] = np.where(tbl_ppm_ED_Service['StartDateTime'].dt.normalize() < tbl_ppm_ED_Service['start_date_dt'].dt.normalize(), \
    tbl_ppm_ED_Service['start_date_dt'], tbl_ppm_ED_Service['StartDateTime'])  
    tbl_ppm_ED_Service['EndDateTime'] = np.where(tbl_ppm_ED_Service['EndDateTime'].dt.normalize() > tbl_ppm_ED_Service['start_date_dt'].dt.normalize(), pd.to_datetime((tbl_ppm_ED_Service['end_date_dt'].astype(str).str[:10]+' 23:59:59'), errors='coerce', format="%Y-%m-%d %H:%M:%S"), tbl_ppm_ED_Service['EndDateTime'])
    tbl_ppm_ED_Service['Duration'] = np.where(((tbl_ppm_ED_Service['EndDateTime_dummy'].isnull()) | (tbl_ppm_ED_Service['EndDateTime_dummy']=='')) & pd.notna(tbl_ppm_ED_Service['Extra:DepartureReadyDTTM']) & (tbl_ppm_ED_Service['Extra:DepartureReadyDTTM']!=''),  (pd.to_datetime(tbl_ppm_ED_Service['Extra:DepartureReadyDTTM'], errors='coerce', format="%Y-%m-%d %H:%M:%S")-tbl_ppm_ED_Service['StartDateTime']) / pd.Timedelta(minutes=1) , (tbl_ppm_ED_Service['EndDateTime']-tbl_ppm_ED_Service['StartDateTime']) / pd.Timedelta(minutes=1))
    tbl_ppm_ED_Service['Extra:DepartureReadyDTTM'] = pd.to_datetime(tbl_ppm_ED_Service['Extra:DepartureReadyDTTM'], errors='coerce', format="%Y-%m-%d %H:%M:%S")
    tbl_ppm_ED_Service['ActualCharge'] = 'WeightedSeparation'
    #tbl_ppm_ED_Service['Duration'] = np.where((tbl_ppm_ED_Service['Extra:DepartureReadyDTTM'].isnull() | (tbl_ppm_ED_Service['Extra:DepartureReadyDTTM']=='')) & ((tbl_ppm_ED_Service['EndDateTime'].isnull()) | (tbl_ppm_ED_Service['EndDateTime']=='')), '', tbl_ppm_ED_Service['Duration'])
    tbl_ppm_ED_Service = tbl_ppm_ED_Service[['PatientNumber', 'EncounterNumber', 'Extra:InpatientStayNumber', 'ServiceCode', 'Quantity', 'ServicingDepartment', 'StartDateTime', 'EndDateTime', 'ActualCharge', 'Hospital', 'Duration', 'Extra:WIP']]
    #tbl_ppm_ED_Service = tbl_ppm_ED_Service.groupby(['PatientNumber', 'EncounterNumber', 'Extra:InpatientStayNumber', 'ServiceCode', 'Quantity', 'ServicingDepartment', 'StartDateTime', 'EndDateTime', 'ActualCharge', 'Hospital', 'Duration', 'Extra:WIP'], as_index=False, dropna=False)#.reset_index()
    tbl_ppm_ED_Service = tbl_ppm_ED_Service.drop_duplicates( keep='last')
    logging.info('Query: Append to tbl_ppm_ED_Service completed. tbl_ppm_ED_Service created with %s records.',len(tbl_ppm_ED_Service))
    # Access query: qry upate duration ed service
    # UPDATE tbl_ppm_ED_Encounter INNER JOIN tbl_ppm_ED_Service ON tbl_ppm_ED_Encounter.EncounterNumber = tbl_ppm_ED_Service.EncounterNumber SET tbl_ppm_ED_Service.Duration = DateDiff("n",DateValue([tbl_ppm_ED_Service]![StartDateTime])+TimeValue([tbl_ppm_ED_Service]![StartDateTime]),DateValue([tbl_ppm_ED_Service]![EndDateTime])+TimeValue([tbl_ppm_ED_Service]![EndDateTime])) WHERE (((tbl_ppm_ED_Encounter.[Extra:WIP])<>"4"));
    # To ocnvert time diff to minutes (i.e. 'n') -> Ref: https://stackoverflow.com/questions/22923775/calculate-time-difference-between-two-pandas-columns-in-hours-and-minutes
    #len_dummy = len(tbl_ppm_ED_Service[tbl_ppm_ED_Service['Extra:WIP']!='4'])
    tbl_ppm_ED_Service['Duration'] = np.where(tbl_ppm_ED_Service['Extra:WIP']!='4', (tbl_ppm_ED_Service['EndDateTime']-tbl_ppm_ED_Service['StartDateTime']) / pd.Timedelta(minutes=1), tbl_ppm_ED_Service['Duration'])
    tbl_ppm_ED_Service = tbl_ppm_ED_Service.drop_duplicates( keep='last')
    logging.info('Query: qry upate duration ed service completed. tbl_ppm_ED_Service has %s records.',len(tbl_ppm_ED_Service))
    tbl_ppm_ED_Service = tbl_ppm_ED_Service[['PatientNumber', 'EncounterNumber', 'Extra:InpatientStayNumber', 'ServiceCode', 'Quantity', 'ServicingDepartment', 'StartDateTime', 'EndDateTime', 'ActualCharge', 'Hospital', 'Duration']]
    tbl_ppm_ED_Service = tbl_ppm_ED_Service.applymap(str)#.apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    tbl_ppm_ED_Service = tbl_ppm_ED_Service.applymap(lambda x: x.strip() if isinstance(x, str) else x)
    tbl_ppm_ED_Service = tbl_ppm_ED_Service.apply(lambda x: x.replace(regex=r'^NaT$', value='') if x.dtype == 'object' else x)
    tbl_ppm_ED_Service = tbl_ppm_ED_Service.apply(lambda x: x.replace(regex=r'^nan$', value='') if x.dtype == 'object' else x)
    try:
        tbl_ppm_ED_Service.to_csv('./ExtractorDB/tbl_ppm_ED_Service_'+versionID_underscore+'.csv', index=False, na_rep='', float_format=str, decimal=str, date_format=str)
    except Exception as e:
        logging.exception("Exception occurred")
        label_6_status = 0
        messagebox.showerror("Export Error","Error exporting tbl_ppm_ED_Service\n"+str(e))
        label_6_sub.configure(text="Failed (tbl_ppm_ED_Service)...",fg='red')
        main_screen.update()
        return # stop export
    logging.info('%s records saved to ./ExtractorDB/tbl_ppm_ED_Service_%s.csv.', len(tbl_ppm_ED_Service), versionID_underscore)    
    """
    """ Export all data from tbl_ExcludedEncounters as c:\costing\tbl_ExcludedEncounters.txt"""
    # Access query: tbl_ExcludedEncounters
    tbl_ExcludedEncounters = tbl_ExcludedEncounters[
        [
            "facility_identifier",
            "stay_number",
            "episode_sequence_number",
            "ed_identifier",
            "SNAP_encounter",
            "ReasonForExclusion",
            "EncounterNumber",
        ]
    ]
    # I see there are EncounterNumber =  H214-M-04831094-001-001 where Ed_identifier=XXXXXXXXXX, SNAP_encounter=XXXX_XXXXXXXX. Commented this.
    # Access query: update tbl_excluded encounters Inpatient
    # UPDATE tbl_ExcludedEncounters SET tbl_ExcludedEncounters.EncounterNumber = IIf([tbl_ExcludedEncounters]![SNAP_encounter] Not Like "XX*",[tbl_ExcludedEncounters]![SNAP_encounter],[tbl_ExcludedEncounters]![facility_identifier] & "-I-" & Format([tbl_ExcludedEncounters]![Stay_number],"00000000") & "-" & Format([tbl_ExcludedEncounters]![episode_sequence_number],"000")) WHERE (((tbl_ExcludedEncounters.Ed_identifier) Like "XX*"));
    tbl_ExcludedEncounters["stay_number"] = (
        tbl_ExcludedEncounters["stay_number"].astype(str).str.strip()
    )
    tbl_ExcludedEncounters["episode_sequence_number"] = tbl_ExcludedEncounters[
        "episode_sequence_number"
    ].astype(int, errors="ignore")  # .str.strip()
    tbl_ExcludedEncounters["stay_number"] = (
        tbl_ExcludedEncounters["stay_number"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0")
    )
    """
    condlist=[~(tbl_ExcludedEncounters.SNAP_encounter.astype(str).str.startswith(('XX'))) & (tbl_ExcludedEncounters.ed_identifier.astype(str).str.startswith(('XX'))), (tbl_ExcludedEncounters.SNAP_encounter.astype(str).str.startswith(('XX'))) & (tbl_ExcludedEncounters.ed_identifier.astype(str).str.startswith(('XX')))]
    choicelist = [tbl_ExcludedEncounters['SNAP_encounter'], tbl_ExcludedEncounters['facility_identifier'].astype(str).str.strip()+ "-I-" + tbl_ExcludedEncounters['stay_number'].astype(str).str.strip()+ "-" + tbl_ExcludedEncounters['episode_sequence_number'].astype(str).str.strip()] 
    tbl_ExcludedEncounters['EncounterNumber'] = np.select(condlist, choicelist, tbl_ExcludedEncounters['EncounterNumber'])
    """
    tbl_ExcludedEncounters = tbl_ExcludedEncounters.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    tbl_ExcludedEncounters = tbl_ExcludedEncounters.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    tbl_ExcludedEncounters = tbl_ExcludedEncounters.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    tbl_ExcludedEncounters = tbl_ExcludedEncounters.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    tbl_ExcludedEncounters = tbl_ExcludedEncounters.drop_duplicates(keep="last")
    tbl_ExcludedEncounters.sort_values(by=["ReasonForExclusion"], inplace=True)
    try:
        tbl_ExcludedEncounters.to_csv(
            "./Output/tbl_ExcludedEncounters.csv",
            index=False,
            na_rep="",
            float_format=str,
            decimal=str,
            date_format=str,
        )
    except Exception as e:
        logging.exception("Exception occurred")
        label_6_status = 0
        messagebox.showerror(
            "Export Error", "Error exporting tbl_ExcludedEncounters\n" + str(e)
        )
        label_6_sub.configure(text="Failed ()...", fg="red")
        main_screen.update()
        return  # stop export
    logging.info(
        "Query: update tbl_excluded encounters Inpatient completed. %s records saved to ./Output/tbl_ExcludedEncounters.csv.",
        len(tbl_ExcludedEncounters),
    )
    # Update Sub task status
    if label_6_status == 0:
        label_6_sub.configure(text="Failed", fg="red")
        main_screen.update()
    else:
        label_6_sub.configure(text="Completed", fg="green")
        main_screen.update()
    main_screen.update()
    logging.info("Export ED_Encounter Data completed.")
    ############### "7. Export ED_Patient Data"#################
    logging.info("Export ED_Patient Data started.")
    # Set default value of sub-task status to 1
    label_7_status = 1
    label_7_sub.configure(text="In Progress (ED_Patient)...", fg="blue")
    main_screen.update()
    # file_tbl_ppm_ED_Patient = "./ExtractorDB/PpmEdPatient.csv"
    file_tbl_ppm_ED_Patient = "./ExtractorDB/tbl_PPM_ED_Patient.csv"
    if os.path.isfile(file_tbl_ppm_ED_Patient):
        try:
            tbl_ppm_ED_Patient = read_csv_file(
                file_tbl_ppm_ED_Patient,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            label_7_status = 0
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_ppm_ED_Patient from ./ExtractorDB/tbl_PPM_ED_Patient.csv.\n"
                + str(e),
            )
            label_7_sub.configure(text="Failed (tbl_ppm_ED_Patient)...", fg="red")
            main_screen.update()
            return
        else:
            tbl_ppm_ED_Patient = tbl_ppm_ED_Patient.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_ppm_ED_Patient = tbl_ppm_ED_Patient.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_ppm_ED_Patient = tbl_ppm_ED_Patient.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_ppm_ED_Patient = tbl_ppm_ED_Patient.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
            # AQA-280 - Add AUID
            tbl_ppm_ED_Patient = tbl_ppm_ED_Patient[
                [
                    "PatientNumber",
                    "Gender",
                    "EthnicOrigin",
                    "indigenous_status",
                    "DateOfBirth",
                    "AUID",
                ]
            ]
    else:
        tbl_ppm_ED_Patient = pd.DataFrame()
    tbl_ppm_ED_Patient = tbl_ppm_ED_Patient.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    tbl_ppm_ED_Patient = tbl_ppm_ED_Patient.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    tbl_ppm_ED_Patient = tbl_ppm_ED_Patient.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    tbl_ppm_ED_Patient = tbl_ppm_ED_Patient.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    tbl_ppm_ED_Patient.sort_values(by=["PatientNumber"], inplace=True)
    tbl_ppm_ED_Patient.drop_duplicates(
        subset=["PatientNumber"], keep="last", inplace=True
    )
    try:
        tbl_ppm_ED_Patient.to_csv(
            "./ExtractorDB/tbl_PPM_ED_Patient_" + versionID_hash + ".csv",
            index=False,
            na_rep="",
            float_format=str,
            decimal=str,
            date_format=str,
        )
    except Exception as e:
        logging.exception("Exception occurred")
        label_7_status = 0
        messagebox.showerror(
            "Export Error", "Error exporting tbl_ppm_ED_Patient\n" + str(e)
        )
        label_7_sub.configure(text="Failed ()...", fg="red")
        main_screen.update()
        return  # stop export
    logging.info(
        "%s records saved to ./ExtractorDB/tbl_PPM_ED_Patient_%s.csv.",
        len(tbl_ppm_ED_Patient),
        versionID_hash,
    )
    file_tbl_ppm_Patient = "./ExtractorDB/tbl_PPM_IP_Patient_" + versionID_hash + ".csv"
    if os.path.isfile(file_tbl_ppm_Patient):
        try:
            tbl_ppm_Patient = read_csv_file(
                file_tbl_ppm_Patient,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            label_7_status = 0
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_ppm_Patient from ./ExtractorDB/tbl_ppm_Patient.csv.\n"
                + str(e),
            )
            label_7_sub.configure(text="Failed (tbl_ppm_Patient)...", fg="red")
            main_screen.update()
            return
        else:
            tbl_ppm_Patient = tbl_ppm_Patient.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_ppm_Patient = tbl_ppm_Patient.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_ppm_Patient = tbl_ppm_Patient.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_ppm_Patient = tbl_ppm_Patient.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
            # AQA-280 - Add AUID
            tbl_ppm_Patient = tbl_ppm_Patient[
                [
                    "PatientNumber",
                    "Gender",
                    "EthnicOrigin",
                    "Extra:IndigenousStatus",
                    "DateOfBirth",
                    "AUID",
                ]
            ]
    else:
        tbl_ppm_Patient = pd.DataFrame()
    ip_patient_orig_len = len(tbl_ppm_Patient)
    # exclude patients already in IP
    tbl_ppm_IP_Patient_list = tbl_ppm_Patient["PatientNumber"].tolist()
    tbl_ppm_ED_Patient = tbl_ppm_ED_Patient[
        ~tbl_ppm_ED_Patient["PatientNumber"].isin(tbl_ppm_IP_Patient_list)
    ]
    tbl_ppm_Patient = pd.concat([tbl_ppm_Patient, tbl_ppm_ED_Patient], axis=0)
    tbl_ppm_Patient.sort_values(by=["PatientNumber"], inplace=True)
    tbl_ppm_Patient.drop_duplicates(subset=["PatientNumber"], keep="last", inplace=True)
    logging.info(
        "%s records saved to ./Output/Tbl_PPM_Patient.csv. after concatenating %s InPatient and %s EDPatient records",
        len(tbl_ppm_Patient),
        ip_patient_orig_len,
        len(tbl_ppm_ED_Patient),
    )
    tbl_ppm_Patient["Extra:IndigenousStatus"] = np.where(
        (tbl_ppm_Patient["Extra:IndigenousStatus"].isnull())
        | (tbl_ppm_Patient["Extra:IndigenousStatus"] == ""),
        tbl_ppm_Patient["indigenous_status"],
        tbl_ppm_Patient["Extra:IndigenousStatus"],
    )
    """
    From: Kylie Hawkins <Kylie.Hawkins2@health.nsw.gov.au> 
    Sent: Thursday, July 11, 2024 12:21 PM
    To: Ranjit Sukumaran <Ranjit.Sukumaran@health.nsw.gov.au>; Badari Lanka Venkata <Badari.LankaVenkata@health.nsw.gov.au>
    Cc: Julia Heberle <Julia.Heberle@health.nsw.gov.au>
    Subject: Indigenous Status
    Hi both
    I have just discovered another issue with extractor in some testing I just did. We have indigenous status as an Extra field in the Encounter files. But it appears it has also been added to the Patient file.
    This poses an issue. If the values dont match for example it will always take what is in the encounter file as that is usually loaded AFTER the Patient file. And the question should be asked each time a patient presents to a health facility and not just once. So that value could in fact change multiple times if they have multiple encounters in the encounter file (which is correct). If we base of Patient File, it will only ever get one value.
    Can you remember why it was added to Patient file? We actually need to remove it.
    Ta
    Kylie
    """
    # tbl_ppm_Patient = tbl_ppm_Patient[['PatientNumber','Gender','EthnicOrigin','Extra:IndigenousStatus','DateOfBirth']]
    # AQA-280 - Add AUID
    tbl_ppm_Patient = tbl_ppm_Patient[
        ["PatientNumber", "Gender", "EthnicOrigin", "DateOfBirth", "AUID"]
    ]
    tbl_ppm_Patient["Extra:AUID"] = tbl_ppm_Patient["AUID"]
    tbl_ppm_Patient = tbl_ppm_Patient[
        ["PatientNumber", "Gender", "EthnicOrigin", "DateOfBirth", "Extra:AUID"]
    ]
    tbl_ppm_Patient.drop_duplicates(keep="last", inplace=True)
    # Issue raised by Derek on 6th June 2025.
    tbl_ppm_Patient["EthnicOrigin"] = tbl_ppm_Patient["EthnicOrigin"].apply(
        lambda x: str(x).zfill(4)
        if pd.notnull(x)
        and x != ""
        and x != "NULL"
        and x != "nan"
        and x != "NaN"
        and x != "U"
        else x
    )

    # https://abft101.atlassian.net/browse/AQA-348
    # tbl_ppm_Patient=clear_neg_one(tbl_ppm_Patient)
    logging.info(
        "%s records saved to ./Output/Tbl_PPM_Patient.csv. after deleting duplicate records",
        len(tbl_ppm_Patient),
    )
    try:
        tbl_ppm_Patient.to_csv(
            "./Output/Tbl_PPM_Patient_" + versionID_hash + ".csv",
            index=False,
            na_rep="",
            float_format=str,
            decimal=str,
            date_format=str,
        )
    except Exception as e:
        logging.exception("Exception occurred")
        label_7_status = 0
        messagebox.showerror(
            "Export Error", "Error exporting tbl_ppm_Patient\n" + str(e)
        )
        label_7_sub.configure(text="Failed ()...", fg="red")
        main_screen.update()
        return  # stop export
    logging.info(
        "%s records saved to ./Output/Tbl_PPM_Patient_%s.csv.",
        len(tbl_ppm_Patient),
        versionID_hash,
    )
    # Update Sub task status
    if label_7_status == 0:
        label_7_sub.configure(text="Failed", fg="red")
        main_screen.update()
    else:
        label_7_sub.configure(text="Completed", fg="green")
        main_screen.update()
    main_screen.update()
    logging.info("Export ED_Patient Data completed.")
    ############### "8. Execute DRG Weight Maker"#################
    # Kylie on 25th Oct 2024 10:30-12PM meeting informed tht this step is not required anymore. So commenting it and setting the label to default success state.
    label_8_status = 1
    """
    logging.info('Execute DRG Weight Maker started.')
    # Set default value of sub-task status to 1
    label_8_status = 1
    label_8_sub.configure(text="In Progress (DRG Weight Maker)...",fg='blue')
    main_screen.update()
    
    file_tbl_PPM_Encounter = "./Output/tbl_PPM_Encounter_"+versionID_underscore+".csv"
    if os.path.isfile(file_tbl_PPM_Encounter):
        try:
            tbl_PPM_Encounter = read_csv_file(file_tbl_PPM_Encounter, encoding = 'unicode_escape', dtype=str, keep_default_na=False, na_values='')
        except Exception as e:
            logging.exception("Exception occurred")
            label_8_status = 0
            messagebox.showerror("File Error","Error extracting tbl_PPM_Encounter from ./Output/tbl_PPM_Encounter.csv.\n"+str(e))
            label_8_sub.configure(text="Failed (tbl_PPM_Encounter)...",fg='red')
            main_screen.update()
            return
        else:
            tbl_PPM_Encounter = tbl_PPM_Encounter.applymap(str)#.apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_PPM_Encounter = tbl_PPM_Encounter.applymap(lambda x: x.strip() if isinstance(x, str) else x)
            tbl_PPM_Encounter = tbl_PPM_Encounter.apply(lambda x: x.replace(regex=r'^NaT$', value='') if x.dtype == 'object' else x)
            tbl_PPM_Encounter = tbl_PPM_Encounter.apply(lambda x: x.replace(regex=r'^nan$', value='') if x.dtype == 'object' else x)
    else:
        tbl_PPM_Encounter = pd.DataFrame()
    
    # Access query: qry Sites DRG_SNAP_CLASS
    # SELECT IIf([extra:SNAP_CLASS] Is Null,[DRG1],[DRG3]) AS [DRG 6_0x], tbl_PPM_Encounter.[Extra:SNAP_Class] AS SNAP_Class, tbl_PPM_Encounter.DRG1 AS DRG_CODE, tbl_PPM_Encounter.[Extra:AMHCC_Class] AS AMHCC_Class, IIf([tbl_PPM_Encounter]![Extra:AMHCC_Class]>"0",[DRG3],[DRG1]) AS DRG_CODE1 FROM tbl_PPM_Encounter GROUP BY IIf([extra:SNAP_CLASS] Is Null,[DRG1],[DRG3]), tbl_PPM_Encounter.[Extra:SNAP_Class], tbl_PPM_Encounter.DRG1, tbl_PPM_Encounter.[Extra:AMHCC_Class], IIf([tbl_PPM_Encounter]![Extra:AMHCC_Class]>"0",[DRG3],[DRG1]);
    qry_Sites_drg_SNAP_CLASS = tbl_PPM_Encounter[['Extra:SNAP_Class', 'DRG1', 'DRG3', 'Extra:AMHCC_Class']]
    qry_Sites_drg_SNAP_CLASS['DRG 6_0x'] = np.where((qry_Sites_drg_SNAP_CLASS['Extra:SNAP_Class'].isnull()) | (qry_Sites_drg_SNAP_CLASS['Extra:SNAP_Class']==''),qry_Sites_drg_SNAP_CLASS['DRG1'], qry_Sites_drg_SNAP_CLASS['DRG3'])
    qry_Sites_drg_SNAP_CLASS['SNAP_Class'] = qry_Sites_drg_SNAP_CLASS['Extra:SNAP_Class']
    qry_Sites_drg_SNAP_CLASS['DRG_CODE'] = qry_Sites_drg_SNAP_CLASS['DRG1']
    qry_Sites_drg_SNAP_CLASS['AMHCC_Class'] = qry_Sites_drg_SNAP_CLASS['Extra:AMHCC_Class']
    qry_Sites_drg_SNAP_CLASS['DRG_CODE1'] = np.where(pd.notna(qry_Sites_drg_SNAP_CLASS['Extra:AMHCC_Class']) & (qry_Sites_drg_SNAP_CLASS['Extra:AMHCC_Class']!=''),qry_Sites_drg_SNAP_CLASS['DRG3'], qry_Sites_drg_SNAP_CLASS['DRG1'])
    qry_Sites_drg_SNAP_CLASS = qry_Sites_drg_SNAP_CLASS[['DRG 6_0x', 'SNAP_Class', 'DRG_CODE', 'AMHCC_Class', 'DRG_CODE1', 'DRG1', 'DRG3']]
    qry_Sites_drg_SNAP_CLASS.sort_values(by=['DRG 6_0x', 'SNAP_Class', 'DRG_CODE', 'AMHCC_Class', 'DRG_CODE1', 'DRG1', 'DRG3'], inplace=True)
    qry_Sites_drg_SNAP_CLASS.drop_duplicates(subset=['DRG 6_0x', 'SNAP_Class', 'DRG_CODE', 'AMHCC_Class', 'DRG_CODE1', 'DRG1', 'DRG3'], keep='last', inplace=True)
    qry_Sites_drg_SNAP_CLASS = qry_Sites_drg_SNAP_CLASS.applymap(str)#.apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    qry_Sites_drg_SNAP_CLASS = qry_Sites_drg_SNAP_CLASS.applymap(lambda x: x.strip() if isinstance(x, str) else x)
    qry_Sites_drg_SNAP_CLASS = qry_Sites_drg_SNAP_CLASS.apply(lambda x: x.replace(regex=r'^NaT$', value='') if x.dtype == 'object' else x)
    qry_Sites_drg_SNAP_CLASS = qry_Sites_drg_SNAP_CLASS.apply(lambda x: x.replace(regex=r'^nan$', value='') if x.dtype == 'object' else x)
    try:
        qry_Sites_drg_SNAP_CLASS.to_csv('./ExtractorDB/qry_Sites_drg_SNAP_CLASS.csv', index=False, na_rep='', float_format=str, decimal=str, date_format=str)
    except Exception as e:
        logging.exception("Exception occurred")
        label_8_status = 0
        messagebox.showerror("Export Error","Error exporting qry_Sites_drg_SNAP_CLASS.csv\n"+str(e))
        label_8_sub.configure(text="Failed ()...",fg='red')
        main_screen.update()
        return # stop export
    logging.info('Query: qry Sites DRG_SNAP_CLASS completed. %s records saved to ./ExtractorDB/qry_Sites_drg_SNAP_CLASS.csv.', len(qry_Sites_drg_SNAP_CLASS))    
    ###########################AMHCC_SNAP NEW LOGIC ################################
    file_Class_Descriptions = "./Costing/Class_Descriptions.csv"
    if os.path.isfile(file_Class_Descriptions):
        try:
            class_Descriptions = read_csv_file(file_Class_Descriptions, encoding = 'unicode_escape', dtype=str, keep_default_na=False, na_values='')
        except Exception as e:
            logging.exception("Exception occurred")
            label_8_status = 0
            messagebox.showerror("File Error","Error extracting Class_Descriptions from ./Costing/Class_Descriptions.csv.\n"+str(e))
            label_8_sub.configure(text="Failed (Class_Descriptions)...",fg='red')
            main_screen.update()
            return
        else:
            class_Descriptions = class_Descriptions[['Code','Description','Version']]
    else:
        class_Descriptions = pd.DataFrame(columns=['Code','Description','Version'])
    file_MDC = "./Costing/MDC.csv"
    if os.path.isfile(file_MDC):
        try:
            mdc = read_csv_file(file_MDC, encoding = 'unicode_escape', dtype=str, keep_default_na=False, na_values='')
        except Exception as e:
            logging.exception("Exception occurred")
            label_8_status = 0
            messagebox.showerror("File Error","Error extracting MDC from ./Costing/MDC.csv.\n"+str(e))
            label_8_sub.configure(text="Failed (MDC)...",fg='red')
            main_screen.update()
            return
        else:
            mdc = mdc[['DRG', 'MDC']]
    else:
        mdc = pd.DataFrame(columns=['DRG', 'MDC'])
    drg_PPM_1 = pd.merge(qry_Sites_drg_SNAP_CLASS[(qry_Sites_drg_SNAP_CLASS['SNAP_Class']!='') & (pd.notna(qry_Sites_drg_SNAP_CLASS['SNAP_Class']))], class_Descriptions[['Code','Description']], how='inner', left_on=['SNAP_Class'], right_on=['Code'], suffixes=('', '_drop')).merge(mdc, how='inner', left_on=['DRG 6_0x'], right_on = ['DRG'], suffixes=('', '_drop'))
    drg_PPM_1 = drg_PPM_1.apply(lambda x: x.replace(regex=r'^nan$', value='') if x.dtype == 'object' else x)
    drg_PPM_1['DRGTYPE'] = 'SNAP'
    drg_PPM_1['DRGVERSION'] = np.where((drg_PPM_1['AMHCC_Class'].isnull() ) | (drg_PPM_1['AMHCC_Class']==''),'S4','1')#drg_PPM_1['DRG_VERSION']
    drg_PPM_1['CODE'] = drg_PPM_1['DRG1'] # Note: in Inform8 this is DRG1. Earlier we had assigned drg_code = drg1
    drg_PPM_1 = drg_PPM_1[['DRGVERSION','CODE','Description','MDC','DRGTYPE']]
    drg_PPM_1.sort_values(by=['DRGVERSION','CODE','Description','MDC','DRGTYPE'], inplace=True)
    drg_PPM_1.drop_duplicates(subset=['DRGVERSION','CODE','Description','MDC','DRGTYPE'], keep='last', inplace=True)
    drg_PPM_2 = pd.merge(qry_Sites_drg_SNAP_CLASS[(qry_Sites_drg_SNAP_CLASS['AMHCC_Class']!='') & (pd.notna(qry_Sites_drg_SNAP_CLASS['AMHCC_Class']))], class_Descriptions[['Code','Description']], how='inner', left_on=['AMHCC_Class'], right_on=['Code'], suffixes=('', '_drop')).merge(mdc, how='inner', left_on=['DRG3'], right_on = ['DRG'], suffixes=('', '_drop'))
    drg_PPM_2 = drg_PPM_2.apply(lambda x: x.replace(regex=r'^nan$', value='') if x.dtype == 'object' else x)
    drg_PPM_2['DRGTYPE'] = 'AMHCC'
    drg_PPM_2['DRGVERSION'] = np.where((drg_PPM_2['AMHCC_Class'].isnull() ) | (drg_PPM_2['AMHCC_Class']==''),'S4','1')#drg_PPM_2['DRG_VERSION']
    drg_PPM_2['CODE'] = drg_PPM_2['DRG1'] # Note: in Inform8 this is DRG1. Earlier we had assigned drg_code = drg1
    drg_PPM_2 = drg_PPM_2[['DRGVERSION','CODE','Description','MDC','DRGTYPE']]
    drg_PPM_2.sort_values(by=['DRGVERSION','CODE','Description','MDC','DRGTYPE'], inplace=True)
    drg_PPM_2.drop_duplicates(subset=['DRGVERSION','CODE','Description','MDC','DRGTYPE'], keep='last', inplace=True)
    drg_PPM_2 = drg_PPM_2[['DRGVERSION', 'CODE', 'Description', 'MDC', 'DRGTYPE']]
    drg_PPM = pd.concat([drg_PPM_1, drg_PPM_2], axis=0)
    drg_PPM = drg_PPM.applymap(str)#.apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    drg_PPM = drg_PPM.applymap(lambda x: x.strip() if isinstance(x, str) else x)
    drg_PPM = drg_PPM.apply(lambda x: x.replace(regex=r'^NaT$', value='') if x.dtype == 'object' else x)
    drg_PPM = drg_PPM.apply(lambda x: x.replace(regex=r'^nan$', value='') if x.dtype == 'object' else x)
    try:
        drg_PPM.to_csv('./Output/AMHCC_SNAP.txt', sep=',', index=False, na_rep='', float_format=str, decimal=str, date_format=str)
    except Exception as e:
        logging.exception("Exception occurred")
        label_8_status = 0
        messagebox.showerror("Export Error","Error exporting AMHCC_SNAP.txt\n"+str(e))
        label_8_sub.configure(text="Failed ()...",fg='red')
        main_screen.update()
        return # stop export
    logging.info('Query: DRG_PPM completed. %s records saved to ./Output/AMHCC_SNAP.txt.', len(drg_PPM))    
    ##########################AMHCC_SNAP NEW LOGIC - STOP ##########################
    logging.info('Execute DRG Weight Maker started.')
    # Set default value of sub-task status to 1
    # tbl_PPM_Encounter 
    file_tbl_PPM_Encounter = "./Output/tbl_PPM_Encounter_"+versionID_underscore+".csv"
    if os.path.isfile(file_tbl_PPM_Encounter):
        try:
            tbl_PPM_Encounter = read_csv_file(file_tbl_PPM_Encounter, encoding = 'unicode_escape', dtype=str, keep_default_na=False, na_values='')
        except Exception as e:
            logging.exception("Exception occurred")
            label_4_status = 0
            messagebox.showerror("File Error","Error extracting tbl_PPM_Encounter from ./Output/tbl_PPM_Encounter.csv.\n"+str(e))
            label_4_sub.configure(text="Failed (tbl_PPM_Encounter)...",fg='red')
            main_screen.update()
            return
        else:
            tbl_PPM_Encounter = tbl_PPM_Encounter.applymap(str)#.apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_PPM_Encounter = tbl_PPM_Encounter.applymap(lambda x: x.strip() if isinstance(x, str) else x)
            tbl_PPM_Encounter = tbl_PPM_Encounter.apply(lambda x: x.replace(regex=r'^NaT$', value='') if x.dtype == 'object' else x)
            tbl_PPM_Encounter = tbl_PPM_Encounter.apply(lambda x: x.replace(regex=r'^nan$', value='') if x.dtype == 'object' else x)
    else:
        tbl_PPM_Encounter = pd.DataFrame()        
    #qry Sites DRG_SNAP_CLASS
    # Access query: qry Sites DRG_SNAP_CLASS
    # SELECT IIf([extra:SNAP_CLASS] Is Null,[DRG1],[DRG3]) AS [DRG 6_0x], tbl_PPM_Encounter.[Extra:SNAP_Class] AS SNAP_Class, tbl_PPM_Encounter.DRG1 AS DRG_CODE, tbl_PPM_Encounter.[Extra:AMHCC_Class] AS AMHCC_Class, IIf([tbl_PPM_Encounter]![Extra:AMHCC_Class]>"0",[DRG3],[DRG1]) AS DRG_CODE1 FROM tbl_PPM_Encounter GROUP BY IIf([extra:SNAP_CLASS] Is Null,[DRG1],[DRG3]), tbl_PPM_Encounter.[Extra:SNAP_Class], tbl_PPM_Encounter.DRG1, tbl_PPM_Encounter.[Extra:AMHCC_Class], IIf([tbl_PPM_Encounter]![Extra:AMHCC_Class]>"0",[DRG3],[DRG1]);
    qry_Sites_drg_SNAP_CLASS = tbl_PPM_Encounter[['Extra:SNAP_Class', 'DRG1', 'DRG3', 'Extra:AMHCC_Class']]
    qry_Sites_drg_SNAP_CLASS['DRG 6_0x'] = np.where((qry_Sites_drg_SNAP_CLASS['Extra:SNAP_Class'].isnull()) | (qry_Sites_drg_SNAP_CLASS['Extra:SNAP_Class']==''),qry_Sites_drg_SNAP_CLASS['DRG1'], qry_Sites_drg_SNAP_CLASS['DRG3'])
    qry_Sites_drg_SNAP_CLASS['SNAP_Class'] = qry_Sites_drg_SNAP_CLASS['Extra:SNAP_Class']
    qry_Sites_drg_SNAP_CLASS['DRG_CODE'] = qry_Sites_drg_SNAP_CLASS['DRG1']
    qry_Sites_drg_SNAP_CLASS['AMHCC_Class'] = qry_Sites_drg_SNAP_CLASS['Extra:AMHCC_Class']
    #qry_Sites_drg_SNAP_CLASS['DRG_CODE1'] = np.where(pd.notna(qry_Sites_drg_SNAP_CLASS['Extra:AMHCC_Class']) & (qry_Sites_drg_SNAP_CLASS['Extra:AMHCC_Class']!=''),qry_Sites_drg_SNAP_CLASS['DRG3'], qry_Sites_drg_SNAP_CLASS['DRG1'])
    qry_Sites_drg_SNAP_CLASS['DRG_CODE1'] = np.where((qry_Sites_drg_SNAP_CLASS['Extra:AMHCC_Class']>"0"),qry_Sites_drg_SNAP_CLASS['DRG3'], qry_Sites_drg_SNAP_CLASS['DRG1'])
    qry_Sites_drg_SNAP_CLASS = qry_Sites_drg_SNAP_CLASS[['DRG 6_0x', 'SNAP_Class', 'DRG_CODE', 'AMHCC_Class', 'DRG_CODE1']]
    qry_Sites_drg_SNAP_CLASS.sort_values(by=['DRG 6_0x', 'SNAP_Class', 'DRG_CODE', 'AMHCC_Class', 'DRG_CODE1'], inplace=True)
    qry_Sites_drg_SNAP_CLASS.drop_duplicates(subset=['DRG 6_0x', 'SNAP_Class', 'DRG_CODE', 'AMHCC_Class', 'DRG_CODE1'], keep='last', inplace=True)
    qry_Sites_drg_SNAP_CLASS = qry_Sites_drg_SNAP_CLASS.applymap(str)#.apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    qry_Sites_drg_SNAP_CLASS = qry_Sites_drg_SNAP_CLASS.applymap(lambda x: x.strip() if isinstance(x, str) else x)
    qry_Sites_drg_SNAP_CLASS = qry_Sites_drg_SNAP_CLASS.apply(lambda x: x.replace(regex=r'^NaT$', value='') if x.dtype == 'object' else x)
    qry_Sites_drg_SNAP_CLASS = qry_Sites_drg_SNAP_CLASS.apply(lambda x: x.replace(regex=r'^nan$', value='') if x.dtype == 'object' else x)
    try:
        qry_Sites_drg_SNAP_CLASS.to_csv('./ExtractorDB/qry_Sites_drg_SNAP_CLASS.csv', index=False, na_rep='', float_format=str, decimal=str, date_format=str)
    except Exception as e:
        logging.exception("Exception occurred")
        label_8_status = 0
        messagebox.showerror("Export Error","Error exporting qry_Sites_drg_SNAP_CLASS.csv\n"+str(e))
        label_8_sub.configure(text="Failed ()...",fg='red')
        main_screen.update()
        return # stop export
    logging.info('Query: qry Sites DRG_SNAP_CLASS completed. %s records saved to ./ExtractorDB/qry_Sites_drg_SNAP_CLASS.csv.', len(qry_Sites_drg_SNAP_CLASS))   
    #Appends the DRG weights to DRG WEIGHT FILE PPM where DRG Version 6.0X and the corresponding value in the DRG Standard Weights file
    # Access query: Append DRG Weights
    # INSERT INTO [DRG WEIGHT FILE PPM] ( DRG_VERSION, DRG_CODE, NURSEUC, ONE, CritUC, ORPUBUC, PROSPUBUC, SUPPLYUC, ALLIEDUC, OTUC, PHYSIOUC, SPTHERUC, NUTRDIETUC, SOCIALWUC, GENRADUC, PharmUC, CLINLABUC, ALLIEDC, PHYSIOC, OTC, SPTHERC, NUTRDIETC, SOCIALWC, SUPPLYC, RADC, INTERRADC, ANGIOC, ULTSNDC, NUCMEDC, MRIC, CTC, GENRADC, PHARMSTR, PROSPUBC, CLINLABC, ORPUBC, ORPUBXMC, CCU, ICU, NICU, NURSEUC_SA, snapallied, snappath, snapimag, snapnurse, snapdrugs, snapsupply, snapother, HITHNURSE, HITHALLIED, HITHDRUGS, HITHMSS ) SELECT IIf([AMHCC_Class] Is Null,"8.0","1") AS DRG_VERSION, [qry Sites DRG_SNAP_CLASS].DRG_CODE, [DRG Standard Weights].NURSEUC, [DRG Standard Weights].ONE, [DRG Standard Weights].CritUC, [DRG Standard Weights].ORPUBUC, [DRG Standard Weights].PROSPUBUC, [DRG Standard Weights].SUPPLYUC, [DRG Standard Weights].ALLIEDUC, [DRG Standard Weights].OTUC, [DRG Standard Weights].PHYSIOUC, [DRG Standard Weights].SPTHERUC, [DRG Standard Weights].NUTRDIETUC, [DRG Standard Weights].SOCIALWUC, [DRG Standard Weights].GENRADUC, [DRG Standard Weights].PharmUC, [DRG Standard Weights].CLINLABUC, [DRG Standard Weights].ALLIEDC, [DRG Standard Weights].PHYSIOC, [DRG Standard Weights].OTC, [DRG Standard Weights].SPTHERC, [DRG Standard Weights].NUTRDIETC, [DRG Standard Weights].SOCIALWC, [DRG Standard Weights].SUPPLYC, [DRG Standard Weights].RADC, [DRG Standard Weights].INTERRADC, [DRG Standard Weights].ANGIOC, [DRG Standard Weights].ULTSNDC, [DRG Standard Weights].NUCMEDC, [DRG Standard Weights].MRIC, [DRG Standard Weights].CTC, [DRG Standard Weights].GENRADC, [DRG Standard Weights].PHARMSTR, [DRG Standard Weights].PROSPUBC, [DRG Standard Weights].CLINLABC, [DRG Standard Weights].ORPUBC, [DRG Standard Weights].ORPUBXMC, [DRG Standard Weights].CCU, [DRG Standard Weights].ICU, [DRG Standard Weights].NICU, [DRG Standard Weights].NURSEUC_SA, [DRG Standard Weights].snapallied, [DRG Standard Weights].snappath, [DRG Standard Weights].snapimag, [DRG Standard Weights].snapnurse, [DRG Standard Weights].snapdrugs, [DRG Standard Weights].snapsupply, [DRG Standard Weights].snapother, [DRG Standard Weights].HITHNURSE, [DRG Standard Weights].HITHALLIED, [DRG Standard Weights].HITHDRUGS, [DRG Standard Weights].HITHMSS FROM [qry Sites DRG_SNAP_CLASS] INNER JOIN [DRG Standard Weights] ON [qry Sites DRG_SNAP_CLASS].DRG_CODE1 = [DRG Standard Weights].DRG_CODE;
    drg_WEIGHT_FILE_PPM = pd.DataFrame()
    file_drgStandardWeights = "./Costing/DRGStandardWeights.csv"
    if os.path.isfile(file_drgStandardWeights):
        try:
            drgStandardWeights = read_csv_file(file_drgStandardWeights, encoding = 'unicode_escape', dtype=str, keep_default_na=False, na_values='')
        except Exception as e:
            logging.exception("Exception occurred")
        else:
            drgStandardWeights = drgStandardWeights.applymap(str)#.apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            drgStandardWeights = drgStandardWeights.applymap(lambda x: x.strip() if isinstance(x, str) else x)
            drgStandardWeights = drgStandardWeights.apply(lambda x: x.replace(regex=r'^NaT$', value='') if x.dtype == 'object' else x)
            drgStandardWeights = drgStandardWeights.apply(lambda x: x.replace(regex=r'^nan$', value='') if x.dtype == 'object' else x)
            drgStandardWeights.columns = ['DRG_VERSION', 'DRG_CODE', 'NURSEUC', 'ONE', 'CritUC', 'ORPUBUC', 'PROSPUBUC', 'SUPPLYUC', 'ALLIEDUC', 'OTUC', 'PHYSIOUC', 'SPTHERUC', 'NUTRDIETUC', 'SOCIALWUC', 'GENRADUC', 'PharmUC', 'CLINLABUC', 'ALLIEDC', 'PHYSIOC', 'OTC', 'SPTHERC', 'NUTRDIETC', 'SOCIALWC', 'SUPPLYC', 'RADC', 'INTERRADC', 'ANGIOC', 'ULTSNDC', 'NUCMEDC', 'MRIC', 'CTC', 'GENRADC', 'PHARMSTR', 'PROSPUBC', 'CLINLABC', 'ORPUBC', 'ORPUBXMC', 'CCU', 'ICU', 'NICU', 'NURSEUC_SA', 'snapallied', 'snappath', 'snapimag', 'snapnurse', 'snapdrugs', 'snapsupply', 'snapother', 'HITHNURSE', 'HITHALLIED', 'HITHDRUGS', 'HITHMSS']
    else:
        drgStandardWeights = pd.DataFrame(columns=['DRG_VERSION', 'DRG_CODE', 'NURSEUC', 'ONE', 'CritUC', 'ORPUBUC', 'PROSPUBUC', 'SUPPLYUC', 'ALLIEDUC', 'OTUC', 'PHYSIOUC', 'SPTHERUC', 'NUTRDIETUC', 'SOCIALWUC', 'GENRADUC', 'PharmUC', 'CLINLABUC', 'ALLIEDC', 'PHYSIOC', 'OTC', 'SPTHERC', 'NUTRDIETC', 'SOCIALWC', 'SUPPLYC', 'RADC', 'INTERRADC', 'ANGIOC', 'ULTSNDC', 'NUCMEDC', 'MRIC', 'CTC', 'GENRADC', 'PHARMSTR', 'PROSPUBC', 'CLINLABC', 'ORPUBC', 'ORPUBXMC', 'CCU', 'ICU', 'NICU', 'NURSEUC_SA', 'snapallied', 'snappath', 'snapimag', 'snapnurse', 'snapdrugs', 'snapsupply', 'snapother', 'HITHNURSE', 'HITHALLIED', 'HITHDRUGS', 'HITHMSS'])
    qry_Sites_drg_SNAP_CLASS['DRG_CODE_dummy'] = qry_Sites_drg_SNAP_CLASS['DRG_CODE']
    drg_WEIGHT_FILE_PPM = pd.merge(qry_Sites_drg_SNAP_CLASS[['DRG_CODE_dummy', 'AMHCC_Class', 'DRG_CODE1']], drgStandardWeights[['DRG_CODE', 'NURSEUC', 'ONE', 'CritUC', 'ORPUBUC', 'PROSPUBUC', 'SUPPLYUC', 'ALLIEDUC', 'OTUC', 'PHYSIOUC', 'SPTHERUC', 'NUTRDIETUC', 'SOCIALWUC', 'GENRADUC', 'PharmUC', 'CLINLABUC', 'ALLIEDC', 'PHYSIOC', 'OTC', 'SPTHERC', 'NUTRDIETC', 'SOCIALWC', 'SUPPLYC', 'RADC', 'INTERRADC', 'ANGIOC', 'ULTSNDC', 'NUCMEDC', 'MRIC', 'CTC', 'GENRADC', 'PHARMSTR', 'PROSPUBC', 'CLINLABC', 'ORPUBC', 'ORPUBXMC', 'CCU', 'ICU', 'NICU', 'NURSEUC_SA', 'snapallied', 'snappath', 'snapimag', 'snapnurse', 'snapdrugs', 'snapsupply', 'snapother', 'HITHNURSE', 'HITHALLIED', 'HITHDRUGS', 'HITHMSS']], how='inner', left_on=['DRG_CODE1'], right_on=['DRG_CODE'], suffixes=('', '_drop'))
    drg_WEIGHT_FILE_PPM = drg_WEIGHT_FILE_PPM.apply(lambda x: x.replace(regex=r'^nan$', value='') if x.dtype == 'object' else x)
    # Ranjit: This might need to be changed to 11.0 instead of 8.0
    drg_WEIGHT_FILE_PPM['DRG_VERSION'] = np.where((drg_WEIGHT_FILE_PPM['AMHCC_Class'].isnull()) | (drg_WEIGHT_FILE_PPM['AMHCC_Class']==''),'8.0','1')
    drg_WEIGHT_FILE_PPM['DRG_CODE'] = drg_WEIGHT_FILE_PPM['DRG_CODE_dummy']
    drg_WEIGHT_FILE_PPM = drg_WEIGHT_FILE_PPM[['DRG_VERSION', 'DRG_CODE', 'NURSEUC', 'ONE', 'CritUC', 'ORPUBUC', 'PROSPUBUC', 'SUPPLYUC', 'ALLIEDUC', 'OTUC', 'PHYSIOUC', 'SPTHERUC', 'NUTRDIETUC', 'SOCIALWUC', 'GENRADUC', 'PharmUC', 'CLINLABUC', 'ALLIEDC', 'PHYSIOC', 'OTC', 'SPTHERC', 'NUTRDIETC', 'SOCIALWC', 'SUPPLYC', 'RADC', 'INTERRADC', 'ANGIOC', 'ULTSNDC', 'NUCMEDC', 'MRIC', 'CTC', 'GENRADC', 'PHARMSTR', 'PROSPUBC', 'CLINLABC', 'ORPUBC', 'ORPUBXMC', 'CCU', 'ICU', 'NICU', 'NURSEUC_SA', 'snapallied', 'snappath', 'snapimag', 'snapnurse', 'snapdrugs', 'snapsupply', 'snapother', 'HITHNURSE', 'HITHALLIED', 'HITHDRUGS', 'HITHMSS']]
    drg_WEIGHT_FILE_PPM.to_csv('./ExtractorDB/drg_WEIGHT_FILE_PPM_AMHCC.csv', index=False, na_rep='', float_format=str, decimal=str, date_format=str)
    logging.info('Query: Append DRG Weights completed. drg_WEIGHT_FILE_PPM created with %s records.', len(drg_WEIGHT_FILE_PPM))     
    #Appends the SNAP  weights to DRG WEIGHT FILE PPM where SNAP class version 4 is populated in the encounter file and the corresponding value in the SNAP Standard Weights file 
    # Access query: append SNAP weights
    # INSERT INTO [DRG WEIGHT FILE PPM] ( DRG_VERSION, DRG_CODE, NURSEUC, ONE, CritUC, ORPUBUC, PROSPUBUC, SUPPLYUC, ALLIEDUC, OTUC, PHYSIOUC, SPTHERUC, NUTRDIETUC, SOCIALWUC, GENRADUC, PharmUC, CLINLABUC, ALLIEDC, PHYSIOC, OTC, SPTHERC, NUTRDIETC, SOCIALWC, SUPPLYC, RADC, INTERRADC, ANGIOC, ULTSNDC, NUCMEDC, MRIC, CTC, GENRADC, PHARMSTR, PROSPUBC, CLINLABC, ORPUBC, ORPUBXMC, CCU, ICU, NICU, NURSEUC_SA, snapallied, snappath, snapimag, snapnurse, snapdrugs, snapsupply, snapother, HITHNURSE, HITHALLIED, HITHDRUGS, HITHMSS ) SELECT "S4" AS Expr1, [qry Sites DRG_SNAP_CLASS].DRG_CODE, [DRG Standard Weights].NURSEUC, [DRG Standard Weights].ONE, [DRG Standard Weights].CritUC, [DRG Standard Weights].ORPUBUC, [DRG Standard Weights].PROSPUBUC, [DRG Standard Weights].SUPPLYUC, [DRG Standard Weights].ALLIEDUC, [DRG Standard Weights].OTUC, [DRG Standard Weights].PHYSIOUC, [DRG Standard Weights].SPTHERUC, [DRG Standard Weights].NUTRDIETUC, [DRG Standard Weights].SOCIALWUC, [DRG Standard Weights].GENRADUC, [DRG Standard Weights].PharmUC, [DRG Standard Weights].CLINLABUC, [DRG Standard Weights].ALLIEDC, [DRG Standard Weights].PHYSIOC, [DRG Standard Weights].OTC, [DRG Standard Weights].SPTHERC, [DRG Standard Weights].NUTRDIETC, [DRG Standard Weights].SOCIALWC, [DRG Standard Weights].SUPPLYC, [DRG Standard Weights].RADC, [DRG Standard Weights].INTERRADC, [DRG Standard Weights].ANGIOC, [DRG Standard Weights].ULTSNDC, [DRG Standard Weights].NUCMEDC, [DRG Standard Weights].MRIC, [DRG Standard Weights].CTC, [DRG Standard Weights].GENRADC, [DRG Standard Weights].PHARMSTR, [DRG Standard Weights].PROSPUBC, [DRG Standard Weights].CLINLABC, [DRG Standard Weights].ORPUBC, [DRG Standard Weights].ORPUBXMC, [DRG Standard Weights].CCU, [DRG Standard Weights].ICU, [DRG Standard Weights].NICU, [DRG Standard Weights].NURSEUC_SA, [SNAP Standard Weights].AvgOfsnapallied, [SNAP Standard Weights].AvgOfsnappath, [SNAP Standard Weights].AvgOfsnapimag, [SNAP Standard Weights].AvgOfsnapnurse, [SNAP Standard Weights].AvgOfsnapdrugs, [SNAP Standard Weights].AvgOfsnapsupply, [SNAP Standard Weights].AvgOfsnapother, [DRG Standard Weights].HITHNURSE, [DRG Standard Weights].HITHALLIED, [DRG Standard Weights].HITHDRUGS, [DRG Standard Weights].HITHMSS FROM ([DRG Standard Weights] INNER JOIN [qry Sites DRG_SNAP_CLASS] ON [DRG Standard Weights].DRG_CODE = [qry Sites DRG_SNAP_CLASS].[DRG 6_0x]) INNER JOIN [SNAP Standard Weights] ON [qry Sites DRG_SNAP_CLASS].SNAP_Class = [SNAP Standard Weights].DRG_CODE;
    drg_WEIGHT_FILE_PPM_SNAP = pd.DataFrame()
    file_snapStandardWeights = "./Costing/SNAPStandardWeights.csv"
    if os.path.isfile(file_snapStandardWeights):
        try:
            snapStandardWeights = read_csv_file(file_snapStandardWeights, encoding = 'unicode_escape', dtype=str, keep_default_na=False, na_values='')
        except Exception as e:
            logging.exception("Exception occurred")
        else:
            snapStandardWeights = snapStandardWeights.applymap(str)#.apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            snapStandardWeights = snapStandardWeights.applymap(lambda x: x.strip() if isinstance(x, str) else x)
            snapStandardWeights = snapStandardWeights.apply(lambda x: x.replace(regex=r'^NaT$', value='') if x.dtype == 'object' else x)
            snapStandardWeights = snapStandardWeights.apply(lambda x: x.replace(regex=r'^nan$', value='') if x.dtype == 'object' else x)
            snapStandardWeights = snapStandardWeights[['DRG_VERSION','DRG_CODE','AvgOfsnapallied','AvgOfsnappath','AvgOfsnapimag','AvgOfsnapnurse','AvgOfsnapdrugs','AvgOfsnapsupply','AvgOfsnapother']]
    else:
        snapStandardWeights = pd.DataFrame(columns=['DRG_VERSION','DRG_CODE','AvgOfsnapallied','AvgOfsnappath','AvgOfsnapimag','AvgOfsnapnurse','AvgOfsnapdrugs','AvgOfsnapsupply','AvgOfsnapother'])
    drg_WEIGHT_FILE_PPM_SNAP = pd.merge(drgStandardWeights[['DRG_CODE', 'NURSEUC', 'ONE', 'CritUC', 'ORPUBUC', 'PROSPUBUC', 'SUPPLYUC', 'ALLIEDUC', 'OTUC', 'PHYSIOUC', 'SPTHERUC', 'NUTRDIETUC', 'SOCIALWUC', 'GENRADUC', 'PharmUC', 'CLINLABUC', 'ALLIEDC', 'PHYSIOC', 'OTC', 'SPTHERC', 'NUTRDIETC', 'SOCIALWC', 'SUPPLYC', 'RADC', 'INTERRADC', 'ANGIOC', 'ULTSNDC', 'NUCMEDC', 'MRIC', 'CTC', 'GENRADC', 'PHARMSTR', 'PROSPUBC', 'CLINLABC', 'ORPUBC', 'ORPUBXMC', 'CCU', 'ICU', 'NICU', 'NURSEUC_SA', 'HITHNURSE', 'HITHALLIED', 'HITHDRUGS', 'HITHMSS']], qry_Sites_drg_SNAP_CLASS[['SNAP_Class', 'DRG 6_0x', 'DRG_CODE_dummy']], how='inner', left_on=['DRG_CODE'], right_on=['DRG 6_0x'], suffixes=('', '_drop')).merge(snapStandardWeights[['DRG_CODE', 'AvgOfsnapallied', 'AvgOfsnappath', 'AvgOfsnapimag', 'AvgOfsnapnurse', 'AvgOfsnapdrugs', 'AvgOfsnapsupply', 'AvgOfsnapother']], how='inner', left_on=['SNAP_Class'], right_on=['DRG_CODE'], suffixes=('', '_drop'))
    drg_WEIGHT_FILE_PPM_SNAP = drg_WEIGHT_FILE_PPM_SNAP.apply(lambda x: x.replace(regex=r'^nan$', value='') if x.dtype == 'object' else x)
    drg_WEIGHT_FILE_PPM_SNAP['DRG_VERSION'] = 'S4'
    drg_WEIGHT_FILE_PPM_SNAP['DRG_CODE'] = drg_WEIGHT_FILE_PPM_SNAP['DRG_CODE_dummy']
    drg_WEIGHT_FILE_PPM_SNAP['snapallied'] = drg_WEIGHT_FILE_PPM_SNAP['AvgOfsnapallied']
    drg_WEIGHT_FILE_PPM_SNAP['snappath'] = drg_WEIGHT_FILE_PPM_SNAP['AvgOfsnappath']
    drg_WEIGHT_FILE_PPM_SNAP['snapimag'] = drg_WEIGHT_FILE_PPM_SNAP['AvgOfsnapimag']
    drg_WEIGHT_FILE_PPM_SNAP['snapnurse'] = drg_WEIGHT_FILE_PPM_SNAP['AvgOfsnapnurse']
    drg_WEIGHT_FILE_PPM_SNAP['snapdrugs'] = drg_WEIGHT_FILE_PPM_SNAP['AvgOfsnapdrugs']
    drg_WEIGHT_FILE_PPM_SNAP['snapsupply'] = drg_WEIGHT_FILE_PPM_SNAP['AvgOfsnapsupply']
    drg_WEIGHT_FILE_PPM_SNAP['snapother'] = drg_WEIGHT_FILE_PPM_SNAP['AvgOfsnapother']
    drg_WEIGHT_FILE_PPM_SNAP.to_csv('./ExtractorDB/drg_WEIGHT_FILE_PPM_SNAP.csv', index=False)
    drg_WEIGHT_FILE_PPM_SNAP = drg_WEIGHT_FILE_PPM_SNAP[['DRG_VERSION', 'DRG_CODE', 'NURSEUC', 'ONE', 'CritUC', 'ORPUBUC', 'PROSPUBUC', 'SUPPLYUC', 'ALLIEDUC', 'OTUC', 'PHYSIOUC', 'SPTHERUC', 'NUTRDIETUC', 'SOCIALWUC', 'GENRADUC', 'PharmUC', 'CLINLABUC', 'ALLIEDC', 'PHYSIOC', 'OTC', 'SPTHERC', 'NUTRDIETC', 'SOCIALWC', 'SUPPLYC', 'RADC', 'INTERRADC', 'ANGIOC', 'ULTSNDC', 'NUCMEDC', 'MRIC', 'CTC', 'GENRADC', 'PHARMSTR', 'PROSPUBC', 'CLINLABC', 'ORPUBC', 'ORPUBXMC', 'CCU', 'ICU', 'NICU', 'NURSEUC_SA', 'snapallied', 'snappath', 'snapimag', 'snapnurse', 'snapdrugs', 'snapsupply', 'snapother', 'HITHNURSE', 'HITHALLIED', 'HITHDRUGS', 'HITHMSS']]
    drg_WEIGHT_FILE_PPM = pd.concat([drg_WEIGHT_FILE_PPM, drg_WEIGHT_FILE_PPM_SNAP], axis=0)
    drg_WEIGHT_FILE_PPM = drg_WEIGHT_FILE_PPM.applymap(str)#.apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    drg_WEIGHT_FILE_PPM = drg_WEIGHT_FILE_PPM.applymap(lambda x: x.strip() if isinstance(x, str) else x)
    drg_WEIGHT_FILE_PPM = drg_WEIGHT_FILE_PPM.apply(lambda x: x.replace(regex=r'^NaT$', value='') if x.dtype == 'object' else x)
    drg_WEIGHT_FILE_PPM = drg_WEIGHT_FILE_PPM.apply(lambda x: x.replace(regex=r'^nan$', value='') if x.dtype == 'object' else x)
    drg_WEIGHT_FILE_PPM = drg_WEIGHT_FILE_PPM[['DRG_VERSION', 'DRG_CODE', 'NURSEUC', 'ONE', 'CritUC', 'ORPUBUC', 'PROSPUBUC', 'SUPPLYUC', 'ALLIEDUC', 'OTUC', 'PHYSIOUC', 'SPTHERUC', 'NUTRDIETUC', 'SOCIALWUC', 'GENRADUC', 'PharmUC', 'CLINLABUC', 'ALLIEDC', 'PHYSIOC', 'OTC', 'SPTHERC', 'NUTRDIETC', 'SOCIALWC', 'SUPPLYC', 'RADC', 'INTERRADC', 'ANGIOC', 'ULTSNDC', 'NUCMEDC', 'MRIC', 'CTC', 'GENRADC', 'PHARMSTR', 'PROSPUBC', 'CLINLABC', 'ORPUBC', 'ORPUBXMC', 'CCU', 'ICU', 'NICU', 'NURSEUC_SA', 'snapallied', 'snappath', 'snapimag', 'snapnurse', 'snapdrugs', 'snapsupply', 'snapother', 'HITHNURSE', 'HITHALLIED', 'HITHDRUGS', 'HITHMSS']]
    logging.info('Query: append SNAP weights completed. drg_WEIGHT_FILE_PPM_SNAP with %s records has been appended to drg_WEIGHT_FILE_PPM. drg_WEIGHT_FILE_PPM now has %s records.', len(drg_WEIGHT_FILE_PPM_SNAP), len(drg_WEIGHT_FILE_PPM)) 
    drg_WEIGHT_FILE_PPM = drg_WEIGHT_FILE_PPM.applymap(str)#.apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    drg_WEIGHT_FILE_PPM = drg_WEIGHT_FILE_PPM.applymap(lambda x: x.strip() if isinstance(x, str) else x)
    drg_WEIGHT_FILE_PPM = drg_WEIGHT_FILE_PPM.apply(lambda x: x.replace(regex=r'^NaT$', value='') if x.dtype == 'object' else x)
    drg_WEIGHT_FILE_PPM = drg_WEIGHT_FILE_PPM.apply(lambda x: x.replace(regex=r'^nan$', value='') if x.dtype == 'object' else x)
    # Exports the DRG WEIGHT FILE PPM to c:\costing\DRGWeight.txt which contains the weights for loading into DRG Weight table in PPM
    # Access query: DRG WEIGHT FILE PPM
    try:
        drg_WEIGHT_FILE_PPM.to_csv('./Output/DRGWeight.txt', sep=',', index=False, na_rep='', float_format=str, decimal=str, date_format=str)
    except Exception as e:
        logging.exception("Exception occurred")
        label_8_status = 0
        messagebox.showerror("Export Error","Error exporting DRGWeight.txt\n"+str(e))
        label_8_sub.configure(text="Failed ()...",fg='red')
        main_screen.update()
        return # stop export    
    logging.info('%s records saved to ./Output/DRGWeight.txt.', len(drg_WEIGHT_FILE_PPM))
    # Condtion: The number of rows is greater than 0
    # Access query: qry check missing weights
    # SELECT [qry Sites DRG_SNAP_CLASS].DRG_CODE, [DRG WEIGHT FILE PPM].DRG_CODE FROM [qry Sites DRG_SNAP_CLASS] LEFT JOIN [DRG WEIGHT FILE PPM] ON [qry Sites DRG_SNAP_CLASS].DRG_CODE = [DRG WEIGHT FILE PPM].DRG_CODE WHERE ((([DRG WEIGHT FILE PPM].DRG_CODE) Is Null));
    #drg_WEIGHT_FILE_PPM['DRG_CODE_dummy'] = drg_WEIGHT_FILE_PPM['DRG_CODE'] 
    #check_missing_weights = pd.merge(qry_Sites_drg_SNAP_CLASS[['DRG_CODE']], drg_WEIGHT_FILE_PPM[['DRG_CODE', 'DRG_CODE_dummy']], how='left', on=['DRG_CODE'], suffixes=('', '_drop'), indicator=True)
    #check_missing_weights = check_missing_weights[(check_missing_weights['DRG_CODE_dummy'].isnull()) | (check_missing_weights['DRG_CODE_dummy']=='')]
    check_missing_weights = pd.merge(qry_Sites_drg_SNAP_CLASS[['DRG_CODE']], drg_WEIGHT_FILE_PPM[['DRG_CODE']], how='left', on=['DRG_CODE'], suffixes=('', '_drop'), indicator=True)
    check_missing_weights = check_missing_weights[check_missing_weights['_merge']=='left_only']
    check_missing_weights = check_missing_weights[['DRG_CODE']]
    check_missing_weights = check_missing_weights.apply(lambda x: x.replace(regex=r'^nan$', value='') if x.dtype == 'object' else x)
    check_missing_weights = check_missing_weights.drop_duplicates(keep='last')
    check_missing_weights.to_csv('./ExtractorDB/qry_check_missing_weights.csv', sep=',', index=False, na_rep='', float_format=str, decimal=str, date_format=str)
    logging.info('qry check missing weights completed. %s records saved to ./Output/./ExtractorDB/qry_check_missing_weights.csv.', len(check_missing_weights))
    if len(check_missing_weights)>0:
        logging.info('Query: qry check missing weights completed. Please notify the ABF taskforce for an updated weight file as there are missing DRG/SNAP weights.')
    else:
        logging.info('Query: qry check missing weights completed. There are NO missing DRG/SNAP weights.')
    # Update Sub task status    
    if label_8_status ==1:
        if len(check_missing_weights)>0:
            label_8_sub.configure(text="Completed. DRG/SNAPs without weights.\nPlease notify ABF taskforce",fg='blue')
        else:
            label_8_sub.configure(text="Completed.",fg='green')
        main_screen.update()     
    else:
        label_8_sub.configure(text="Failed",fg='red')
        main_screen.update()
    main_screen.update() 
    logging.info('Execute DRG Weight Maker completed.')
    """
    ############### "9. Execute AECC"#################
    label_9_status = 1
    if str(roundid) in aecc_round_id_list:
        logging.info("Execute AECC update started.")
        # Set default value of sub-task status to 1
        label_9_sub.configure(text="In Progress (Final updates)...", fg="blue")
        main_screen.update()
        ##############
        file_tbl_PPM_ED_Encounter = (
            "./Output/tbl_PPM_ED_Encounter_" + versionID_underscore + ".csv"
        )
        if os.path.isfile(file_tbl_PPM_ED_Encounter):
            try:
                tbl_PPM_ED_Encounter = read_csv_file(
                    file_tbl_PPM_ED_Encounter,
                    encoding="unicode_escape",
                    dtype=str,
                    keep_default_na=False,
                    na_values="",
                )
            except Exception as e:
                logging.exception("Exception occurred")
                label_9_status = 0
                messagebox.showerror(
                    "File Error",
                    "Error extracting tbl_PPM_ED_Encounter from ./Output/tbl_PPM_ED_Encounter.csv.\n"
                    + str(e),
                )
                label_9_sub.configure(text="Failed (tbl_PPM_ED_Encounter)...", fg="red")
                main_screen.update()
                return
            else:
                tbl_PPM_ED_Encounter = tbl_PPM_ED_Encounter.applymap(
                    str
                )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
                tbl_PPM_ED_Encounter = tbl_PPM_ED_Encounter.applymap(
                    lambda x: x.strip() if isinstance(x, str) else x
                )
                tbl_PPM_ED_Encounter = tbl_PPM_ED_Encounter.apply(
                    lambda x: x.replace(regex=r"^NaT$", value="")
                    if x.dtype == "object"
                    else x
                )
                tbl_PPM_ED_Encounter = tbl_PPM_ED_Encounter.apply(
                    lambda x: x.replace(regex=r"^nan$", value="")
                    if x.dtype == "object"
                    else x
                )
        else:
            tbl_PPM_ED_Encounter = pd.DataFrame()
        #################
        # file_tbl_PPM_ED_Encounter_EVT13 = "./Output/tbl_PPM_ED_Encounter_"+versionID_underscore+"EVT13.csv"
        file_tbl_PPM_ED_Encounter_EVT13 = (
            "./ExtractorDB/tbl_PPM_ED_Encounter_EVT13_"
            + versionID_underscore
            + "_OLD_FORMAT.csv"
        )
        if os.path.isfile(file_tbl_PPM_ED_Encounter_EVT13):
            try:
                tbl_PPM_ED_Encounter_EVT13 = read_csv_file(
                    file_tbl_PPM_ED_Encounter_EVT13,
                    encoding="unicode_escape",
                    dtype=str,
                    keep_default_na=False,
                    na_values="",
                )
            except Exception as e:
                logging.exception("Exception occurred")
                label_9_status = 0
                messagebox.showerror(
                    "File Error",
                    "Error extracting tbl_PPM_ED_Encounter_EVT13 from ./Output/tbl_PPM_ED_Encounter_EVT13.csv.\n"
                    + str(e),
                )
                label_9_sub.configure(
                    text="Failed (tbl_PPM_ED_Encounter_EVT13)...", fg="red"
                )
                main_screen.update()
                return
            else:
                tbl_PPM_ED_Encounter_EVT13 = tbl_PPM_ED_Encounter_EVT13.applymap(
                    str
                )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
                tbl_PPM_ED_Encounter_EVT13 = tbl_PPM_ED_Encounter_EVT13.applymap(
                    lambda x: x.strip() if isinstance(x, str) else x
                )
                tbl_PPM_ED_Encounter_EVT13 = tbl_PPM_ED_Encounter_EVT13.apply(
                    lambda x: x.replace(regex=r"^NaT$", value="")
                    if x.dtype == "object"
                    else x
                )
                tbl_PPM_ED_Encounter_EVT13 = tbl_PPM_ED_Encounter_EVT13.apply(
                    lambda x: x.replace(regex=r"^nan$", value="")
                    if x.dtype == "object"
                    else x
                )
        else:
            tbl_PPM_ED_Encounter_EVT13 = pd.DataFrame()
        ###############
        file_tbl_ExcludedEncounters = "./Output/tbl_ExcludedEncounters.csv"
        if os.path.isfile(file_tbl_ExcludedEncounters):
            try:
                tbl_ExcludedEncounters = read_csv_file(
                    file_tbl_ExcludedEncounters,
                    encoding="unicode_escape",
                    dtype=str,
                    keep_default_na=False,
                    na_values="",
                )
            except Exception as e:
                logging.exception("Exception occurred")
                label_9_status = 0
                messagebox.showerror(
                    "File Error",
                    "Error extracting tbl_ExcludedEncounters from ./Output/tbl_ExcludedEncounters.csv.\n"
                    + str(e),
                )
                label_9_sub.configure(
                    text="Failed (tbl_ExcludedEncounters)...", fg="red"
                )
                main_screen.update()
                return
            else:
                tbl_ExcludedEncounters = tbl_ExcludedEncounters.applymap(
                    str
                )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
                tbl_ExcludedEncounters = tbl_ExcludedEncounters.applymap(
                    lambda x: x.strip() if isinstance(x, str) else x
                )
                tbl_ExcludedEncounters = tbl_ExcludedEncounters.apply(
                    lambda x: x.replace(regex=r"^NaT$", value="")
                    if x.dtype == "object"
                    else x
                )
                tbl_ExcludedEncounters = tbl_ExcludedEncounters.apply(
                    lambda x: x.replace(regex=r"^nan$", value="")
                    if x.dtype == "object"
                    else x
                )
        else:
            tbl_ExcludedEncounters = pd.DataFrame()
        ##########
        file_aecc = "./ExtractorDB/aecc.csv"
        if os.path.isfile(file_aecc):
            try:
                aecc = read_csv_file(
                    file_aecc,
                    encoding="unicode_escape",
                    dtype=str,
                    keep_default_na=False,
                    na_values="",
                )
            except Exception as e:
                logging.exception("Exception occurred")
                label_9_status = 0
                messagebox.showerror(
                    "File Error",
                    "Error extracting aecc from ./Output/aecc.csv.\n" + str(e),
                )
                label_9_sub.configure(text="Failed (aecc)...", fg="red")
                main_screen.update()
                return
            else:
                aecc = aecc.applymap(
                    str
                )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
                aecc = aecc.applymap(lambda x: x.strip() if isinstance(x, str) else x)
                aecc = aecc.apply(
                    lambda x: x.replace(regex=r"^NaT$", value="")
                    if x.dtype == "object"
                    else x
                )
                aecc = aecc.apply(
                    lambda x: x.replace(regex=r"^nan$", value="")
                    if x.dtype == "object"
                    else x
                )
        else:
            aecc = pd.DataFrame()
        ############# FOR ROUND 27 AND ABOVE - BEGIN #######################
        ####################################################################
        file_tbl_PPM_Encounter = (
            "./Output/tbl_PPM_Encounter_" + versionID_underscore + ".csv"
        )
        if os.path.isfile(file_tbl_PPM_Encounter):
            try:
                tbl_PPM_Encounter = read_csv_file(
                    file_tbl_PPM_Encounter,
                    encoding="unicode_escape",
                    dtype=str,
                    keep_default_na=False,
                    na_values="",
                )
            except Exception as e:
                logging.exception("Exception occurred")
                label_9_status = 0
                messagebox.showerror(
                    "File Error",
                    "Error extracting tbl_PPM_Encounter from ./Output/tbl_PPM_Encounter.csv.\n"
                    + str(e),
                )
                label_9_sub.configure(text="Failed (tbl_PPM_Encounter)...", fg="red")
                main_screen.update()
                return
            else:
                tbl_PPM_Encounter = tbl_PPM_Encounter.applymap(
                    str
                )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
                tbl_PPM_Encounter = tbl_PPM_Encounter.applymap(
                    lambda x: x.strip() if isinstance(x, str) else x
                )
                tbl_PPM_Encounter = tbl_PPM_Encounter.apply(
                    lambda x: x.replace(regex=r"^NaT$", value="")
                    if x.dtype == "object"
                    else x
                )
                tbl_PPM_Encounter = tbl_PPM_Encounter.apply(
                    lambda x: x.replace(regex=r"^nan$", value="")
                    if x.dtype == "object"
                    else x
                )
        else:
            tbl_PPM_Encounter = pd.DataFrame()
        ###############
        file_tbl_PPM_ICD_diagnoses_V25 = (
            "./Output/tbl_PPM_ICD_diagnoses_" + versionID_hash + ".csv"
        )
        if os.path.isfile(file_tbl_PPM_ICD_diagnoses_V25):
            try:
                tbl_PPM_ICD_diagnoses_V25 = read_csv_file(
                    file_tbl_PPM_ICD_diagnoses_V25,
                    encoding="unicode_escape",
                    dtype=str,
                    keep_default_na=False,
                    na_values="",
                )
            except Exception as e:
                logging.exception("Exception occurred")
                label_9_status = 0
                messagebox.showerror(
                    "File Error",
                    "Error extracting tbl_PPM_ICD_diagnoses_V25 from ./Output/tbl_PPM_ICD_diagnoses.csv.\n"
                    + str(e),
                )
                label_9_sub.configure(
                    text="Failed (tbl_PPM_ICD_diagnoses_V25)...", fg="red"
                )
                main_screen.update()
                return
            else:
                tbl_PPM_ICD_diagnoses_V25 = tbl_PPM_ICD_diagnoses_V25.applymap(
                    str
                )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
                tbl_PPM_ICD_diagnoses_V25 = tbl_PPM_ICD_diagnoses_V25.applymap(
                    lambda x: x.strip() if isinstance(x, str) else x
                )
                tbl_PPM_ICD_diagnoses_V25 = tbl_PPM_ICD_diagnoses_V25.apply(
                    lambda x: x.replace(regex=r"^NaT$", value="")
                    if x.dtype == "object"
                    else x
                )
                tbl_PPM_ICD_diagnoses_V25 = tbl_PPM_ICD_diagnoses_V25.apply(
                    lambda x: x.replace(regex=r"^nan$", value="")
                    if x.dtype == "object"
                    else x
                )
        else:
            tbl_PPM_ICD_diagnoses_V25 = pd.DataFrame()
        #################
        file_tbl_PPM_ICD_procedures_V25 = (
            "./Output/tbl_PPM_ICD_procedures_" + versionID_hash + ".csv"
        )
        if os.path.isfile(file_tbl_PPM_ICD_procedures_V25):
            try:
                tbl_PPM_ICD_procedures_V25 = read_csv_file(
                    file_tbl_PPM_ICD_procedures_V25,
                    encoding="unicode_escape",
                    dtype=str,
                    keep_default_na=False,
                    na_values="",
                )
            except Exception as e:
                logging.exception("Exception occurred")
                label_9_status = 0
                messagebox.showerror(
                    "File Error",
                    "Error extracting tbl_PPM_ICD_procedures_V25 from ./Output/tbl_PPM_ICD_procedures_V25.csv.\n"
                    + str(e),
                )
                label_9_sub.configure(
                    text="Failed (tbl_PPM_ICD_procedures_V25)...", fg="red"
                )
                main_screen.update()
                return
            else:
                tbl_PPM_ICD_procedures_V25 = tbl_PPM_ICD_procedures_V25.applymap(
                    str
                )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
                tbl_PPM_ICD_procedures_V25 = tbl_PPM_ICD_procedures_V25.applymap(
                    lambda x: x.strip() if isinstance(x, str) else x
                )
                tbl_PPM_ICD_procedures_V25 = tbl_PPM_ICD_procedures_V25.apply(
                    lambda x: x.replace(regex=r"^NaT$", value="")
                    if x.dtype == "object"
                    else x
                )
                tbl_PPM_ICD_procedures_V25 = tbl_PPM_ICD_procedures_V25.apply(
                    lambda x: x.replace(regex=r"^nan$", value="")
                    if x.dtype == "object"
                    else x
                )
        else:
            tbl_PPM_ICD_procedures_V25 = pd.DataFrame()
        #################
        # Kylie informed that this step is not required anymore.
        """
        file_drgweight = "./Output/DRGWeight.txt"
        if os.path.isfile(file_drgweight):
            try:
                drgweight = read_csv_file(file_drgweight, encoding = 'unicode_escape', dtype=str, keep_default_na=False, na_values='')
            except Exception as e:
                logging.exception("Exception occurred")
                label_9_status = 0
                messagebox.showerror("File Error","Error extracting drgweight from ./Output/DRGWeight.txt.\n"+str(e))
                label_9_sub.configure(text="Failed (drgweight)...",fg='red')
                main_screen.update()
                return
            else:
                drgweight = drgweight.applymap(str)#.apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
                drgweight = drgweight.applymap(lambda x: x.strip() if isinstance(x, str) else x)
                drgweight = drgweight.apply(lambda x: x.replace(regex=r'^NaT$', value='') if x.dtype == 'object' else x)
                drgweight = drgweight.apply(lambda x: x.replace(regex=r'^nan$', value='') if x.dtype == 'object' else x)
        else:
            drgweight = pd.DataFrame()
        """
        #############
        file_tbl_ppm_ObstetEpi = "./Output/tbl_ppm_ObstetEpi.txt"
        if os.path.isfile(file_tbl_ppm_ObstetEpi):
            try:
                tbl_ppm_ObstetEpi = read_csv_file(
                    file_tbl_ppm_ObstetEpi,
                    encoding="unicode_escape",
                    dtype=str,
                    keep_default_na=False,
                    na_values="",
                )
            except Exception as e:
                logging.exception("Exception occurred")
                label_9_status = 0
                messagebox.showerror(
                    "File Error",
                    "Error extracting tbl_ppm_ObstetEpi from ./Output/tbl_ppm_ObstetEpi.txt.\n"
                    + str(e),
                )
                label_9_sub.configure(text="Failed (tbl_ppm_ObstetEpi)...", fg="red")
                main_screen.update()
                return
            else:
                tbl_ppm_ObstetEpi = tbl_ppm_ObstetEpi.applymap(
                    str
                )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
                tbl_ppm_ObstetEpi = tbl_ppm_ObstetEpi.applymap(
                    lambda x: x.strip() if isinstance(x, str) else x
                )
                tbl_ppm_ObstetEpi = tbl_ppm_ObstetEpi.apply(
                    lambda x: x.replace(regex=r"^NaT$", value="")
                    if x.dtype == "object"
                    else x
                )
                tbl_ppm_ObstetEpi = tbl_ppm_ObstetEpi.apply(
                    lambda x: x.replace(regex=r"^nan$", value="")
                    if x.dtype == "object"
                    else x
                )
        else:
            tbl_ppm_ObstetEpi = pd.DataFrame()
        #############
        file_drgs_960Z_Not_in_10 = "./ExtractorDB/drgs_960Z_Not_in_10.csv"
        if os.path.isfile(file_drgs_960Z_Not_in_10):
            try:
                drgs_960Z_Not_in_10 = read_csv_file(
                    file_drgs_960Z_Not_in_10,
                    encoding="unicode_escape",
                    dtype=str,
                    keep_default_na=False,
                    na_values="",
                )
            except Exception as e:
                logging.exception("Exception occurred")
                label_9_status = 0
                messagebox.showerror(
                    "File Error",
                    "Error extracting drgs_960Z_Not_in_10 from ./Output/drgs_960Z_Not_in_10.csv.\n"
                    + str(e),
                )
                label_9_sub.configure(text="Failed (drgs_960Z_Not_in_10)...", fg="red")
                main_screen.update()
                return
            else:
                drgs_960Z_Not_in_10 = drgs_960Z_Not_in_10.applymap(
                    str
                )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
                drgs_960Z_Not_in_10 = drgs_960Z_Not_in_10.applymap(
                    lambda x: x.strip() if isinstance(x, str) else x
                )
                drgs_960Z_Not_in_10 = drgs_960Z_Not_in_10.apply(
                    lambda x: x.replace(regex=r"^NaT$", value="")
                    if x.dtype == "object"
                    else x
                )
                drgs_960Z_Not_in_10 = drgs_960Z_Not_in_10.apply(
                    lambda x: x.replace(regex=r"^nan$", value="")
                    if x.dtype == "object"
                    else x
                )
        else:
            drgs_960Z_Not_in_10 = pd.DataFrame()
        #############
        file_procedure_ICD10V12 = "./ExtractorDB/procedure_ICD10V12.csv"
        if os.path.isfile(file_procedure_ICD10V12):
            try:
                procedure_ICD10V12 = read_csv_file(
                    file_procedure_ICD10V12,
                    encoding="unicode_escape",
                    dtype=str,
                    keep_default_na=False,
                    na_values="",
                )
            except Exception as e:
                logging.exception("Exception occurred")
                label_9_status = 0
                messagebox.showerror(
                    "File Error",
                    "Error extracting procedure_ICD10V12 from ./Output/procedure_ICD10V12.csv.\n"
                    + str(e),
                )
                label_9_sub.configure(text="Failed (procedure_ICD10V12)...", fg="red")
                main_screen.update()
                return
            else:
                procedure_ICD10V12 = procedure_ICD10V12.applymap(
                    str
                )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
                procedure_ICD10V12 = procedure_ICD10V12.applymap(
                    lambda x: x.strip() if isinstance(x, str) else x
                )
                procedure_ICD10V12 = procedure_ICD10V12.apply(
                    lambda x: x.replace(regex=r"^NaT$", value="")
                    if x.dtype == "object"
                    else x
                )
                procedure_ICD10V12 = procedure_ICD10V12.apply(
                    lambda x: x.replace(regex=r"^nan$", value="")
                    if x.dtype == "object"
                    else x
                )
        else:
            procedure_ICD10V12 = pd.DataFrame()
        #############
        file_diagnosis_ICD10V12 = "./ExtractorDB/diagnosis_ICD10V12.csv"
        if os.path.isfile(file_diagnosis_ICD10V12):
            try:
                diagnosis_ICD10V12 = read_csv_file(
                    file_diagnosis_ICD10V12,
                    encoding="unicode_escape",
                    dtype=str,
                    keep_default_na=False,
                    na_values="",
                )
            except Exception as e:
                logging.exception("Exception occurred")
                label_9_status = 0
                messagebox.showerror(
                    "File Error",
                    "Error extracting diagnosis_ICD10V12 from ./Output/diagnosis_ICD10V12.csv.\n"
                    + str(e),
                )
                label_9_sub.configure(text="Failed (diagnosis_ICD10V12)...", fg="red")
                main_screen.update()
                return
            else:
                diagnosis_ICD10V12 = diagnosis_ICD10V12.applymap(
                    str
                )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
                diagnosis_ICD10V12 = diagnosis_ICD10V12.applymap(
                    lambda x: x.strip() if isinstance(x, str) else x
                )
                diagnosis_ICD10V12 = diagnosis_ICD10V12.apply(
                    lambda x: x.replace(regex=r"^NaT$", value="")
                    if x.dtype == "object"
                    else x
                )
                diagnosis_ICD10V12 = diagnosis_ICD10V12.apply(
                    lambda x: x.replace(regex=r"^nan$", value="")
                    if x.dtype == "object"
                    else x
                )
        else:
            diagnosis_ICD10V12 = pd.DataFrame()
        #############
        file_nwau21_Inpatient = "./ExtractorDB/nwau21_Inpatient.csv"
        if os.path.isfile(file_nwau21_Inpatient):
            try:
                nwau21_Inpatient = read_csv_file(
                    file_nwau21_Inpatient,
                    encoding="unicode_escape",
                    dtype=str,
                    keep_default_na=False,
                    na_values="",
                )
            except Exception as e:
                logging.exception("Exception occurred")
                label_9_status = 0
                messagebox.showerror(
                    "File Error",
                    "Error extracting nwau21_Inpatient from ./Output/nwau21_Inpatient.csv.\n"
                    + str(e),
                )
                label_9_sub.configure(text="Failed (nwau21_Inpatient)...", fg="red")
                main_screen.update()
                return
            else:
                nwau21_Inpatient = nwau21_Inpatient.applymap(
                    str
                )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
                nwau21_Inpatient = nwau21_Inpatient.applymap(
                    lambda x: x.strip() if isinstance(x, str) else x
                )
                nwau21_Inpatient = nwau21_Inpatient.apply(
                    lambda x: x.replace(regex=r"^NaT$", value="")
                    if x.dtype == "object"
                    else x
                )
                nwau21_Inpatient = nwau21_Inpatient.apply(
                    lambda x: x.replace(regex=r"^nan$", value="")
                    if x.dtype == "object"
                    else x
                )
        else:
            nwau21_Inpatient = pd.DataFrame()
        #############
        file_snomed_Update = "./ExtractorDB/snomed_Update.csv"
        if os.path.isfile(file_snomed_Update):
            try:
                snomed_Update = read_csv_file(
                    file_snomed_Update,
                    encoding="unicode_escape",
                    dtype=str,
                    keep_default_na=False,
                    na_values="",
                )
            except Exception as e:
                logging.exception("Exception occurred")
                label_9_status = 0
                messagebox.showerror(
                    "File Error",
                    "Error extracting snomed_Update from ./Output/snomed_Update.csv.\n"
                    + str(e),
                )
                label_9_sub.configure(text="Failed (snomed_Update)...", fg="red")
                main_screen.update()
                return
            else:
                snomed_Update = snomed_Update.applymap(
                    str
                )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
                snomed_Update = snomed_Update.applymap(
                    lambda x: x.strip() if isinstance(x, str) else x
                )
                snomed_Update = snomed_Update.apply(
                    lambda x: x.replace(regex=r"^NaT$", value="")
                    if x.dtype == "object"
                    else x
                )
                snomed_Update = snomed_Update.apply(
                    lambda x: x.replace(regex=r"^nan$", value="")
                    if x.dtype == "object"
                    else x
                )
        else:
            snomed_Update = pd.DataFrame()
        ##############
        # Kylie informed that this step is not required anymore.
        """
        drgStandardWeights = pd.DataFrame()
        file_drgStandardWeights = "./Costing/DRGStandardWeights.csv"
        if os.path.isfile(file_drgStandardWeights):
            try:
                drgStandardWeights = read_csv_file(file_drgStandardWeights, encoding = 'unicode_escape', dtype=str, keep_default_na=False, na_values='')
            except Exception as e:
                logging.exception("Exception occurred")
                label_4_status = 0
                messagebox.showerror("File Error","Error extracting drgStandardWeights from ./Costing/DRGStandardWeights.csv.\n"+str(e))
                label_4_sub.configure(text="Failed (drgStandardWeights)...",fg='red')
                main_screen.update()
                return
            else:
                drgStandardWeights = drgStandardWeights.applymap(str)#.apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
                drgStandardWeights = drgStandardWeights.applymap(lambda x: x.strip() if isinstance(x, str) else x)
                drgStandardWeights = drgStandardWeights.apply(lambda x: x.replace(regex=r'^NaT$', value='') if x.dtype == 'object' else x)
                drgStandardWeights = drgStandardWeights.apply(lambda x: x.replace(regex=r'^nan$', value='') if x.dtype == 'object' else x)
                drgStandardWeights.columns = ['DRG_VERSION', 'DRG_CODE', 'NURSEUC', 'ONE', 'CritUC', 'ORPUBUC', 'PROSPUBUC', 'SUPPLYUC', 'ALLIEDUC', 'OTUC', 'PHYSIOUC', 'SPTHERUC', 'NUTRDIETUC', 'SOCIALWUC', 'GENRADUC', 'PharmUC', 'CLINLABUC', 'ALLIEDC', 'PHYSIOC', 'OTC', 'SPTHERC', 'NUTRDIETC', 'SOCIALWC', 'SUPPLYC', 'RADC', 'INTERRADC', 'ANGIOC', 'ULTSNDC', 'NUCMEDC', 'MRIC', 'CTC', 'GENRADC', 'PHARMSTR', 'PROSPUBC', 'CLINLABC', 'ORPUBC', 'ORPUBXMC', 'CCU', 'ICU', 'NICU', 'NURSEUC_SA', 'snapallied', 'snappath', 'snapimag', 'snapnurse', 'snapdrugs', 'snapsupply', 'snapother', 'HITHNURSE', 'HITHALLIED', 'HITHDRUGS', 'HITHMSS']
        else:
            drgStandardWeights = pd.DataFrame(columns=['DRG_VERSION', 'DRG_CODE', 'NURSEUC', 'ONE', 'CritUC', 'ORPUBUC', 'PROSPUBUC', 'SUPPLYUC', 'ALLIEDUC', 'OTUC', 'PHYSIOUC', 'SPTHERUC', 'NUTRDIETUC', 'SOCIALWUC', 'GENRADUC', 'PharmUC', 'CLINLABUC', 'ALLIEDC', 'PHYSIOC', 'OTC', 'SPTHERC', 'NUTRDIETC', 'SOCIALWC', 'SUPPLYC', 'RADC', 'INTERRADC', 'ANGIOC', 'ULTSNDC', 'NUCMEDC', 'MRIC', 'CTC', 'GENRADC', 'PHARMSTR', 'PROSPUBC', 'CLINLABC', 'ORPUBC', 'ORPUBXMC', 'CCU', 'ICU', 'NICU', 'NURSEUC_SA', 'snapallied', 'snappath', 'snapimag', 'snapnurse', 'snapdrugs', 'snapsupply', 'snapother', 'HITHNURSE', 'HITHALLIED', 'HITHDRUGS', 'HITHMSS'])
        """
        ###############################################################################
        # Access query: qry_update_DRGS_960Z_with_valid_DRG
        # UPDATE Tbl_PPM_Encounter_V25 INNER JOIN DRGS_960Z_Not_in_10 ON (Tbl_PPM_Encounter_V25.[Extra:HospitalStayNumber] = DRGS_960Z_Not_in_10.STN) AND (Tbl_PPM_Encounter_V25.[Extra:EpisodeSequenceNumber] = DRGS_960Z_Not_in_10.ESN) AND (Tbl_PPM_Encounter_V25.Hospital = DRGS_960Z_Not_in_10.Hospital) SET Tbl_PPM_Encounter_V25.DRG1 = [DRG10], Tbl_PPM_Encounter_V25.[Extra:DRG4] = [DRG10]
        # WHERE (((Tbl_PPM_Encounter_V25.EncounterNumber) Not Like "*_*"));
        """
        drgs_960Z_Not_in_10['ESN'] = drgs_960Z_Not_in_10['ESN'].astype(str).str.replace('SN' ,'')
        drgs_960Z_Not_in_10['ESN'] = drgs_960Z_Not_in_10['ESN'].astype(str).str.pad(8, side ='left', fillchar ='0')
        drgs_960Z_Not_in_10['ESN'] = 'SN' + drgs_960Z_Not_in_10['ESN']
        """
        drgs_960Z_Not_in_10["STN"] = (
            drgs_960Z_Not_in_10["STN"].astype(str).str.replace("SN", "")
        )
        drgs_960Z_Not_in_10["STN"] = (
            drgs_960Z_Not_in_10["STN"].astype(str).str.pad(8, side="left", fillchar="0")
        )
        drgs_960Z_Not_in_10["STN"] = "SN" + drgs_960Z_Not_in_10["STN"]
        tbl_PPM_Encounter["Extra:EpisodeSequenceNumber"] = (
            tbl_PPM_Encounter["Extra:EpisodeSequenceNumber"]
            .astype(str)
            .str.pad(3, side="left", fillchar="0")
        )
        drgs_960Z_Not_in_10["ESN"] = (
            drgs_960Z_Not_in_10["ESN"].astype(str).str.pad(3, side="left", fillchar="0")
        )
        tbl_PPM_Encounter_V25 = pd.merge(
            tbl_PPM_Encounter,
            drgs_960Z_Not_in_10,
            how="left",
            left_on=[
                "Extra:HospitalStayNumber",
                "Extra:EpisodeSequenceNumber",
                "Hospital",
            ],
            right_on=["STN", "ESN", "Hospital"],
            suffixes=("", "_drop"),
            indicator=True,
        )
        tbl_PPM_Encounter_V25 = tbl_PPM_Encounter_V25.apply(
            lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
        )
        tbl_PPM_Encounter_V25["DRG1"] = np.where(
            (tbl_PPM_Encounter_V25.EncounterNumber.str.contains("_") == False)
            & (tbl_PPM_Encounter_V25["_merge"] == "both"),
            tbl_PPM_Encounter_V25["DRG10"],
            tbl_PPM_Encounter_V25["DRG1"],
        )
        # AQA-279: populate 960Z for current inpatient in FY2324 and is not coded. Check comments in the JIRA. This is needed.
        tbl_PPM_Encounter_V25["DRG1"] = np.where(
            (
                (tbl_PPM_Encounter_V25["DRG1"].isnull())
                | (tbl_PPM_Encounter_V25["DRG1"] == "")
            ),
            "960Z",
            tbl_PPM_Encounter_V25["DRG1"],
        )
        tbl_PPM_Encounter_V25["Extra:DRG4"] = np.where(
            (tbl_PPM_Encounter_V25.EncounterNumber.str.contains("_") == False)
            & (tbl_PPM_Encounter_V25["_merge"] == "both"),
            tbl_PPM_Encounter_V25["DRG10"],
            tbl_PPM_Encounter_V25["Extra:DRG4"],
        )
        tbl_PPM_Encounter_V25 = tbl_PPM_Encounter_V25.drop(["_merge"], axis=1)
        logging.info("Qry_update_DRGS_960Z_with_valid_DRG completed.")
        ###############################################################################
        # Access query: qry_update_nwau21
        # UPDATE NWAU21_Inpatient INNER JOIN Tbl_PPM_Encounter_V25 ON NWAU21_Inpatient.EncounterNumber = Tbl_PPM_Encounter_V25.EncounterNumber SET Tbl_PPM_Encounter_V25.[Extra:nwau_base] = [nwau_base], Tbl_PPM_Encounter_V25.[Extra:nwau_paed_incr] = [paediatric_adj], Tbl_PPM_Encounter_V25.[Extra:nwau_indig_incr] = [indigenous_adj], Tbl_PPM_Encounter_V25.[Extra:nwau_remote_incr] = [remoteness_area_adj], Tbl_PPM_Encounter_V25.[Extra:nwau_icu_incr] = [icu_adj], Tbl_PPM_Encounter_V25.[Extra:nwau_private_patient_service_incr] = [NWAU21_Inpatient]![private_service_adj], Tbl_PPM_Encounter_V25.[Extra:nwau_private_patient_accom_incr] = [NWAU21_Inpatient]![private_accom_adj], Tbl_PPM_Encounter_V25.[Extra:nwau] = [NWAU21_Inpatient]![nwau_final], Tbl_PPM_Encounter_V25.[Extra:nwau_PublicEquivModel] = [NWAU21_Inpatient]![public_equiv_nwau], Tbl_PPM_Encounter_V25.[Extra:nwau_version] = [NWAU21_Inpatient]![nwau_version], Tbl_PPM_Encounter_V25.[Extra:sp_psy_age_adj] = [NWAU21_Inpatient]![sp_psy_age_adj], Tbl_PPM_Encounter_V25.[Extra:Radiotherapy_adj] = [NWAU21_Inpatient]![radiotherapy_adj], Tbl_PPM_Encounter_V25.[Extra:compensable_nwau] = [NWAU21_Inpatient]![compensable_nwau]
        # WHERE (((Tbl_PPM_Encounter_V25.EncounterNumber) Not Like "*_*"));
        # 28 Jan 2025 - Memory issue occuring below. So commenting

        """
        tbl_PPM_Encounter_V25 = pd.merge(tbl_PPM_Encounter_V25, nwau21_Inpatient, how='left', left_on=['EncounterNumber'], right_on=['EncounterNumber'], suffixes=('', '_drop'), indicator=True)
        tbl_PPM_Encounter_V25 = tbl_PPM_Encounter_V25.apply(lambda x: x.replace(regex=r'^nan$', value='') if x.dtype == 'object' else x)
        tbl_PPM_Encounter_V25['Extra:nwau_base'] = np.where((tbl_PPM_Encounter_V25.EncounterNumber.str.contains('_') == False) & (tbl_PPM_Encounter_V25['_merge']=='both'), tbl_PPM_Encounter_V25['nwau_base'], tbl_PPM_Encounter_V25['Extra:nwau_base'])
        tbl_PPM_Encounter_V25['Extra:nwau_paed_incr'] = np.where((tbl_PPM_Encounter_V25.EncounterNumber.str.contains('_') == False) & (tbl_PPM_Encounter_V25['_merge']=='both'), tbl_PPM_Encounter_V25['paediatric_adj'], tbl_PPM_Encounter_V25['Extra:nwau_paed_incr'])
        tbl_PPM_Encounter_V25['Extra:nwau_indig_incr'] = np.where((tbl_PPM_Encounter_V25.EncounterNumber.str.contains('_') == False) & (tbl_PPM_Encounter_V25['_merge']=='both'), tbl_PPM_Encounter_V25['indigenous_adj'], tbl_PPM_Encounter_V25['Extra:nwau_indig_incr'])
        tbl_PPM_Encounter_V25['Extra:nwau_remote_incr'] = np.where((tbl_PPM_Encounter_V25.EncounterNumber.str.contains('_') == False) & (tbl_PPM_Encounter_V25['_merge']=='both'), tbl_PPM_Encounter_V25['remoteness_area_adj'], tbl_PPM_Encounter_V25['Extra:nwau_remote_incr'])   
        tbl_PPM_Encounter_V25['Extra:nwau_icu_incr'] = np.where((tbl_PPM_Encounter_V25.EncounterNumber.str.contains('_') == False) & (tbl_PPM_Encounter_V25['_merge']=='both'), tbl_PPM_Encounter_V25['icu_adj'], tbl_PPM_Encounter_V25['Extra:nwau_icu_incr'])
        tbl_PPM_Encounter_V25['Extra:nwau_private_patient_service_incr'] = np.where((tbl_PPM_Encounter_V25.EncounterNumber.str.contains('_') == False) & (tbl_PPM_Encounter_V25['_merge']=='both'), tbl_PPM_Encounter_V25['private_service_adj'], tbl_PPM_Encounter_V25['Extra:nwau_private_patient_service_incr'])     
        tbl_PPM_Encounter_V25['Extra:nwau_private_patient_accom_incr'] = np.where((tbl_PPM_Encounter_V25.EncounterNumber.str.contains('_') == False) & (tbl_PPM_Encounter_V25['_merge']=='both'), tbl_PPM_Encounter_V25['private_accom_adj'], tbl_PPM_Encounter_V25['Extra:nwau_private_patient_accom_incr'])
        tbl_PPM_Encounter_V25['Extra:nwau'] = np.where((tbl_PPM_Encounter_V25.EncounterNumber.str.contains('_') == False) & (tbl_PPM_Encounter_V25['_merge']=='both'), tbl_PPM_Encounter_V25['nwau_final'], tbl_PPM_Encounter_V25['Extra:nwau'])
        tbl_PPM_Encounter_V25['Extra:nwau_PublicEquivModel'] = np.where((tbl_PPM_Encounter_V25.EncounterNumber.str.contains('_') == False) & (tbl_PPM_Encounter_V25['_merge']=='both'), tbl_PPM_Encounter_V25['public_equiv_nwau'], tbl_PPM_Encounter_V25['Extra:nwau_PublicEquivModel'])
        tbl_PPM_Encounter_V25['Extra:nwau_version'] = np.where((tbl_PPM_Encounter_V25.EncounterNumber.str.contains('_') == False) & (tbl_PPM_Encounter_V25['_merge']=='both'), tbl_PPM_Encounter_V25['nwau_version'], tbl_PPM_Encounter_V25['Extra:nwau_version'])
        tbl_PPM_Encounter_V25['Extra:sp_psy_age_adj'] = np.where((tbl_PPM_Encounter_V25.EncounterNumber.str.contains('_') == False) & (tbl_PPM_Encounter_V25['_merge']=='both'), tbl_PPM_Encounter_V25['sp_psy_age_adj'], tbl_PPM_Encounter_V25['Extra:sp_psy_age_adj'])
        tbl_PPM_Encounter_V25['Extra:Radiotherapy_adj'] = np.where((tbl_PPM_Encounter_V25.EncounterNumber.str.contains('_') == False) & (tbl_PPM_Encounter_V25['_merge']=='both'), tbl_PPM_Encounter_V25['radiotherapy_adj'], tbl_PPM_Encounter_V25['Extra:Radiotherapy_adj'])
        tbl_PPM_Encounter_V25['Extra:compensable_nwau'] = np.where((tbl_PPM_Encounter_V25.EncounterNumber.str.contains('_') == False) & (tbl_PPM_Encounter_V25['_merge']=='both'), tbl_PPM_Encounter_V25['compensable_nwau'], tbl_PPM_Encounter_V25['Extra:compensable_nwau'])
        """
        ###############
        tbl_PPM_Encounter_V25["DRG3Version"] = np.where(
            tbl_PPM_Encounter_V25["DRG3Version"] == 0.0,
            "",
            tbl_PPM_Encounter_V25["DRG3Version"],
        )
        # tbl_PPM_Encounter_V25['Extra:LeaveinCostingPeriod'] = np.where(tbl_PPM_Encounter_V25['Extra:LeaveinCostingPeriod']
        tbl_PPM_Encounter_V25["Extra:nwau_paed_incr"] = np.where(
            tbl_PPM_Encounter_V25["Extra:nwau_paed_incr"] == 0,
            "",
            tbl_PPM_Encounter_V25["Extra:nwau_paed_incr"],
        )
        tbl_PPM_Encounter_V25["Extra:nwau_indig_incr"] = np.where(
            tbl_PPM_Encounter_V25["Extra:nwau_indig_incr"] == 0,
            "",
            tbl_PPM_Encounter_V25["Extra:nwau_indig_incr"],
        )
        tbl_PPM_Encounter_V25["Extra:nwau_remote_incr"] = np.where(
            tbl_PPM_Encounter_V25["Extra:nwau_remote_incr"] == 0,
            "",
            tbl_PPM_Encounter_V25["Extra:nwau_remote_incr"],
        )
        tbl_PPM_Encounter_V25["Extra:nwau_icu_incr"] = np.where(
            tbl_PPM_Encounter_V25["Extra:nwau_icu_incr"] == 0,
            "",
            tbl_PPM_Encounter_V25["Extra:nwau_icu_incr"],
        )
        tbl_PPM_Encounter_V25["Extra:nwau_private_patient_service_incr"] = np.where(
            tbl_PPM_Encounter_V25["Extra:nwau_private_patient_service_incr"] == 0,
            "",
            tbl_PPM_Encounter_V25["Extra:nwau_private_patient_service_incr"],
        )
        tbl_PPM_Encounter_V25["Extra:nwau_private_patient_accom_incr"] = np.where(
            tbl_PPM_Encounter_V25["Extra:nwau_private_patient_accom_incr"] == 0,
            "",
            tbl_PPM_Encounter_V25["Extra:nwau_private_patient_accom_incr"],
        )
        tbl_PPM_Encounter_V25["Extra:compensable_nwau"] = np.where(
            tbl_PPM_Encounter_V25["Extra:compensable_nwau"] == 0,
            "",
            tbl_PPM_Encounter_V25["Extra:compensable_nwau"],
        )
        # 19 Feb 2025 - Radiotherapy_adj not extracted correctly for SNAP
        tbl_PPM_Encounter_V25["Extra:Radiotherapy_adj"] = np.where(
            tbl_PPM_Encounter_V25["Extra:Radiotherapy_adj"] == 0,
            "",
            tbl_PPM_Encounter_V25["Extra:Radiotherapy_adj"],
        )
        logging.info("qry_update_nwau21 completed.")
        ###############################
        tbl_PPM_Encounter_V25["Extra:EpisodeSequenceNumber"] = (
            tbl_PPM_Encounter_V25["Extra:EpisodeSequenceNumber"]
            .astype(str)
            .str.lstrip("0")
        )  # .fillna(value='0')
        tbl_PPM_Encounter_V25["Extra:AUID"] = np.where(
            tbl_PPM_Encounter_V25["Extra:AUID"] != "",
            tbl_PPM_Encounter_V25["Extra:AUID"]
            .astype(str)
            .str.pad(10, side="left", fillchar="0"),
            "",
        )
        tbl_PPM_Encounter_V25["Extra:MRN"] = np.where(
            tbl_PPM_Encounter_V25["Extra:MRN"] != "",
            tbl_PPM_Encounter_V25["Extra:MRN"]
            .astype(str)
            .str.pad(10, side="left", fillchar="0"),
            "",
        )
        tbl_PPM_Encounter_V25["Extra:indicatorProcedurecode"] = np.where(
            tbl_PPM_Encounter_V25["Extra:indicatorProcedurecode"] != "",
            tbl_PPM_Encounter_V25["Extra:indicatorProcedurecode"]
            .astype(str)
            .str.pad(3, side="left", fillchar="0"),
            "",
        )
        tbl_PPM_Encounter_V25["Extra:MedicareEligibility"] = np.where(
            tbl_PPM_Encounter_V25["Extra:MedicareEligibility"] != "",
            tbl_PPM_Encounter_V25["Extra:MedicareEligibility"]
            .astype(str)
            .str.pad(2, side="left", fillchar="0"),
            "",
        )
        tbl_PPM_Encounter_V25["AdmissionCategory"] = tbl_PPM_Encounter_V25[
            "AdmissionCategory"
        ].astype("Int64", errors="ignore")
        tbl_PPM_Encounter_V25["AdmissionCategory"] = tbl_PPM_Encounter_V25[
            "AdmissionCategory"
        ].astype("Int64", errors="ignore")
        tbl_PPM_Encounter_V25["DRG1Version"] = np.where(
            tbl_PPM_Encounter_V25["DRG1Version"] == "11.0",
            "11",
            tbl_PPM_Encounter_V25["DRG1Version"],
        )
        tbl_PPM_Encounter_V25["DRG1Version"] = np.where(
            tbl_PPM_Encounter_V25["DRG1Version"] == "8.0",
            "8",
            tbl_PPM_Encounter_V25["DRG1Version"],
        )
        tbl_PPM_Encounter_V25["DRG1Version"] = np.where(
            tbl_PPM_Encounter_V25["DRG1Version"] == "1.0",
            "1",
            tbl_PPM_Encounter_V25["DRG1Version"],
        )
        tbl_PPM_Encounter_V25["DRG2Version"] = np.where(
            tbl_PPM_Encounter_V25["DRG2Version"] == "7.0",
            "7",
            tbl_PPM_Encounter_V25["DRG2Version"],
        )
        tbl_PPM_Encounter_V25["DRG3Version"] = np.where(
            tbl_PPM_Encounter_V25["DRG3Version"] == "8.0",
            "8",
            tbl_PPM_Encounter_V25["DRG3Version"],
        )
        tbl_PPM_Encounter_V25["DRG3Version"] = np.where(
            tbl_PPM_Encounter_V25["DRG3Version"] == "0.0",
            "0",
            tbl_PPM_Encounter_V25["DRG3Version"],
        )
        tbl_PPM_Encounter_V25["MechVentHours"] = np.where(
            tbl_PPM_Encounter_V25["MechVentHours"] == "0.0",
            "0",
            tbl_PPM_Encounter_V25["MechVentHours"],
        )
        tbl_PPM_Encounter_V25["Age"] = tbl_PPM_Encounter_V25["Age"].astype(
            "Int64", errors="ignore"
        )
        tbl_PPM_Encounter_V25["Extra:IntendedSameDay"] = tbl_PPM_Encounter_V25[
            "Extra:IntendedSameDay"
        ].astype("Int64", errors="ignore")
        tbl_PPM_Encounter_V25["Extra:ICUStatus"] = tbl_PPM_Encounter_V25[
            "Extra:ICUStatus"
        ].astype("Int64", errors="ignore")
        tbl_PPM_Encounter_V25["Extra:SRGcurrent"] = tbl_PPM_Encounter_V25[
            "Extra:SRGcurrent"
        ].astype("Int64", errors="ignore")
        tbl_PPM_Encounter_V25["Extra:ESRGcurrent"] = tbl_PPM_Encounter_V25[
            "Extra:ESRGcurrent"
        ].astype("Int64", errors="ignore")
        tbl_PPM_Encounter_V25["Extra:TrimPoint"] = tbl_PPM_Encounter_V25[
            "Extra:TrimPoint"
        ].astype("Int64", errors="ignore")
        tbl_PPM_Encounter_V25["Extra:SurgeryIndicator"] = tbl_PPM_Encounter_V25[
            "Extra:SurgeryIndicator"
        ].astype("Int64", errors="ignore")
        tbl_PPM_Encounter_V25["Extra:DRG1_pccl"] = tbl_PPM_Encounter_V25[
            "Extra:DRG1_pccl"
        ].astype("Int64", errors="ignore")
        tbl_PPM_Encounter_V25["Extra:IndigenousStatus"] = tbl_PPM_Encounter_V25[
            "Extra:IndigenousStatus"
        ].astype("Int64", errors="ignore")
        tbl_PPM_Encounter_V25["Extra:MedicareEligibility"] = tbl_PPM_Encounter_V25[
            "Extra:MedicareEligibility"
        ].astype("Int64", errors="ignore")
        tbl_PPM_Encounter_V25["Extra:LengthofStay_EpisodeTable"] = (
            tbl_PPM_Encounter_V25["Extra:LengthofStay_EpisodeTable"].astype(
                "Int64", errors="ignore"
            )
        )
        tbl_PPM_Encounter_V25["Extra:MDC"] = tbl_PPM_Encounter_V25["Extra:MDC"].astype(
            "Int64", errors="ignore"
        )
        tbl_PPM_Encounter_V25["Extra:MDC"] = (
            tbl_PPM_Encounter_V25["Extra:MDC"]
            .astype(str)
            .str.pad(2, side="left", fillchar="0")
        )
        tbl_PPM_Encounter_V25["Extra:MDC2"] = tbl_PPM_Encounter_V25[
            "Extra:MDC2"
        ].astype("Int64", errors="ignore")
        tbl_PPM_Encounter_V25["Extra:MDC2"] = (
            tbl_PPM_Encounter_V25["Extra:MDC2"]
            .astype(str)
            .str.pad(2, side="left", fillchar="0")
        )
        tbl_PPM_Encounter_V25["Extra:DaysinPsychUnit"] = tbl_PPM_Encounter_V25[
            "Extra:DaysinPsychUnit"
        ].astype("Int64", errors="ignore")
        tbl_PPM_Encounter_V25["ICUHours"] = tbl_PPM_Encounter_V25["ICUHours"].astype(
            "Int64", errors="ignore"
        )
        ######################

        tbl_PPM_Encounter_V25 = tbl_PPM_Encounter_V25.applymap(
            str
        )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
        tbl_PPM_Encounter_V25 = tbl_PPM_Encounter_V25.applymap(
            lambda x: x.strip() if isinstance(x, str) else x
        )
        tbl_PPM_Encounter_V25 = tbl_PPM_Encounter_V25.apply(
            lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
        )
        tbl_PPM_Encounter_V25.drop_duplicates(keep="last", inplace=True)
        tbl_PPM_Encounter_V25_new = tbl_PPM_Encounter_V25.copy()

        # AQA-308, AQA-295, AQA-294, AQA-292, (Issues : 33,35,36,43,45,48)
        columns_to_convert = [
            "Age",
            "Extra:AICU1_Hours",
            "Extra:AICU2_Hours",
            "Extra:AICU3_Hours",
            "Extra:CCU_Hours",
            "Extra:HDU_Hours",
            "Extra:HITH_Hours",
            "Extra:NICU_Hours",
            "Extra:PICU_Hours",
            "Extra:PSICU_Hours",
            "Extra:SCN_Hours",
            "Extra:ESRGcurrent",
            "Extra:SRGcurrent",
            "Extra:SRG_Version",
            "MechVentHours",
            "Extra:ICUStatus",
        ]
        for column in columns_to_convert:
            tbl_PPM_Encounter_V25_new[column] = tbl_PPM_Encounter_V25_new[column].apply(
                lambda x: int(float(x)) if x != "" and x != -1 else x
            )
        # List of columns to pad to two zeros before decimal
        columns_to_pad = ["Extra:FacilityType", "Extra:Collabrtve_Care_Type"]
        for col in columns_to_pad:
            tbl_PPM_Encounter_V25_new[col] = tbl_PPM_Encounter_V25_new[col].apply(
                lambda x: "{:05.2f}".format(float(x))
                if x.replace(".", "", 1).isdigit() and x != "" and x != -1
                else x
            )
        # List of columns to pad to two zeros . These do not have any decimal
        columns_to_pad = ["Extra:Collabrtve_Care_Role"]
        for col in columns_to_pad:
            tbl_PPM_Encounter_V25_new[col] = tbl_PPM_Encounter_V25_new[col].apply(
                lambda x: "{:02d}".format(int(float(x)))
                if x.replace(".", "", 1).isdigit() and x != "" and x != -1
                else x
            )

        # Add: , 'Extra:FRML_DISCH_MODE_CD', 'Extra:SE_SEP_MODE_NHDD_CD'
        logging.info("new IP encounter file generated.")
        tbl_PPM_Encounter_V25_new = tbl_PPM_Encounter_V25_new[
            [
                "EncounterNumber",
                "EncounterType",
                "PatientNumber",
                "EpisodeOfCare",
                "Hospital",
                "StartDateTime",
                "EndDateTime",
                "Extra:HospitalStayNumber",
                "Extra:LHDIdentifier",
                "Extra:EpisodeSequenceNumber",
                "AdmissionCategory",
                "AdmissionElection",
                "AdmissionSource",
                "AdmissionType",
                "AdmissionWeight",
                "Age",
                "AttendingConsultant",
                "AttendingConsultantSpecialty",
                "DischargeElection",
                "DischargeStatus",
                "DRG1",
                "Extra:AdmittingSpecialtyPortal",
                "Extra:AICU1_Hours",
                "Extra:AICU2_Hours",
                "Extra:AICU3_Hours",
                "Extra:AssessOnly",
                "Extra:AUID",
                "Extra:bookingIdentifier",
                "Extra:CareFocus",
                "Extra:CaseType",
                "Extra:CCU_Hours",
                "Extra:Collabrtve_Care_Facility",
                "Extra:Collabrtve_Care_Role",
                "Extra:Collabrtve_Care_Type",
                "Extra:compensable_nwau",
                "Extra:Contract_Status",
                "Extra:DaysinPsychUnit",
                "Extra:Delirium_Flag",
                "Extra:Dementia_Flag",
                "Extra:DRG1_pccl",
                "Extra:SNAP_Class",
                "Extra:AMHCC_Class",
                "Extra:EDStatus",
                "Extra:ElectionStatusSummary",
                "Extra:StartDateTime_EpisodeTable",
                "Extra:EndDateTime_EpisodeTable",
                "Extra:EpisodeLeaveDays",
                "Extra:EpisodeLeaveDays_EpisodeTable",
                "Extra:EpisodeofCare_EpisodeTable",
                "Extra:EpisType",
                "Extra:ESRGcurrent",
                "Extra:ExtractDate",
                "Extra:FacilityTransferredfrom",
                "Extra:FacilityTransferredto",
                "Extra:FacilityType",
                "Extra:HDU_Hours",
                "Extra:HITH_Hours",
                "Extra:HospInsuranceonAdmit",
                "Extra:ICUStatus",
                "Extra:Impair",
                "Extra:indicatorProcedurecode",
                "Extra:IndigenousStatus",
                "Extra:IntendedSameDay",
                "Extra:LeaveinCostingPeriod",
                "Extra:LegalStatus",
                "Extra:LengthofStay_EpisodeTable",
                "Extra:LGACode",
                "Extra:LHD_of_Usual_Residence",
                "Extra:LOSinCostingPeriod",
                "Extra:MaintType",
                "Extra:MDC",
                "Extra:MedicareEligibility",
                "Extra:MHPhaseSeqNo",
                "Extra:MothersEncounterNumber",
                "Extra:MothersMRN",
                "Extra:MothersPersonIdentifier",
                "Extra:MothersStayNumber",
                "Extra:MRN",
                "Extra:N_Z_FinancialProgram",
                "Extra:NICU_Hours",
                "Extra:nwau",
                "Extra:nwau_base",
                "Extra:nwau_cwt_type",
                "Extra:nwau_icu_incr",
                "Extra:nwau_indig_incr",
                "Extra:nwau_paed_incr",
                "Extra:nwau_private_patient_accom_incr",
                "Extra:nwau_private_patient_service_incr",
                "Extra:nwau_PublicEquivModel",
                "Extra:nwau_remote_incr",
                "Extra:nwau_version",
                "Extra:Outlierdays",
                "Extra:PCPhase",
                "Extra:PICU_Hours",
                "Extra:ProdType",
                "Extra:PSICU_Hours",
                "Extra:QualifiedBedDays",
                "Extra:Radiotherapy_adj",
                "Extra:ReasonforRemoval",
                "Extra:ReferralFurtherHealthcare",
                "Extra:SCN_Hours",
                "Extra:SNAPCareType",
                "Extra:sp_psy_age_adj",
                "Extra:SpecialtyPortal",
                "Extra:SRG_Version",
                "Extra:SRGcurrent",
                "Extra:SurgeryIndicator",
                "Extra:TrimPoint",
                "Extra:UnplannedReadmission",
                "Extra:UnplannedTheatre",
                "Extra:ExtractorVersion",
                "Extra:waitinglistcategory",
                "Extra:WIP",
                "Extra:WIP2",
                "FinancialClass",
                "HealthFund",
                "ICUHours",
                "LengthOfStay",
                "MaritalStatus",
                "MechVentHours",
                "PostCode",
                "Suburb",
                "Extra:FIMBathBeg",
                "Extra:FIMBathEnd",
                "Extra:FIMBladderBeg",
                "Extra:FIMBladderEnd",
                "Extra:FIMBowelBeg",
                "Extra:FIMBowelEnd",
                "Extra:FIMCompBeg",
                "Extra:FIMCompEnd",
                "Extra:FIMEatBeg",
                "Extra:FIMEatEnd",
                "Extra:FIMExpBeg",
                "Extra:FIMExpEnd",
                "Extra:FIMGroomBeg",
                "Extra:FIMGroomEnd",
                "Extra:FIMLowerBeg",
                "Extra:FIMLowerEnd",
                "Extra:FIMMemoryBeg",
                "Extra:FIMMemoryEnd",
                "Extra:FIMProbBeg",
                "Extra:FIMProbEnd",
                "Extra:FIMSocialBeg",
                "Extra:FIMSocialEnd",
                "Extra:FIMStairBeg",
                "Extra:FIMStairEnd",
                "Extra:FIMToiletBeg",
                "Extra:FIMToiletEnd",
                "Extra:FIMTubBeg",
                "Extra:FIMTubEnd",
                "Extra:FIMUpperBeg",
                "Extra:FIMUpperEnd",
                "Extra:FIMWalkBeg",
                "Extra:FIMWalkEnd",
                "Extra:FIMXferBeg",
                "Extra:FIMXferEnd",
                "Extra:FIMXferToilBeg",
                "Extra:FIMXferToilEnd",
                "Extra:HON1",
                "Extra:HON2",
                "Extra:HON3",
                "Extra:HON4",
                "Extra:HON5",
                "Extra:HON6",
                "Extra:HON7",
                "Extra:HON8",
                "Extra:HON9",
                "Extra:HON10",
                "Extra:HON11",
                "Extra:HON12",
                "Extra:HON13",
                "Extra:HON14",
                "Extra:HON15",
                "Extra:HONOS1",
                "Extra:HONOS2",
                "Extra:HONOS3",
                "Extra:HONOS4",
                "Extra:HONOS5",
                "Extra:HONOS6",
                "Extra:HONOS7",
                "Extra:HONOS8",
                "Extra:HONOS9",
                "Extra:HONOS10",
                "Extra:HONOS11",
                "Extra:HONOS12",
                "Extra:HONOS65_1",
                "Extra:HONOS65_2",
                "Extra:HONOS65_3",
                "Extra:HONOS65_4",
                "Extra:HONOS65_5",
                "Extra:HONOS65_6",
                "Extra:HONOS65_7",
                "Extra:HONOS65_8",
                "Extra:HONOS65_9",
                "Extra:HONOS65_10",
                "Extra:HONOS65_11",
                "Extra:HONOS65_12",
                "Extra:HONOSCA1",
                "Extra:HONOSCA2",
                "Extra:HONOSCA3",
                "Extra:HONOSCA4",
                "Extra:HONOSCA5",
                "Extra:HONOSCA6",
                "Extra:HONOSCA7",
                "Extra:HONOSCA8",
                "Extra:HONOSCA9",
                "Extra:HONOSCA10",
                "Extra:HONOSCA11",
                "Extra:HONOSCA12",
                "Extra:HONOSCA13",
                "Extra:HONOSCA14",
                "Extra:HONOSCA15",
                "Extra:IHPA_LSP_01",
                "Extra:IHPA_LSP_02",
                "Extra:IHPA_LSP_03",
                "Extra:IHPA_LSP_04",
                "Extra:IHPA_LSP_05",
                "Extra:IHPA_LSP_06",
                "Extra:IHPA_LSP_07",
                "Extra:IHPA_LSP_08",
                "Extra:IHPA_LSP_09",
                "Extra:IHPA_LSP_10",
                "Extra:IHPA_LSP_11",
                "Extra:IHPA_LSP_12",
                "Extra:IHPA_LSP_13",
                "Extra:IHPA_LSP_14",
                "Extra:IHPA_LSP_15",
                "Extra:IHPA_LSP_16",
                "Extra:HonActiveBeg",
                "Extra:HonActiveEnd",
                "Extra:HonADLBeg",
                "Extra:HonADLEnd",
                "Extra:HonCognitBeg",
                "Extra:HonCognitEnd",
                "Extra:HonDeprsBeg",
                "Extra:HonDeprsEnd",
                "Extra:HonDisabBeg",
                "Extra:HonDisabEnd",
                "Extra:HonDrinkBeg",
                "Extra:HonDrinkEnd",
                "Extra:HonHallucBeg",
                "Extra:HonHallucEnd",
                "Extra:HonInjuryBeg",
                "Extra:HonInjuryEnd",
                "Extra:HonLivingBeg",
                "Extra:HonLivingEnd",
                "Extra:HonOccupBeg",
                "Extra:HonOccupEnd",
                "Extra:HonOtherBeg",
                "Extra:HonOtherEnd",
                "Extra:HonRelatBeg",
                "Extra:HonRelatEnd",
                "Extra:PCFamilyCarerScoreStart",
                "Extra:PCPsychSpiritualScoreStart",
                "Extra:PCSeverityStart",
                "Extra:PCSymptomScoreStart",
                "Extra:RugBedBeg",
                "Extra:RugEatBeg",
                "Extra:RugToilBeg",
                "Extra:RugXferBeg",
                "Extra:HLTH_ORG_OSP_OSP_ID",
                "Extra:MG_AUTH_OSP_OSP_ID",
                "Extra:SE_CBK_SK",
                "Extra:CL_ID_EUID",
                "Extra:CL_ID_IHI",
                "Extra:HLTH_ORG_OSP_TYP",
                "Extra:SRV_ENC_REC_ID",
                "Extra:FRML_DISCH_MODE_CD",
                "Extra:SE_SEP_MODE_NHDD_CD",
                "Extra:Responsible_Facility",
                "Extra:SE_TYP_CD",
                "Extra:SE_ADM_MODE_NHDD_CD",
                "Extra:DIM_RSP_ISP_SK",
                "Extra:AR_DRG_ECCS_RAW",
                "Extra:WAU_ADJ_PT_TX_REMT_AREA",
                "Extra:WAU_ADJ_DIALYSIS",
                "Extra:WAU_ADJ_COVID19",
                "Extra:WAU_ADJ_HAC",
                "Extra:ASGS_SA_L2_16_CD",
                "Extra:CL_URES_ADDR_ASGS21_SA_L2_CD",
            ]
        ]
        # 02 July - remove 'Extra:Responsible_Facility','Extra:SE_TYP_CD','Extra:DIM_RSP_ISP_SK','Extra:AR_DRG_ECCS_RAW','Extra:WAU_ADJ_DIALYSIS', 'Extra:WAU_ADJ_COVID19', 'Extra:WAU_ADJ_HAC'
        # tbl_PPM_Encounter_V25_new = tbl_PPM_Encounter_V25_new[['EncounterNumber', 'EncounterType', 'PatientNumber', 'EpisodeOfCare', 'Hospital', 'StartDateTime', 'EndDateTime', 'Extra:HospitalStayNumber', 'Extra:LHDIdentifier', 'Extra:EpisodeSequenceNumber', 'AdmissionCategory', 'AdmissionElection', 'AdmissionSource', 'AdmissionType', 'AdmissionWeight', 'Age', 'AttendingConsultant', 'AttendingConsultantSpecialty', 'DischargeElection', 'DischargeStatus', 'DRG1', 'Extra:AdmittingSpecialtyPortal', 'Extra:AICU1_Hours', 'Extra:AICU2_Hours', 'Extra:AICU3_Hours', 'Extra:AssessOnly', 'Extra:AUID', 'Extra:bookingIdentifier', 'Extra:CareFocus', 'Extra:CaseType', 'Extra:CCU_Hours', 'Extra:Collabrtve_Care_Facility', 'Extra:Collabrtve_Care_Role', 'Extra:Collabrtve_Care_Type', 'Extra:compensable_nwau', 'Extra:Contract_Status', 'Extra:DaysinPsychUnit', 'Extra:Delirium_Flag', 'Extra:Dementia_Flag', 'Extra:DRG1_pccl', 'Extra:SNAP_Class', 'Extra:AMHCC_Class','Extra:EDStatus', 'Extra:ElectionStatusSummary', 'Extra:StartDateTime_EpisodeTable','Extra:EndDateTime_EpisodeTable', 'Extra:EpisodeLeaveDays', 'Extra:EpisodeLeaveDays_EpisodeTable', 'Extra:EpisodeofCare_EpisodeTable', 'Extra:EpisType', 'Extra:ESRGcurrent', 'Extra:ExtractDate', 'Extra:FacilityTransferredfrom', 'Extra:FacilityTransferredto', 'Extra:FacilityType', 'Extra:HDU_Hours', 'Extra:HITH_Hours', 'Extra:HospInsuranceonAdmit', 'Extra:ICUStatus', 'Extra:Impair', 'Extra:indicatorProcedurecode', 'Extra:IndigenousStatus', 'Extra:IntendedSameDay', 'Extra:LeaveinCostingPeriod', 'Extra:LegalStatus', 'Extra:LengthofStay_EpisodeTable', 'Extra:LGACode', 'Extra:LHD_of_Usual_Residence', 'Extra:LOSinCostingPeriod', 'Extra:MaintType', 'Extra:MDC', 'Extra:MedicareEligibility', 'Extra:MHPhaseSeqNo', 'Extra:MothersEncounterNumber', 'Extra:MothersMRN', 'Extra:MothersPersonIdentifier', 'Extra:MothersStayNumber', 'Extra:MRN', 'Extra:N_Z_FinancialProgram', 'Extra:NICU_Hours', 'Extra:nwau', 'Extra:nwau_base', 'Extra:nwau_cwt_type', 'Extra:nwau_icu_incr', 'Extra:nwau_indig_incr', 'Extra:nwau_paed_incr', 'Extra:nwau_private_patient_accom_incr', 'Extra:nwau_private_patient_service_incr', 'Extra:nwau_PublicEquivModel', 'Extra:nwau_remote_incr', 'Extra:nwau_version', 'Extra:Outlierdays', 'Extra:PCPhase', 'Extra:PICU_Hours', 'Extra:ProdType', 'Extra:PSICU_Hours', 'Extra:QualifiedBedDays', 'Extra:Radiotherapy_adj', 'Extra:ReasonforRemoval', 'Extra:ReferralFurtherHealthcare', 'Extra:SCN_Hours', 'Extra:SNAPCareType', 'Extra:sp_psy_age_adj', 'Extra:SpecialtyPortal', 'Extra:SRG_Version', 'Extra:SRGcurrent', 'Extra:SurgeryIndicator', 'Extra:TrimPoint', 'Extra:UnplannedReadmission', 'Extra:UnplannedTheatre', 'Extra:ExtractorVersion', 'Extra:waitinglistcategory', 'Extra:WIP', 'Extra:WIP2', 'FinancialClass', 'HealthFund', 'ICUHours', 'LengthOfStay', 'MaritalStatus', 'MechVentHours', 'PostCode', 'Suburb', 'Extra:FIMBathBeg', 'Extra:FIMBathEnd', 'Extra:FIMBladderBeg', 'Extra:FIMBladderEnd', 'Extra:FIMBowelBeg', 'Extra:FIMBowelEnd', 'Extra:FIMCompBeg', 'Extra:FIMCompEnd', 'Extra:FIMEatBeg', 'Extra:FIMEatEnd', 'Extra:FIMExpBeg', 'Extra:FIMExpEnd', 'Extra:FIMGroomBeg', 'Extra:FIMGroomEnd', 'Extra:FIMLowerBeg', 'Extra:FIMLowerEnd', 'Extra:FIMMemoryBeg', 'Extra:FIMMemoryEnd', 'Extra:FIMProbBeg', 'Extra:FIMProbEnd', 'Extra:FIMSocialBeg', 'Extra:FIMSocialEnd', 'Extra:FIMStairBeg', 'Extra:FIMStairEnd', 'Extra:FIMToiletBeg', 'Extra:FIMToiletEnd', 'Extra:FIMTubBeg', 'Extra:FIMTubEnd', 'Extra:FIMUpperBeg', 'Extra:FIMUpperEnd', 'Extra:FIMWalkBeg', 'Extra:FIMWalkEnd', 'Extra:FIMXferBeg', 'Extra:FIMXferEnd', 'Extra:FIMXferToilBeg', 'Extra:FIMXferToilEnd', 'Extra:HON1', 'Extra:HON2', 'Extra:HON3', 'Extra:HON4', 'Extra:HON5', 'Extra:HON6', 'Extra:HON7', 'Extra:HON8', 'Extra:HON9', 'Extra:HON10', 'Extra:HON11', 'Extra:HON12', 'Extra:HON13', 'Extra:HON14', 'Extra:HON15', 'Extra:HONOS1', 'Extra:HONOS2', 'Extra:HONOS3', 'Extra:HONOS4', 'Extra:HONOS5', 'Extra:HONOS6', 'Extra:HONOS7', 'Extra:HONOS8', 'Extra:HONOS9', 'Extra:HONOS10', 'Extra:HONOS11', 'Extra:HONOS12', 'Extra:HONOS65_1', 'Extra:HONOS65_2', 'Extra:HONOS65_3', 'Extra:HONOS65_4', 'Extra:HONOS65_5', 'Extra:HONOS65_6', 'Extra:HONOS65_7', 'Extra:HONOS65_8', 'Extra:HONOS65_9', 'Extra:HONOS65_10', 'Extra:HONOS65_11', 'Extra:HONOS65_12', 'Extra:HONOSCA1', 'Extra:HONOSCA2', 'Extra:HONOSCA3', 'Extra:HONOSCA4', 'Extra:HONOSCA5', 'Extra:HONOSCA6', 'Extra:HONOSCA7', 'Extra:HONOSCA8', 'Extra:HONOSCA9', 'Extra:HONOSCA10', 'Extra:HONOSCA11', 'Extra:HONOSCA12', 'Extra:HONOSCA13', 'Extra:HONOSCA14', 'Extra:HONOSCA15', 'Extra:IHPA_LSP_01', 'Extra:IHPA_LSP_02', 'Extra:IHPA_LSP_03', 'Extra:IHPA_LSP_04', 'Extra:IHPA_LSP_05', 'Extra:IHPA_LSP_06', 'Extra:IHPA_LSP_07', 'Extra:IHPA_LSP_08', 'Extra:IHPA_LSP_09', 'Extra:IHPA_LSP_10', 'Extra:IHPA_LSP_11', 'Extra:IHPA_LSP_12', 'Extra:IHPA_LSP_13', 'Extra:IHPA_LSP_14', 'Extra:IHPA_LSP_15', 'Extra:IHPA_LSP_16', 'Extra:HonActiveBeg', 'Extra:HonActiveEnd', 'Extra:HonADLBeg', 'Extra:HonADLEnd', 'Extra:HonCognitBeg', 'Extra:HonCognitEnd', 'Extra:HonDeprsBeg', 'Extra:HonDeprsEnd', 'Extra:HonDisabBeg', 'Extra:HonDisabEnd', 'Extra:HonDrinkBeg', 'Extra:HonDrinkEnd', 'Extra:HonHallucBeg', 'Extra:HonHallucEnd', 'Extra:HonInjuryBeg', 'Extra:HonInjuryEnd', 'Extra:HonLivingBeg', 'Extra:HonLivingEnd', 'Extra:HonOccupBeg', 'Extra:HonOccupEnd', 'Extra:HonOtherBeg', 'Extra:HonOtherEnd', 'Extra:HonRelatBeg', 'Extra:HonRelatEnd', 'Extra:PCFamilyCarerScoreStart', 'Extra:PCPsychSpiritualScoreStart', 'Extra:PCSeverityStart', 'Extra:PCSymptomScoreStart', 'Extra:RugBedBeg', 'Extra:RugEatBeg', 'Extra:RugToilBeg', 'Extra:RugXferBeg', 'Extra:HLTH_ORG_OSP_OSP_ID', 'Extra:MG_AUTH_OSP_OSP_ID', 'Extra:SE_CBK_SK', 'Extra:CL_ID_EUID', 'Extra:CL_ID_IHI', 'Extra:HLTH_ORG_OSP_TYP', 'Extra:SRV_ENC_REC_ID', 'Extra:FRML_DISCH_MODE_CD', 'Extra:SE_SEP_MODE_NHDD_CD','Extra:WAU_ADJ_PT_TX_REMT_AREA','Extra:SE_ADM_MODE_NHDD_CD']]
        tbl_PPM_Encounter_V25_new["Extra:DRG1_pccl"] = ""
        tbl_PPM_Encounter_V25_new["Extra:MothersStayNumber"] = np.where(
            tbl_PPM_Encounter_V25_new["Extra:MothersStayNumber"] == "SN0",
            "",
            tbl_PPM_Encounter_V25_new["Extra:MothersStayNumber"],
        )
        tbl_PPM_Encounter_V25_new["AttendingConsultant"] = (
            tbl_PPM_Encounter_V25_new["AttendingConsultant"]
            .astype(str)
            .str.replace("nan", "")
        )
        tbl_PPM_Encounter_V25_new["AttendingConsultantSpecialty"] = (
            tbl_PPM_Encounter_V25_new["AttendingConsultantSpecialty"]
            .astype(str)
            .str.replace("nan", "")
        )
        tbl_PPM_Encounter_V25_new.sort_values(
            by=[
                "EncounterNumber",
                "EncounterType",
                "PatientNumber",
                "EpisodeOfCare",
                "Hospital",
                "StartDateTime",
                "EndDateTime",
                "Extra:HospitalStayNumber",
                "Extra:LHDIdentifier",
                "Extra:EpisodeSequenceNumber",
                "AdmissionCategory",
                "AdmissionElection",
                "AdmissionSource",
                "AdmissionType",
                "AdmissionWeight",
                "Age",
                "AttendingConsultantSpecialty",
                "DischargeElection",
                "DischargeStatus",
                "DRG1",
                "Extra:AdmittingSpecialtyPortal",
                "Extra:AICU1_Hours",
                "Extra:AICU2_Hours",
                "Extra:AICU3_Hours",
                "Extra:AssessOnly",
                "Extra:AUID",
                "Extra:bookingIdentifier",
                "Extra:CareFocus",
                "Extra:CaseType",
                "Extra:CCU_Hours",
                "Extra:Collabrtve_Care_Facility",
                "Extra:Collabrtve_Care_Role",
                "Extra:Collabrtve_Care_Type",
                "Extra:compensable_nwau",
                "Extra:Contract_Status",
                "Extra:DaysinPsychUnit",
                "Extra:Delirium_Flag",
                "Extra:Dementia_Flag",
                "Extra:DRG1_pccl",
                "Extra:SNAP_Class",
                "Extra:AMHCC_Class",
                "Extra:EDStatus",
                "Extra:ElectionStatusSummary",
                "Extra:StartDateTime_EpisodeTable",
                "Extra:EndDateTime_EpisodeTable",
                "Extra:EpisodeLeaveDays",
                "Extra:EpisodeLeaveDays_EpisodeTable",
                "Extra:EpisodeofCare_EpisodeTable",
                "Extra:EpisType",
                "Extra:ESRGcurrent",
                "Extra:ExtractDate",
                "Extra:FacilityTransferredfrom",
                "Extra:FacilityTransferredto",
                "Extra:FacilityType",
                "Extra:HDU_Hours",
                "Extra:HITH_Hours",
                "Extra:HospInsuranceonAdmit",
                "Extra:ICUStatus",
                "Extra:Impair",
                "Extra:indicatorProcedurecode",
                "Extra:IndigenousStatus",
                "Extra:IntendedSameDay",
                "Extra:LeaveinCostingPeriod",
                "Extra:LegalStatus",
                "Extra:LengthofStay_EpisodeTable",
                "Extra:LGACode",
                "Extra:LHD_of_Usual_Residence",
                "Extra:LOSinCostingPeriod",
                "Extra:MaintType",
                "Extra:MDC",
                "Extra:MedicareEligibility",
                "Extra:MHPhaseSeqNo",
                "Extra:MothersEncounterNumber",
                "Extra:MothersMRN",
                "Extra:MothersPersonIdentifier",
                "Extra:MothersStayNumber",
                "Extra:MRN",
                "Extra:N_Z_FinancialProgram",
                "Extra:NICU_Hours",
                "Extra:nwau",
                "Extra:nwau_base",
                "Extra:nwau_cwt_type",
                "Extra:nwau_icu_incr",
                "Extra:nwau_indig_incr",
                "Extra:nwau_paed_incr",
                "Extra:nwau_private_patient_accom_incr",
                "Extra:nwau_private_patient_service_incr",
                "Extra:nwau_PublicEquivModel",
                "Extra:nwau_remote_incr",
                "Extra:nwau_version",
                "Extra:Outlierdays",
                "Extra:PCPhase",
                "Extra:PICU_Hours",
                "Extra:ProdType",
                "Extra:PSICU_Hours",
                "Extra:QualifiedBedDays",
                "Extra:Radiotherapy_adj",
                "Extra:ReasonforRemoval",
                "Extra:ReferralFurtherHealthcare",
                "Extra:SCN_Hours",
                "Extra:SNAPCareType",
                "Extra:sp_psy_age_adj",
                "Extra:SpecialtyPortal",
                "Extra:SRG_Version",
                "Extra:SRGcurrent",
                "Extra:SurgeryIndicator",
                "Extra:TrimPoint",
                "Extra:UnplannedReadmission",
                "Extra:UnplannedTheatre",
                "Extra:ExtractorVersion",
                "Extra:waitinglistcategory",
                "Extra:WIP",
                "Extra:WIP2",
                "FinancialClass",
                "HealthFund",
                "ICUHours",
                "LengthOfStay",
                "MaritalStatus",
                "MechVentHours",
                "PostCode",
                "Suburb",
                "Extra:FIMBathBeg",
                "Extra:FIMBathEnd",
                "Extra:FIMBladderBeg",
                "Extra:FIMBladderEnd",
                "Extra:FIMBowelBeg",
                "Extra:FIMBowelEnd",
                "Extra:FIMCompBeg",
                "Extra:FIMCompEnd",
                "Extra:FIMEatBeg",
                "Extra:FIMEatEnd",
                "Extra:FIMExpBeg",
                "Extra:FIMExpEnd",
                "Extra:FIMGroomBeg",
                "Extra:FIMGroomEnd",
                "Extra:FIMLowerBeg",
                "Extra:FIMLowerEnd",
                "Extra:FIMMemoryBeg",
                "Extra:FIMMemoryEnd",
                "Extra:FIMProbBeg",
                "Extra:FIMProbEnd",
                "Extra:FIMSocialBeg",
                "Extra:FIMSocialEnd",
                "Extra:FIMStairBeg",
                "Extra:FIMStairEnd",
                "Extra:FIMToiletBeg",
                "Extra:FIMToiletEnd",
                "Extra:FIMTubBeg",
                "Extra:FIMTubEnd",
                "Extra:FIMUpperBeg",
                "Extra:FIMUpperEnd",
                "Extra:FIMWalkBeg",
                "Extra:FIMWalkEnd",
                "Extra:FIMXferBeg",
                "Extra:FIMXferEnd",
                "Extra:FIMXferToilBeg",
                "Extra:FIMXferToilEnd",
                "Extra:HON1",
                "Extra:HON2",
                "Extra:HON3",
                "Extra:HON4",
                "Extra:HON5",
                "Extra:HON6",
                "Extra:HON7",
                "Extra:HON8",
                "Extra:HON9",
                "Extra:HON10",
                "Extra:HON11",
                "Extra:HON12",
                "Extra:HON13",
                "Extra:HON14",
                "Extra:HON15",
                "Extra:HONOS1",
                "Extra:HONOS2",
                "Extra:HONOS3",
                "Extra:HONOS4",
                "Extra:HONOS5",
                "Extra:HONOS6",
                "Extra:HONOS7",
                "Extra:HONOS8",
                "Extra:HONOS9",
                "Extra:HONOS10",
                "Extra:HONOS11",
                "Extra:HONOS12",
                "Extra:HONOS65_1",
                "Extra:HONOS65_2",
                "Extra:HONOS65_3",
                "Extra:HONOS65_4",
                "Extra:HONOS65_5",
                "Extra:HONOS65_6",
                "Extra:HONOS65_7",
                "Extra:HONOS65_8",
                "Extra:HONOS65_9",
                "Extra:HONOS65_10",
                "Extra:HONOS65_11",
                "Extra:HONOS65_12",
                "Extra:HONOSCA1",
                "Extra:HONOSCA2",
                "Extra:HONOSCA3",
                "Extra:HONOSCA4",
                "Extra:HONOSCA5",
                "Extra:HONOSCA6",
                "Extra:HONOSCA7",
                "Extra:HONOSCA8",
                "Extra:HONOSCA9",
                "Extra:HONOSCA10",
                "Extra:HONOSCA11",
                "Extra:HONOSCA12",
                "Extra:HONOSCA13",
                "Extra:HONOSCA14",
                "Extra:HONOSCA15",
                "Extra:IHPA_LSP_01",
                "Extra:IHPA_LSP_02",
                "Extra:IHPA_LSP_03",
                "Extra:IHPA_LSP_04",
                "Extra:IHPA_LSP_05",
                "Extra:IHPA_LSP_06",
                "Extra:IHPA_LSP_07",
                "Extra:IHPA_LSP_08",
                "Extra:IHPA_LSP_09",
                "Extra:IHPA_LSP_10",
                "Extra:IHPA_LSP_11",
                "Extra:IHPA_LSP_12",
                "Extra:IHPA_LSP_13",
                "Extra:IHPA_LSP_14",
                "Extra:IHPA_LSP_15",
                "Extra:IHPA_LSP_16",
                "Extra:HonActiveBeg",
                "Extra:HonActiveEnd",
                "Extra:HonADLBeg",
                "Extra:HonADLEnd",
                "Extra:HonCognitBeg",
                "Extra:HonCognitEnd",
                "Extra:HonDeprsBeg",
                "Extra:HonDeprsEnd",
                "Extra:HonDisabBeg",
                "Extra:HonDisabEnd",
                "Extra:HonDrinkBeg",
                "Extra:HonDrinkEnd",
                "Extra:HonHallucBeg",
                "Extra:HonHallucEnd",
                "Extra:HonInjuryBeg",
                "Extra:HonInjuryEnd",
                "Extra:HonLivingBeg",
                "Extra:HonLivingEnd",
                "Extra:HonOccupBeg",
                "Extra:HonOccupEnd",
                "Extra:HonOtherBeg",
                "Extra:HonOtherEnd",
                "Extra:HonRelatBeg",
                "Extra:HonRelatEnd",
                "Extra:PCFamilyCarerScoreStart",
                "Extra:PCPsychSpiritualScoreStart",
                "Extra:PCSeverityStart",
                "Extra:PCSymptomScoreStart",
                "Extra:RugBedBeg",
                "Extra:RugEatBeg",
                "Extra:RugToilBeg",
                "Extra:RugXferBeg",
                "Extra:HLTH_ORG_OSP_OSP_ID",
                "Extra:MG_AUTH_OSP_OSP_ID",
                "Extra:SE_CBK_SK",
                "Extra:CL_ID_EUID",
                "Extra:CL_ID_IHI",
                "Extra:HLTH_ORG_OSP_TYP",
                "AttendingConsultant",
                "Extra:SRV_ENC_REC_ID",
                "Extra:FRML_DISCH_MODE_CD",
                "Extra:SE_SEP_MODE_NHDD_CD",
            ],
            inplace=True,
        )
        tbl_PPM_Encounter_V25_new.rename(
            columns={
                "DRG1": "Classification:DRGV11",
                "Extra:SNAP_Class": "Classification:SNAPV5",
                "Extra:AMHCC_Class": "Classification:AMHCCV1",
                "Extra:DaysinPsychUnit": "Extra:PsychDays",
                "Extra:ElectionStatusSummary": "Extra:CompStatus",
                "Extra:EpisodeSequenceNumber": "Extra:episode_sequence_number",
                "Extra:HospitalStayNumber": "Extra:stay_number",
                "Extra:N_Z_FinancialProgram": "Extra:Subprogram",
                "Extra:PCPhase": "Extra:Phase",
                "Extra:QualifiedBedDays": "Extra:QualifiedDays",
                "Extra:EndDateTime_EpisodeTable": "Extra:EndDateTime_Episode",
                "Extra:StartDateTime_EpisodeTable": "Extra:StartDateTime_Episode",
                "Extra:EpisodeLeaveDays_EpisodeTable": "Extra:EpisodeLeaveDays_Episode",
                "Extra:EpisodeofCare_EpisodeTable": "Extra:EpisodeofCare_Episode",
                "Extra:LengthofStay_EpisodeTable": "Extra:LengthofStay_Episode",
            },
            inplace=True,
            errors="ignore",
        )
        # AQA-297 : Add roundid
        tbl_PPM_Encounter_V25_new["Extra:RoundID"] = versionID_dot.replace("V", "")
        # 149, #151 -  MH and SNAP encounters has same start date time and end date time, are getting dropped from PPM
        tbl_PPM_Encounter_V25_new["StartDateTime"] = pd.to_datetime(
            tbl_PPM_Encounter_V25_new["StartDateTime"]
        )
        tbl_PPM_Encounter_V25_new["EndDateTime"] = pd.to_datetime(
            tbl_PPM_Encounter_V25_new["EndDateTime"]
        )
        # adjust their 'LengthOfStay'
        tbl_PPM_Encounter_V25_new.loc[
            (
                tbl_PPM_Encounter_V25_new["StartDateTime"].dt.time
                == pd.Timestamp("00:00:00").time()
            )
            & (
                tbl_PPM_Encounter_V25_new["EndDateTime"].dt.time
                == pd.Timestamp("00:00:00").time()
            )
            & (
                tbl_PPM_Encounter_V25_new["StartDateTime"]
                == tbl_PPM_Encounter_V25_new["EndDateTime"]
            ),
            "LengthOfStay",
        ] = 1
        # adjust their LosinCostingperiod
        tbl_PPM_Encounter_V25_new["Extra:LeaveinCostingPeriod"] = np.where(
            (tbl_PPM_Encounter_V25_new["Extra:LeaveinCostingPeriod"] == "")
            | (tbl_PPM_Encounter_V25_new["Extra:LeaveinCostingPeriod"].isnull()),
            0,
            tbl_PPM_Encounter_V25_new["Extra:LeaveinCostingPeriod"],
        )
        tbl_PPM_Encounter_V25_new["Extra:LOSinCostingPeriod"] = np.where(
            (tbl_PPM_Encounter_V25_new["Extra:LOSinCostingPeriod"] == "")
            | (tbl_PPM_Encounter_V25_new["Extra:LOSinCostingPeriod"].isnull()),
            0,
            tbl_PPM_Encounter_V25_new["Extra:LOSinCostingPeriod"],
        )
        tbl_PPM_Encounter_V25_new["Extra:LeaveinCostingPeriod"] = (
            tbl_PPM_Encounter_V25_new["Extra:LeaveinCostingPeriod"].astype(int)
        )
        tbl_PPM_Encounter_V25_new["Extra:LOSinCostingPeriod"] = (
            tbl_PPM_Encounter_V25_new["Extra:LOSinCostingPeriod"].astype(int)
        )
        # tbl_PPM_Encounter_V25_new['Extra:LeaveinCostingPeriod'] = tbl_PPM_Encounter_V25_new['Extra:LeaveinCostingPeriod'].replace('', 0)
        tbl_PPM_Encounter_V25_new.loc[
            (
                tbl_PPM_Encounter_V25_new["StartDateTime"].dt.time
                == pd.Timestamp("00:00:00").time()
            )
            & (
                tbl_PPM_Encounter_V25_new["EndDateTime"].dt.time
                == pd.Timestamp("00:00:00").time()
            )
            & (
                tbl_PPM_Encounter_V25_new["StartDateTime"]
                == tbl_PPM_Encounter_V25_new["EndDateTime"]
            ),
            "Extra:LOSinCostingPeriod",
        ] = 1 - tbl_PPM_Encounter_V25_new["Extra:LeaveinCostingPeriod"].astype(int)
        tbl_PPM_Encounter_V25_new["Extra:LOSinCostingPeriod"] = np.where(
            (tbl_PPM_Encounter_V25_new["Extra:LOSinCostingPeriod"] < 0),
            0,
            tbl_PPM_Encounter_V25_new["Extra:LOSinCostingPeriod"],
        )
        # if time component of startdatetime=time component of enddatetime =00:00:00, then, make the timecomponent of enddatetime to 23:59:59
        tbl_PPM_Encounter_V25_new.loc[
            (
                tbl_PPM_Encounter_V25_new["StartDateTime"].dt.time
                == pd.Timestamp("00:00:00").time()
            )
            & (
                tbl_PPM_Encounter_V25_new["EndDateTime"].dt.time
                == pd.Timestamp("00:00:00").time()
            )
            & (
                tbl_PPM_Encounter_V25_new["StartDateTime"]
                == tbl_PPM_Encounter_V25_new["EndDateTime"]
            ),
            "EndDateTime",
        ] = tbl_PPM_Encounter_V25_new["EndDateTime"] + pd.DateOffset(
            hours=23, minutes=59, seconds=59
        )
        tbl_PPM_Encounter_V25_new = tbl_PPM_Encounter_V25_new.applymap(
            str
        )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
        tbl_PPM_Encounter_V25_new = tbl_PPM_Encounter_V25_new.applymap(
            lambda x: x.strip() if isinstance(x, str) else x
        )
        tbl_PPM_Encounter_V25_new = tbl_PPM_Encounter_V25_new.apply(
            lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
        )
        tbl_PPM_Encounter_V25_new = tbl_PPM_Encounter_V25_new.apply(
            lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
        )
        """
        tbl_PPM_Encounter_V25_supp = tbl_PPM_Encounter_V25.copy()
        tbl_PPM_Encounter_V25_supp = tbl_PPM_Encounter_V25_supp[['EncounterNumber', 'EncounterType', 'PatientNumber', 'EpisodeOfCare', 'Hospital', 'StartDateTime', 'EndDateTime', 'Extra:HospitalStayNumber', 'Extra:LHDIdentifier', 'Extra:EpisodeSequenceNumber', \
        'Extra:FIMBathBeg', 'Extra:FIMBathEnd', 'Extra:FIMBladderBeg', 'Extra:FIMBladderEnd', 'Extra:FIMBowelBeg', 'Extra:FIMBowelEnd', 'Extra:FIMCompBeg', 'Extra:FIMCompEnd', 'Extra:FIMEatBeg', 'Extra:FIMEatEnd', 'Extra:FIMExpBeg', 'Extra:FIMExpEnd', 'Extra:FIMGroomBeg', \
        'Extra:FIMGroomEnd', 'Extra:FIMLowerBeg', 'Extra:FIMLowerEnd', 'Extra:FIMMemoryBeg', 'Extra:FIMMemoryEnd', 'Extra:FIMProbBeg', 'Extra:FIMProbEnd', 'Extra:FIMSocialBeg', 'Extra:FIMSocialEnd', 'Extra:FIMStairBeg', 'Extra:FIMStairEnd', 'Extra:FIMToiletBeg', 'Extra:FIMToiletEnd', \
        'Extra:FIMTubBeg', 'Extra:FIMTubEnd', 'Extra:FIMUpperBeg', 'Extra:FIMUpperEnd', 'Extra:FIMWalkBeg', 'Extra:FIMWalkEnd', 'Extra:FIMXferBeg', 'Extra:FIMXferEnd', 'Extra:FIMXferToilBeg', 'Extra:FIMXferToilEnd', 'Extra:HON1', 'Extra:HON10', 'Extra:HON11', 'Extra:HON12', 'Extra:HON13', \
        'Extra:HON14', 'Extra:HON15', 'Extra:HON2', 'Extra:HON3', 'Extra:HON4', 'Extra:HON5', 'Extra:HON6', 'Extra:HON7', 'Extra:HON8', 'Extra:HON9', 'Extra:HonActiveBeg', 'Extra:HonActiveEnd', 'Extra:HonADLBeg', 'Extra:HonADLEnd', 'Extra:HonCognitBeg', 'Extra:HonCognitEnd', 'Extra:HonDeprsBeg', \
        'Extra:HonDeprsEnd', 'Extra:HonDisabBeg', 'Extra:HonDisabEnd', 'Extra:HonDrinkBeg', 'Extra:HonDrinkEnd', 'Extra:HonHallucBeg', 'Extra:HonHallucEnd', 'Extra:HonInjuryBeg', 'Extra:HonInjuryEnd', 'Extra:HonLivingBeg', 'Extra:HonLivingEnd', 'Extra:HonOccupBeg', 'Extra:HonOccupEnd', \
        'Extra:HonOtherBeg', 'Extra:HonOtherEnd', 'Extra:HonRelatBeg', 'Extra:HonRelatEnd', 'Extra:PCFamilyCarerScoreStart', 'Extra:PCPhase', 'Extra:PCPsychSpiritualScoreStart', 'Extra:PCSeverityStart', 'Extra:PCSymptomScoreStart', 'Extra:RugBedBeg', 'Extra:RugEatBeg', 'Extra:RugToilBeg', 'Extra:RugXferBeg', \
        'Extra:HLTH_ORG_OSP_OSP_ID', 'Extra:MG_AUTH_OSP_OSP_ID', 'Extra:SE_CBK_SK', 'Extra:CL_ID_EUID', 'Extra:CL_ID_IHI', 'Extra:HLTH_ORG_OSP_TYP']]
        tbl_PPM_Encounter_V25_supp.rename(columns = {'DRG1':'DRGV11', 'DRG2':'SNAPV4', 'DRG3':'AMHCCV1', 'Extra:DaysinPsychUnit':'Extra:PsychDays', 'Extra:ElectionStatusSummary':'Extra:CompStatus', 'Extra:EpisodeSequenceNumber':'Extra:episode_sequence_number', \
        'Extra:HospitalStayNumber':'Extra:stay_number', 'Extra:N_Z_FinancialProgram':'Extra:Subprogram', 'Extra:PCPhase':'Extra:Phase', 'Extra:QualifiedBedDays':'Extra:QualifiedDays', 'Extra:FIMXferToilBeg':'Extra:FIMXfrToilBeg', 'Extra:FIMXferToilEnd':'Extra:FIMXfrToilEnd'}, inplace = True, errors='ignore')
        """

        # https://abft101.atlassian.net/browse/AQA-348
        # tbl_PPM_Encounter_V25_new=clear_neg_one(tbl_PPM_Encounter_V25_new)
        try:
            tbl_PPM_Encounter_V25.to_csv(
                "./ExtractorDB/Tbl_PPM_Encounter_"
                + versionID_underscore
                + "_OLD_FORMAT.csv",
                index=False,
                na_rep="",
                float_format=str,
                decimal=str,
                date_format=str,
            )
            tbl_PPM_Encounter_V25_new.to_csv(
                "./Output/Tbl_PPM_Encounter_" + versionID_underscore + ".csv",
                index=False,
                na_rep="",
                float_format=str,
                decimal=str,
                date_format=str,
            )
        except Exception as e:
            logging.exception("Exception occurred")
            label_9_status = 0
            messagebox.showerror(
                "Export Error", "Error exporting tbl_PPM_Encounter_updated.\n" + str(e)
            )
            label_9_sub.configure(text="Failed ()...", fg="red")
            main_screen.update()
            return  # stop export
        logging.info("new IP encounter file exported to Output.")
        ###############################################################################
        # Kylie informed on 25th October that this step is not required.
        """
        # Access query: qry_Append_new_DRG_Weights
        # INSERT INTO DRGWeight ( DRG_VERSION, DRG_CODE, NURSEUC, ONE, CritUC, ORPUBUC, PROSPUBUC, SUPPLYUC, ALLIEDUC, OTUC, PHYSIOUC, SPTHERUC, NUTRDIETUC, SOCIALWUC, GENRADUC, PharmUC, CLINLABUC, ALLIEDC, PHYSIOC, OTC, SPTHERC, NUTRDIETC, SOCIALWC, SUPPLYC, RADC, INTERRADC, ANGIOC, ULTSNDC, NUCMEDC, MRIC, CTC, GENRADC, PHARMSTR, PROSPUBC, CLINLABC, ORPUBC, ORPUBXMC, CCU, ICU, NICU, NURSEUC_SA, snapallied, snappath, snapimag, snapnurse, snapdrugs, snapsupply, snapother, HITHNURSE, HITHALLIED, HITHDRUGS, HITHMSS )
        # SELECT DRGStandardWeights.[DRG_VERSION], DRGStandardWeights.DRG_CODE, DRGStandardWeights.NURSEUC, DRGStandardWeights.ONE, DRGStandardWeights.CritUC, DRGStandardWeights.ORPUBUC, DRGStandardWeights.PROSPUBUC, DRGStandardWeights.SUPPLYUC, DRGStandardWeights.ALLIEDUC, DRGStandardWeights.OTUC, DRGStandardWeights.PHYSIOUC, DRGStandardWeights.SPTHERUC, DRGStandardWeights.NUTRDIETUC, DRGStandardWeights.SOCIALWUC, DRGStandardWeights.GENRADUC, DRGStandardWeights.PharmUC, DRGStandardWeights.CLINLABUC, DRGStandardWeights.ALLIEDC, DRGStandardWeights.PHYSIOC, DRGStandardWeights.OTC, DRGStandardWeights.SPTHERC, DRGStandardWeights.NUTRDIETC, DRGStandardWeights.SOCIALWC, DRGStandardWeights.SUPPLYC, DRGStandardWeights.RADC, DRGStandardWeights.INTERRADC, DRGStandardWeights.ANGIOC, DRGStandardWeights.ULTSNDC, DRGStandardWeights.NUCMEDC, DRGStandardWeights.MRIC, DRGStandardWeights.CTC, DRGStandardWeights.GENRADC, DRGStandardWeights.PHARMSTR, DRGStandardWeights.PROSPUBC, DRGStandardWeights.CLINLABC, DRGStandardWeights.ORPUBC, DRGStandardWeights.ORPUBXMC, DRGStandardWeights.CCU, DRGStandardWeights.ICU, DRGStandardWeights.NICU, DRGStandardWeights.NURSEUC_SA, DRGStandardWeights.snapallied, DRGStandardWeights.snappath, DRGStandardWeights.snapimag, DRGStandardWeights.snapnurse, DRGStandardWeights.snapdrugs, DRGStandardWeights.snapsupply, DRGStandardWeights.snapother, DRGStandardWeights.HITHNURSE, DRGStandardWeights.HITHALLIED, DRGStandardWeights.HITHDRUGS, DRGStandardWeights.HITHMSS
        # FROM (Tbl_PPM_Encounter_V25 LEFT JOIN DRGWeight ON Tbl_PPM_Encounter_V25.DRG1 = DRGWeight.DRG_CODE) LEFT JOIN DRGStandardWeights ON Tbl_PPM_Encounter_V25.DRG1 = DRGStandardWeights.DRG_CODE
        # GROUP BY DRGStandardWeights.[DRG_VERSION], DRGStandardWeights.DRG_CODE, DRGStandardWeights.NURSEUC, DRGStandardWeights.ONE, DRGStandardWeights.CritUC, DRGStandardWeights.ORPUBUC, DRGStandardWeights.PROSPUBUC, DRGStandardWeights.SUPPLYUC, DRGStandardWeights.ALLIEDUC, DRGStandardWeights.OTUC, DRGStandardWeights.PHYSIOUC, DRGStandardWeights.SPTHERUC, DRGStandardWeights.NUTRDIETUC, DRGStandardWeights.SOCIALWUC, DRGStandardWeights.GENRADUC, DRGStandardWeights.PharmUC, DRGStandardWeights.CLINLABUC, DRGStandardWeights.ALLIEDC, DRGStandardWeights.PHYSIOC, DRGStandardWeights.OTC, DRGStandardWeights.SPTHERC, DRGStandardWeights.NUTRDIETC, DRGStandardWeights.SOCIALWC, DRGStandardWeights.SUPPLYC, DRGStandardWeights.RADC, DRGStandardWeights.INTERRADC, DRGStandardWeights.ANGIOC, DRGStandardWeights.ULTSNDC, DRGStandardWeights.NUCMEDC, DRGStandardWeights.MRIC, DRGStandardWeights.CTC, DRGStandardWeights.GENRADC, DRGStandardWeights.PHARMSTR, DRGStandardWeights.PROSPUBC, DRGStandardWeights.CLINLABC, DRGStandardWeights.ORPUBC, DRGStandardWeights.ORPUBXMC, DRGStandardWeights.CCU, DRGStandardWeights.ICU, DRGStandardWeights.NICU, DRGStandardWeights.NURSEUC_SA, DRGStandardWeights.snapallied, DRGStandardWeights.snappath, DRGStandardWeights.snapimag, DRGStandardWeights.snapnurse, DRGStandardWeights.snapdrugs, DRGStandardWeights.snapsupply, DRGStandardWeights.snapother, DRGStandardWeights.HITHNURSE, DRGStandardWeights.HITHALLIED, DRGStandardWeights.HITHDRUGS, DRGStandardWeights.HITHMSS, DRGWeight.DRG_CODE
        # HAVING (((DRGStandardWeights.DRG_CODE) Is Not Null) AND ((DRGWeight.DRG_CODE) Is Null));
        drgStandardWeights.rename(columns = {'DRG_CODE':'DRG_CODE_stdweight'}, inplace = True)
        tbl_PPM_Encounter_V25_dummy = tbl_PPM_Encounter_V25[['DRG1']]
        tbl_PPM_Encounter_V25_dummy.sort_values(['DRG1'], inplace=True)
        tbl_PPM_Encounter_V25_dummy.drop_duplicates(subset=['DRG1'], keep='last', inplace=True)
        drgweight_dummy = drgweight[['DRG_CODE']]
        drgweight_dummy.sort_values(['DRG_CODE'], inplace=True)
        drgweight_dummy.drop_duplicates(subset=['DRG_CODE'], keep='last', inplace=True)
        drg_WEIGHT_updated = pd.merge(tbl_PPM_Encounter_V25_dummy[['DRG1']], drgweight_dummy[['DRG_CODE']], how='left', left_on=['DRG1'], right_on=['DRG_CODE'], suffixes=('', '_drop'), indicator=True)
        drg_WEIGHT_updated = drg_WEIGHT_updated[drg_WEIGHT_updated['_merge']=='left_only']
        drg_WEIGHT_updated.drop(['_merge', 'DRG_CODE'], axis=1, inplace=True)
        drg_WEIGHT_updated = drg_WEIGHT_updated.merge(drgStandardWeights, how='left', left_on=['DRG1'], right_on=['DRG_CODE_stdweight'], suffixes=('', '_drop'), indicator=True)
        drg_WEIGHT_updated = drg_WEIGHT_updated[drg_WEIGHT_updated['_merge']=='both']
        drg_WEIGHT_updated.drop(['_merge'], axis=1, inplace=True)
        drg_WEIGHT_updated = drg_WEIGHT_updated.apply(lambda x: x.replace(regex=r'^nan$', value='') if x.dtype == 'object' else x)
        #drg_WEIGHT_updated = drg_WEIGHT_updated[((drg_WEIGHT_updated['DRG_CODE'].isnull()) | (drg_WEIGHT_updated['DRG_CODE']=='')) & ((pd.notna(drg_WEIGHT_updated['DRG_CODE_stdweight'])) & (drg_WEIGHT_updated['DRG_CODE_stdweight']!=''))]
        #drg_WEIGHT_updated.drop(['DRG_CODE'], axis=1, inplace=True)
        drg_WEIGHT_updated.rename(columns = {'DRG_CODE_stdweight':'DRG_CODE'}, inplace = True)
        drg_WEIGHT_updated = drg_WEIGHT_updated[['DRG_VERSION', 'DRG_CODE', 'NURSEUC', 'ONE', 'CritUC', 'ORPUBUC', 'PROSPUBUC', 'SUPPLYUC', 'ALLIEDUC', 'OTUC', 'PHYSIOUC', 'SPTHERUC', 'NUTRDIETUC', 'SOCIALWUC', 'GENRADUC', 'PharmUC', 'CLINLABUC', 'ALLIEDC', 'PHYSIOC', 'OTC', 'SPTHERC', 'NUTRDIETC', 'SOCIALWC', 'SUPPLYC', 'RADC', 'INTERRADC', 'ANGIOC', 'ULTSNDC', 'NUCMEDC', 'MRIC', 'CTC', 'GENRADC', 'PHARMSTR', 'PROSPUBC', 'CLINLABC', 'ORPUBC', 'ORPUBXMC', 'CCU', 'ICU', 'NICU', 'NURSEUC_SA', 'snapallied', 'snappath', 'snapimag', 'snapnurse', 'snapdrugs', 'snapsupply', 'snapother', 'HITHNURSE', 'HITHALLIED', 'HITHDRUGS', 'HITHMSS']]
        #drg_WEIGHT_concat = drg_WEIGHT_updated.copy()
        drg_WEIGHT_concat = pd.concat([drgweight, drg_WEIGHT_updated], axis=0)
        # sort
        drg_WEIGHT_concat.sort_values(['DRG_VERSION', 'DRG_CODE', 'NURSEUC', 'ONE', 'CritUC', 'ORPUBUC', 'PROSPUBUC', 'SUPPLYUC', 'ALLIEDUC', 'OTUC', 'PHYSIOUC', 'SPTHERUC', 'NUTRDIETUC', 'SOCIALWUC', 'GENRADUC', 'PharmUC', 'CLINLABUC', 'ALLIEDC', 'PHYSIOC', 'OTC', 'SPTHERC', 'NUTRDIETC', 'SOCIALWC', 'SUPPLYC', 'RADC', 'INTERRADC', 'ANGIOC', 'ULTSNDC', 'NUCMEDC', 'MRIC', 'CTC', 'GENRADC', 'PHARMSTR', 'PROSPUBC', 'CLINLABC', 'ORPUBC', 'ORPUBXMC', 'CCU', 'ICU', 'NICU', 'NURSEUC_SA', 'snapallied', 'snappath', 'snapimag', 'snapnurse', 'snapdrugs', 'snapsupply', 'snapother', 'HITHNURSE', 'HITHALLIED', 'HITHDRUGS', 'HITHMSS'], inplace=True)
        # dropping duplicate values
        drg_WEIGHT_concat.drop_duplicates(subset=['DRG_VERSION', 'DRG_CODE', 'NURSEUC', 'ONE', 'CritUC', 'ORPUBUC', 'PROSPUBUC', 'SUPPLYUC', 'ALLIEDUC', 'OTUC', 'PHYSIOUC', 'SPTHERUC', 'NUTRDIETUC', 'SOCIALWUC', 'GENRADUC', 'PharmUC', 'CLINLABUC', 'ALLIEDC', 'PHYSIOC', 'OTC', 'SPTHERC', 'NUTRDIETC', 'SOCIALWC', 'SUPPLYC', 'RADC', 'INTERRADC', 'ANGIOC', 'ULTSNDC', 'NUCMEDC', 'MRIC', 'CTC', 'GENRADC', 'PHARMSTR', 'PROSPUBC', 'CLINLABC', 'ORPUBC', 'ORPUBXMC', 'CCU', 'ICU', 'NICU', 'NURSEUC_SA', 'snapallied', 'snappath', 'snapimag', 'snapnurse', 'snapdrugs', 'snapsupply', 'snapother', 'HITHNURSE', 'HITHALLIED', 'HITHDRUGS', 'HITHMSS'], keep='last', inplace=True)
        # Ranjit - change DRG to v11
        drg_WEIGHT_concat['DRG_VERSION'] = np.where(drg_WEIGHT_concat['DRG_VERSION'] =='8.0', '8', drg_WEIGHT_concat['DRG_VERSION'])
        drg_WEIGHT_concat = drg_WEIGHT_concat.applymap(str)#.apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
        drg_WEIGHT_concat = drg_WEIGHT_concat.applymap(lambda x: x.strip() if isinstance(x, str) else x)
        drg_WEIGHT_concat = drg_WEIGHT_concat.apply(lambda x: x.replace(regex=r'^NaT$', value='') if x.dtype == 'object' else x)
        drg_WEIGHT_concat = drg_WEIGHT_concat.apply(lambda x: x.replace(regex=r'^nan$', value='') if x.dtype == 'object' else x)
        if len(drg_WEIGHT_concat) > 0:
            try:
                drg_WEIGHT_concat.to_csv('./Output/DRGWeight.txt', sep=',', index=False, na_rep='', float_format=str, decimal=str, date_format=str)
            except Exception as e:
                logging.exception("Exception occurred")
                label_9_status = 0
                messagebox.showerror("Export Error","Error exporting DRGWeight_updated.txt\n"+str(e))
                label_9_sub.configure(text="Failed ()...",fg='red')
                main_screen.update()
                return # stop export    
        logging.info('%s records saved to ./Output/DRGWeight_updated.txt.', len(drg_WEIGHT_concat))
        """
        ###############################################################################
        # Access query: qry_append_obstet_epi
        # INSERT INTO Tbl_ppm_ObstetEpi ( EncounterNumber, patientnumber, AttendingConsultant, AttendingConsultantSpecialty, [extra:mrn], [extra:auid], startdatetime, hospital, DiagnosisCode, ProcedureCode, ProcedureDateTime, enddatetime )
        # SELECT Tbl_PPM_Encounter_V25.EncounterNumber, Tbl_PPM_Encounter_V25.patientnumber, Tbl_PPM_Encounter_V25.AttendingConsultant, Tbl_PPM_Encounter_V25.AttendingConsultantSpecialty, Tbl_PPM_Encounter_V25.[extra:mrn], Tbl_PPM_Encounter_V25.[extra:auid], Tbl_PPM_Encounter_V25.startdatetime, Tbl_PPM_Encounter_V25.hospital, Max(diagnosis_ICD10V12.diagnosis_code_curr) AS MaxOfdiagnosis_code_curr, Max(Procedure_ICD10V12.procedure_code_curr) AS MaxOfprocedure_code_curr, Procedure_ICD10V12.procedure_date, Tbl_PPM_Encounter_V25.enddatetime
        # FROM Procedure_ICD10V12 INNER JOIN (diagnosis_ICD10V12 INNER JOIN Tbl_PPM_Encounter_V25 ON diagnosis_ICD10V12.[EncounterNumber] = Tbl_PPM_Encounter_V25.EncounterNumber) ON Procedure_ICD10V12.EncounterNumber = Tbl_PPM_Encounter_V25.EncounterNumber
        # GROUP BY Tbl_PPM_Encounter_V25.EncounterNumber, Tbl_PPM_Encounter_V25.patientnumber, Tbl_PPM_Encounter_V25.AttendingConsultant, Tbl_PPM_Encounter_V25.AttendingConsultantSpecialty, Tbl_PPM_Encounter_V25.[extra:mrn], Tbl_PPM_Encounter_V25.[extra:auid], Tbl_PPM_Encounter_V25.startdatetime, Tbl_PPM_Encounter_V25.hospital, Procedure_ICD10V12.procedure_date, Tbl_PPM_Encounter_V25.enddatetime, Tbl_PPM_Encounter_V25.[extra:wip]
        # HAVING (((Max(Procedure_ICD10V12.procedure_code_curr)) Like '92506*') AND ((Tbl_PPM_Encounter_V25.[extra:wip]) In ("4","2"))) OR (((Max(Procedure_ICD10V12.procedure_code_curr)) Like '92507*') AND ((Tbl_PPM_Encounter_V25.[extra:wip]) In ("4","2"))) OR (((Max(Procedure_ICD10V12.procedure_code_curr)) Like '92508*') AND ((Tbl_PPM_Encounter_V25.[extra:wip]) In ("4","2")));
        tbl_ppm_ObstetEpi_updated = pd.merge(
            diagnosis_ICD10V12[["EncounterNumber", "diagnosis_code_curr"]],
            tbl_PPM_Encounter_V25[
                [
                    "EncounterNumber",
                    "AttendingConsultant",
                    "PatientNumber",
                    "AttendingConsultantSpecialty",
                    "Extra:MRN",
                    "Extra:AUID",
                    "StartDateTime",
                    "Hospital",
                    "EndDateTime",
                    "Extra:WIP",
                ]
            ],
            how="inner",
            on=["EncounterNumber"],
            suffixes=("", "_drop"),
        ).merge(
            procedure_ICD10V12[
                ["procedure_date", "EncounterNumber", "procedure_code_curr"]
            ],
            how="inner",
            on=["EncounterNumber"],
            suffixes=("", "_drop"),
        )
        tbl_ppm_ObstetEpi_updated = (
            tbl_ppm_ObstetEpi_updated.groupby(
                [
                    "EncounterNumber",
                    "PatientNumber",
                    "AttendingConsultant",
                    "AttendingConsultantSpecialty",
                    "Extra:MRN",
                    "Extra:AUID",
                    "StartDateTime",
                    "Hospital",
                    "procedure_date",
                    "EndDateTime",
                    "Extra:WIP",
                ],
                as_index=False,
                dropna=False,
            )
            .agg(
                DiagnosisCode=("diagnosis_code_curr", "max"),
                ProcedureCode=("procedure_code_curr", "max"),
            )
            .reset_index()
        )
        tbl_ppm_ObstetEpi_updated = tbl_ppm_ObstetEpi_updated.apply(
            lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
        )
        tbl_ppm_ObstetEpi_updated.drop_duplicates(keep="last", inplace=True)
        tbl_ppm_ObstetEpi_updated = tbl_ppm_ObstetEpi_updated[
            [
                "EncounterNumber",
                "PatientNumber",
                "AttendingConsultant",
                "AttendingConsultantSpecialty",
                "Extra:MRN",
                "Extra:AUID",
                "StartDateTime",
                "Hospital",
                "DiagnosisCode",
                "ProcedureCode",
                "procedure_date",
                "EndDateTime",
                "Extra:WIP",
            ]
        ]
        tbl_ppm_ObstetEpi_updated.rename(
            columns={"procedure_date": "ProcedureDateTime"}, inplace=True
        )
        tbl_ppm_ObstetEpi_updated["Extra:WIP"] = tbl_ppm_ObstetEpi_updated[
            "Extra:WIP"
        ].astype(str)
        tbl_ppm_ObstetEpi_updated["DiagnosisCode"] = tbl_ppm_ObstetEpi_updated[
            "DiagnosisCode"
        ].astype(str)
        tbl_ppm_ObstetEpi_updated["ProcedureCode"] = tbl_ppm_ObstetEpi_updated[
            "ProcedureCode"
        ].astype(str)
        # Lai-Mun on 11/10/2023 on Teams - The Extraction Team - We deliver channel - "The Obstet should be RESTRICTED by diagnosis please. "
        tbl_ppm_ObstetEpi_updated = tbl_ppm_ObstetEpi_updated[
            (
                (
                    tbl_ppm_ObstetEpi_updated.DiagnosisCode.astype(str).str.startswith(
                        ("Z37")
                    )
                    == True
                )
                & (
                    tbl_ppm_ObstetEpi_updated.ProcedureCode.astype(str).str.startswith(
                        ("92506")
                    )
                    == True
                )
                & (tbl_ppm_ObstetEpi_updated["Extra:WIP"].isin(["4", "2"]))
            )
            | (
                (
                    tbl_ppm_ObstetEpi_updated.DiagnosisCode.astype(str).str.startswith(
                        ("Z37")
                    )
                    == True
                )
                & (
                    tbl_ppm_ObstetEpi_updated.ProcedureCode.astype(str).str.startswith(
                        ("92507")
                    )
                    == True
                )
                & (tbl_ppm_ObstetEpi_updated["Extra:WIP"].isin(["4", "2"]))
            )
            | (
                (
                    tbl_ppm_ObstetEpi_updated.DiagnosisCode.astype(str).str.startswith(
                        ("Z37")
                    )
                    == True
                )
                & (
                    tbl_ppm_ObstetEpi_updated.ProcedureCode.astype(str).str.startswith(
                        ("92508")
                    )
                    == True
                )
                & (tbl_ppm_ObstetEpi_updated["Extra:WIP"].isin(["4", "2"]))
            )
        ]
        """
        tbl_ppm_ObstetEpi_updated = tbl_ppm_ObstetEpi_updated[((tbl_ppm_ObstetEpi_updated.ProcedureCode.astype(str).str.startswith(('92506'))==True) & (tbl_ppm_ObstetEpi_updated['Extra:WIP'].isin(['4', '2']))) | \
        ((tbl_ppm_ObstetEpi_updated.ProcedureCode.astype(str).str.startswith(('92507'))==True) & (tbl_ppm_ObstetEpi_updated['Extra:WIP'].isin(['4', '2']) )) | \
        ((tbl_ppm_ObstetEpi_updated.ProcedureCode.astype(str).str.startswith(('92508'))==True) & (tbl_ppm_ObstetEpi_updated['Extra:WIP'].isin(['4', '2']) )) ]
        """
        tbl_ppm_ObstetEpi_updated = tbl_ppm_ObstetEpi_updated.apply(
            lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
        )
        tbl_ppm_ObstetEpi_updated["Extra:MRN"] = np.where(
            tbl_ppm_ObstetEpi_updated["Extra:MRN"] != "",
            tbl_ppm_ObstetEpi_updated["Extra:MRN"]
            .astype(str)
            .str.pad(10, side="left", fillchar="0"),
            "",
        )
        tbl_ppm_ObstetEpi_updated["Extra:AUID"] = np.where(
            tbl_ppm_ObstetEpi_updated["Extra:AUID"] != "",
            tbl_ppm_ObstetEpi_updated["Extra:AUID"]
            .astype(str)
            .str.pad(10, side="left", fillchar="0"),
            "",
        )
        tbl_ppm_ObstetEpi_updated = tbl_ppm_ObstetEpi_updated[
            [
                "PatientNumber",
                "EncounterNumber",
                "Hospital",
                "AttendingConsultant",
                "AttendingConsultantSpecialty",
                "StartDateTime",
                "Extra:MRN",
                "Extra:AUID",
                "DiagnosisCode",
                "ProcedureCode",
                "ProcedureDateTime",
                "EndDateTime",
            ]
        ]
        tbl_ppm_ObstetEpi_updated = tbl_ppm_ObstetEpi_updated.applymap(
            str
        )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
        tbl_ppm_ObstetEpi_updated = tbl_ppm_ObstetEpi_updated.applymap(
            lambda x: x.strip() if isinstance(x, str) else x
        )
        tbl_ppm_ObstetEpi_updated = tbl_ppm_ObstetEpi_updated.apply(
            lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
        )
        logging.info(
            "tbl_ppm_ObstetEpi_updated has %s records.", len(tbl_ppm_ObstetEpi_updated)
        )
        # tbl_ppm_ObstetEpi_updated = pd.concat([tbl_ppm_ObstetEpi, tbl_ppm_ObstetEpi_updated], axis=0)
        tbl_ppm_ObstetEpi_updated["ProcedureDateTime"] = pd.to_datetime(
            tbl_ppm_ObstetEpi_updated["ProcedureDateTime"], format="%Y-%m-%d %H:%M:%S"
        )
        """
        The output file tbl_PPM_ObstetEpi will not load to PPM due to the date not being formatted correctly.
        """
        # tbl_ppm_ObstetEpi_updated['ProcedureDateTime'] = tbl_ppm_ObstetEpi_updated['ProcedureDateTime'].dt.strftime("%d/%m/%Y")
        tbl_ppm_ObstetEpi_updated["ProcedureDateTime"] = tbl_ppm_ObstetEpi_updated[
            "ProcedureDateTime"
        ].dt.strftime("%Y-%m-%d %H:%M:%S")
        tbl_ppm_ObstetEpi_updated = tbl_ppm_ObstetEpi_updated[
            [
                "PatientNumber",
                "EncounterNumber",
                "Hospital",
                "AttendingConsultant",
                "AttendingConsultantSpecialty",
                "StartDateTime",
                "Extra:MRN",
                "Extra:AUID",
                "DiagnosisCode",
                "ProcedureCode",
                "ProcedureDateTime",
                "EndDateTime",
            ]
        ]
        tbl_ppm_ObstetEpi_updated.drop_duplicates(keep="last", inplace=True)
        try:
            tbl_ppm_ObstetEpi_updated.to_csv(
                "./ExtractorDB/Tbl_ppm_ObstetEpi_OBSOLETE.txt",
                sep=",",
                index=False,
                na_rep="",
                float_format=str,
                decimal=str,
                date_format=str,
            )
        except Exception as e:
            logging.exception("Exception occurred")
            label_9_status = 0
            messagebox.showerror(
                "Export Error",
                "Error exporting tbl_ppm_ObstetEpi_updated.txt\n" + str(e),
            )
            label_9_sub.configure(text="Failed ()...", fg="red")
            main_screen.update()
            return  # stop export
        logging.info(
            "%s records saved to ./Output/tbl_ppm_ObstetEpi_updated.txt.",
            len(tbl_ppm_ObstetEpi_updated),
        )
        ###############################################################################
        # Access query: qry_append_tbl_PPM_ICD_DIagnoses_V25
        # INSERT INTO Tbl_PPM_ICD_diagnoses_V25 ( DiagnosisVersion, Sequence, ConditionOnset, DiagnosisCode, EncounterNumber )
        # SELECT diagnosis_ICD10V12.clinical_codeset_curr, diagnosis_ICD10V12.diagnosis_type, diagnosis_ICD10V12.condition_onset_flag, diagnosis_ICD10V12.diagnosis_code_curr, Tbl_PPM_Encounter_V25.EncounterNumber
        # FROM diagnosis_ICD10V12 INNER JOIN Tbl_PPM_Encounter_V25 ON (diagnosis_ICD10V12.facility_identifier = Tbl_PPM_Encounter_V25.Hospital) AND (Tbl_PPM_Encounter_V25.[Extra:EpisodeSequenceNumber] = diagnosis_ICD10V12.episode_sequence_number) AND (diagnosis_ICD10V12.stay_number = Tbl_PPM_Encounter_V25.[Extra:HospitalStayNumber]);
        diagnosis_ICD10V12["stay_number"] = (
            diagnosis_ICD10V12["stay_number"].astype(str).str.replace("SN", "")
        )
        diagnosis_ICD10V12["stay_number"] = (
            diagnosis_ICD10V12["stay_number"]
            .astype(str)
            .str.pad(8, side="left", fillchar="0")
        )
        diagnosis_ICD10V12["stay_number"] = "SN" + diagnosis_ICD10V12["stay_number"]
        diagnosis_ICD10V12["episode_sequence_number"] = (
            diagnosis_ICD10V12["episode_sequence_number"]
            .astype(str)
            .str.pad(3, side="left", fillchar="0")
        )
        tbl_PPM_Encounter_V25["Extra:EpisodeSequenceNumber"] = (
            tbl_PPM_Encounter_V25["Extra:EpisodeSequenceNumber"]
            .astype(str)
            .str.pad(3, side="left", fillchar="0")
        )
        # tbl_PPM_ICD_diagnoses_V25 = pd.merge(diagnosis_ICD10V12[['facility_identifier', 'episode_sequence_number', 'stay_number', 'clinical_codeset_curr', 'diagnosis_type', 'condition_onset_flag', 'diagnosis_code_curr']], tbl_PPM_Encounter_V25[['Hospital', 'Extra:EpisodeSequenceNumber', 'Extra:HospitalStayNumber', 'EncounterNumber']], how='inner', left_on=['facility_identifier', 'episode_sequence_number', 'stay_number'], right_on=['Hospital', 'Extra:EpisodeSequenceNumber', 'Extra:HospitalStayNumber'], suffixes=('', '_drop'))
        tbl_PPM_ICD_diagnoses_V25 = pd.merge(
            diagnosis_ICD10V12[
                [
                    "facility_identifier",
                    "episode_sequence_number",
                    "stay_number",
                    "clinical_codeset_curr",
                    "diagnosis_type",
                    "condition_onset_flag",
                    "diagnosis_code_curr",
                ]
            ],
            tbl_PPM_Encounter_V25[
                [
                    "Hospital",
                    "Extra:EpisodeSequenceNumber",
                    "Extra:HospitalStayNumber",
                    "EncounterNumber",
                    "Extra:HLTH_ORG_OSP_OSP_ID",
                    "Extra:MG_AUTH_OSP_OSP_ID",
                    "Extra:SE_CBK_SK",
                ]
            ],
            how="inner",
            left_on=["facility_identifier", "episode_sequence_number", "stay_number"],
            right_on=[
                "Hospital",
                "Extra:EpisodeSequenceNumber",
                "Extra:HospitalStayNumber",
            ],
            suffixes=("", "_drop"),
        )
        tbl_PPM_ICD_diagnoses_V25.rename(
            columns={
                "diagnosis_type": "Sequence",
                "condition_onset_flag": "ConditionOnset",
                "clinical_codeset_curr": "DiagnosisVersion",
                "diagnosis_code_curr": "DiagnosisCode",
            },
            inplace=True,
        )
        # tbl_PPM_ICD_diagnoses_V25 = tbl_PPM_ICD_diagnoses_V25[['DiagnosisVersion', 'Sequence', 'ConditionOnset', 'DiagnosisCode', 'EncounterNumber']]
        tbl_PPM_ICD_diagnoses_V25 = tbl_PPM_ICD_diagnoses_V25[
            [
                "DiagnosisVersion",
                "Sequence",
                "ConditionOnset",
                "DiagnosisCode",
                "EncounterNumber",
                "Extra:HLTH_ORG_OSP_OSP_ID",
                "Extra:MG_AUTH_OSP_OSP_ID",
                "Extra:SE_CBK_SK",
            ]
        ]
        logging.info("qry_append_tbl_PPM_ICD_DIagnoses_V25 completed.")
        ###############################################################################
        # Access query: qry_update_diag_SN
        # UPDATE Tbl_PPM_ICD_diagnoses_V25 SET Tbl_PPM_ICD_diagnoses_V25.Sequence = IIf([Sequence] Is Null,1,[Sequence]+1);
        # tbl_PPM_ICD_diagnoses_V25['Sequence'] = np.where(tbl_PPM_ICD_diagnoses_V25['Sequence']=='P',0,tbl_PPM_ICD_diagnoses_V25['Sequence'])
        # tbl_PPM_ICD_diagnoses_V25['Sequence'] = np.where((tbl_PPM_ICD_diagnoses_V25['Sequence'].isnull()) | (tbl_PPM_ICD_diagnoses_V25['Sequence']==''),1,tbl_PPM_ICD_diagnoses_V25['Sequence'].astype(int, errors='ignore')+1)
        # tbl_PPM_ICD_diagnoses_V25['Sequence'] = tbl_PPM_ICD_diagnoses_V25['Sequence'].apply(lambda x: '' if pd.isna(x) or x == '' else pd.to_numeric(x, errors='coerce')).astype('Int64')
        tbl_PPM_ICD_diagnoses_V25 = tbl_PPM_ICD_diagnoses_V25[
            [
                "EncounterNumber",
                "DiagnosisCode",
                "DiagnosisVersion",
                "Sequence",
                "ConditionOnset",
            ]
        ]
        tbl_PPM_ICD_diagnoses_V25.drop_duplicates(
            subset=[
                "EncounterNumber",
                "DiagnosisCode",
                "DiagnosisVersion",
                "Sequence",
                "ConditionOnset",
            ],
            keep="last",
            inplace=True,
        )
        ###############################################################################
        # Export C:\costing\Output\Tbl_PPM_ICD_diagnoses_V27.csv
        # https://abft101.atlassian.net/browse/AQA-348
        # tbl_PPM_ICD_diagnoses_V25=clear_neg_one(tbl_PPM_ICD_diagnoses_V25)
        try:
            tbl_PPM_ICD_diagnoses_V25.to_csv(
                "./Output/Tbl_PPM_ICD_diagnoses_" + versionID_hash + ".csv",
                index=False,
                na_rep="",
                float_format=str,
                decimal=str,
                date_format=str,
            )
        except Exception as e:
            logging.exception("Exception occurred")
            label_9_status = 0
            messagebox.showerror(
                "Export Error",
                "Error exporting tbl_PPM_ICD_diagnoses_updated.csv\n" + str(e),
            )
            label_9_sub.configure(text="Failed ()...", fg="red")
            main_screen.update()
            return  # stop export
        logging.info(
            "%s records saved to ./Output/tbl_PPM_ICD_diagnoses_updated.csv.",
            len(tbl_PPM_ICD_diagnoses_V25),
        )

        # AQA-342 New Diagnosis and Procedure Coding Count
        tbl_PPM_ICD_diagnoses_V25_dup = tbl_PPM_ICD_diagnoses_V25.copy()
        # tbl_PPM_ICD_diagnoses_V25_dup['Sequence'] = np.where((tbl_PPM_ICD_diagnoses_V25_dup['Sequence'].isnull()) | (tbl_PPM_ICD_diagnoses_V25_dup['Sequence']==''),1,tbl_PPM_ICD_diagnoses_V25_dup['Sequence'].astype(int, errors='ignore'))
        # tbl_PPM_ICD_diagnoses_V25_dup['Sequence'] = pd.to_numeric(tbl_PPM_ICD_diagnoses_V25_dup['Sequence'], errors='coerce').apply(lambda x: 1 if pd.isna(x) else int(x) + 1)
        tbl_PPM_ICD_diagnoses_V25_dup["Sequence"] = pd.to_numeric(
            tbl_PPM_ICD_diagnoses_V25_dup["Sequence"], errors="coerce"
        ).apply(lambda x: 1 if pd.isna(x) else int(x))
        max_diag_sequence = (
            tbl_PPM_ICD_diagnoses_V25_dup.groupby("EncounterNumber")["Sequence"]
            .max()
            .reset_index()
        )
        # max_diag_sequence = tbl_PPM_ICD_diagnoses_V25.groupby('EncounterNumber')['Sequence'].max().reset_index()
        max_diag_sequence.rename(
            columns={"Sequence": "Extra:DiagnosisCount"}, inplace=True
        )
        max_diag_sequence.to_csv("./ExtractorDB/max_diag_sequence.csv", index=False)
        ###############################################################################
        # Access query: qry_append_Tbl_PPM_ICD_procedures_V25
        # INSERT INTO Tbl_PPM_ICD_procedures_V25 ( ProcedureVersion, Sequence, ProcedureCode, ProcedureDateTime, EncounterNumber )
        # SELECT Procedure_ICD10V12.clinical_codeset_curr, Procedure_ICD10V12.procedure_type, Procedure_ICD10V12.procedure_code_curr, Procedure_ICD10V12.procedure_date, Tbl_PPM_Encounter_V25.EncounterNumber
        # FROM Tbl_PPM_Encounter_V25 INNER JOIN Procedure_ICD10V12 ON (Procedure_ICD10V12.facility_identifier = Tbl_PPM_Encounter_V25.Hospital) AND (Procedure_ICD10V12.episode_sequence_number = Tbl_PPM_Encounter_V25.[Extra:EpisodeSequenceNumber]) AND (Tbl_PPM_Encounter_V25.[Extra:HospitalStayNumber] = Procedure_ICD10V12.stay_number);
        procedure_ICD10V12["stay_number"] = (
            procedure_ICD10V12["stay_number"].astype(str).str.replace("SN", "")
        )
        procedure_ICD10V12["stay_number"] = (
            procedure_ICD10V12["stay_number"]
            .astype(str)
            .str.pad(8, side="left", fillchar="0")
        )
        procedure_ICD10V12["stay_number"] = "SN" + procedure_ICD10V12["stay_number"]
        procedure_ICD10V12["episode_sequence_number"] = (
            procedure_ICD10V12["episode_sequence_number"]
            .astype(str)
            .str.pad(3, side="left", fillchar="0")
        )
        tbl_PPM_Encounter_V25["Extra:EpisodeSequenceNumber"] = (
            tbl_PPM_Encounter_V25["Extra:EpisodeSequenceNumber"]
            .astype(str)
            .str.pad(3, side="left", fillchar="0")
        )
        # tbl_PPM_ICD_procedures_V25 = pd.merge(procedure_ICD10V12[['facility_identifier', 'episode_sequence_number', 'stay_number', 'clinical_codeset_curr', 'procedure_type', 'procedure_code_curr', 'procedure_date']], tbl_PPM_Encounter_V25[['Hospital', 'Extra:EpisodeSequenceNumber', 'Extra:HospitalStayNumber', 'EncounterNumber']], how='inner', left_on=['facility_identifier', 'episode_sequence_number', 'stay_number'], right_on=['Hospital', 'Extra:EpisodeSequenceNumber', 'Extra:HospitalStayNumber'], suffixes=('', '_drop'))
        tbl_PPM_ICD_procedures_V25 = pd.merge(
            procedure_ICD10V12[
                [
                    "facility_identifier",
                    "episode_sequence_number",
                    "stay_number",
                    "clinical_codeset_curr",
                    "procedure_type",
                    "procedure_code_curr",
                    "procedure_date",
                ]
            ],
            tbl_PPM_Encounter_V25[
                [
                    "Hospital",
                    "Extra:EpisodeSequenceNumber",
                    "Extra:HospitalStayNumber",
                    "EncounterNumber",
                    "Extra:HLTH_ORG_OSP_OSP_ID",
                    "Extra:MG_AUTH_OSP_OSP_ID",
                    "Extra:SE_CBK_SK",
                ]
            ],
            how="inner",
            left_on=["facility_identifier", "episode_sequence_number", "stay_number"],
            right_on=[
                "Hospital",
                "Extra:EpisodeSequenceNumber",
                "Extra:HospitalStayNumber",
            ],
            suffixes=("", "_drop"),
        )
        tbl_PPM_ICD_procedures_V25.rename(
            columns={
                "procedure_type": "Sequence",
                "procedure_date": "ProcedureDateTime",
                "clinical_codeset_curr": "ProcedureVersion",
                "procedure_code_curr": "ProcedureCode",
            },
            inplace=True,
        )
        # tbl_PPM_ICD_procedures_V25 = tbl_PPM_ICD_procedures_V25[['ProcedureVersion', 'Sequence', 'ProcedureCode', 'ProcedureDateTime', 'EncounterNumber']]
        tbl_PPM_ICD_procedures_V25 = tbl_PPM_ICD_procedures_V25[
            [
                "ProcedureVersion",
                "Sequence",
                "ProcedureCode",
                "ProcedureDateTime",
                "EncounterNumber",
                "Extra:HLTH_ORG_OSP_OSP_ID",
                "Extra:MG_AUTH_OSP_OSP_ID",
                "Extra:SE_CBK_SK",
            ]
        ]
        logging.info("qry_append_Tbl_PPM_ICD_procedures_V25 completed.")
        ###############################################################################
        # Access query: qry_update_proc_SN
        # UPDATE Tbl_PPM_ICD_procedures_V25 SET Tbl_PPM_ICD_procedures_V25.Sequence = IIf([Sequence] Is Null,1,[Sequence]+1);
        # tbl_PPM_ICD_procedures_V25['Sequence'] = np.where(tbl_PPM_ICD_procedures_V25['Sequence']=='P',0,tbl_PPM_ICD_procedures_V25['Sequence'])
        # tbl_PPM_ICD_procedures_V25['Sequence'] = np.where((tbl_PPM_ICD_procedures_V25['Sequence'].isnull()) | (tbl_PPM_ICD_procedures_V25['Sequence']==''),1,tbl_PPM_ICD_procedures_V25['Sequence'].astype(int, errors='ignore')+1)
        # tbl_PPM_ICD_procedures_V25['Sequence'] = tbl_PPM_ICD_procedures_V25['Sequence'].apply(lambda x: '' if pd.isna(x) or x == '' else pd.to_numeric(x, errors='coerce')).astype('Int64')
        tbl_PPM_ICD_procedures_V25["ProcedureDateTime"] = pd.to_datetime(
            tbl_PPM_ICD_procedures_V25["ProcedureDateTime"], format="%Y-%m-%d %H:%M:%S"
        )
        """
        The output file tbl_PPM_ICD_procedures_V28 will not load to PPM due to the date not being formatted correctly.
        """
        # tbl_PPM_ICD_procedures_V25['ProcedureDateTime'] = tbl_PPM_ICD_procedures_V25['ProcedureDateTime'].dt.strftime("%d/%m/%Y")
        tbl_PPM_ICD_procedures_V25["ProcedureDateTime"] = tbl_PPM_ICD_procedures_V25[
            "ProcedureDateTime"
        ].dt.strftime("%Y-%m-%d %H:%M:%S")
        tbl_PPM_ICD_procedures_V25["ProcedureDateTime"] = np.where(
            tbl_PPM_ICD_procedures_V25["ProcedureDateTime"] == "nan",
            "",
            tbl_PPM_ICD_procedures_V25["ProcedureDateTime"],
        )
        tbl_PPM_ICD_procedures_V25 = tbl_PPM_ICD_procedures_V25[
            [
                "EncounterNumber",
                "ProcedureCode",
                "ProcedureDateTime",
                "ProcedureVersion",
                "Sequence",
            ]
        ]
        tbl_PPM_ICD_procedures_V25.drop_duplicates(
            subset=[
                "EncounterNumber",
                "ProcedureCode",
                "ProcedureDateTime",
                "ProcedureVersion",
                "Sequence",
            ],
            keep="last",
            inplace=True,
        )
        logging.info("qry_update_proc_SN completed.")
        ###############################################################################
        # https://abft101.atlassian.net/browse/AQA-348
        # tbl_PPM_ICD_procedures_V25=clear_neg_one(tbl_PPM_ICD_procedures_V25)
        # Export C:\costing\Output\Tbl_PPM_ICD_procedures_V27.csv
        try:
            tbl_PPM_ICD_procedures_V25.to_csv(
                "./Output/Tbl_PPM_ICD_procedures_" + versionID_hash + ".csv",
                index=False,
                na_rep="",
                float_format=str,
                decimal=str,
                date_format=str,
            )
        except Exception as e:
            logging.exception("Exception occurred")
            label_9_status = 0
            messagebox.showerror(
                "Export Error",
                "Error exporting tbl_PPM_ICD_procedures_V25.csv\n" + str(e),
            )
            label_9_sub.configure(text="Failed ()...", fg="red")
            main_screen.update()
            return  # stop export
        logging.info(
            "%s records saved to ./Output/tbl_PPM_ICD_procedures_updated.csv.",
            len(tbl_PPM_ICD_procedures_V25),
        )

        # AQA-342 New Diagnosis and Procedure Coding Count
        tbl_PPM_ICD_procedures_V25_dup = tbl_PPM_ICD_procedures_V25.copy()
        # tbl_PPM_ICD_procedures_V25_dup['Sequence'] = np.where((tbl_PPM_ICD_procedures_V25_dup['Sequence'].isnull()) | (tbl_PPM_ICD_procedures_V25_dup['Sequence']==''),1,tbl_PPM_ICD_procedures_V25_dup['Sequence'].astype(int, errors='ignore')+1)
        # tbl_PPM_ICD_procedures_V25_dup['Sequence'] = pd.to_numeric(tbl_PPM_ICD_procedures_V25_dup['Sequence'], errors='coerce').apply(lambda x: 1 if pd.isna(x) else int(x) + 1)
        tbl_PPM_ICD_procedures_V25_dup["Sequence"] = pd.to_numeric(
            tbl_PPM_ICD_procedures_V25_dup["Sequence"], errors="coerce"
        ).apply(lambda x: 1 if pd.isna(x) else int(x))
        max_proc_sequence = (
            tbl_PPM_ICD_procedures_V25_dup.groupby("EncounterNumber")["Sequence"]
            .max()
            .reset_index()
        )
        max_proc_sequence.rename(
            columns={"Sequence": "Extra:ProcedureCount"}, inplace=True
        )
        max_proc_sequence.to_csv("./ExtractorDB/max_proc_sequence.csv", index=False)

        cleanup_memory(tbl_PPM_Encounter_V25)
        logging.info("tbl_PPM_Encounter_V25_new_merged going to be generated.")
        # AQA-342 New Diagnosis and Procedure Coding Count - from v1.14
        tbl_PPM_Encounter_V25_new_merged = pd.merge(
            tbl_PPM_Encounter_V25_new,
            max_proc_sequence,
            how="left",
            on=["EncounterNumber"],
            suffixes=("", "_drop"),
        ).merge(
            max_diag_sequence,
            how="left",
            on=["EncounterNumber"],
            suffixes=("", "_drop"),
        )
        cleanup_memory(tbl_PPM_Encounter_V25_new)
        tbl_PPM_Encounter_V25_new_merged = tbl_PPM_Encounter_V25_new_merged.apply(
            lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
        )
        # Fill NaNs in colA with a specified value
        tbl_PPM_Encounter_V25_new_merged["Extra:ProcedureCount"] = (
            tbl_PPM_Encounter_V25_new_merged["Extra:ProcedureCount"].fillna(0)
        )
        tbl_PPM_Encounter_V25_new_merged["Extra:DiagnosisCount"] = (
            tbl_PPM_Encounter_V25_new_merged["Extra:DiagnosisCount"].fillna(0)
        )
        tbl_PPM_Encounter_V25_new_merged["Extra:CodingCount"] = (
            tbl_PPM_Encounter_V25_new_merged["Extra:ProcedureCount"].fillna(0)
            + tbl_PPM_Encounter_V25_new_merged["Extra:DiagnosisCount"].fillna(0)
        )
        tbl_PPM_Encounter_V25_new_merged["Extra:CodingCount"] = (
            tbl_PPM_Encounter_V25_new_merged["Extra:CodingCount"].fillna(0)
        )
        tbl_PPM_Encounter_V25_new_merged = tbl_PPM_Encounter_V25_new_merged[
            [
                "EncounterNumber",
                "EncounterType",
                "PatientNumber",
                "EpisodeOfCare",
                "Hospital",
                "StartDateTime",
                "EndDateTime",
                "Extra:stay_number",
                "Extra:LHDIdentifier",
                "Extra:episode_sequence_number",
                "AdmissionCategory",
                "AdmissionElection",
                "AdmissionSource",
                "AdmissionType",
                "AdmissionWeight",
                "Age",
                "AttendingConsultant",
                "AttendingConsultantSpecialty",
                "DischargeElection",
                "DischargeStatus",
                "Classification:DRGV11",
                "Extra:AdmittingSpecialtyPortal",
                "Extra:AICU1_Hours",
                "Extra:AICU2_Hours",
                "Extra:AICU3_Hours",
                "Extra:AssessOnly",
                "Extra:AUID",
                "Extra:bookingIdentifier",
                "Extra:CareFocus",
                "Extra:CaseType",
                "Extra:CCU_Hours",
                "Extra:Collabrtve_Care_Facility",
                "Extra:Collabrtve_Care_Role",
                "Extra:Collabrtve_Care_Type",
                "Extra:compensable_nwau",
                "Extra:Contract_Status",
                "Extra:PsychDays",
                "Extra:Delirium_Flag",
                "Extra:Dementia_Flag",
                "Extra:DRG1_pccl",
                "Classification:SNAPV5",
                "Classification:AMHCCV1",
                "Extra:EDStatus",
                "Extra:CompStatus",
                "Extra:StartDateTime_Episode",
                "Extra:EndDateTime_Episode",
                "Extra:EpisodeLeaveDays",
                "Extra:EpisodeLeaveDays_Episode",
                "Extra:EpisodeofCare_Episode",
                "Extra:EpisType",
                "Extra:ESRGcurrent",
                "Extra:ExtractDate",
                "Extra:FacilityTransferredfrom",
                "Extra:FacilityTransferredto",
                "Extra:FacilityType",
                "Extra:HDU_Hours",
                "Extra:HITH_Hours",
                "Extra:HospInsuranceonAdmit",
                "Extra:ICUStatus",
                "Extra:Impair",
                "Extra:indicatorProcedurecode",
                "Extra:IndigenousStatus",
                "Extra:IntendedSameDay",
                "Extra:LeaveinCostingPeriod",
                "Extra:LegalStatus",
                "Extra:LengthofStay_Episode",
                "Extra:LGACode",
                "Extra:LHD_of_Usual_Residence",
                "Extra:LOSinCostingPeriod",
                "Extra:MaintType",
                "Extra:MDC",
                "Extra:MedicareEligibility",
                "Extra:MHPhaseSeqNo",
                "Extra:MothersEncounterNumber",
                "Extra:MothersMRN",
                "Extra:MothersPersonIdentifier",
                "Extra:MothersStayNumber",
                "Extra:MRN",
                "Extra:Subprogram",
                "Extra:NICU_Hours",
                "Extra:nwau",
                "Extra:nwau_base",
                "Extra:nwau_cwt_type",
                "Extra:nwau_icu_incr",
                "Extra:nwau_indig_incr",
                "Extra:nwau_paed_incr",
                "Extra:nwau_private_patient_accom_incr",
                "Extra:nwau_private_patient_service_incr",
                "Extra:nwau_PublicEquivModel",
                "Extra:nwau_remote_incr",
                "Extra:nwau_version",
                "Extra:Outlierdays",
                "Extra:Phase",
                "Extra:PICU_Hours",
                "Extra:ProdType",
                "Extra:PSICU_Hours",
                "Extra:QualifiedDays",
                "Extra:Radiotherapy_adj",
                "Extra:ReasonforRemoval",
                "Extra:ReferralFurtherHealthcare",
                "Extra:SCN_Hours",
                "Extra:SNAPCareType",
                "Extra:sp_psy_age_adj",
                "Extra:SpecialtyPortal",
                "Extra:SRG_Version",
                "Extra:SRGcurrent",
                "Extra:SurgeryIndicator",
                "Extra:TrimPoint",
                "Extra:UnplannedReadmission",
                "Extra:UnplannedTheatre",
                "Extra:ExtractorVersion",
                "Extra:waitinglistcategory",
                "Extra:WIP",
                "Extra:WIP2",
                "FinancialClass",
                "HealthFund",
                "ICUHours",
                "LengthOfStay",
                "MaritalStatus",
                "MechVentHours",
                "PostCode",
                "Suburb",
                "Extra:FIMBathBeg",
                "Extra:FIMBathEnd",
                "Extra:FIMBladderBeg",
                "Extra:FIMBladderEnd",
                "Extra:FIMBowelBeg",
                "Extra:FIMBowelEnd",
                "Extra:FIMCompBeg",
                "Extra:FIMCompEnd",
                "Extra:FIMEatBeg",
                "Extra:FIMEatEnd",
                "Extra:FIMExpBeg",
                "Extra:FIMExpEnd",
                "Extra:FIMGroomBeg",
                "Extra:FIMGroomEnd",
                "Extra:FIMLowerBeg",
                "Extra:FIMLowerEnd",
                "Extra:FIMMemoryBeg",
                "Extra:FIMMemoryEnd",
                "Extra:FIMProbBeg",
                "Extra:FIMProbEnd",
                "Extra:FIMSocialBeg",
                "Extra:FIMSocialEnd",
                "Extra:FIMStairBeg",
                "Extra:FIMStairEnd",
                "Extra:FIMToiletBeg",
                "Extra:FIMToiletEnd",
                "Extra:FIMTubBeg",
                "Extra:FIMTubEnd",
                "Extra:FIMUpperBeg",
                "Extra:FIMUpperEnd",
                "Extra:FIMWalkBeg",
                "Extra:FIMWalkEnd",
                "Extra:FIMXferBeg",
                "Extra:FIMXferEnd",
                "Extra:FIMXferToilBeg",
                "Extra:FIMXferToilEnd",
                "Extra:HON1",
                "Extra:HON2",
                "Extra:HON3",
                "Extra:HON4",
                "Extra:HON5",
                "Extra:HON6",
                "Extra:HON7",
                "Extra:HON8",
                "Extra:HON9",
                "Extra:HON10",
                "Extra:HON11",
                "Extra:HON12",
                "Extra:HON13",
                "Extra:HON14",
                "Extra:HON15",
                "Extra:HONOS1",
                "Extra:HONOS2",
                "Extra:HONOS3",
                "Extra:HONOS4",
                "Extra:HONOS5",
                "Extra:HONOS6",
                "Extra:HONOS7",
                "Extra:HONOS8",
                "Extra:HONOS9",
                "Extra:HONOS10",
                "Extra:HONOS11",
                "Extra:HONOS12",
                "Extra:HONOS65_1",
                "Extra:HONOS65_2",
                "Extra:HONOS65_3",
                "Extra:HONOS65_4",
                "Extra:HONOS65_5",
                "Extra:HONOS65_6",
                "Extra:HONOS65_7",
                "Extra:HONOS65_8",
                "Extra:HONOS65_9",
                "Extra:HONOS65_10",
                "Extra:HONOS65_11",
                "Extra:HONOS65_12",
                "Extra:HONOSCA1",
                "Extra:HONOSCA2",
                "Extra:HONOSCA3",
                "Extra:HONOSCA4",
                "Extra:HONOSCA5",
                "Extra:HONOSCA6",
                "Extra:HONOSCA7",
                "Extra:HONOSCA8",
                "Extra:HONOSCA9",
                "Extra:HONOSCA10",
                "Extra:HONOSCA11",
                "Extra:HONOSCA12",
                "Extra:HONOSCA13",
                "Extra:HONOSCA14",
                "Extra:HONOSCA15",
                "Extra:IHPA_LSP_01",
                "Extra:IHPA_LSP_02",
                "Extra:IHPA_LSP_03",
                "Extra:IHPA_LSP_04",
                "Extra:IHPA_LSP_05",
                "Extra:IHPA_LSP_06",
                "Extra:IHPA_LSP_07",
                "Extra:IHPA_LSP_08",
                "Extra:IHPA_LSP_09",
                "Extra:IHPA_LSP_10",
                "Extra:IHPA_LSP_11",
                "Extra:IHPA_LSP_12",
                "Extra:IHPA_LSP_13",
                "Extra:IHPA_LSP_14",
                "Extra:IHPA_LSP_15",
                "Extra:IHPA_LSP_16",
                "Extra:HonActiveBeg",
                "Extra:HonActiveEnd",
                "Extra:HonADLBeg",
                "Extra:HonADLEnd",
                "Extra:HonCognitBeg",
                "Extra:HonCognitEnd",
                "Extra:HonDeprsBeg",
                "Extra:HonDeprsEnd",
                "Extra:HonDisabBeg",
                "Extra:HonDisabEnd",
                "Extra:HonDrinkBeg",
                "Extra:HonDrinkEnd",
                "Extra:HonHallucBeg",
                "Extra:HonHallucEnd",
                "Extra:HonInjuryBeg",
                "Extra:HonInjuryEnd",
                "Extra:HonLivingBeg",
                "Extra:HonLivingEnd",
                "Extra:HonOccupBeg",
                "Extra:HonOccupEnd",
                "Extra:HonOtherBeg",
                "Extra:HonOtherEnd",
                "Extra:HonRelatBeg",
                "Extra:HonRelatEnd",
                "Extra:PCFamilyCarerScoreStart",
                "Extra:PCPsychSpiritualScoreStart",
                "Extra:PCSeverityStart",
                "Extra:PCSymptomScoreStart",
                "Extra:RugBedBeg",
                "Extra:RugEatBeg",
                "Extra:RugToilBeg",
                "Extra:RugXferBeg",
                "Extra:HLTH_ORG_OSP_OSP_ID",
                "Extra:MG_AUTH_OSP_OSP_ID",
                "Extra:SE_CBK_SK",
                "Extra:CL_ID_EUID",
                "Extra:CL_ID_IHI",
                "Extra:HLTH_ORG_OSP_TYP",
                "Extra:SRV_ENC_REC_ID",
                "Extra:FRML_DISCH_MODE_CD",
                "Extra:SE_SEP_MODE_NHDD_CD",
                "Extra:Responsible_Facility",
                "Extra:SE_TYP_CD",
                "Extra:SE_ADM_MODE_NHDD_CD",
                "Extra:DIM_RSP_ISP_SK",
                "Extra:AR_DRG_ECCS_RAW",
                "Extra:WAU_ADJ_PT_TX_REMT_AREA",
                "Extra:WAU_ADJ_DIALYSIS",
                "Extra:WAU_ADJ_COVID19",
                "Extra:WAU_ADJ_HAC",
                "Extra:RoundID",
                "Extra:ProcedureCount",
                "Extra:DiagnosisCount",
                "Extra:CodingCount",
                "Extra:ASGS_SA_L2_16_CD",
                "Extra:CL_URES_ADDR_ASGS21_SA_L2_CD",
            ]
        ]

        tbl_PPM_Encounter_V25_supp = tbl_PPM_Encounter_V25_new_merged[
            [
                "EncounterNumber",
                "Extra:RoundID",
                "Extra:SE_CBK_SK",
                "Extra:ExtractDate",
                "Extra:ExtractorVersion",
                "StartDateTime",
                "EndDateTime",
                "Extra:StartDateTime_Episode",
                "Extra:EndDateTime_Episode",
                "Extra:AR_DRG_ECCS_RAW",
                "Extra:ASGS_SA_L2_16_CD",
                "Extra:CL_URES_ADDR_ASGS21_SA_L2_CD",
                "Extra:EpisodeLeaveDays_Episode",
                "Extra:HLTH_ORG_OSP_TYP",
                "Extra:LengthofStay_Episode",
                "Extra:FRML_DISCH_MODE_CD",
                "Extra:Responsible_Facility",
                "Extra:SE_SEP_MODE_NHDD_CD",
                "Extra:SRV_ENC_REC_ID",
                "Extra:WAU_ADJ_COVID19",
                "Extra:WAU_ADJ_DIALYSIS",
                "Extra:WAU_ADJ_HAC",
                "Extra:WAU_ADJ_PT_TX_REMT_AREA",
                "Extra:AICU1_Hours",
                "Extra:AICU2_Hours",
                "Extra:AICU3_Hours",
                "Extra:CCU_Hours",
                "Extra:compensable_nwau",
                "Extra:HDU_Hours",
                "Extra:HITH_Hours",
                "ICUHours",
                "Extra:LeaveinCostingPeriod",
                "LengthOfStay",
                "Extra:LOSinCostingPeriod",
                "MechVentHours",
                "Extra:NICU_Hours",
                "Extra:nwau",
                "Extra:nwau_base",
                "Extra:nwau_cwt_type",
                "Extra:nwau_icu_incr",
                "Extra:nwau_indig_incr",
                "Extra:nwau_paed_incr",
                "Extra:nwau_private_patient_accom_incr",
                "Extra:nwau_private_patient_service_incr",
                "Extra:nwau_PublicEquivModel",
                "Extra:nwau_remote_incr",
                "Extra:nwau_version",
                "Extra:PICU_Hours",
                "Extra:PSICU_Hours",
                "Extra:PsychDays",
                "Extra:QualifiedDays",
                "Extra:Radiotherapy_adj",
            ]
        ]
        date_str = datetime.datetime.today().strftime("%d%b%Y")
        try:
            tbl_PPM_Encounter_V25_new_merged.to_csv(
                "./ExtractorDB/Tbl_PPM_Encounter_FULL_" + versionID_underscore + ".csv",
                index=False,
                na_rep="",
                float_format=str,
                decimal=str,
                date_format=str,
            )
            tbl_PPM_Encounter_V25_supp.to_csv(
                "./Output/Tbl_Non_PPM_IP_Encounter_"
                + lhd_global
                + "_"
                + versionID_underscore
                + "_"
                + date_str
                + ".csv",
                index=False,
                na_rep="",
                float_format=str,
                decimal=str,
                date_format=str,
            )
            # os.chmod('./Output/Tbl_Non_PPM_IP_Encounter_'+lhd_global+'_'+versionID_underscore+'_'+date_str+'.csv', stat.S_IREAD)
            # os.chmod('./Output/Tbl_Non_PPM_IP_Encounter_'+lhd_global+'_'+versionID_underscore+'_'+date_str+'.csv')
            with zipfile.ZipFile(
                "./Output/Tbl_Non_PPM_IP_Encounter_"
                + lhd_global
                + "_"
                + versionID_underscore
                + "_"
                + date_str
                + ".zip",
                "w",
                zipfile.ZIP_DEFLATED,
            ) as zipf:
                zipf.write(
                    "./Output/Tbl_Non_PPM_IP_Encounter_"
                    + lhd_global
                    + "_"
                    + versionID_underscore
                    + "_"
                    + date_str
                    + ".csv",
                    arcname="Tbl_Non_PPM_IP_Encounter_"
                    + lhd_global
                    + "_"
                    + versionID_underscore
                    + "_"
                    + date_str
                    + ".csv",
                )
            if os.path.exists(
                "./Output/Tbl_Non_PPM_IP_Encounter_"
                + lhd_global
                + "_"
                + versionID_underscore
                + "_"
                + date_str
                + ".csv"
            ):
                os.remove(
                    "./Output/Tbl_Non_PPM_IP_Encounter_"
                    + lhd_global
                    + "_"
                    + versionID_underscore
                    + "_"
                    + date_str
                    + ".csv"
                )
        except Exception as e:
            logging.exception("Exception occurred")
            label_9_status = 0
            messagebox.showerror(
                "Export Error", "Error exporting tbl_PPM_Encounter_updated.\n" + str(e)
            )
            label_9_sub.configure(text="Failed ()...", fg="red")
            main_screen.update()
            return  # stop export
        cleanup_memory(tbl_PPM_Encounter_V25_supp)
        logging.info("tbl_PPM_Encounter_V25_supp generated.")
        tbl_PPM_Encounter_V25_new_merged = tbl_PPM_Encounter_V25_new_merged[
            [
                "EncounterNumber",
                "EncounterType",
                "PatientNumber",
                "EpisodeOfCare",
                "Hospital",
                "StartDateTime",
                "EndDateTime",
                "Extra:stay_number",
                "Extra:LHDIdentifier",
                "Extra:episode_sequence_number",
                "AdmissionCategory",
                "AdmissionElection",
                "AdmissionSource",
                "AdmissionType",
                "AdmissionWeight",
                "Age",
                "AttendingConsultant",
                "AttendingConsultantSpecialty",
                "DischargeElection",
                "DischargeStatus",
                "Classification:DRGV11",
                "Extra:AdmittingSpecialtyPortal",
                "Extra:AICU1_Hours",
                "Extra:AICU2_Hours",
                "Extra:AICU3_Hours",
                "Extra:AssessOnly",
                "Extra:AUID",
                "Extra:bookingIdentifier",
                "Extra:CareFocus",
                "Extra:CaseType",
                "Extra:CCU_Hours",
                "Extra:Collabrtve_Care_Facility",
                "Extra:Collabrtve_Care_Role",
                "Extra:Collabrtve_Care_Type",
                "Extra:compensable_nwau",
                "Extra:Contract_Status",
                "Extra:PsychDays",
                "Extra:Delirium_Flag",
                "Extra:Dementia_Flag",
                "Extra:DRG1_pccl",
                "Classification:SNAPV5",
                "Classification:AMHCCV1",
                "Extra:EDStatus",
                "Extra:CompStatus",
                "Extra:StartDateTime_Episode",
                "Extra:EndDateTime_Episode",
                "Extra:EpisodeLeaveDays",
                "Extra:EpisodeLeaveDays_Episode",
                "Extra:EpisodeofCare_Episode",
                "Extra:EpisType",
                "Extra:ESRGcurrent",
                "Extra:ExtractDate",
                "Extra:FacilityTransferredfrom",
                "Extra:FacilityTransferredto",
                "Extra:FacilityType",
                "Extra:HDU_Hours",
                "Extra:HITH_Hours",
                "Extra:HospInsuranceonAdmit",
                "Extra:ICUStatus",
                "Extra:Impair",
                "Extra:indicatorProcedurecode",
                "Extra:IndigenousStatus",
                "Extra:IntendedSameDay",
                "Extra:LeaveinCostingPeriod",
                "Extra:LegalStatus",
                "Extra:LengthofStay_Episode",
                "Extra:LGACode",
                "Extra:LHD_of_Usual_Residence",
                "Extra:LOSinCostingPeriod",
                "Extra:MaintType",
                "Extra:MDC",
                "Extra:MedicareEligibility",
                "Extra:MHPhaseSeqNo",
                "Extra:MothersEncounterNumber",
                "Extra:MothersMRN",
                "Extra:MothersPersonIdentifier",
                "Extra:MothersStayNumber",
                "Extra:MRN",
                "Extra:Subprogram",
                "Extra:NICU_Hours",
                "Extra:nwau",
                "Extra:nwau_base",
                "Extra:nwau_cwt_type",
                "Extra:nwau_icu_incr",
                "Extra:nwau_indig_incr",
                "Extra:nwau_paed_incr",
                "Extra:nwau_private_patient_accom_incr",
                "Extra:nwau_private_patient_service_incr",
                "Extra:nwau_PublicEquivModel",
                "Extra:nwau_remote_incr",
                "Extra:nwau_version",
                "Extra:Outlierdays",
                "Extra:Phase",
                "Extra:PICU_Hours",
                "Extra:ProdType",
                "Extra:PSICU_Hours",
                "Extra:QualifiedDays",
                "Extra:Radiotherapy_adj",
                "Extra:ReasonforRemoval",
                "Extra:ReferralFurtherHealthcare",
                "Extra:SCN_Hours",
                "Extra:SNAPCareType",
                "Extra:sp_psy_age_adj",
                "Extra:SpecialtyPortal",
                "Extra:SRG_Version",
                "Extra:SRGcurrent",
                "Extra:SurgeryIndicator",
                "Extra:TrimPoint",
                "Extra:UnplannedReadmission",
                "Extra:UnplannedTheatre",
                "Extra:ExtractorVersion",
                "Extra:waitinglistcategory",
                "Extra:WIP",
                "Extra:WIP2",
                "FinancialClass",
                "HealthFund",
                "ICUHours",
                "LengthOfStay",
                "MaritalStatus",
                "MechVentHours",
                "PostCode",
                "Suburb",
                "Extra:FIMBathBeg",
                "Extra:FIMBathEnd",
                "Extra:FIMBladderBeg",
                "Extra:FIMBladderEnd",
                "Extra:FIMBowelBeg",
                "Extra:FIMBowelEnd",
                "Extra:FIMCompBeg",
                "Extra:FIMCompEnd",
                "Extra:FIMEatBeg",
                "Extra:FIMEatEnd",
                "Extra:FIMExpBeg",
                "Extra:FIMExpEnd",
                "Extra:FIMGroomBeg",
                "Extra:FIMGroomEnd",
                "Extra:FIMLowerBeg",
                "Extra:FIMLowerEnd",
                "Extra:FIMMemoryBeg",
                "Extra:FIMMemoryEnd",
                "Extra:FIMProbBeg",
                "Extra:FIMProbEnd",
                "Extra:FIMSocialBeg",
                "Extra:FIMSocialEnd",
                "Extra:FIMStairBeg",
                "Extra:FIMStairEnd",
                "Extra:FIMToiletBeg",
                "Extra:FIMToiletEnd",
                "Extra:FIMTubBeg",
                "Extra:FIMTubEnd",
                "Extra:FIMUpperBeg",
                "Extra:FIMUpperEnd",
                "Extra:FIMWalkBeg",
                "Extra:FIMWalkEnd",
                "Extra:FIMXferBeg",
                "Extra:FIMXferEnd",
                "Extra:FIMXferToilBeg",
                "Extra:FIMXferToilEnd",
                "Extra:HON1",
                "Extra:HON2",
                "Extra:HON3",
                "Extra:HON4",
                "Extra:HON5",
                "Extra:HON6",
                "Extra:HON7",
                "Extra:HON8",
                "Extra:HON9",
                "Extra:HON10",
                "Extra:HON11",
                "Extra:HON12",
                "Extra:HON13",
                "Extra:HON14",
                "Extra:HON15",
                "Extra:HONOS1",
                "Extra:HONOS2",
                "Extra:HONOS3",
                "Extra:HONOS4",
                "Extra:HONOS5",
                "Extra:HONOS6",
                "Extra:HONOS7",
                "Extra:HONOS8",
                "Extra:HONOS9",
                "Extra:HONOS10",
                "Extra:HONOS11",
                "Extra:HONOS12",
                "Extra:HONOS65_1",
                "Extra:HONOS65_2",
                "Extra:HONOS65_3",
                "Extra:HONOS65_4",
                "Extra:HONOS65_5",
                "Extra:HONOS65_6",
                "Extra:HONOS65_7",
                "Extra:HONOS65_8",
                "Extra:HONOS65_9",
                "Extra:HONOS65_10",
                "Extra:HONOS65_11",
                "Extra:HONOS65_12",
                "Extra:HONOSCA1",
                "Extra:HONOSCA2",
                "Extra:HONOSCA3",
                "Extra:HONOSCA4",
                "Extra:HONOSCA5",
                "Extra:HONOSCA6",
                "Extra:HONOSCA7",
                "Extra:HONOSCA8",
                "Extra:HONOSCA9",
                "Extra:HONOSCA10",
                "Extra:HONOSCA11",
                "Extra:HONOSCA12",
                "Extra:HONOSCA13",
                "Extra:HONOSCA14",
                "Extra:HONOSCA15",
                "Extra:IHPA_LSP_01",
                "Extra:IHPA_LSP_02",
                "Extra:IHPA_LSP_03",
                "Extra:IHPA_LSP_04",
                "Extra:IHPA_LSP_05",
                "Extra:IHPA_LSP_06",
                "Extra:IHPA_LSP_07",
                "Extra:IHPA_LSP_08",
                "Extra:IHPA_LSP_09",
                "Extra:IHPA_LSP_10",
                "Extra:IHPA_LSP_11",
                "Extra:IHPA_LSP_12",
                "Extra:IHPA_LSP_13",
                "Extra:IHPA_LSP_14",
                "Extra:IHPA_LSP_15",
                "Extra:IHPA_LSP_16",
                "Extra:HonActiveBeg",
                "Extra:HonActiveEnd",
                "Extra:HonADLBeg",
                "Extra:HonADLEnd",
                "Extra:HonCognitBeg",
                "Extra:HonCognitEnd",
                "Extra:HonDeprsBeg",
                "Extra:HonDeprsEnd",
                "Extra:HonDisabBeg",
                "Extra:HonDisabEnd",
                "Extra:HonDrinkBeg",
                "Extra:HonDrinkEnd",
                "Extra:HonHallucBeg",
                "Extra:HonHallucEnd",
                "Extra:HonInjuryBeg",
                "Extra:HonInjuryEnd",
                "Extra:HonLivingBeg",
                "Extra:HonLivingEnd",
                "Extra:HonOccupBeg",
                "Extra:HonOccupEnd",
                "Extra:HonOtherBeg",
                "Extra:HonOtherEnd",
                "Extra:HonRelatBeg",
                "Extra:HonRelatEnd",
                "Extra:PCFamilyCarerScoreStart",
                "Extra:PCPsychSpiritualScoreStart",
                "Extra:PCSeverityStart",
                "Extra:PCSymptomScoreStart",
                "Extra:RugBedBeg",
                "Extra:RugEatBeg",
                "Extra:RugToilBeg",
                "Extra:RugXferBeg",
                "Extra:HLTH_ORG_OSP_OSP_ID",
                "Extra:MG_AUTH_OSP_OSP_ID",
                "Extra:SE_CBK_SK",
                "Extra:CL_ID_EUID",
                "Extra:CL_ID_IHI",
                "Extra:HLTH_ORG_OSP_TYP",
                "Extra:SRV_ENC_REC_ID",
                "Extra:FRML_DISCH_MODE_CD",
                "Extra:SE_SEP_MODE_NHDD_CD",
                "Extra:SE_TYP_CD",
                "Extra:SE_ADM_MODE_NHDD_CD",
                "Extra:DIM_RSP_ISP_SK",
                "Extra:WAU_ADJ_PT_TX_REMT_AREA",
                "Extra:RoundID",
                "Extra:ProcedureCount",
                "Extra:DiagnosisCount",
                "Extra:CodingCount",
            ]
        ]
        try:
            tbl_PPM_Encounter_V25_new_merged.to_csv(
                "./Output/Tbl_PPM_Encounter_" + versionID_underscore + ".csv",
                index=False,
                na_rep="",
                float_format=str,
                decimal=str,
                date_format=str,
            )
        except Exception as e:
            logging.exception("Exception occurred")
            label_9_status = 0
            messagebox.showerror(
                "Export Error", "Error exporting tbl_PPM_Encounter_updated.\n" + str(e)
            )
            label_9_sub.configure(text="Failed ()...", fg="red")
            main_screen.update()
            return  # stop export
        cleanup_memory(tbl_PPM_Encounter_V25_new_merged)
        logging.info("tbl_PPM_Encounter_V25_new_merged generated.")
        """
        ###############################################################################
        # https://abft101.atlassian.net/browse/AQA-346 New QC file: Identify missing encounters between Transfer and IP file
        file_tbl_PPM_Transfer = "./Output/tbl_PPM_Transfer_"+versionID_hash+".csv"
        if os.path.isfile(file_tbl_PPM_Transfer):
            try:
                tbl_PPM_Transfer = read_csv_file(file_tbl_PPM_Transfer, encoding = 'unicode_escape', dtype=str, keep_default_na=False, na_values='')
            except Exception as e:
                logging.exception("Exception occurred")
                label_9_status = 0
                messagebox.showerror("File Error","Error extracting tbl_PPM_Transfer from ./Output/tbl_PPM_Transfer.csv.\n"+str(e))
                label_9_sub.configure(text="Failed (tbl_PPM_Transfer)...",fg='red')
                main_screen.update()
                return
            else:
                tbl_PPM_Transfer = tbl_PPM_Transfer.applymap(str)#.apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
                tbl_PPM_Transfer = tbl_PPM_Transfer.applymap(lambda x: x.strip() if isinstance(x, str) else x)
                tbl_PPM_Transfer = tbl_PPM_Transfer.apply(lambda x: x.replace(regex=r'^NaT$', value='') if x.dtype == 'object' else x)
                tbl_PPM_Transfer = tbl_PPM_Transfer.apply(lambda x: x.replace(regex=r'^nan$', value='') if x.dtype == 'object' else x)
        else:
            tbl_PPM_Transfer = pd.DataFrame()
        
        qc_IP_Transfer = pd.DataFrame({'EncounterNumber': pd.concat([tbl_PPM_Encounter_V25_new_merged['EncounterNumber'], tbl_PPM_Transfer['EncounterNumber']]).unique()})
        # Define a function to populate the Details column
        def get_details(encounter):
            in_encounter = encounter in tbl_PPM_Encounter_V25_new_merged['EncounterNumber'].values
            in_transfer = encounter in tbl_PPM_Transfer['EncounterNumber'].values
            
            if in_encounter and in_transfer:
                return "present in Transfer and IP"
            elif in_transfer:
                return "present in Transfer not in IP"
            else:
                return "present in IP not in Transfer"

        # Apply the function to get the Details
        qc_IP_Transfer['Details'] = qc_IP_Transfer['EncounterNumber'].apply(get_details)
        qc_IP_Transfer.to_csv('./Output/QualityChecks_Encounters_in_Transfer_and_IP.csv', index=False, na_rep='', float_format=str, decimal=str, date_format=str)
        """
        ###############################################################################
        logging.info("Export tbl_ppm_ED_Encounter started.")
        # Export tbl_ppm_ED_Encounter before SNOMED and AECC update to /ExtractorDB
        try:
            tbl_PPM_ED_Encounter.to_csv(
                "./ExtractorDB/tbl_PPM_ED_Encounter_"
                + versionID_hash
                + "_before_snomed_update.csv",
                index=False,
                na_rep="",
                float_format=str,
                decimal=str,
                date_format=str,
            )
        except Exception as e:
            logging.exception("Exception occurred")
            label_9_status = 0
            messagebox.showerror(
                "Export Error",
                "Error exporting tbl_PPM_ED_Encounter.csv to ExtractorDB, before SNOMED and AECC update \n"
                + str(e),
            )
            label_9_sub.configure(text="Failed ()...", fg="red")
            main_screen.update()
            return  # stop export
        logging.info(
            "%s records saved to ./ExtractorDB/tbl_PPM_ED_Encounter.csv.",
            len(tbl_PPM_ICD_procedures_V25),
        )
        ###############################################################################
        # Access query: qry_Update_SNOMED_Diag_to_P
        # UPDATE Tbl_ppm_ED_Encounter_25 INNER JOIN snomed_Update ON (Tbl_ppm_ED_Encounter_25.Hospital = snomed_Update.facility_identifier) AND (Tbl_ppm_ED_Encounter_25.[Extra:ED_visit_identifier] = snomed_Update.ed_visit_identifier) SET Tbl_ppm_ED_Encounter_25.[Extra:EDDiagnosis] = [P_Diag], Tbl_ppm_ED_Encounter_25.[Extra:EDDiagnosisType] = "SNOMEDCT"
        # WHERE (((Tbl_ppm_ED_Encounter_25.[Extra:EDDiagnosis]) Is Null));
        tbl_ppm_ED_Encounter_25 = pd.merge(
            tbl_PPM_ED_Encounter,
            snomed_Update,
            how="left",
            left_on=["Hospital", "Extra:ED_visit_identifier"],
            right_on=["facility_identifier", "ed_visit_identifier"],
            suffixes=("", "_drop"),
            indicator=True,
        )
        tbl_ppm_ED_Encounter_25 = tbl_ppm_ED_Encounter_25.apply(
            lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
        )
        tbl_ppm_ED_Encounter_25["Extra:EDDiagnosis"] = np.where(
            (
                (tbl_ppm_ED_Encounter_25["Extra:EDDiagnosis"].isnull())
                | (tbl_ppm_ED_Encounter_25["Extra:EDDiagnosis"] == "")
            )
            & (tbl_ppm_ED_Encounter_25["_merge"] == "both"),
            tbl_ppm_ED_Encounter_25["P_Diag"],
            tbl_ppm_ED_Encounter_25["Extra:EDDiagnosis"],
        )
        tbl_ppm_ED_Encounter_25["Extra:EDDiagnosisType"] = np.where(
            (
                (tbl_ppm_ED_Encounter_25["Extra:EDDiagnosis"].isnull())
                | (tbl_ppm_ED_Encounter_25["Extra:EDDiagnosis"] == "")
            )
            & (tbl_ppm_ED_Encounter_25["_merge"] == "both"),
            "SNOMEDCT",
            tbl_ppm_ED_Encounter_25["Extra:EDDiagnosisType"],
        )
        tbl_ppm_ED_Encounter_25.drop(["_merge"], axis=1, inplace=True)
        logging.info("qry_Update_SNOMED_Diag_to_P completed.")
        ############# FOR ROUND 27 AND ABOVE - STOP #######################
        # Access query: qry_update_AECC_NWAU_SNOMEDCT
        # UPDATE AECC INNER JOIN Tbl_ppm_ED_Encounter_25 ON (Tbl_ppm_ED_Encounter_25.[Extra:ED_visit_identifier] = AECC.ed_visit_identifier) AND (AECC.facility_identifier = Tbl_ppm_ED_Encounter_25.Hospital) SET Tbl_ppm_ED_Encounter_25.DRG1 = [aecc_end_class], Tbl_ppm_ED_Encounter_25.DRG1Version = [aecc_version], Tbl_ppm_ED_Encounter_25.[Extra:nwau_base] = [nwau_base], Tbl_ppm_ED_Encounter_25.[Extra:nwau_version] = [nwau_version], Tbl_ppm_ED_Encounter_25.[Extra:compensable_nwau] = [compensable_nwau], Tbl_ppm_ED_Encounter_25.[Extra:nwau_indig_incr] = [indigenous_adj], Tbl_ppm_ED_Encounter_25.[Extra:EDDiagnosis] = IIf([Tbl_ppm_ED_Encounter_25]![Extra:EDDiagnosis]>"0",IIf([Tbl_ppm_ED_Encounter_25]![Extra:EDDiagnosisType]="SNOMEDCT","SCT" & [Tbl_ppm_ED_Encounter_25]![Extra:EDDiagnosis],[Tbl_ppm_ED_Encounter_25]![Extra:EDDiagnosis])), Tbl_ppm_ED_Encounter_25.[Extra:nwau_type] = "AECC", Tbl_ppm_ED_Encounter_25.[Extra:nwau] = [nwau_final];
        # tbl_ppm_ED_Encounter_25 = pd.merge(tbl_PPM_ED_Encounter, aecc, how='left', left_on=['Hospital', 'Extra:ED_visit_identifier'], right_on=['facility_identifier', 'ed_visit_identifier'], suffixes=('', '_drop'), indicator=True)
        tbl_ppm_ED_Encounter_25 = pd.merge(
            tbl_ppm_ED_Encounter_25,
            aecc,
            how="left",
            left_on=["Hospital", "Extra:ED_visit_identifier"],
            right_on=["facility_identifier", "ed_visit_identifier"],
            suffixes=("", "_drop"),
            indicator=True,
        )
        tbl_ppm_ED_Encounter_25 = tbl_ppm_ED_Encounter_25.apply(
            lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
        )
        tbl_ppm_ED_Encounter_25["DRG1"] = np.where(
            (tbl_ppm_ED_Encounter_25["_merge"] == "both"),
            tbl_ppm_ED_Encounter_25["aecc_end_class"],
            tbl_ppm_ED_Encounter_25["DRG1"],
        )
        tbl_ppm_ED_Encounter_25["DRG1Version"] = np.where(
            (tbl_ppm_ED_Encounter_25["_merge"] == "both"),
            tbl_ppm_ED_Encounter_25["aecc_version"],
            tbl_ppm_ED_Encounter_25["DRG1Version"],
        )
        tbl_ppm_ED_Encounter_25["Extra:nwau_base"] = np.where(
            (tbl_ppm_ED_Encounter_25["_merge"] == "both"),
            tbl_ppm_ED_Encounter_25["nwau_base"],
            tbl_ppm_ED_Encounter_25["Extra:nwau_base"],
        )
        tbl_ppm_ED_Encounter_25["Extra:nwau_version"] = np.where(
            (tbl_ppm_ED_Encounter_25["_merge"] == "both"),
            tbl_ppm_ED_Encounter_25["nwau_version"],
            tbl_ppm_ED_Encounter_25["Extra:nwau_version"],
        )
        tbl_ppm_ED_Encounter_25["Extra:compensable_nwau"] = np.where(
            (tbl_ppm_ED_Encounter_25["_merge"] == "both"),
            tbl_ppm_ED_Encounter_25["compensable_nwau"],
            tbl_ppm_ED_Encounter_25["Extra:compensable_nwau"],
        )
        tbl_ppm_ED_Encounter_25["Extra:nwau_indig_incr"] = np.where(
            (tbl_ppm_ED_Encounter_25["_merge"] == "both"),
            tbl_ppm_ED_Encounter_25["indigenous_adj"],
            tbl_ppm_ED_Encounter_25["Extra:nwau_indig_incr"],
        )
        tbl_ppm_ED_Encounter_25["Extra:nwau_type"] = np.where(
            (tbl_ppm_ED_Encounter_25["_merge"] == "both"),
            "AECC",
            tbl_ppm_ED_Encounter_25["Extra:nwau_type"],
        )
        tbl_ppm_ED_Encounter_25["Extra:nwau"] = np.where(
            (tbl_ppm_ED_Encounter_25["_merge"] == "both"),
            tbl_ppm_ED_Encounter_25["nwau_final"],
            tbl_ppm_ED_Encounter_25["Extra:nwau"],
        )
        tbl_ppm_ED_Encounter_25["Extra:EDDiagnosis"] = np.where(
            (tbl_ppm_ED_Encounter_25["Extra:EDDiagnosis"] != "")
            & (pd.notna(tbl_ppm_ED_Encounter_25["Extra:EDDiagnosis"]))
            & (tbl_ppm_ED_Encounter_25["Extra:EDDiagnosis"] != "0")
            & (tbl_ppm_ED_Encounter_25["Extra:EDDiagnosisType"] == "SNOMEDCT"),
            "SCT" + tbl_ppm_ED_Encounter_25["Extra:EDDiagnosis"],
            tbl_ppm_ED_Encounter_25["Extra:EDDiagnosis"],
        )
        ###############################################################################
        tbl_ppm_ED_Encounter_25["Extra:EDVisitType"] = (
            tbl_ppm_ED_Encounter_25["Extra:EDVisitType"]
            .astype(str)
            .str.pad(2, side="left", fillchar="0")
        )
        tbl_ppm_ED_Encounter_25["Extra:EDReferralSource"] = (
            tbl_ppm_ED_Encounter_25["Extra:EDReferralSource"]
            .astype(str)
            .str.pad(2, side="left", fillchar="0")
        )
        tbl_ppm_ED_Encounter_25["Extra:UDG_IPHA"] = (
            tbl_ppm_ED_Encounter_25["Extra:UDG_IPHA"]
            .astype(str)
            .str.pad(2, side="left", fillchar="0")
        )
        logging.info("qry_update_AECC_NWAU_SNOMEDCT completed.")
        ###############################################################################
        # Export C:\costing\Output\Tbl_ppm_ED_Encounter_27.csv
        tbl_ppm_ED_Encounter_25 = tbl_ppm_ED_Encounter_25[
            [
                "EncounterNumber",
                "PostCode",
                "Suburb",
                "EncounterType",
                "PatientNumber",
                "Hospital",
                "LengthofStay",
                "StartDateTime",
                "EndDateTime",
                "Age",
                "WeightedSeparation",
                "Extra:InpatientStayNumber",
                "Extra:TriageCategory",
                "Extra:ModeofArrival",
                "Extra:EDVisitType",
                "Extra:EDDiagnosis",
                "Extra:ModeofSep",
                "Extra:EDTriageDateTime",
                "Extra:EDReferralSource",
                "Extra:IndigenousStatus",
                "Extra:MedicareNumber",
                "Extra:EmergRoleDelin",
                "Extra:UDG",
                "Extra:URG",
                "Extra:ClinStartDTTM",
                "Extra:DepartureReadyDTTM",
                "Extra:EDDiagnosisType",
                "Extra:EDDiagnosis2",
                "Extra:EDDiagnosisType2",
                "Extra:EDDiagnosis3",
                "Extra:EDDiagnosisType3",
                "Extra:AdmWard",
                "Extra:EdCompStatus",
                "Extra:ExtractorVersion",
                "Extra:nwau",
                "Extra:sla_ra06",
                "Extra:InpatientEncounterNumber",
                "Extra:postcode_ra06",
                "Extra:hosp_ra06",
                "Extra:MDB",
                "Extra:UDG_IPHA",
                "Extra:ED_visit_identifier",
                "Extra:ED_Hosp_A233",
                "Extra:LHD_of_Usual_Residence",
                "Extra:compensable_nwau",
                "Extra:nwau_base",
                "Extra:nwau_indig_incr",
                "Extra:nwau_version",
                "Extra:nwau_urg_ed_diagnosis_mapped",
                "Extra:nwau_type",
                "Extra:WIP",
                "DRG1",
                "DRG1Version",
                "Extra:N_Z_FinancialProgram",
                "Extra:ExtractDate",
                "Extra:AUID",
                "Extra:HLTH_ORG_OSP_OSP_ID",
                "Extra:MG_AUTH_OSP_OSP_ID",
                "Extra:SE_CBK_SK",
                "Extra:CL_ID_EUID",
                "Extra:CL_ID_IHI",
                "Extra:FST_BILL_CATEGORY_CD",
                "Extra:FST_FIN_CLASS_CD",
                "Extra:EDW_Pat_Number",
                "Extra:EDW_Enc_Number",
                "Extra:SRV_ENC_REC_ID",
                "Extra:WAU_ADJ_PT_TX_REMT_AREA",
                "Extra:WAU_ADJ_PT_RES_REMT_AREA",
                "Extra:EDDiag_ver",
                "Extra:EDINTERVENTION_VER",
                "Extra:EDINTERVENTION_CD",
                "Extra:ASGS_SA_L2_16_CD",
                "Extra:CL_URES_ADDR_ASGS21_SA_L2_CD",
                "Extra:AP_SE_CBK_SK",
                "Extra:IP_SRV_ENC_REC_ID",
            ]
        ]
        tbl_ppm_ED_Encounter_25 = tbl_ppm_ED_Encounter_25.applymap(
            str
        )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
        tbl_ppm_ED_Encounter_25 = tbl_ppm_ED_Encounter_25.applymap(
            lambda x: x.strip() if isinstance(x, str) else x
        )
        tbl_ppm_ED_Encounter_25 = tbl_ppm_ED_Encounter_25.apply(
            lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
        )
        tbl_ppm_ED_Encounter_25.drop_duplicates(keep="last", inplace=True)
        # AQA-315 - remove EDW_Enc_Number - not implemented for this file as it is not an input to PPM
        # tbl_ppm_ED_Encounter_25_new = tbl_ppm_ED_Encounter_25[['EncounterNumber', 'PostCode', 'Suburb', 'EncounterType', 'PatientNumber', 'Hospital', 'LengthofStay', 'StartDateTime', 'EndDateTime', 'Age', 'WeightedSeparation', 'Extra:InpatientStayNumber', 'Extra:TriageCategory', 'Extra:ModeofArrival', 'Extra:EDVisitType', 'Extra:EDDiagnosis', 'Extra:ModeofSep', 'Extra:EDTriageDateTime', 'Extra:EDReferralSource', 'Extra:IndigenousStatus', 'Extra:EmergRoleDelin', 'Extra:UDG', 'Extra:ClinStartDTTM', 'Extra:DepartureReadyDTTM', 'Extra:EDDiagnosisType', 'Extra:EDDiagnosis2', 'Extra:EDDiagnosisType2', 'Extra:EDDiagnosis3', 'Extra:EDDiagnosisType3', 'Extra:AdmWard', 'Extra:EdCompStatus', 'Extra:ExtractorVersion', 'Extra:nwau', 'Extra:InpatientEncounterNumber', 'Extra:MDB', 'Extra:ED_visit_identifier', 'Extra:LHD_of_Usual_Residence', 'Extra:compensable_nwau', 'Extra:nwau_base', 'Extra:nwau_indig_incr', 'Extra:nwau_version', 'Extra:nwau_urg_ed_diagnosis_mapped', 'Extra:nwau_type', 'Extra:WIP', 'DRG1', 'Extra:N_Z_FinancialProgram', 'Extra:ExtractDate', 'Extra:AUID', 'Extra:HLTH_ORG_OSP_OSP_ID', 'Extra:MG_AUTH_OSP_OSP_ID', 'Extra:SE_CBK_SK', 'Extra:CL_ID_EUID', 'Extra:CL_ID_IHI', 'Extra:FST_BILL_CATEGORY_CD', 'Extra:EDW_Pat_Number', 'Extra:EDW_Enc_Number']]

        tbl_ppm_ED_Encounter_25["Age"] = tbl_ppm_ED_Encounter_25["Age"].astype(
            int, errors="ignore"
        )
        tbl_ppm_ED_Encounter_25["Extra:AP_SE_CBK_SK"] = tbl_ppm_ED_Encounter_25[
            "Extra:AP_SE_CBK_SK"
        ].astype("Int64", errors="ignore")
        tbl_ppm_ED_Encounter_25_new = tbl_ppm_ED_Encounter_25[
            [
                "EncounterNumber",
                "PostCode",
                "Suburb",
                "EncounterType",
                "PatientNumber",
                "Hospital",
                "LengthofStay",
                "StartDateTime",
                "EndDateTime",
                "Age",
                "WeightedSeparation",
                "Extra:InpatientStayNumber",
                "Extra:TriageCategory",
                "Extra:ModeofArrival",
                "Extra:EDVisitType",
                "Extra:EDDiagnosis",
                "Extra:ModeofSep",
                "Extra:EDTriageDateTime",
                "Extra:EDReferralSource",
                "Extra:IndigenousStatus",
                "Extra:EmergRoleDelin",
                "Extra:UDG",
                "Extra:ClinStartDTTM",
                "Extra:DepartureReadyDTTM",
                "Extra:EDDiagnosisType",
                "Extra:EDDiagnosis2",
                "Extra:EDDiagnosisType2",
                "Extra:EDDiagnosis3",
                "Extra:EDDiagnosisType3",
                "Extra:AdmWard",
                "Extra:EdCompStatus",
                "Extra:ExtractorVersion",
                "Extra:nwau",
                "Extra:InpatientEncounterNumber",
                "Extra:MDB",
                "Extra:ED_visit_identifier",
                "Extra:LHD_of_Usual_Residence",
                "Extra:compensable_nwau",
                "Extra:nwau_base",
                "Extra:nwau_indig_incr",
                "Extra:nwau_version",
                "Extra:nwau_urg_ed_diagnosis_mapped",
                "Extra:nwau_type",
                "Extra:WIP",
                "DRG1",
                "Extra:N_Z_FinancialProgram",
                "Extra:ExtractDate",
                "Extra:AUID",
                "Extra:HLTH_ORG_OSP_OSP_ID",
                "Extra:MG_AUTH_OSP_OSP_ID",
                "Extra:SE_CBK_SK",
                "Extra:CL_ID_EUID",
                "Extra:CL_ID_IHI",
                "Extra:FST_BILL_CATEGORY_CD",
                "Extra:FST_FIN_CLASS_CD",
                "Extra:SRV_ENC_REC_ID",
                "Extra:WAU_ADJ_PT_TX_REMT_AREA",
                "Extra:WAU_ADJ_PT_RES_REMT_AREA",
                "Extra:EDDiag_ver",
                "Extra:EDINTERVENTION_VER",
                "Extra:EDINTERVENTION_CD",
                "Extra:ASGS_SA_L2_16_CD",
                "Extra:CL_URES_ADDR_ASGS21_SA_L2_CD",
                "Extra:AP_SE_CBK_SK",
                "Extra:IP_SRV_ENC_REC_ID",
            ]
        ]
        cleanup_memory(tbl_ppm_ED_Encounter_25)
        # 02 July removed , 'Extra:EDINTERVENTION_CD', 'Extra:EDDiag_ver'
        # tbl_ppm_ED_Encounter_25_new = tbl_ppm_ED_Encounter_25[['EncounterNumber', 'PostCode', 'Suburb', 'EncounterType', 'PatientNumber', 'Hospital', 'LengthofStay', 'StartDateTime', 'EndDateTime', 'Age', 'WeightedSeparation', 'Extra:InpatientStayNumber', 'Extra:TriageCategory', 'Extra:ModeofArrival', 'Extra:EDVisitType', 'Extra:EDDiagnosis', 'Extra:ModeofSep', 'Extra:EDTriageDateTime', 'Extra:EDReferralSource', 'Extra:IndigenousStatus', 'Extra:EmergRoleDelin', 'Extra:UDG', 'Extra:ClinStartDTTM', 'Extra:DepartureReadyDTTM', 'Extra:EDDiagnosisType', 'Extra:EDDiagnosis2', 'Extra:EDDiagnosisType2', 'Extra:EDDiagnosis3', 'Extra:EDDiagnosisType3', 'Extra:AdmWard', 'Extra:EdCompStatus', 'Extra:ExtractorVersion', 'Extra:nwau', 'Extra:InpatientEncounterNumber', 'Extra:MDB', 'Extra:ED_visit_identifier', 'Extra:LHD_of_Usual_Residence', 'Extra:compensable_nwau', 'Extra:nwau_base', 'Extra:nwau_indig_incr', 'Extra:nwau_version', 'Extra:nwau_urg_ed_diagnosis_mapped', 'Extra:nwau_type', 'Extra:WIP', 'DRG1', 'Extra:N_Z_FinancialProgram', 'Extra:ExtractDate', 'Extra:AUID', 'Extra:HLTH_ORG_OSP_OSP_ID', 'Extra:MG_AUTH_OSP_OSP_ID', 'Extra:SE_CBK_SK', 'Extra:CL_ID_EUID', 'Extra:CL_ID_IHI', 'Extra:FST_BILL_CATEGORY_CD', 'Extra:FST_FIN_CLASS_CD', 'Extra:SRV_ENC_REC_ID', 'Extra:WAU_ADJ_PT_TX_REMT_AREA', 'Extra:WAU_ADJ_PT_RES_REMT_AREA', 'Extra:EDINTERVENTION_VER']]
        # https://abft101.atlassian.net/browse/AQA-227 pad
        # List of columns to pad to two zeros before decimal
        columns_to_pad = ["Extra:ModeofSep"]
        for col in columns_to_pad:
            tbl_ppm_ED_Encounter_25_new[col] = tbl_ppm_ED_Encounter_25_new[col].apply(
                lambda x: "{:05.2f}".format(float(x))
                if x.replace(".", "", 1).isdigit() and x != "" and x != -1
                else x
            )
        # https://abft101.atlassian.net/browse/AQA-405

        def convert_mode_of_sep(x):
            # Standardize the input as string
            x_str = str(x).strip()

            # Direct mappings based on specific patterns
            if x_str in ["01.00", "02.00", "03.00", "04.00"]:
                return x_str.split(".")[0]
            elif x_str in ["98", "98.0", "98.00"]:
                return "98"
            elif x_str == "-1.0":
                return "-1"
            else:
                return x_str  # Leave other values untouched

        # Apply the function to the column
        tbl_ppm_ED_Encounter_25_new["Extra:ModeofSep"] = tbl_ppm_ED_Encounter_25_new[
            "Extra:ModeofSep"
        ].apply(convert_mode_of_sep)

        # List of columns to pad to two zeros . These do not have any decimal
        columns_to_pad = ["Extra:EDVisitType", "Extra:ModeofArrival"]
        for col in columns_to_pad:
            tbl_ppm_ED_Encounter_25_new[col] = tbl_ppm_ED_Encounter_25_new[col].apply(
                lambda x: "{:02d}".format(int(float(x)))
                if x.replace(".", "", 1).isdigit() and x != "" and x != -1
                else x
            )

        tbl_ppm_ED_Encounter_25_new.rename(
            columns={
                "DRG1": "Classification:AECCV1",
                "Extra:N_Z_FinancialProgram": "Extra:Subprogram",
                "Extra:nwau_urg_ed_diagnosis_mapped": "Extra:nwau_ed_diagnosis_mapped",
            },
            inplace=True,
        )
        # AQA-297 : Add roundid
        tbl_ppm_ED_Encounter_25_new["Extra:RoundID"] = versionID_dot.replace("V", "")

        tbl_ppm_ED_Encounter_25_new = tbl_ppm_ED_Encounter_25_new[
            [
                "EncounterNumber",
                "PostCode",
                "Suburb",
                "EncounterType",
                "PatientNumber",
                "Hospital",
                "LengthofStay",
                "StartDateTime",
                "EndDateTime",
                "Age",
                "WeightedSeparation",
                "Extra:InpatientStayNumber",
                "Extra:TriageCategory",
                "Extra:ModeofArrival",
                "Extra:EDVisitType",
                "Extra:EDDiagnosis",
                "Extra:ModeofSep",
                "Extra:EDTriageDateTime",
                "Extra:EDReferralSource",
                "Extra:IndigenousStatus",
                "Extra:EmergRoleDelin",
                "Extra:UDG",
                "Extra:ClinStartDTTM",
                "Extra:DepartureReadyDTTM",
                "Extra:EDDiagnosisType",
                "Extra:EDDiagnosis2",
                "Extra:EDDiagnosisType2",
                "Extra:EDDiagnosis3",
                "Extra:EDDiagnosisType3",
                "Extra:AdmWard",
                "Extra:EdCompStatus",
                "Extra:ExtractorVersion",
                "Extra:nwau",
                "Extra:InpatientEncounterNumber",
                "Extra:MDB",
                "Extra:ED_visit_identifier",
                "Extra:LHD_of_Usual_Residence",
                "Extra:compensable_nwau",
                "Extra:nwau_base",
                "Extra:nwau_indig_incr",
                "Extra:nwau_version",
                "Extra:nwau_ed_diagnosis_mapped",
                "Extra:nwau_type",
                "Extra:WIP",
                "Classification:AECCV1",
                "Extra:Subprogram",
                "Extra:ExtractDate",
                "Extra:AUID",
                "Extra:HLTH_ORG_OSP_OSP_ID",
                "Extra:MG_AUTH_OSP_OSP_ID",
                "Extra:SE_CBK_SK",
                "Extra:CL_ID_EUID",
                "Extra:CL_ID_IHI",
                "Extra:FST_BILL_CATEGORY_CD",
                "Extra:FST_FIN_CLASS_CD",
                "Extra:SRV_ENC_REC_ID",
                "Extra:WAU_ADJ_PT_TX_REMT_AREA",
                "Extra:WAU_ADJ_PT_RES_REMT_AREA",
                "Extra:EDDiag_ver",
                "Extra:EDINTERVENTION_VER",
                "Extra:EDINTERVENTION_CD",
                "Extra:RoundID",
                "Extra:ASGS_SA_L2_16_CD",
                "Extra:CL_URES_ADDR_ASGS21_SA_L2_CD",
                "Extra:AP_SE_CBK_SK",
                "Extra:IP_SRV_ENC_REC_ID",
            ]
        ]
        # https://abft101.atlassian.net/browse/AQA-348
        # tbl_ppm_ED_Encounter_25_new=clear_neg_one(tbl_ppm_ED_Encounter_25_new)

        tbl_ppm_ED_Encounter_25_supp = tbl_ppm_ED_Encounter_25_new.copy()
        tbl_ppm_ED_Encounter_25_supp = tbl_ppm_ED_Encounter_25_supp[
            [
                "EncounterNumber",
                "Extra:SE_CBK_SK",
                "Extra:RoundID",
                "Extra:ExtractDate",
                "Extra:ExtractorVersion",
                "Extra:ASGS_SA_L2_16_CD",
                "Extra:CL_URES_ADDR_ASGS21_SA_L2_CD",
                "Extra:AUID",
                "Extra:CL_ID_EUID",
                "Extra:CL_ID_IHI",
                "Extra:ClinStartDTTM",
                "Extra:EdCompStatus",
                "Extra:EDDiag_ver",
                "Extra:EDDiagnosis",
                "Extra:EDDiagnosisType2",
                "Extra:EDDiagnosisType3",
                "Extra:EDDiagnosis2",
                "Extra:EDDiagnosis3",
                "Extra:EDDiagnosisType",
                "Extra:EDINTERVENTION_CD",
                "Extra:EDINTERVENTION_VER",
                "Extra:FST_BILL_CATEGORY_CD",
                "Extra:FST_FIN_CLASS_CD",
                "Extra:ModeofSep",
                "Extra:nwau",
                "Extra:nwau_base",
                "Extra:nwau_ed_diagnosis_mapped",
                "Extra:nwau_indig_incr",
                "Extra:nwau_type",
                "Extra:nwau_version",
                "Extra:WAU_ADJ_PT_RES_REMT_AREA",
                "Extra:WAU_ADJ_PT_TX_REMT_AREA",
                "Extra:compensable_nwau",
                "Extra:IP_SRV_ENC_REC_ID",
                "Extra:InpatientEncounterNumber",
                "Extra:AP_SE_CBK_SK",
            ]
        ]
        date_str = datetime.datetime.today().strftime("%d%b%Y")
        try:
            tbl_ppm_ED_Encounter_25.to_csv(
                "./ExtractorDB/Tbl_PPM_ED_Encounter_"
                + versionID_underscore
                + "_OLD_FORMAT.csv",
                index=False,
                na_rep="",
                float_format=str,
                decimal=str,
                date_format=str,
            )
            tbl_ppm_ED_Encounter_25_new.to_csv(
                "./ExtractorDB/Tbl_PPM_ED_Encounter_FULL_"
                + versionID_underscore
                + ".csv",
                index=False,
                na_rep="",
                float_format=str,
                decimal=str,
                date_format=str,
            )
            tbl_ppm_ED_Encounter_25_supp.to_csv(
                "./Output/Tbl_Non_PPM_ED_Encounter_"
                + lhd_global
                + "_"
                + versionID_underscore
                + "_"
                + date_str
                + ".csv",
                index=False,
                na_rep="",
                float_format=str,
                decimal=str,
                date_format=str,
            )
            # os.chmod('./Output/Tbl_Non_PPM_ED_Encounter_'+lhd_global+'_'+versionID_underscore+'_'+date_str+'.csv', stat.S_IREAD)
            # os.chmod('./Output/Tbl_Non_PPM_ED_Encounter_'+lhd_global+'_'+versionID_underscore+'_'+date_str+'.csv')
            with zipfile.ZipFile(
                "./Output/Tbl_Non_PPM_ED_Encounter_"
                + lhd_global
                + "_"
                + versionID_underscore
                + "_"
                + date_str
                + ".zip",
                "w",
                zipfile.ZIP_DEFLATED,
            ) as zipf:
                zipf.write(
                    "./Output/Tbl_Non_PPM_ED_Encounter_"
                    + lhd_global
                    + "_"
                    + versionID_underscore
                    + "_"
                    + date_str
                    + ".csv",
                    arcname="Tbl_Non_PPM_ED_Encounter_"
                    + lhd_global
                    + "_"
                    + versionID_underscore
                    + "_"
                    + date_str
                    + ".csv",
                )
            if os.path.exists(
                "./Output/Tbl_Non_PPM_ED_Encounter_"
                + lhd_global
                + "_"
                + versionID_underscore
                + "_"
                + date_str
                + ".csv"
            ):
                os.remove(
                    "./Output/Tbl_Non_PPM_ED_Encounter_"
                    + lhd_global
                    + "_"
                    + versionID_underscore
                    + "_"
                    + date_str
                    + ".csv"
                )
        except Exception as e:
            logging.exception("Exception occurred")
            label_9_status = 0
            messagebox.showerror(
                "Export Error",
                "Error exporting tbl_PPM_ED_Encounter_updated.\n" + str(e),
            )
            label_9_sub.configure(text="Failed ()...", fg="red")
            main_screen.update()
            return  # stop export
        cleanup_memory(tbl_ppm_ED_Encounter_25_supp)
        tbl_ppm_ED_Encounter_25_new = tbl_ppm_ED_Encounter_25_new[
            [
                "EncounterNumber",
                "PostCode",
                "Suburb",
                "EncounterType",
                "PatientNumber",
                "Hospital",
                "LengthofStay",
                "StartDateTime",
                "EndDateTime",
                "Age",
                "WeightedSeparation",
                "Extra:InpatientStayNumber",
                "Extra:TriageCategory",
                "Extra:ModeofArrival",
                "Extra:EDVisitType",
                "Extra:EDDiagnosis",
                "Extra:ModeofSep",
                "Extra:EDTriageDateTime",
                "Extra:EDReferralSource",
                "Extra:IndigenousStatus",
                "Extra:EmergRoleDelin",
                "Extra:UDG",
                "Extra:ClinStartDTTM",
                "Extra:DepartureReadyDTTM",
                "Extra:EDDiagnosisType",
                "Extra:EDDiagnosis2",
                "Extra:EDDiagnosisType2",
                "Extra:EDDiagnosis3",
                "Extra:EDDiagnosisType3",
                "Extra:AdmWard",
                "Extra:EdCompStatus",
                "Extra:ExtractorVersion",
                "Extra:nwau",
                "Extra:InpatientEncounterNumber",
                "Extra:MDB",
                "Extra:ED_visit_identifier",
                "Extra:LHD_of_Usual_Residence",
                "Extra:compensable_nwau",
                "Extra:nwau_base",
                "Extra:nwau_indig_incr",
                "Extra:nwau_version",
                "Extra:nwau_ed_diagnosis_mapped",
                "Extra:nwau_type",
                "Extra:WIP",
                "Classification:AECCV1",
                "Extra:Subprogram",
                "Extra:ExtractDate",
                "Extra:AUID",
                "Extra:HLTH_ORG_OSP_OSP_ID",
                "Extra:MG_AUTH_OSP_OSP_ID",
                "Extra:SE_CBK_SK",
                "Extra:CL_ID_EUID",
                "Extra:CL_ID_IHI",
                "Extra:FST_BILL_CATEGORY_CD",
                "Extra:FST_FIN_CLASS_CD",
                "Extra:SRV_ENC_REC_ID",
                "Extra:WAU_ADJ_PT_TX_REMT_AREA",
                "Extra:WAU_ADJ_PT_RES_REMT_AREA",
                "Extra:EDINTERVENTION_VER",
                "Extra:RoundID",
            ]
        ]
        # https://abft101.atlassian.net/browse/AQA-348
        # tbl_ppm_ED_Encounter_25_new=clear_neg_one(tbl_ppm_ED_Encounter_25_new)
        try:
            tbl_ppm_ED_Encounter_25_new.to_csv(
                "./Output/Tbl_PPM_ED_Encounter_" + versionID_underscore + ".csv",
                index=False,
                na_rep="",
                float_format=str,
                decimal=str,
                date_format=str,
            )
        except Exception as e:
            logging.exception("Exception occurred")
            label_9_status = 0
            messagebox.showerror(
                "Export Error",
                "Error exporting tbl_PPM_ED_Encounter_updated.\n" + str(e),
            )
            label_9_sub.configure(text="Failed ()...", fg="red")
            main_screen.update()
            return  # stop export
        cleanup_memory(tbl_ppm_ED_Encounter_25_new)
        logging.info(
            "tbl_ppm_ED_Encounter_25_new and tbl_ppm_ED_Encounter_25_supp generated."
        )
        ######################################PERFORM SAME OPERATIONS ON EVT13 AS ABOVE - NOT DONE in ACCESS UPDATE#########################################
        # Export tbl_ppm_ED_Encounter before SNOMED and AECC update to /ExtractorDB
        try:
            tbl_PPM_ED_Encounter_EVT13.to_csv(
                "./ExtractorDB/tbl_PPM_ED_Encounter_EVT13_"
                + versionID_hash
                + "_before_snomed_update.csv",
                index=False,
                na_rep="",
                float_format=str,
                decimal=str,
                date_format=str,
            )
        except Exception as e:
            logging.exception("Exception occurred")
            label_9_status = 0
            messagebox.showerror(
                "Export Error",
                "Error exporting tbl_PPM_ED_Encounter_EVT13.csv to ExtractorDB, before SNOMED and AECC update \n"
                + str(e),
            )
            label_9_sub.configure(text="Failed ()...", fg="red")
            main_screen.update()
            return  # stop export
        logging.info(
            "%s records saved to ./ExtractorDB/tbl_PPM_ED_Encounter_EVT13.csv.",
            len(tbl_PPM_ICD_procedures_V25),
        )
        ###############################################################################
        # Access query: qry_Update_SNOMED_Diag_to_P
        # UPDATE tbl_PPM_ED_Encounter_EVT13_25 INNER JOIN snomed_Update ON (tbl_PPM_ED_Encounter_EVT13_25.Hospital = snomed_Update.facility_identifier) AND (tbl_PPM_ED_Encounter_EVT13_25.[Extra:ED_visit_identifier] = snomed_Update.ed_visit_identifier) SET tbl_PPM_ED_Encounter_EVT13_25.[Extra:EDDiagnosis] = [P_Diag], tbl_PPM_ED_Encounter_EVT13_25.[Extra:EDDiagnosisType] = "SNOMEDCT"
        # WHERE (((tbl_PPM_ED_Encounter_EVT13_25.[Extra:EDDiagnosis]) Is Null));
        tbl_PPM_ED_Encounter_EVT13_25 = pd.merge(
            tbl_PPM_ED_Encounter_EVT13,
            snomed_Update,
            how="left",
            left_on=["Hospital", "Extra:ED_visit_identifier"],
            right_on=["facility_identifier", "ed_visit_identifier"],
            suffixes=("", "_drop"),
            indicator=True,
        )
        tbl_PPM_ED_Encounter_EVT13_25 = tbl_PPM_ED_Encounter_EVT13_25.apply(
            lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
        )
        tbl_PPM_ED_Encounter_EVT13_25["Extra:EDDiagnosis"] = np.where(
            (
                (tbl_PPM_ED_Encounter_EVT13_25["Extra:EDDiagnosis"].isnull())
                | (tbl_PPM_ED_Encounter_EVT13_25["Extra:EDDiagnosis"] == "")
            )
            & (tbl_PPM_ED_Encounter_EVT13_25["_merge"] == "both"),
            tbl_PPM_ED_Encounter_EVT13_25["P_Diag"],
            tbl_PPM_ED_Encounter_EVT13_25["Extra:EDDiagnosis"],
        )
        tbl_PPM_ED_Encounter_EVT13_25["Extra:EDDiagnosisType"] = np.where(
            (
                (tbl_PPM_ED_Encounter_EVT13_25["Extra:EDDiagnosis"].isnull())
                | (tbl_PPM_ED_Encounter_EVT13_25["Extra:EDDiagnosis"] == "")
            )
            & (tbl_PPM_ED_Encounter_EVT13_25["_merge"] == "both"),
            "SNOMEDCT",
            tbl_PPM_ED_Encounter_EVT13_25["Extra:EDDiagnosisType"],
        )
        tbl_PPM_ED_Encounter_EVT13_25.drop(["_merge"], axis=1, inplace=True)
        logging.info("for EVT13, qry_Update_SNOMED_Diag_to_P completed.")
        ############# FOR ROUND 27 AND ABOVE - STOP #######################
        ####################################################################
        ###############################################################################
        # Access query: qry_update_AECC_NWAU_SNOMEDCT
        # UPDATE AECC INNER JOIN tbl_PPM_ED_Encounter_EVT13_25 ON (tbl_PPM_ED_Encounter_EVT13_25.[Extra:ED_visit_identifier] = AECC.ed_visit_identifier) AND (AECC.facility_identifier = tbl_PPM_ED_Encounter_EVT13_25.Hospital) SET tbl_PPM_ED_Encounter_EVT13_25.DRG1 = [aecc_end_class], tbl_PPM_ED_Encounter_EVT13_25.DRG1Version = [aecc_version], tbl_PPM_ED_Encounter_EVT13_25.[Extra:nwau_base] = [nwau_base], tbl_PPM_ED_Encounter_EVT13_25.[Extra:nwau_version] = [nwau_version], tbl_PPM_ED_Encounter_EVT13_25.[Extra:compensable_nwau] = [compensable_nwau], tbl_PPM_ED_Encounter_EVT13_25.[Extra:nwau_indig_incr] = [indigenous_adj], tbl_PPM_ED_Encounter_EVT13_25.[Extra:EDDiagnosis] = IIf([tbl_PPM_ED_Encounter_EVT13_25]![Extra:EDDiagnosis]>"0",IIf([tbl_PPM_ED_Encounter_EVT13_25]![Extra:EDDiagnosisType]="SNOMEDCT","SCT" & [tbl_PPM_ED_Encounter_EVT13_25]![Extra:EDDiagnosis],[tbl_PPM_ED_Encounter_EVT13_25]![Extra:EDDiagnosis])), tbl_PPM_ED_Encounter_EVT13_25.[Extra:nwau_type] = "AECC", tbl_PPM_ED_Encounter_EVT13_25.[Extra:nwau] = [nwau_final];
        # tbl_PPM_ED_Encounter_EVT13_25 = pd.merge(tbl_PPM_ED_Encounter_EVT13, aecc, how='left', left_on=['Hospital', 'Extra:ED_visit_identifier'], right_on=['facility_identifier', 'ed_visit_identifier'], suffixes=('', '_drop'), indicator=True)
        tbl_PPM_ED_Encounter_EVT13_25 = pd.merge(
            tbl_PPM_ED_Encounter_EVT13_25,
            aecc,
            how="left",
            left_on=["Hospital", "Extra:ED_visit_identifier"],
            right_on=["facility_identifier", "ed_visit_identifier"],
            suffixes=("", "_drop"),
            indicator=True,
        )
        tbl_PPM_ED_Encounter_EVT13_25 = tbl_PPM_ED_Encounter_EVT13_25.apply(
            lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
        )
        tbl_PPM_ED_Encounter_EVT13_25["DRG1"] = np.where(
            (tbl_PPM_ED_Encounter_EVT13_25["_merge"] == "both"),
            tbl_PPM_ED_Encounter_EVT13_25["aecc_end_class"],
            tbl_PPM_ED_Encounter_EVT13_25["DRG1"],
        )
        tbl_PPM_ED_Encounter_EVT13_25["DRG1Version"] = np.where(
            (tbl_PPM_ED_Encounter_EVT13_25["_merge"] == "both"),
            tbl_PPM_ED_Encounter_EVT13_25["aecc_version"],
            tbl_PPM_ED_Encounter_EVT13_25["DRG1Version"],
        )
        tbl_PPM_ED_Encounter_EVT13_25["Extra:nwau_base"] = np.where(
            (tbl_PPM_ED_Encounter_EVT13_25["_merge"] == "both"),
            tbl_PPM_ED_Encounter_EVT13_25["nwau_base"],
            tbl_PPM_ED_Encounter_EVT13_25["Extra:nwau_base"],
        )
        tbl_PPM_ED_Encounter_EVT13_25["Extra:nwau_version"] = np.where(
            (tbl_PPM_ED_Encounter_EVT13_25["_merge"] == "both"),
            tbl_PPM_ED_Encounter_EVT13_25["nwau_version"],
            tbl_PPM_ED_Encounter_EVT13_25["Extra:nwau_version"],
        )
        tbl_PPM_ED_Encounter_EVT13_25["Extra:compensable_nwau"] = np.where(
            (tbl_PPM_ED_Encounter_EVT13_25["_merge"] == "both"),
            tbl_PPM_ED_Encounter_EVT13_25["compensable_nwau"],
            tbl_PPM_ED_Encounter_EVT13_25["Extra:compensable_nwau"],
        )
        tbl_PPM_ED_Encounter_EVT13_25["Extra:nwau_indig_incr"] = np.where(
            (tbl_PPM_ED_Encounter_EVT13_25["_merge"] == "both"),
            tbl_PPM_ED_Encounter_EVT13_25["indigenous_adj"],
            tbl_PPM_ED_Encounter_EVT13_25["Extra:nwau_indig_incr"],
        )
        tbl_PPM_ED_Encounter_EVT13_25["Extra:nwau_type"] = np.where(
            (tbl_PPM_ED_Encounter_EVT13_25["_merge"] == "both"),
            "AECC",
            tbl_PPM_ED_Encounter_EVT13_25["Extra:nwau_type"],
        )
        tbl_PPM_ED_Encounter_EVT13_25["Extra:nwau"] = np.where(
            (tbl_PPM_ED_Encounter_EVT13_25["_merge"] == "both"),
            tbl_PPM_ED_Encounter_EVT13_25["nwau_final"],
            tbl_PPM_ED_Encounter_EVT13_25["Extra:nwau"],
        )
        tbl_PPM_ED_Encounter_EVT13_25["Extra:EDDiagnosis"] = np.where(
            (tbl_PPM_ED_Encounter_EVT13_25["Extra:EDDiagnosis"] != "")
            & (pd.notna(tbl_PPM_ED_Encounter_EVT13_25["Extra:EDDiagnosis"]))
            & (tbl_PPM_ED_Encounter_EVT13_25["Extra:EDDiagnosis"] != "0")
            & (tbl_PPM_ED_Encounter_EVT13_25["Extra:EDDiagnosisType"] == "SNOMEDCT"),
            "SCT" + tbl_PPM_ED_Encounter_EVT13_25["Extra:EDDiagnosis"],
            tbl_PPM_ED_Encounter_EVT13_25["Extra:EDDiagnosis"],
        )
        logging.info("for EVT13, qry_update_AECC_NWAU_SNOMEDCT completed.")
        ###############################################################################
        tbl_PPM_ED_Encounter_EVT13_25["Extra:EDVisitType"] = (
            tbl_PPM_ED_Encounter_EVT13_25["Extra:EDVisitType"]
            .astype(str)
            .str.pad(2, side="left", fillchar="0")
        )
        tbl_PPM_ED_Encounter_EVT13_25["Extra:EDReferralSource"] = (
            tbl_PPM_ED_Encounter_EVT13_25["Extra:EDReferralSource"]
            .astype(str)
            .str.pad(2, side="left", fillchar="0")
        )
        tbl_PPM_ED_Encounter_EVT13_25["Extra:UDG_IPHA"] = (
            tbl_PPM_ED_Encounter_EVT13_25["Extra:UDG_IPHA"]
            .astype(str)
            .str.pad(2, side="left", fillchar="0")
        )
        ###############################################################################
        # Export C:\costing\Output\tbl_PPM_ED_Encounter_EVT13_27.csv
        tbl_PPM_ED_Encounter_EVT13_25 = tbl_PPM_ED_Encounter_EVT13_25[
            [
                "EncounterNumber",
                "PostCode",
                "Suburb",
                "EncounterType",
                "PatientNumber",
                "Hospital",
                "LengthofStay",
                "StartDateTime",
                "EndDateTime",
                "Age",
                "WeightedSeparation",
                "Extra:InpatientStayNumber",
                "Extra:TriageCategory",
                "Extra:ModeofArrival",
                "Extra:EDVisitType",
                "Extra:EDDiagnosis",
                "Extra:ModeofSep",
                "Extra:EDTriageDateTime",
                "Extra:EDReferralSource",
                "Extra:IndigenousStatus",
                "Extra:MedicareNumber",
                "Extra:EmergRoleDelin",
                "Extra:UDG",
                "Extra:URG",
                "Extra:ClinStartDTTM",
                "Extra:DepartureReadyDTTM",
                "Extra:EDDiagnosisType",
                "Extra:EDDiagnosis2",
                "Extra:EDDiagnosisType2",
                "Extra:EDDiagnosis3",
                "Extra:EDDiagnosisType3",
                "Extra:AdmWard",
                "Extra:EdCompStatus",
                "Extra:ExtractorVersion",
                "Extra:nwau",
                "Extra:sla_ra06",
                "Extra:InpatientEncounterNumber",
                "Extra:postcode_ra06",
                "Extra:hosp_ra06",
                "Extra:MDB",
                "Extra:UDG_IPHA",
                "Extra:ED_visit_identifier",
                "Extra:ED_Hosp_A233",
                "Extra:LHD_of_Usual_Residence",
                "Extra:compensable_nwau",
                "Extra:nwau_base",
                "Extra:nwau_indig_incr",
                "Extra:nwau_version",
                "Extra:nwau_urg_ed_diagnosis_mapped",
                "Extra:nwau_type",
                "Extra:WIP",
                "DRG1",
                "DRG1Version",
                "Extra:N_Z_FinancialProgram",
                "Extra:AUID",
                "Extra:HLTH_ORG_OSP_OSP_ID",
                "Extra:MG_AUTH_OSP_OSP_ID",
                "Extra:SE_CBK_SK",
                "Extra:CL_ID_EUID",
                "Extra:CL_ID_IHI",
                "Extra:FST_BILL_CATEGORY_CD",
                "Extra:FST_FIN_CLASS_CD",
                "Extra:EDW_Pat_Number",
                "Extra:EDW_Enc_Number",
                "Extra:SRV_ENC_REC_ID",
                "Extra:WAU_ADJ_PT_TX_REMT_AREA",
                "Extra:WAU_ADJ_PT_RES_REMT_AREA",
                "Extra:EDDiag_ver",
                "Extra:EDINTERVENTION_VER",
                "Extra:EDINTERVENTION_CD",
                "Extra:AP_SE_CBK_SK",
                "Extra:IP_SRV_ENC_REC_ID",
            ]
        ]
        tbl_PPM_ED_Encounter_EVT13_25 = tbl_PPM_ED_Encounter_EVT13_25.applymap(
            str
        )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
        tbl_PPM_ED_Encounter_EVT13_25 = tbl_PPM_ED_Encounter_EVT13_25.applymap(
            lambda x: x.strip() if isinstance(x, str) else x
        )
        tbl_PPM_ED_Encounter_EVT13_25 = tbl_PPM_ED_Encounter_EVT13_25.apply(
            lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
        )
        tbl_PPM_ED_Encounter_EVT13_25.drop_duplicates(keep="last", inplace=True)
        # AQA-315
        # tbl_PPM_ED_Encounter_EVT13_25_new = tbl_PPM_ED_Encounter_EVT13_25[['EncounterNumber', 'PostCode', 'Suburb', 'EncounterType', 'PatientNumber', 'Hospital', 'LengthofStay', 'StartDateTime', 'EndDateTime', 'Age', 'WeightedSeparation', 'Extra:InpatientStayNumber', 'Extra:TriageCategory', 'Extra:ModeofArrival', 'Extra:EDVisitType', 'Extra:EDDiagnosis', 'Extra:ModeofSep', 'Extra:EDTriageDateTime', 'Extra:EDReferralSource', 'Extra:IndigenousStatus', 'Extra:EmergRoleDelin', 'Extra:UDG', 'Extra:ClinStartDTTM', 'Extra:DepartureReadyDTTM', 'Extra:EDDiagnosisType', 'Extra:EDDiagnosis2', 'Extra:EDDiagnosisType2', 'Extra:EDDiagnosis3', 'Extra:EDDiagnosisType3', 'Extra:AdmWard', 'Extra:EdCompStatus', 'Extra:ExtractorVersion', 'Extra:nwau', 'Extra:InpatientEncounterNumber', 'Extra:MDB', 'Extra:ED_visit_identifier', 'Extra:LHD_of_Usual_Residence', 'Extra:compensable_nwau', 'Extra:nwau_base', 'Extra:nwau_indig_incr', 'Extra:nwau_version', 'Extra:nwau_urg_ed_diagnosis_mapped', 'Extra:nwau_type', 'Extra:WIP', 'DRG1', 'Extra:N_Z_FinancialProgram', 'Extra:AUID', 'Extra:HLTH_ORG_OSP_OSP_ID', 'Extra:MG_AUTH_OSP_OSP_ID', 'Extra:SE_CBK_SK', 'Extra:CL_ID_EUID', 'Extra:CL_ID_IHI', 'Extra:FST_BILL_CATEGORY_CD', 'Extra:EDW_Pat_Number', 'Extra:EDW_Enc_Number']]
        tbl_PPM_ED_Encounter_EVT13_25_new = tbl_PPM_ED_Encounter_EVT13_25[
            [
                "EncounterNumber",
                "PostCode",
                "Suburb",
                "EncounterType",
                "PatientNumber",
                "Hospital",
                "LengthofStay",
                "StartDateTime",
                "EndDateTime",
                "Age",
                "WeightedSeparation",
                "Extra:InpatientStayNumber",
                "Extra:TriageCategory",
                "Extra:ModeofArrival",
                "Extra:EDVisitType",
                "Extra:EDDiagnosis",
                "Extra:ModeofSep",
                "Extra:EDTriageDateTime",
                "Extra:EDReferralSource",
                "Extra:IndigenousStatus",
                "Extra:EmergRoleDelin",
                "Extra:UDG",
                "Extra:ClinStartDTTM",
                "Extra:DepartureReadyDTTM",
                "Extra:EDDiagnosisType",
                "Extra:EDDiagnosis2",
                "Extra:EDDiagnosisType2",
                "Extra:EDDiagnosis3",
                "Extra:EDDiagnosisType3",
                "Extra:AdmWard",
                "Extra:EdCompStatus",
                "Extra:ExtractorVersion",
                "Extra:nwau",
                "Extra:InpatientEncounterNumber",
                "Extra:MDB",
                "Extra:ED_visit_identifier",
                "Extra:LHD_of_Usual_Residence",
                "Extra:compensable_nwau",
                "Extra:nwau_base",
                "Extra:nwau_indig_incr",
                "Extra:nwau_version",
                "Extra:nwau_urg_ed_diagnosis_mapped",
                "Extra:nwau_type",
                "Extra:WIP",
                "DRG1",
                "Extra:N_Z_FinancialProgram",
                "Extra:AUID",
                "Extra:HLTH_ORG_OSP_OSP_ID",
                "Extra:MG_AUTH_OSP_OSP_ID",
                "Extra:SE_CBK_SK",
                "Extra:CL_ID_EUID",
                "Extra:CL_ID_IHI",
                "Extra:FST_BILL_CATEGORY_CD",
                "Extra:FST_FIN_CLASS_CD",
                "Extra:SRV_ENC_REC_ID",
                "Extra:WAU_ADJ_PT_TX_REMT_AREA",
                "Extra:WAU_ADJ_PT_RES_REMT_AREA",
                "Extra:EDDiag_ver",
                "Extra:EDINTERVENTION_VER",
                "Extra:EDINTERVENTION_CD",
                "Extra:AP_SE_CBK_SK",
                "Extra:IP_SRV_ENC_REC_ID",
            ]
        ]
        # AQA-297 : Add roundid
        tbl_PPM_ED_Encounter_EVT13_25_new["Extra:RoundID"] = versionID_dot.replace(
            "V", ""
        )
        # https://abft101.atlassian.net/browse/AQA-227 pad
        # List of columns to pad to two zeros before decimal
        columns_to_pad = ["Extra:ModeofSep"]
        for col in columns_to_pad:
            tbl_PPM_ED_Encounter_EVT13_25_new[col] = tbl_PPM_ED_Encounter_EVT13_25_new[
                col
            ].apply(
                lambda x: "{:05.2f}".format(float(x))
                if x.replace(".", "", 1).isdigit() and x != "" and x != -1
                else x
            )

        # List of columns to pad to two zeros . These do not have any decimal
        columns_to_pad = ["Extra:EDVisitType", "Extra:ModeofArrival"]
        for col in columns_to_pad:
            tbl_PPM_ED_Encounter_EVT13_25_new[col] = tbl_PPM_ED_Encounter_EVT13_25_new[
                col
            ].apply(
                lambda x: "{:02d}".format(int(float(x)))
                if x.replace(".", "", 1).isdigit() and x != "" and x != -1
                else x
            )

        tbl_PPM_ED_Encounter_EVT13_25_new.rename(
            columns={
                "DRG1": "Classification:AECCV1",
                "Extra:N_Z_FinancialProgram": "Extra:Subprogram",
                "Extra:nwau_urg_ed_diagnosis_mapped": "Extra:nwau_ed_diagnosis_mapped",
            },
            inplace=True,
        )
        # https://abft101.atlassian.net/browse/AQA-348
        # tbl_PPM_ED_Encounter_EVT13_25_new=clear_neg_one(tbl_PPM_ED_Encounter_EVT13_25_new)
        tbl_PPM_ED_Encounter_EVT13_25_new = tbl_PPM_ED_Encounter_EVT13_25_new[
            [
                "EncounterNumber",
                "PostCode",
                "Suburb",
                "EncounterType",
                "PatientNumber",
                "Hospital",
                "LengthofStay",
                "StartDateTime",
                "EndDateTime",
                "Age",
                "WeightedSeparation",
                "Extra:InpatientStayNumber",
                "Extra:TriageCategory",
                "Extra:ModeofArrival",
                "Extra:EDVisitType",
                "Extra:EDDiagnosis",
                "Extra:ModeofSep",
                "Extra:EDTriageDateTime",
                "Extra:EDReferralSource",
                "Extra:IndigenousStatus",
                "Extra:EmergRoleDelin",
                "Extra:UDG",
                "Extra:ClinStartDTTM",
                "Extra:DepartureReadyDTTM",
                "Extra:EDDiagnosisType",
                "Extra:EDDiagnosis2",
                "Extra:EDDiagnosisType2",
                "Extra:EDDiagnosis3",
                "Extra:EDDiagnosisType3",
                "Extra:AdmWard",
                "Extra:EdCompStatus",
                "Extra:ExtractorVersion",
                "Extra:nwau",
                "Extra:InpatientEncounterNumber",
                "Extra:MDB",
                "Extra:ED_visit_identifier",
                "Extra:LHD_of_Usual_Residence",
                "Extra:compensable_nwau",
                "Extra:nwau_base",
                "Extra:nwau_indig_incr",
                "Extra:nwau_version",
                "Extra:nwau_ed_diagnosis_mapped",
                "Extra:nwau_type",
                "Extra:WIP",
                "Classification:AECCV1",
                "Extra:Subprogram",
                "Extra:AUID",
                "Extra:HLTH_ORG_OSP_OSP_ID",
                "Extra:MG_AUTH_OSP_OSP_ID",
                "Extra:SE_CBK_SK",
                "Extra:CL_ID_EUID",
                "Extra:CL_ID_IHI",
                "Extra:FST_BILL_CATEGORY_CD",
                "Extra:FST_FIN_CLASS_CD",
                "Extra:SRV_ENC_REC_ID",
                "Extra:WAU_ADJ_PT_TX_REMT_AREA",
                "Extra:WAU_ADJ_PT_RES_REMT_AREA",
                "Extra:EDDiag_ver",
                "Extra:EDINTERVENTION_VER",
                "Extra:EDINTERVENTION_CD",
                "Extra:AP_SE_CBK_SK",
                "Extra:IP_SRV_ENC_REC_ID",
                "Extra:RoundID",
            ]
        ]
        try:
            tbl_PPM_ED_Encounter_EVT13_25.to_csv(
                "./ExtractorDB/tbl_PPM_ED_Encounter_EVT13_"
                + versionID_underscore
                + "_OLD_FORMAT2.csv",
                index=False,
                na_rep="",
                float_format=str,
                decimal=str,
                date_format=str,
            )
            tbl_PPM_ED_Encounter_EVT13_25_new.to_csv(
                "./ExtractorDB/tbl_PPM_ED_Encounter_"
                + versionID_underscore
                + "EVT13.csv",
                index=False,
                na_rep="",
                float_format=str,
                decimal=str,
                date_format=str,
            )
        except Exception as e:
            logging.exception("Exception occurred")
            label_9_status = 0
            messagebox.showerror(
                "Export Error",
                "Error exporting tbl_PPM_ED_Encounter_EVT13_updated.\n" + str(e),
            )
            label_9_sub.configure(text="Failed ()...", fg="red")
            main_screen.update()
            return  # stop export
        tbl_PPM_ED_Encounter_EVT13_25_new = tbl_PPM_ED_Encounter_EVT13_25_new[
            [
                "EncounterNumber",
                "PostCode",
                "Suburb",
                "EncounterType",
                "PatientNumber",
                "Hospital",
                "LengthofStay",
                "StartDateTime",
                "EndDateTime",
                "Age",
                "WeightedSeparation",
                "Extra:InpatientStayNumber",
                "Extra:TriageCategory",
                "Extra:ModeofArrival",
                "Extra:EDVisitType",
                "Extra:EDDiagnosis",
                "Extra:ModeofSep",
                "Extra:EDTriageDateTime",
                "Extra:EDReferralSource",
                "Extra:IndigenousStatus",
                "Extra:EmergRoleDelin",
                "Extra:UDG",
                "Extra:ClinStartDTTM",
                "Extra:DepartureReadyDTTM",
                "Extra:EDDiagnosisType",
                "Extra:EDDiagnosis2",
                "Extra:EDDiagnosisType2",
                "Extra:EDDiagnosis3",
                "Extra:EDDiagnosisType3",
                "Extra:AdmWard",
                "Extra:EdCompStatus",
                "Extra:ExtractorVersion",
                "Extra:nwau",
                "Extra:InpatientEncounterNumber",
                "Extra:MDB",
                "Extra:ED_visit_identifier",
                "Extra:LHD_of_Usual_Residence",
                "Extra:compensable_nwau",
                "Extra:nwau_base",
                "Extra:nwau_indig_incr",
                "Extra:nwau_version",
                "Extra:nwau_ed_diagnosis_mapped",
                "Extra:nwau_type",
                "Extra:WIP",
                "Classification:AECCV1",
                "Extra:Subprogram",
                "Extra:AUID",
                "Extra:HLTH_ORG_OSP_OSP_ID",
                "Extra:MG_AUTH_OSP_OSP_ID",
                "Extra:SE_CBK_SK",
                "Extra:CL_ID_EUID",
                "Extra:CL_ID_IHI",
                "Extra:FST_BILL_CATEGORY_CD",
                "Extra:FST_FIN_CLASS_CD",
                "Extra:SRV_ENC_REC_ID",
                "Extra:WAU_ADJ_PT_TX_REMT_AREA",
                "Extra:WAU_ADJ_PT_RES_REMT_AREA",
                "Extra:EDINTERVENTION_VER",
                "Extra:RoundID",
            ]
        ]
        try:
            tbl_PPM_ED_Encounter_EVT13_25_new.to_csv(
                "./Output/tbl_PPM_ED_Encounter_" + versionID_underscore + "EVT13.csv",
                index=False,
                na_rep="",
                float_format=str,
                decimal=str,
                date_format=str,
            )
        except Exception as e:
            logging.exception("Exception occurred")
            label_9_status = 0
            messagebox.showerror(
                "Export Error",
                "Error exporting tbl_PPM_ED_Encounter_EVT13_updated.\n" + str(e),
            )
            label_9_sub.configure(text="Failed ()...", fg="red")
            main_screen.update()
            return  # stop export
    cleanup_memory(tbl_PPM_ED_Encounter_EVT13_25_new)
    cleanup_memory(tbl_PPM_ED_Encounter_EVT13_25)
    logging.info("tbl_PPM_ED_Encounter_EVT13_25_new generated.")
    ##########
    run_reconciliation()
    # format_output_files()
    # quote_output_files()
    """
    ###############################################################################################################
    ###############################################################################################################
    ######################################################FORMAT OUTPUT FILES #####################################
    #1. tbl ppm IP Encounter
    logging.info("formatting of IP output file STARTED.")
    try:
        dst = './Costing/Tbl_PPM_transfer_AMO_%s.csv' % strftime("%Y_%m_%d", gmtime())
        os.rename('./Costing/Tbl_PPM_transfer_AMO.csv', dst)
    except FileExistsError:
        #os.remove('./Costing/Tbl_PPM_transfer_AMO_temp.csv')
        #os.rename('./Costing/Tbl_PPM_transfer_AMO.csv', './Costing/Tbl_PPM_transfer_AMO_temp.csv')
        dst = './Costing/Tbl_PPM_transfer_AMO_%s.csv' % strftime("%Y_%m_%d", gmtime())
        os.remove(dst)
        os.rename('./Costing/Tbl_PPM_transfer_AMO.csv', dst)
    df_file_PpmTransferAmo.to_csv('./Costing/Tbl_PPM_transfer_AMO.csv', index=False, na_rep='', float_format=str, decimal=str, date_format=str)
    logging.info("formatting of IP output files COMPLETED.")   
    #2. tbl ppm ED Encounter 
    logging.info("formatting of ED output file STARTED.") 
    logging.info("formatting of ED output file COMPLETED.")   
    #3. Transfer File
    logging.info("formatting of transfer output file STARTED.") 
    logging.info("formatting of transfer output file COMPLETED.")  
    """
    ###############################################################################################################
    ###############################################################################################################
    # Update Sub task status
    if label_9_status == 1:
        label_9_sub.configure(text="Completed", fg="green")
        main_screen.update()
    else:
        label_9_sub.configure(text="Failed", fg="red")
        main_screen.update()
    main_screen.update()
    logging.info("Execute AECC update completed.")
    ############### "Export Data OVERALL "#################
    # If all exports are successful.
    if (
        label_1_status == 1
        and label_2_status == 1
        and label_3_status == 1
        and label_4_status == 1
        and label_5_status == 1
        and label_6_status == 1
        and label_7_status == 1
        and label_8_status == 1
        and label_9_status == 1
    ):
        logging.info("All exports are successful.")
        export_complete()
    else:
        logging.info("Export data failed due to errors.")
        messagebox.showerror(
            "Export Data",
            "Export data failed due to errors.\nYou will have to restart the export.",
        )
        return


def transform_ppm_transform_amo():
    logging.info("transform_ppm_transform_amo() started.")
    global \
        lhd_global, \
        facilities_excluded_list_global, \
        facilities_included_list_global, \
        roundid, \
        start_date, \
        end_date, \
        nwau_v, \
        icd10_v, \
        drg1_v, \
        drg2_v, \
        drg4_v, \
        snap_v, \
        amhcc_v, \
        cost_weight_v, \
        srg_drg_v
    """
    Tbl_PPM_transfer_AMO - given,mandatory
    """
    # label_map_1_status = 1
    file_PpmTransferAmo = "./Costing/Tbl_PPM_transfer_AMO.csv"
    if os.path.isfile(file_PpmTransferAmo):
        try:
            df_file_PpmTransferAmo = read_csv_file(
                file_PpmTransferAmo,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error", "Error extracting Tbl_PPM_transfer_AMO.\n" + str(e)
            )
            # label_map_1_status = 0
            return
        else:
            # rename columns to facility_identifier,mo_code,Code,clinician_name,Consultant_Status,LHD
            try:
                df_file_PpmTransferAmo.columns = [
                    "facility_identifier",
                    "mo_code",
                    "Code",
                    "clinician_name",
                    "Consultant_Status",
                    "LHD",
                    "HLTH_ORG_OSP_OSP_ID",
                    "MG_AUTH_OSP_OSP_ID",
                    "SE_CBK_SK",
                    "DIM_RSP_ISP_SK",
                ]
            except ValueError as e:
                df_file_PpmTransferAmo.columns = [
                    "facility_identifier",
                    "mo_code",
                    "Code",
                    "clinician_name",
                    "Consultant_Status",
                    "LHD",
                ]
            df_file_PpmTransferAmo = df_file_PpmTransferAmo[
                df_file_PpmTransferAmo["LHD"] == lhd_global
            ]
            df_file_PpmTransferAmo = df_file_PpmTransferAmo[
                df_file_PpmTransferAmo["facility_identifier"].isin(
                    facilities_included_list_global
                )
            ]
            logging.info("df_file_PpmTransferAmo=%s", len(df_file_PpmTransferAmo))
            df_file_PpmTransferAmo = df_file_PpmTransferAmo.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            df_file_PpmTransferAmo = df_file_PpmTransferAmo.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            df_file_PpmTransferAmo = df_file_PpmTransferAmo.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            df_file_PpmTransferAmo = df_file_PpmTransferAmo.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
            df_file_PpmTransferAmo.to_csv(
                "./temp_transform/imported_Tbl_PPM_transfer_AMO.csv",
                index=False,
                na_rep="",
                float_format=str,
                decimal=str,
                date_format=str,
            )
    else:
        messagebox.showerror(
            "File Error", "Error extracting Tbl_PPM_transfer_AMO. File is missing."
        )
        # label_map_1_status = 0
    # concatenate PpmTransferAmo
    file_df_PpmTransferAmo = "./temp_transform/query_Tbl_PPM_transfer_AMO.csv"
    if os.path.isfile(file_df_PpmTransferAmo):
        try:
            df_PpmTransferAmo = read_csv_file(
                file_df_PpmTransferAmo,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error",
                "Error extracting ./temp_transform/query_Tbl_PPM_transfer_AMO.\n"
                + str(e),
            )
            # label_map_1_status = 0
            return
        else:
            # rename columns from facility_identifier,mo_code,Code,clinician_name,Consultant_Status,LHD
            df_PpmTransferAmo.columns = [
                "facility_identifier",
                "mo_code",
                "Code",
                "clinician_name",
                "Consultant_Status",
                "LHD",
                "HLTH_ORG_OSP_OSP_ID",
                "MG_AUTH_OSP_OSP_ID",
                "SE_CBK_SK",
                "DIM_RSP_ISP_SK",
            ]
            df_PpmTransferAmo = df_PpmTransferAmo.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            df_PpmTransferAmo = df_PpmTransferAmo.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            df_PpmTransferAmo = df_PpmTransferAmo.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            df_PpmTransferAmo = df_PpmTransferAmo.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
    else:
        df_PpmTransferAmo = pd.DataFrame(
            columns=[
                "facility_identifier",
                "mo_code",
                "Code",
                "clinician_name",
                "Consultant_Status",
                "LHD",
                "HLTH_ORG_OSP_OSP_ID",
                "MG_AUTH_OSP_OSP_ID",
                "SE_CBK_SK",
                "DIM_RSP_ISP_SK",
            ]
        )
    logging.info("df_PpmTransferAmo=%s", len(df_PpmTransferAmo))
    # tbl_PPM_transfer_AMO = pd.concat([df_file_PpmTransferAmo, df_PpmTransferAmo], axis=0)
    # 31 oct - test
    # df_file_PpmTransferAmo.to_csv('./temp_transform/test_imported_Tbl_PPM_transfer_AMO.csv', index=False, na_rep='', float_format=str, decimal=str, date_format=str)
    # df_PpmTransferAmo.to_csv('./temp_transform/test_query_df_PpmTransferAmo.csv', index=False, na_rep='', float_format=str, decimal=str, date_format=str)

    # 31 Oct : Due to issue mentioned in https://abft101.atlassian.net/browse/AQA-259 below merge is commented and concatenation is a better option
    """
    tbl_PPM_transfer_AMO = pd.merge(df_file_PpmTransferAmo[['facility_identifier', 'mo_code', 'Code', 'clinician_name', 'Consultant_Status', 'LHD']], \
    df_PpmTransferAmo[['facility_identifier', 'mo_code', 'Code', 'clinician_name', 'LHD', 'HLTH_ORG_OSP_OSP_ID', 'MG_AUTH_OSP_OSP_ID', 'SE_CBK_SK']], how='outer', on=['facility_identifier', 'mo_code', 'Code', 'LHD'], suffixes=('_x', '_y'))
    df_PpmTransferAmo = df_PpmTransferAmo.applymap(str)#.apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    df_PpmTransferAmo = df_PpmTransferAmo.applymap(lambda x: x.strip() if isinstance(x, str) else x)
    df_PpmTransferAmo = df_PpmTransferAmo.apply(lambda x: x.replace(regex=r'^NaT$', value='') if x.dtype == 'object' else x)
    df_PpmTransferAmo = df_PpmTransferAmo.apply(lambda x: x.replace(regex=r'^nan$', value='') if x.dtype == 'object' else x)  
    tbl_PPM_transfer_AMO= tbl_PPM_transfer_AMO.fillna("")
    tbl_PPM_transfer_AMO['clinician_name'] = np.where((tbl_PPM_transfer_AMO['clinician_name_x'].isnull()) | (tbl_PPM_transfer_AMO['clinician_name_x']==''), tbl_PPM_transfer_AMO['clinician_name_y'], tbl_PPM_transfer_AMO['clinician_name_x'])
    tbl_PPM_transfer_AMO.drop(columns=['clinician_name_x', 'clinician_name_y'], inplace=True)
    """
    tbl_PPM_transfer_AMO = pd.concat(
        [df_file_PpmTransferAmo, df_PpmTransferAmo], axis=0
    )

    # 31 oct - test
    # tbl_PPM_transfer_AMO.to_csv('./temp_transform/test_merge_tbl_PPM_transfer_AMO_1.csv', index=False, na_rep='', float_format=str, decimal=str, date_format=str)

    # 31 Oct : Due to issue mentioned in https://abft101.atlassian.net/browse/AQA-259 below code is new
    tbl_PPM_transfer_AMO = tbl_PPM_transfer_AMO[
        tbl_PPM_transfer_AMO["LHD"] == lhd_global
    ]
    tbl_PPM_transfer_AMO["Consultant_Status"] = (
        tbl_PPM_transfer_AMO["Consultant_Status"].astype(str).str.strip()
    )
    tbl_PPM_transfer_AMO = tbl_PPM_transfer_AMO[
        tbl_PPM_transfer_AMO["facility_identifier"].isin(
            facilities_included_list_global
        )
    ]
    tbl_PPM_transfer_AMO.sort_values(
        by=[
            "facility_identifier",
            "mo_code",
            "Code",
            "clinician_name",
            "LHD",
            "Consultant_Status",
        ],
        inplace=True,
    )

    # 31 oct - test
    # tbl_PPM_transfer_AMO.to_csv('./temp_transform/test_merge_tbl_PPM_transfer_AMO_2.csv', index=False, na_rep='', float_format=str, decimal=str, date_format=str)

    tbl_PPM_transfer_AMO.drop_duplicates(
        subset=["facility_identifier", "mo_code", "Code", "clinician_name", "LHD"],
        keep="last",
        inplace=True,
    )
    tbl_PPM_transfer_AMO.sort_values(by=["Consultant_Status"], inplace=True)

    # 31 oct - test
    # tbl_PPM_transfer_AMO.to_csv('./temp_transform/test_merge_tbl_PPM_transfer_AMO_3.csv', index=False, na_rep='', float_format=str, decimal=str, date_format=str)

    logging.info(
        "tbl_PPM_transfer_AMO created with %s records after merging %s records from ./Costing/Tbl_PPM_transfer_AMO.csv and %s records from ./temp_transform/query_Tbl_PPM_transfer_AMO.csv.",
        len(tbl_PPM_transfer_AMO),
        len(df_file_PpmTransferAmo),
        len(df_PpmTransferAmo),
    )
    tbl_PPM_transfer_AMO = tbl_PPM_transfer_AMO[
        [
            "facility_identifier",
            "mo_code",
            "Code",
            "clinician_name",
            "Consultant_Status",
            "LHD",
            "HLTH_ORG_OSP_OSP_ID",
            "MG_AUTH_OSP_OSP_ID",
            "SE_CBK_SK",
            "DIM_RSP_ISP_SK",
        ]
    ]
    # Access query: Update_X800_On_tbl_PPM_transfer_AMO
    # UPDATE tbl_PPM_transfer_AMO SET tbl_PPM_transfer_AMO.LHD = "Q230" WHERE (((tbl_PPM_transfer_AMO.LHD)="X800") AND ((tbl_PPM_transfer_AMO.facility_identifier)="Q230"));
    # 26 Aug - Not required
    """
    if lhd_global=='X800':
        if messagebox.askyesno("Update LHD", "Do you want to set tbl_PPM_transfer_AMO.LHD = Q230 where LHD=X800 and facility_identifier = Q230?"):
            logging.info('User wants to set tbl_PPM_transfer_AMO.LHD = Q230 where LHD=X800 and facility_identifier = Q230. This will impact %s records in tbl_PPM_transfer_AMO.', len(tbl_PPM_transfer_AMO[((tbl_PPM_transfer_AMO['LHD']=='X800') & (tbl_PPM_transfer_AMO['facility_identifier']=='Q230'))]))
            tbl_PPM_transfer_AMO['LHD'] =  np.where(((tbl_PPM_transfer_AMO['LHD']=='X800') & (tbl_PPM_transfer_AMO['facility_identifier']=='Q230')), 'Q230', tbl_PPM_transfer_AMO['LHD'])
    """
    tbl_PPM_transfer_AMO = tbl_PPM_transfer_AMO.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    tbl_PPM_transfer_AMO = tbl_PPM_transfer_AMO.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    tbl_PPM_transfer_AMO = tbl_PPM_transfer_AMO.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    tbl_PPM_transfer_AMO.to_csv(
        "./ExtractorDB/Tbl_PPM_transfer_AMO.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    logging.info(
        "%s records saved to ./ExtractorDB/Tbl_PPM_transfer_AMO.csv.",
        len(tbl_PPM_transfer_AMO),
    )
    cleanup_memory(df_file_PpmTransferAmo)
    cleanup_memory(df_PpmTransferAmo)
    logging.info("transform_ppm_transform_amo() completed.")


def transform_pla_role_table():
    logging.info("transform_pla_role_table() started.")
    global \
        lhd_global, \
        facilities_excluded_list_global, \
        facilities_included_list_global, \
        roundid, \
        start_date, \
        end_date, \
        nwau_v, \
        icd10_v, \
        drg1_v, \
        drg2_v, \
        drg4_v, \
        snap_v, \
        amhcc_v, \
        cost_weight_v, \
        srg_drg_v
    """
    PLA_Role_Table - given,mandatory
        Totals records number from PLA_Role_Table file is :
    """
    # label_map_6_status = 1
    file_PLA_Role_Table = "./Costing/PLA_Role_Table.csv"
    if os.path.isfile(file_PLA_Role_Table):
        try:
            df_PLA_Role_Table = read_csv_file(
                file_PLA_Role_Table,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error", "Error extracting PLA_Role_Table.\n" + str(e)
            )
            # label_map_6_status = 0
            return
        else:
            df_PLA_Role_Table = df_PLA_Role_Table[
                df_PLA_Role_Table["LHD"] == lhd_global
            ]
            df_PLA_Role_Table = df_PLA_Role_Table[
                df_PLA_Role_Table["HospID"].isin(facilities_included_list_global)
            ]
            logging.info("df_PLA_Role_Table=%s", len(df_PLA_Role_Table))
            df_PLA_Role_Table.sort_values(
                by=["LHD", "HospID", "Ward", "Role", "RoleType", "Speciality"],
                inplace=True,
            )
            df_PLA_Role_Table["Speciality"] = (
                df_PLA_Role_Table["Speciality"].astype(str).str.strip()
            )
            df_PLA_Role_Table = df_PLA_Role_Table.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            df_PLA_Role_Table = df_PLA_Role_Table.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            df_PLA_Role_Table = df_PLA_Role_Table.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            df_PLA_Role_Table = df_PLA_Role_Table.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
            df_PLA_Role_Table.sort_values(by=["Speciality"], inplace=True)
            df_PLA_Role_Table = df_PLA_Role_Table[
                ["Role", "RoleType", "HospID", "Ward", "Speciality", "LHD"]
            ]
            df_PLA_Role_Table.to_csv(
                "./ExtractorDB/PLA_Role_Table.csv",
                index=False,
                na_rep="",
                float_format=str,
                decimal=str,
                date_format=str,
            )
    else:
        messagebox.showerror(
            "File Error", "Error extracting PLA_Role_Table. File is missing."
        )
    logging.info(
        "%s records saved to ./ExtractorDB/PLA_Role_Table.csv.", len(df_PLA_Role_Table)
    )
    cleanup_memory(df_PLA_Role_Table)
    logging.info("transform_pla_role_table() completed.")


def transform_edroledelin():
    logging.info("transform_edroledelin() started.")
    global \
        lhd_global, \
        facilities_excluded_list_global, \
        facilities_included_list_global, \
        roundid, \
        start_date, \
        end_date, \
        nwau_v, \
        icd10_v, \
        drg1_v, \
        drg2_v, \
        drg4_v, \
        snap_v, \
        amhcc_v, \
        cost_weight_v, \
        srg_drg_v
    """
    EDRoleDelin - given,mandatory
        Totals records number from EDRoleDelin file is :
    """
    file_EdRoleDelin = "./Costing/EDRoleDelin.csv"
    if os.path.isfile(file_EdRoleDelin):
        try:
            df_file_EdRoleDelin = read_csv_file(
                file_EdRoleDelin,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error", "Error extracting EDRoleDelin.\n" + str(e)
            )
            return
        else:
            df_file_EdRoleDelin = df_file_EdRoleDelin[
                df_file_EdRoleDelin["area_identifier"] == lhd_global
            ]
            df_file_EdRoleDelin = df_file_EdRoleDelin[
                df_file_EdRoleDelin["facility_identifier"].isin(
                    facilities_included_list_global
                )
            ]
            logging.info("df_file_EdRoleDelin=%s", len(df_file_EdRoleDelin))
            df_file_EdRoleDelin = df_file_EdRoleDelin[
                [
                    "facility_identifier",
                    "facility_name",
                    "EmergRoleDelin",
                    "area_identifier",
                ]
            ]
            df_file_EdRoleDelin = df_file_EdRoleDelin.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            df_file_EdRoleDelin = df_file_EdRoleDelin.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            df_file_EdRoleDelin = df_file_EdRoleDelin.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            df_file_EdRoleDelin = df_file_EdRoleDelin.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
            df_file_EdRoleDelin = df_file_EdRoleDelin[
                [
                    "facility_identifier",
                    "facility_name",
                    "EmergRoleDelin",
                    "area_identifier",
                ]
            ]
            df_file_EdRoleDelin.to_csv(
                "./temp_transform/imported_EdRoleDelin.csv",
                index=False,
                na_rep="",
                float_format=str,
                decimal=str,
                date_format=str,
            )
    else:
        messagebox.showerror(
            "File Error", "Error extracting EDRoleDelin. File is missing."
        )
    """Appends the Hospital to the tbl_EDRoleDelin table if the hospital is not in the table. This step would rarely append data unless there was a new hospital which had an ED or a hospital without an ED now having a ED"""
    # Access query: append tbl_EDRoleDelin
    # INSERT INTO tbl_EDRoleDelin ( facility_identifier, facility_name, area_identifier ) SELECT tbl_ppm_ED_Encounter_preclean.Hospital, tbl_dbo_Facility.facility_name, tbl_dbo_Facility.area_identifier FROM tbl_ppm_ED_Encounter_preclean INNER JOIN tbl_dbo_Facility ON tbl_ppm_ED_Encounter_preclean.Hospital = tbl_dbo_Facility.facility_identifier GROUP BY tbl_ppm_ED_Encounter_preclean.Hospital, tbl_dbo_Facility.facility_name, tbl_dbo_Facility.area_identifier;
    # download PPMEdEncounterPreClean
    file_PpmEdEncounterPreclean = "./ExtractorDB/PpmEdEncounterPreclean.csv"
    if os.path.isfile(file_PpmEdEncounterPreclean):
        try:
            tbl_ppm_ED_Encounter_preclean = read_csv_file(
                file_PpmEdEncounterPreclean,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_ppm_ED_Encounter_preclean from ./ExtractorDB/PpmEdEncounterPreclean.csv.\n"
                + str(e),
            )
            return
        else:
            tbl_ppm_ED_Encounter_preclean = tbl_ppm_ED_Encounter_preclean.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_ppm_ED_Encounter_preclean = tbl_ppm_ED_Encounter_preclean.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_ppm_ED_Encounter_preclean = tbl_ppm_ED_Encounter_preclean.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_ppm_ED_Encounter_preclean = tbl_ppm_ED_Encounter_preclean.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
    else:
        tbl_ppm_ED_Encounter_preclean = pd.DataFrame(
            columns=[
                "Stu",
                "EncounterNumber",
                "PostCode",
                "Suburb",
                "EncounterType",
                "PatientNumber",
                "Hospital",
                "LengthofStay",
                "StartDateTime",
                "EndDateTime",
                "Age",
                "WeightedSeparation",
                "Extra_InpatientStayNumber",
                "Extra:TriageCategory",
                "Extra_ModeofArrival",
                "Extra:EDVisitType",
                "Extra_EDDiagnosis",
                "Extra:ModeofSep",
                "Extra_EDTriageDateTime",
                "Extra_EDReferralSource",
                "Extra_IndigenousStatus",
                "Extra_MedicareNumber",
                "person_area_uid",
                "SnapFrom",
                "Extra_UDG",
                "Extra:URG",
                "Extra_ClinStartDTTM",
                "Extra_DepartureReadyDTTM",
                "Extra_EDDiagnosisType",
                "Extra_AdmWard",
                "Extra_EdCompStatus",
                "Extra_Version_Id",
                "Extra_LHD_of_usual_residence",
                "getdate",
                "HLTH_ORG_OSP_OSP_ID",
                "MG_AUTH_OSP_OSP_ID",
                "SE_CBK_SK",
                "CL_ID_EUID",
                "CL_ID_IHI",
                "FST_BILL_CATEGORY_CD",
                "EDW_Pat_Number",
                "EDW_Enc_Number",
            ]
        )
    # download OutputFacility
    file_OutputFacility = "./ExtractorDB/OutputFacility.csv"
    if os.path.isfile(file_OutputFacility):
        try:
            tbl_dbo_Facility = read_csv_file(
                file_OutputFacility,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_dbo_Facility from ./ExtractorDB/OutputFacility.csv.\n"
                + str(e),
            )
            return
        else:
            tbl_dbo_Facility = tbl_dbo_Facility.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_dbo_Facility = tbl_dbo_Facility.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_dbo_Facility = tbl_dbo_Facility.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_Facility = tbl_dbo_Facility.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_Facility = tbl_dbo_Facility[
                tbl_dbo_Facility["area_identifier"] == lhd_global
            ]
            tbl_dbo_Facility = tbl_dbo_Facility[
                tbl_dbo_Facility["facility_identifier"].isin(
                    facilities_included_list_global
                )
            ]
            tbl_dbo_Facility.drop_duplicates(
                subset=[
                    "facility_identifier",
                    "area_identifier",
                    "facility_name",
                    "snap_upd_batch_run_no",
                ],
                keep="last",
                inplace=True,
            )
    else:
        tbl_dbo_Facility = pd.DataFrame(
            columns=[
                "facility_identifier",
                "area_identifier",
                "facility_name",
                "snap_upd_batch_run_no",
                "HLTH_ORG_OSP_OSP_ID",
                "MG_AUTH_OSP_OSP_ID",
            ]
        )
    if len(tbl_ppm_ED_Encounter_preclean) > 0 and len(tbl_dbo_Facility) > 0:
        df_tbl_EDRoleDelin = pd.merge(
            tbl_ppm_ED_Encounter_preclean[["Hospital"]],
            tbl_dbo_Facility[
                ["facility_identifier", "facility_name", "area_identifier"]
            ],
            how="inner",
            left_on="Hospital",
            right_on="facility_identifier",
            suffixes=("", "_drop"),
        )
        df_tbl_EDRoleDelin = df_tbl_EDRoleDelin.apply(
            lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
        )
        if len(df_tbl_EDRoleDelin) > 0:
            df_tbl_EDRoleDelin = df_tbl_EDRoleDelin[
                ["facility_identifier", "facility_name", "area_identifier"]
            ]
            df_tbl_EDRoleDelin = df_tbl_EDRoleDelin.fillna("")
            df_tbl_EDRoleDelin = df_tbl_EDRoleDelin.sort_values(
                by=["facility_identifier", "facility_name", "area_identifier"]
            )
            df_tbl_EDRoleDelin = df_tbl_EDRoleDelin[
                df_tbl_EDRoleDelin["area_identifier"] == lhd_global
            ]
            df_tbl_EDRoleDelin = df_tbl_EDRoleDelin[
                df_tbl_EDRoleDelin["facility_identifier"].isin(
                    facilities_included_list_global
                )
            ]
            df_tbl_EDRoleDelin.drop_duplicates(
                subset=["facility_identifier", "facility_name", "area_identifier"],
                keep="last",
                inplace=True,
            )
            logging.info("df_tbl_EDRoleDelin=%s", len(df_tbl_EDRoleDelin))
    else:
        df_tbl_EDRoleDelin = pd.DataFrame(
            columns=["facility_identifier", "facility_name", "area_identifier"]
        )
    df_tbl_EDRoleDelin = df_tbl_EDRoleDelin.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    df_tbl_EDRoleDelin = df_tbl_EDRoleDelin.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    df_tbl_EDRoleDelin = df_tbl_EDRoleDelin.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    df_tbl_EDRoleDelin.to_csv(
        "./temp_transform/query_EDRoleDelin.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    # concatenate tbl_EDRoleDelin
    # tbl_EDRoleDelin = pd.concat([df_file_EdRoleDelin, df_tbl_EDRoleDelin], axis=0)
    # Commenting below code as the join looks to be only on facility_identifier and area_identifier, and the value from the imported takes precedence.
    # tbl_EDRoleDelin = pd.merge(df_file_EdRoleDelin[['facility_identifier', 'facility_name', 'EmergRoleDelin', 'area_identifier']], \
    # df_tbl_EDRoleDelin[['facility_identifier', 'facility_name', 'area_identifier']], how='outer', on=['facility_identifier', 'facility_name', 'area_identifier'], suffixes=('', '_drop'))
    # 31 Oct - Merge is causing some records to have null facility names and
    tbl_EDRoleDelin = pd.merge(
        df_file_EdRoleDelin[
            [
                "facility_identifier",
                "facility_name",
                "EmergRoleDelin",
                "area_identifier",
            ]
        ],
        df_tbl_EDRoleDelin[["facility_identifier", "facility_name", "area_identifier"]],
        how="outer",
        on=["facility_identifier", "area_identifier"],
        suffixes=("_x", "_y"),
    )
    tbl_EDRoleDelin = tbl_EDRoleDelin.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    tbl_EDRoleDelin = tbl_EDRoleDelin.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    tbl_EDRoleDelin = tbl_EDRoleDelin.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    tbl_EDRoleDelin = tbl_EDRoleDelin.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    tbl_EDRoleDelin["facility_name"] = np.where(
        (tbl_EDRoleDelin["facility_name_x"] != tbl_EDRoleDelin["facility_name_y"])
        & (
            (tbl_EDRoleDelin["facility_name_x"].isnull())
            | (tbl_EDRoleDelin["facility_name_x"] == "")
        ),
        tbl_EDRoleDelin["facility_name_y"],
        tbl_EDRoleDelin["facility_name_x"],
    )
    tbl_EDRoleDelin.drop(columns=["facility_name_x", "facility_name_y"], inplace=True)
    tbl_EDRoleDelin = tbl_EDRoleDelin.fillna("")
    tbl_EDRoleDelin = tbl_EDRoleDelin[tbl_EDRoleDelin["area_identifier"] == lhd_global]
    tbl_EDRoleDelin = tbl_EDRoleDelin[
        tbl_EDRoleDelin["facility_identifier"].isin(facilities_included_list_global)
    ]
    tbl_EDRoleDelin["EmergRoleDelin"] = (
        tbl_EDRoleDelin["EmergRoleDelin"].astype(str).str.strip()
    )
    tbl_EDRoleDelin.sort_values(
        by=["area_identifier", "facility_identifier", "EmergRoleDelin"], inplace=True
    )
    tbl_EDRoleDelin.drop_duplicates(
        subset=["area_identifier", "facility_identifier", "EmergRoleDelin"],
        keep="last",
        inplace=True,
    )
    logging.info(
        "tbl_EDRoleDelin created with %s records after merging %s records from ./Costing/EDRoleDelin.csv and %s records from ./temp_transform/query_EDRoleDelin.csv.",
        len(tbl_EDRoleDelin),
        len(df_file_EdRoleDelin),
        len(df_tbl_EDRoleDelin),
    )
    tbl_EDRoleDelin = tbl_EDRoleDelin.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    tbl_EDRoleDelin = tbl_EDRoleDelin.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    tbl_EDRoleDelin = tbl_EDRoleDelin.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    tbl_EDRoleDelin.sort_values(by=["EmergRoleDelin"], inplace=True)
    # Access query: Update_X800_On_tbl_EDRoleDelin
    # UPDATE tbl_EDRoleDelin SET tbl_EDRoleDelin.area_identifier = "Q230" WHERE (((tbl_EDRoleDelin.facility_identifier)="Q230") AND ((tbl_EDRoleDelin.area_identifier)="X800"));
    # 26 Aug - Not required
    """
    if lhd_global=='X800':
        if messagebox.askyesno("Update area_identifier", "Do you want to set tbl_EDRoleDelin.area_identifier = Q230 where area_identifier=X800 and facility_identifier = Q230?"):
            logging.info('User wants to set tbl_EDRoleDelin.area_identifier = Q230 where area_identifier=X800 and facility_identifier = Q230. This will impact %s records in tbl_EDRoleDelin.', len(tbl_EDRoleDelin[((tbl_EDRoleDelin['area_identifier']=='X800') & (tbl_EDRoleDelin['facility_identifier']=='Q230'))]))
            tbl_EDRoleDelin['area_identifier'] =  np.where(((tbl_EDRoleDelin['area_identifier']=='X800') & (tbl_EDRoleDelin['facility_identifier']=='Q230')), 'Q230', tbl_EDRoleDelin['area_identifier'])
    """
    tbl_EDRoleDelin = tbl_EDRoleDelin[
        ["facility_identifier", "facility_name", "EmergRoleDelin", "area_identifier"]
    ]
    tbl_EDRoleDelin.to_csv(
        "./ExtractorDB/EDRoleDelin.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    logging.info(
        "%s records saved to ./ExtractorDB/EDRoleDelin.csv.", len(tbl_EDRoleDelin)
    )
    cleanup_memory(df_file_EdRoleDelin)
    cleanup_memory(tbl_ppm_ED_Encounter_preclean)
    cleanup_memory(tbl_dbo_Facility)
    cleanup_memory(df_tbl_EDRoleDelin)
    cleanup_memory(tbl_EDRoleDelin)
    logging.info("transform_edroledelin() completed.")


def transform_specialtyportalmapping():
    logging.info("transform_specialtyportalmapping() started.")
    global \
        lhd_global, \
        facilities_excluded_list_global, \
        facilities_included_list_global, \
        roundid, \
        start_date, \
        end_date, \
        nwau_v, \
        icd10_v, \
        drg1_v, \
        drg2_v, \
        drg4_v, \
        snap_v, \
        amhcc_v, \
        cost_weight_v, \
        srg_drg_v
    """
    SpecialtyPortalMapping - given,mandatory
        Totals records number from SpecialtyPortalMapping file is :    
    """
    # label_map_4_status = 1
    file_SpecialtyPortalMapping = "./Costing/SpecialityPortalMapping.csv"
    if os.path.isfile(file_SpecialtyPortalMapping):
        try:
            df_file_SpecialtyPortalMapping = read_csv_file(
                file_SpecialtyPortalMapping,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error", "Error extracting SpecialtyPortalMapping.\n" + str(e)
            )
            # label_map_4_status = 0
            return
        else:
            df_file_SpecialtyPortalMapping["Clinic"] = (
                df_file_SpecialtyPortalMapping["Clinic"].astype(str).str.strip()
            )
            df_file_SpecialtyPortalMapping = df_file_SpecialtyPortalMapping[
                df_file_SpecialtyPortalMapping["area_identifier"] == lhd_global
            ]
            df_file_SpecialtyPortalMapping = df_file_SpecialtyPortalMapping[
                df_file_SpecialtyPortalMapping["Hospital"].isin(
                    facilities_included_list_global
                )
            ]
            logging.info(
                "df_file_SpecialtyPortalMapping=%s", len(df_file_SpecialtyPortalMapping)
            )
            df_file_SpecialtyPortalMapping = df_file_SpecialtyPortalMapping.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            df_file_SpecialtyPortalMapping = df_file_SpecialtyPortalMapping.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            df_file_SpecialtyPortalMapping = df_file_SpecialtyPortalMapping.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            df_file_SpecialtyPortalMapping = df_file_SpecialtyPortalMapping.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
            df_file_SpecialtyPortalMapping.to_csv(
                "./temp_transform/imported_SpecialityPortalMapping.csv",
                index=False,
                na_rep="",
                float_format=str,
                decimal=str,
                date_format=str,
            )
    else:
        messagebox.showerror(
            "File Error", "Error extracting SpecialtyPortalMapping. File is missing."
        )
    ##############################################################
    ### Appends data form the tbl_dbo_days_episode into SpecialtyPortalMapping in appendix 1. Used to map facility + specialty_unit_code
    # Access query: append SpecialtyPortalMapping
    # INSERT INTO SpecialtyPortalMapping ( area_identifier, Hospital, Clinic ) SELECT tbl_dbo_Facility.area_identifier, tbl_dbo_Facility.facility_identifier, Trim([tbl_dbo_DAYS_EPISODE]![facility_identifier] & "-" & [tbl_dbo_DAYS_EPISODE]![specialty_unit_code]) AS Expr1 FROM tbl_dbo_days_episode INNER JOIN tbl_dbo_Facility ON tbl_dbo_days_episode.facility_identifier = tbl_dbo_Facility.facility_identifier GROUP BY tbl_dbo_Facility.area_identifier, tbl_dbo_Facility.facility_identifier, Trim([tbl_dbo_DAYS_EPISODE]![facility_identifier] & "-" & [tbl_dbo_DAYS_EPISODE]![specialty_unit_code]);
    # download OutputDaysEpisode
    file_OutputDaysEpisode = "./ExtractorDB/OutputDaysEpisode.csv"
    if os.path.isfile(file_OutputDaysEpisode):
        try:
            tbl_dbo_days_episode = read_csv_file(
                file_OutputDaysEpisode,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_dbo_days_episode from ./ExtractorDB/OutputDaysEpisode.csv.\n"
                + str(e),
            )
            # label_map_1_status = 0
            return
        else:
            tbl_dbo_days_episode = tbl_dbo_days_episode.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_dbo_days_episode = tbl_dbo_days_episode.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_dbo_days_episode = tbl_dbo_days_episode.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_days_episode = tbl_dbo_days_episode.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_days_episode = tbl_dbo_days_episode[
                tbl_dbo_days_episode["facility_identifier"].isin(
                    facilities_included_list_global
                )
            ]
    else:
        tbl_dbo_days_episode = pd.DataFrame(
            columns=[
                "facility_identifier",
                "stay_number",
                "episode_sequence_number",
                "specialty_unit_code",
                "start_date",
                "start_time",
                "end_date",
                "end_time",
                "local_bed_identifier",
                "ward_identifier",
                "unit_type",
                "trans_type",
                "mo_code",
                "dbo_DAYS_EPISODE_snap_curr_indicator",
                "dbo_EPISODE_ATS_snap_curr_indicator",
                "leave_type",
                "clinician_name",
                "dbo_PRACTICE_snap_curr_indicator",
                "dbo_FACILITY_snap_curr_indicator",
                "HLTH_ORG_OSP_OSP_ID",
                "MG_AUTH_OSP_OSP_ID",
                "SE_CBK_SK",
            ]
        )
    # download OutputFacility
    file_OutputFacility = "./ExtractorDB/OutputFacility.csv"
    if os.path.isfile(file_OutputFacility):
        try:
            tbl_dbo_Facility = read_csv_file(
                file_OutputFacility,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_dbo_Facility from ./ExtractorDB/OutputFacility.csv.\n"
                + str(e),
            )
            return
        else:
            tbl_dbo_Facility = tbl_dbo_Facility.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_dbo_Facility = tbl_dbo_Facility.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_dbo_Facility = tbl_dbo_Facility.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_Facility = tbl_dbo_Facility.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_Facility = tbl_dbo_Facility[
                tbl_dbo_Facility["area_identifier"] == lhd_global
            ]
            tbl_dbo_Facility = tbl_dbo_Facility[
                tbl_dbo_Facility["facility_identifier"].isin(
                    facilities_included_list_global
                )
            ]
            tbl_dbo_Facility.drop_duplicates(
                subset=[
                    "facility_identifier",
                    "area_identifier",
                    "facility_name",
                    "snap_upd_batch_run_no",
                ],
                keep="last",
                inplace=True,
            )
    else:
        tbl_dbo_Facility = pd.DataFrame(
            columns=[
                "facility_identifier",
                "area_identifier",
                "facility_name",
                "snap_upd_batch_run_no",
                "HLTH_ORG_OSP_OSP_ID",
                "MG_AUTH_OSP_OSP_ID",
            ]
        )
    if len(tbl_dbo_Facility) > 0 and len(tbl_dbo_days_episode) > 0:
        df_specialtyPortalMapping = pd.merge(
            tbl_dbo_days_episode[["facility_identifier", "specialty_unit_code"]],
            tbl_dbo_Facility[["facility_identifier", "area_identifier"]],
            how="inner",
            on="facility_identifier",
            suffixes=("", "_drop"),
        )
        df_specialtyPortalMapping = df_specialtyPortalMapping.apply(
            lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
        )
        df_specialtyPortalMapping["Clinic"] = (
            df_specialtyPortalMapping["facility_identifier"].astype(str).str.strip()
            + "-"
            + df_specialtyPortalMapping["specialty_unit_code"].astype(str).str.strip()
        )
        df_specialtyPortalMapping["Clinic"] = (
            df_specialtyPortalMapping["Clinic"].astype(str).str.strip()
        )
        df_specialtyPortalMapping = df_specialtyPortalMapping.sort_values(
            by=["area_identifier", "facility_identifier", "Clinic"]
        )
        df_specialtyPortalMapping.drop_duplicates(
            subset=["area_identifier", "facility_identifier", "Clinic"],
            keep="last",
            inplace=True,
        )
        df_specialtyPortalMapping.rename(
            columns={"facility_identifier": "Hospital"}, inplace=True
        )
        df_specialtyPortalMapping = df_specialtyPortalMapping[
            ["area_identifier", "Hospital", "Clinic"]
        ]
        df_specialtyPortalMapping = df_specialtyPortalMapping.fillna("")
        df_specialtyPortalMapping = df_specialtyPortalMapping[
            df_specialtyPortalMapping["area_identifier"] == lhd_global
        ]
        df_specialtyPortalMapping = df_specialtyPortalMapping[
            df_specialtyPortalMapping["Hospital"].isin(facilities_included_list_global)
        ]
    else:
        df_specialtyPortalMapping = pd.DataFrame(
            columns=["area_identifier", "Hospital", "Clinic"]
        )
    df_specialtyPortalMapping = df_specialtyPortalMapping.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    df_specialtyPortalMapping = df_specialtyPortalMapping.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    df_specialtyPortalMapping = df_specialtyPortalMapping.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    df_specialtyPortalMapping.to_csv(
        "./temp_transform/query_SpecialityPortalMapping.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    logging.info("df_specialtyPortalMapping=%s", len(df_specialtyPortalMapping))
    # Append df_file_SpecialtyPortalMapping to df_specialtyPortalMapping
    # specialtyPortalMapping = pd.concat([df_file_SpecialtyPortalMapping, df_specialtyPortalMapping], axis=0)
    specialtyPortalMapping = pd.merge(
        df_file_SpecialtyPortalMapping[
            ["area_identifier", "Hospital", "Clinic", "SpecialityPortal"]
        ],
        df_specialtyPortalMapping[["area_identifier", "Hospital", "Clinic"]],
        how="outer",
        on=["area_identifier", "Hospital", "Clinic"],
        suffixes=("", "_drop"),
    )
    specialtyPortalMapping = specialtyPortalMapping.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    specialtyPortalMapping = specialtyPortalMapping.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    specialtyPortalMapping = specialtyPortalMapping.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    specialtyPortalMapping = specialtyPortalMapping.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    specialtyPortalMapping = specialtyPortalMapping.fillna("")
    specialtyPortalMapping = specialtyPortalMapping[
        specialtyPortalMapping["area_identifier"] == lhd_global
    ]
    specialtyPortalMapping = specialtyPortalMapping[
        specialtyPortalMapping["Hospital"].isin(facilities_included_list_global)
    ]
    specialtyPortalMapping["SpecialityPortal"] = (
        specialtyPortalMapping["SpecialityPortal"].astype(str).str.strip()
    )
    specialtyPortalMapping.sort_values(
        by=["area_identifier", "Hospital", "Clinic", "SpecialityPortal"], inplace=True
    )
    specialtyPortalMapping.drop_duplicates(
        subset=["area_identifier", "Hospital", "Clinic"], keep="first", inplace=True
    )
    specialtyPortalMapping.sort_values(by=["SpecialityPortal"], inplace=True)
    logging.info(
        "specialtyPortalMapping created with %s records after merging %s records from ./Costing/SpecialityPortalMapping.csv and %s records from ./temp_transform/query_SpecialityPortalMapping.csv.",
        len(specialtyPortalMapping),
        len(df_file_SpecialtyPortalMapping),
        len(df_specialtyPortalMapping),
    )
    # Access query: Update_X800_On_SpecialtyPortalMapping
    # UPDATE SpecialityPortalMapping SET SpecialityPortalMapping.area_identifier = "Q230" WHERE (((SpecialityPortalMapping.area_identifier)="X800") AND ((SpecialityPortalMapping.Hospital)="Q230"));
    # 26 Aug - Not required
    """
    if lhd_global=='X800':
        if messagebox.askyesno("Update area_identifier", "Do you want to set specialtyPortalMapping.area_identifier = Q230 where area_identifier=X800 and Hospital = Q230?"):
            logging.info('User wants to set specialtyPortalMapping.area_identifier = Q230 where area_identifier=X800 and Hospital = Q230. This will impact %s records in specialtyPortalMapping.', len(specialtyPortalMapping[((specialtyPortalMapping['area_identifier']=='X800') & (specialtyPortalMapping['Hospital']=='Q230'))]))
            specialtyPortalMapping['area_identifier'] =  np.where(((specialtyPortalMapping['area_identifier']=='X800') & (specialtyPortalMapping['Hospital']=='Q230')), 'Q230', specialtyPortalMapping['area_identifier'])
    """
    specialtyPortalMapping = specialtyPortalMapping[
        ["area_identifier", "Hospital", "Clinic", "SpecialityPortal"]
    ]
    specialtyPortalMapping.to_csv(
        "./ExtractorDB/SpecialityPortalMapping.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    logging.info(
        "%s records saved to ./ExtractorDB/SpecialityPortalMapping.csv.",
        len(specialtyPortalMapping),
    )
    cleanup_memory(df_file_SpecialtyPortalMapping)
    cleanup_memory(tbl_dbo_days_episode)
    cleanup_memory(tbl_dbo_Facility)
    cleanup_memory(df_specialtyPortalMapping)
    cleanup_memory(specialtyPortalMapping)
    logging.info("transform_specialtyportalmapping() completed.")


def transform_criticalcaregroup():
    logging.info("transform_criticalcaregroup() started.")
    global \
        lhd_global, \
        facilities_excluded_list_global, \
        facilities_included_list_global, \
        roundid, \
        start_date, \
        end_date, \
        nwau_v, \
        icd10_v, \
        drg1_v, \
        drg2_v, \
        drg4_v, \
        snap_v, \
        amhcc_v, \
        cost_weight_v, \
        srg_drg_v
    """
    Criticalcaregroup - given,mandatory
        Totals records number from Criticalcaregroup file is :
    """
    # label_map_5_status = 1
    file_CriticalCareGroup = "./Costing/CriticalCareGroup.csv"
    if os.path.isfile(file_CriticalCareGroup):
        try:
            # #UnicodeDecodeError: 'utf-8' codec can't decode byte 0xa0 in position 623: invalid start byte
            # Ref: https://stackoverflow.com/a/60063875
            df_file_CriticalCareGroup = read_csv_file(
                file_CriticalCareGroup,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error", "Error extracting CriticalCareGroup.\n" + str(e)
            )
            # label_map_5_status = 0
            return
        else:
            df_file_CriticalCareGroup = df_file_CriticalCareGroup[
                df_file_CriticalCareGroup["area_identifier"] == lhd_global
            ]
            df_file_CriticalCareGroup = df_file_CriticalCareGroup[
                df_file_CriticalCareGroup["facility_identifier"].isin(
                    facilities_included_list_global
                )
            ]
            df_file_CriticalCareGroup["ward_name"] = (
                df_file_CriticalCareGroup["ward_name"].astype(str).str.strip()
            )
            # df_file_CriticalCareGroup['NSW_Role_Delineation'] = df_file_CriticalCareGroup['NSW_Role_Delineation'].astype(str)
            logging.info("df_file_CriticalCareGroup=%s", len(df_file_CriticalCareGroup))
            df_file_CriticalCareGroup = df_file_CriticalCareGroup.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            df_file_CriticalCareGroup = df_file_CriticalCareGroup.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            df_file_CriticalCareGroup = df_file_CriticalCareGroup.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            df_file_CriticalCareGroup = df_file_CriticalCareGroup.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
            df_file_CriticalCareGroup["unit_type"] = df_file_CriticalCareGroup[
                "unit_type"
            ].astype(str)
            df_file_CriticalCareGroup.to_csv(
                "./temp_transform/imported_CriticalCareGroup.csv",
                index=False,
                na_rep="",
                float_format=str,
                decimal=str,
                date_format=str,
            )
    else:
        messagebox.showerror(
            "File Error", "Error extracting CriticalCareGroup. File is missing."
        )
        # label_map_5_status = 0
    """Appends data in CriticalCareGroup from the db_ward_episode table fields based on the dates and lhd and where unit type = ("12","15","16","25","26","33","34","37") . This is used as a basis to create the critical and HITH ward hours calculations in the encounter file """
    # Access query: append CriticalCareGroup
    # INSERT INTO criticalcaregroup ( facility_identifier, ward_identifier, unit_type, PPMWardUnit, [NSW Role Delineation], [College Intensive Care Medicine Role Delineation], area_identifier ) SELECT tbl_dbo_days_episode.facility_identifier, tbl_dbo_days_episode.ward_identifier, tbl_dbo_days_episode.unit_type, IIf(Trim([tbl_dbo_days_episode]![ward_identifier])="MATERNITY-",[tbl_dbo_days_episode]![facility_identifier] & "-" & Left([tbl_dbo_days_episode]![ward_identifier],9) & Trim([tbl_dbo_days_episode]![unit_type]),[tbl_dbo_days_episode]![facility_identifier] & "-" & Trim([tbl_dbo_days_episode]![ward_identifier]) & Trim([tbl_dbo_days_episode]![unit_type])) AS ward, [ICU RoleDelin].[NSW Role Delineation], [ICU RoleDelin].[College Intensive Care Medicine Role Delineation], tbl_dbo_Facility.area_identifier FROM (tbl_dbo_days_episode LEFT JOIN [ICU RoleDelin] ON tbl_dbo_days_episode.facility_identifier = [ICU RoleDelin].[Hospita;]) INNER JOIN tbl_dbo_Facility ON tbl_dbo_days_episode.facility_identifier = tbl_dbo_Facility.facility_identifier GROUP BY tbl_dbo_days_episode.facility_identifier, tbl_dbo_days_episode.ward_identifier, tbl_dbo_days_episode.unit_type, IIf(Trim([tbl_dbo_days_episode]![ward_identifier])="MATERNITY-",[tbl_dbo_days_episode]![facility_identifier] & "-" & Left([tbl_dbo_days_episode]![ward_identifier],9) & Trim([tbl_dbo_days_episode]![unit_type]),[tbl_dbo_days_episode]![facility_identifier] & "-" & Trim([tbl_dbo_days_episode]![ward_identifier]) & Trim([tbl_dbo_days_episode]![unit_type])), [ICU RoleDelin].[NSW Role Delineation], [ICU RoleDelin].[College Intensive Care Medicine Role Delineation], tbl_dbo_Facility.area_identifier HAVING (((tbl_dbo_days_episode.unit_type) In ("12","15","16","25","26","33","34","37")));
    """ OLD
    NHCDC Cost A File Field     Unit Type
    ICU1Hours   15
    ICU2Hours   15
    ICU3Hours   15
    NICU        37
    PICU        15
    ICCUHours   33
    PsyICUHours 12
    HDU         34
    HITH        25
    SCN         16
    NEW
    AICU1	15, 91, 92,93
    AICU2	15, 91, 92
    AICU3	15, 91, 92
    CCU	33
    HDU	13,34, 92,93
    HITH	25
    NICU	37
    PICU	15, 91, 92
    PSICU	12
    SCN	16
    """
    """
    ICU_RoleDelin - given,mandatory
        Totals records number from ICU_RoleDelin file is :
    """
    # label_map_3_status = 1
    file_ICU_RoleDelin = "./Costing/ICU_RoleDelin.csv"
    if os.path.isfile(file_ICU_RoleDelin):
        try:
            icu_RoleDelin = read_csv_file(
                file_ICU_RoleDelin,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error", "Error extracting ICU_RoleDelin.\n" + str(e)
            )
            # label_map_3_status = 0
            return
        else:
            icu_RoleDelin["College Intensive Care Medicine Role Delineation"] = (
                np.where(
                    (
                        icu_RoleDelin[
                            "College Intensive Care Medicine Role Delineation"
                        ].isnull()
                    )
                    | (
                        icu_RoleDelin[
                            "College Intensive Care Medicine Role Delineation"
                        ]
                        == ""
                    ),
                    "0",
                    icu_RoleDelin["College Intensive Care Medicine Role Delineation"],
                )
            )
            icu_RoleDelin["CICM Role Delineation Self Reported"] = np.where(
                (icu_RoleDelin["CICM Role Delineation Self Reported"].isnull())
                | (icu_RoleDelin["CICM Role Delineation Self Reported"] == ""),
                "0",
                icu_RoleDelin["CICM Role Delineation Self Reported"],
            )
            icu_RoleDelin = icu_RoleDelin[
                [
                    "Hospital",
                    "NSW Role Delineation",
                    "College Intensive Care Medicine Role Delineation",
                    "CICM Role Delineation Self Reported",
                ]
            ]
            icu_RoleDelin = icu_RoleDelin[
                icu_RoleDelin["Hospital"].isin(facilities_included_list)
            ]
            logging.info("icu_RoleDelin=%s", len(icu_RoleDelin))
            icu_RoleDelin = icu_RoleDelin.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            icu_RoleDelin = icu_RoleDelin.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            icu_RoleDelin = icu_RoleDelin.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            icu_RoleDelin = icu_RoleDelin.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
            icu_RoleDelin.to_csv(
                "./Output/ICU_RoleDelin.csv",
                index=False,
                na_rep="",
                float_format=str,
                decimal=str,
                date_format=str,
            )
            # change column names now to merge with tbl_dbo_days_episode
            icu_RoleDelin.columns = [
                "Hospital",
                "NSW_Role_Delineation",
                "College_Intensive_Care_Medicine_Role_Delineation",
                "CICM Role Delineation Self Reported",
            ]
    else:
        messagebox.showerror(
            "File Error", "Error extracting ICU_RoleDelin. File is missing."
        )
        # label_map_3_status = 0
    # download OutputDaysEpisode
    file_OutputDaysEpisode = "./ExtractorDB/OutputDaysEpisode.csv"
    if os.path.isfile(file_OutputDaysEpisode):
        try:
            tbl_dbo_days_episode = read_csv_file(
                file_OutputDaysEpisode,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_dbo_days_episode from ./ExtractorDB/OutputDaysEpisode.csv.\n"
                + str(e),
            )
            # label_map_1_status = 0
            return
        else:
            tbl_dbo_days_episode = tbl_dbo_days_episode.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_dbo_days_episode = tbl_dbo_days_episode.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_dbo_days_episode = tbl_dbo_days_episode.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_days_episode = tbl_dbo_days_episode.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_days_episode = tbl_dbo_days_episode[
                tbl_dbo_days_episode["facility_identifier"].isin(
                    facilities_included_list_global
                )
            ]
    else:
        tbl_dbo_days_episode = pd.DataFrame(
            columns=[
                "facility_identifier",
                "stay_number",
                "episode_sequence_number",
                "specialty_unit_code",
                "start_date",
                "start_time",
                "end_date",
                "end_time",
                "local_bed_identifier",
                "ward_identifier",
                "unit_type",
                "trans_type",
                "mo_code",
                "dbo_DAYS_EPISODE_snap_curr_indicator",
                "dbo_EPISODE_ATS_snap_curr_indicator",
                "leave_type",
                "clinician_name",
                "dbo_PRACTICE_snap_curr_indicator",
                "dbo_FACILITY_snap_curr_indicator",
                "HLTH_ORG_OSP_OSP_ID",
                "MG_AUTH_OSP_OSP_ID",
                "SE_CBK_SK",
            ]
        )
    # download OutputFacility
    file_OutputFacility = "./ExtractorDB/OutputFacility.csv"
    if os.path.isfile(file_OutputFacility):
        try:
            tbl_dbo_Facility = read_csv_file(
                file_OutputFacility,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_dbo_Facility from ./ExtractorDB/OutputFacility.csv.\n"
                + str(e),
            )
            # label_map_1_status = 0
            return
        else:
            tbl_dbo_Facility = tbl_dbo_Facility.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_dbo_Facility = tbl_dbo_Facility.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_dbo_Facility = tbl_dbo_Facility.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_Facility = tbl_dbo_Facility.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_Facility = tbl_dbo_Facility[
                tbl_dbo_Facility["area_identifier"] == lhd_global
            ]
            tbl_dbo_Facility = tbl_dbo_Facility[
                tbl_dbo_Facility["facility_identifier"].isin(
                    facilities_included_list_global
                )
            ]
            tbl_dbo_Facility.drop_duplicates(
                subset=[
                    "facility_identifier",
                    "area_identifier",
                    "facility_name",
                    "snap_upd_batch_run_no",
                ],
                keep="last",
                inplace=True,
            )
    else:
        tbl_dbo_Facility = pd.DataFrame(
            columns=[
                "facility_identifier",
                "area_identifier",
                "facility_name",
                "snap_upd_batch_run_no",
                "HLTH_ORG_OSP_OSP_ID",
                "MG_AUTH_OSP_OSP_ID",
            ]
        )
    if len(tbl_dbo_Facility) > 0 and len(tbl_dbo_days_episode) > 0:
        # OLD UNIT TYPES - 06 May 2024
        # df_ccg_1 =  pd.merge(tbl_dbo_days_episode[tbl_dbo_days_episode['unit_type'].isin(['12','15','16','25','26','33','34','37'])][['facility_identifier', 'ward_identifier', 'unit_type']], icu_RoleDelin[['Hospital', 'NSW_Role_Delineation', 'College_Intensive_Care_Medicine_Role_Delineation']], how='left', left_on = 'facility_identifier', right_on = 'Hospital', suffixes=('', '_drop'))
        # NEW UNIT TYPES - 06 May 2024
        df_ccg_1 = pd.merge(
            tbl_dbo_days_episode[
                tbl_dbo_days_episode["unit_type"].isin(
                    ["12", "15", "16", "25", "26", "33", "34", "37", "91", "92", "93"]
                )
            ][["facility_identifier", "ward_identifier", "unit_type"]],
            icu_RoleDelin[
                [
                    "Hospital",
                    "NSW_Role_Delineation",
                    "College_Intensive_Care_Medicine_Role_Delineation",
                ]
            ],
            how="left",
            left_on="facility_identifier",
            right_on="Hospital",
            suffixes=("", "_drop"),
        )
        df_ccg_1 = df_ccg_1.apply(
            lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
        )
        df_ccg_1 = df_ccg_1.fillna("")
        df_criticalcaregroup = pd.merge(
            df_ccg_1,
            tbl_dbo_Facility[["facility_identifier", "area_identifier"]],
            how="inner",
            on="facility_identifier",
            suffixes=("", "_drop"),
        )
        df_criticalcaregroup = df_criticalcaregroup.apply(
            lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
        )
        df_criticalcaregroup = df_criticalcaregroup.fillna("")
        df_criticalcaregroup = df_criticalcaregroup[
            [
                "facility_identifier",
                "ward_identifier",
                "unit_type",
                "NSW_Role_Delineation",
                "College_Intensive_Care_Medicine_Role_Delineation",
                "area_identifier",
            ]
        ]
        df_criticalcaregroup["PPMWardUnit"] = np.where(
            df_criticalcaregroup["ward_identifier"].astype(str).str.strip().str.upper()
            == "MATERNITY-",
            df_criticalcaregroup["facility_identifier"]
            + "-"
            + df_criticalcaregroup["ward_identifier"].str[:9].str.strip()
            + ""
            + df_criticalcaregroup["unit_type"].astype(str).str.strip(),
            df_criticalcaregroup["facility_identifier"]
            + "-"
            + df_criticalcaregroup["ward_identifier"].astype(str).str.strip()
            + ""
            + df_criticalcaregroup["unit_type"].astype(str).str.strip(),
        )
        df_criticalcaregroup = df_criticalcaregroup.sort_values(
            by=[
                "facility_identifier",
                "ward_identifier",
                "unit_type",
                "PPMWardUnit",
                "NSW_Role_Delineation",
                "College_Intensive_Care_Medicine_Role_Delineation",
            ]
        )
        df_criticalcaregroup.drop_duplicates(
            subset=[
                "facility_identifier",
                "ward_identifier",
                "unit_type",
                "PPMWardUnit",
                "NSW_Role_Delineation",
                "College_Intensive_Care_Medicine_Role_Delineation",
            ],
            keep="last",
            inplace=True,
        )
        df_criticalcaregroup = df_criticalcaregroup[
            [
                "facility_identifier",
                "ward_identifier",
                "unit_type",
                "NSW_Role_Delineation",
                "College_Intensive_Care_Medicine_Role_Delineation",
                "area_identifier",
                "PPMWardUnit",
            ]
        ]
        df_criticalcaregroup = df_criticalcaregroup[
            df_criticalcaregroup["area_identifier"] == lhd_global
        ]
        df_criticalcaregroup = df_criticalcaregroup[
            df_criticalcaregroup["facility_identifier"].isin(facilities_included_list)
        ]
        df_criticalcaregroup["ward_identifier"] = (
            df_criticalcaregroup["ward_identifier"].astype(str).str.strip()
        )
        df_criticalcaregroup = df_criticalcaregroup.fillna("")
    else:
        df_criticalcaregroup = pd.DataFrame(
            columns=[
                "facility_identifier",
                "ward_identifier",
                "unit_type",
                "NSW_Role_Delineation",
                "College_Intensive_Care_Medicine_Role_Delineation",
                "area_identifier",
                "PPMWardUnit",
            ]
        )
        df_ccg_1 = pd.DataFrame()
    df_criticalcaregroup = df_criticalcaregroup.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    df_criticalcaregroup = df_criticalcaregroup.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    df_criticalcaregroup = df_criticalcaregroup.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    df_criticalcaregroup.to_csv(
        "./temp_transform/query_CriticalCareGroup.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    logging.info("df_criticalcaregroup=%s", len(df_criticalcaregroup))
    # dbo.WARD.ward_name, '' AS CritGroup ('') are missing from df_criticalcaregroup. Should they be populated using 'Critical Care query' in access.
    # Append df_file_CriticalCareGroup to df_criticalcaregroup
    # criticalcaregroup = pd.concat([df_file_CriticalCareGroup, df_criticalcaregroup], axis=0)
    df_file_CriticalCareGroup["unit_type"] = df_file_CriticalCareGroup[
        "unit_type"
    ].astype(str)
    df_file_CriticalCareGroup["unit_type"] = df_file_CriticalCareGroup[
        "unit_type"
    ].fillna("")
    # df_criticalcaregroup['NSW_Role_Delineation'] = df_criticalcaregroup['NSW_Role_Delineation'].astype('Int64', errors='ignore')
    # If the above type conversion gives error: TypeError: cannot safely cast non-equivalent float64 to int64
    # Try below fix. Ref: https://stackoverflow.com/a/67021201
    df_criticalcaregroup["NSW_Role_Delineation"] = np.floor(
        pd.to_numeric(df_criticalcaregroup["NSW_Role_Delineation"], errors="coerce")
    ).astype("Int64", errors="ignore")
    df_criticalcaregroup["NSW_Role_Delineation"] = df_criticalcaregroup[
        "NSW_Role_Delineation"
    ].astype(str)
    df_criticalcaregroup["NSW_Role_Delineation"] = df_criticalcaregroup[
        "NSW_Role_Delineation"
    ].fillna("")
    criticalcaregroup = pd.merge(
        df_file_CriticalCareGroup[
            [
                "facility_identifier",
                "ward_identifier",
                "ward_name",
                "unit_type",
                "NSW_Role_Delineation",
                "College_Intensive_Care_Medicine_Role_Delineation",
                "CritGroup",
                "area_identifier",
                "PPMWardUnit",
            ]
        ],
        df_criticalcaregroup[
            [
                "facility_identifier",
                "ward_identifier",
                "unit_type",
                "NSW_Role_Delineation",
                "College_Intensive_Care_Medicine_Role_Delineation",
                "area_identifier",
                "PPMWardUnit",
            ]
        ],
        how="outer",
        on=[
            "facility_identifier",
            "ward_identifier",
            "unit_type",
            "area_identifier",
            "PPMWardUnit",
        ],
        suffixes=("_x", "_y"),
    )
    criticalcaregroup = criticalcaregroup.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    criticalcaregroup = criticalcaregroup.fillna("")
    # Commenting the below 2 steps to implement another logic. If there is any difference between imported file and query file on NSW_Role_Delineation and  College_Intensive_Care_Medicine_Role_Delineation, then the value in the imported file gets precedence.
    # criticalcaregroup['NSW_Role_Delineation'] = np.where((criticalcaregroup['NSW_Role_Delineation_x'].isnull()) | (criticalcaregroup['NSW_Role_Delineation_x']=='') | (criticalcaregroup['NSW_Role_Delineation_x']=='0'), criticalcaregroup['NSW_Role_Delineation_y'], criticalcaregroup['NSW_Role_Delineation_x'])
    # criticalcaregroup['College_Intensive_Care_Medicine_Role_Delineation'] = np.where((criticalcaregroup['College_Intensive_Care_Medicine_Role_Delineation_x'].isnull()) | (criticalcaregroup['College_Intensive_Care_Medicine_Role_Delineation_x']=='') | (criticalcaregroup['College_Intensive_Care_Medicine_Role_Delineation_x']=='0'), criticalcaregroup['College_Intensive_Care_Medicine_Role_Delineation_y'], criticalcaregroup['College_Intensive_Care_Medicine_Role_Delineation_x'])
    criticalcaregroup["NSW_Role_Delineation"] = np.where(
        (
            criticalcaregroup["NSW_Role_Delineation_x"]
            != criticalcaregroup["NSW_Role_Delineation_y"]
        ),
        criticalcaregroup["NSW_Role_Delineation_x"],
        criticalcaregroup["NSW_Role_Delineation_x"],
    )
    criticalcaregroup["College_Intensive_Care_Medicine_Role_Delineation"] = np.where(
        (
            criticalcaregroup["College_Intensive_Care_Medicine_Role_Delineation_x"]
            != criticalcaregroup["College_Intensive_Care_Medicine_Role_Delineation_y"]
        ),
        criticalcaregroup["College_Intensive_Care_Medicine_Role_Delineation_x"],
        criticalcaregroup["College_Intensive_Care_Medicine_Role_Delineation_x"],
    )
    criticalcaregroup.drop(
        columns=[
            "NSW_Role_Delineation_x",
            "NSW_Role_Delineation_y",
            "College_Intensive_Care_Medicine_Role_Delineation_x",
            "College_Intensive_Care_Medicine_Role_Delineation_y",
        ],
        inplace=True,
    )
    criticalcaregroup = criticalcaregroup[
        criticalcaregroup["area_identifier"] == lhd_global
    ]
    criticalcaregroup = criticalcaregroup[
        criticalcaregroup["facility_identifier"].isin(facilities_included_list)
    ]
    criticalcaregroup["CritGroup"] = (
        criticalcaregroup["CritGroup"].astype(str).str.strip()
    )
    criticalcaregroup["College_Intensive_Care_Medicine_Role_Delineation"] = (
        criticalcaregroup["College_Intensive_Care_Medicine_Role_Delineation"]
        .astype(str)
        .str.strip()
    )
    criticalcaregroup["NSW_Role_Delineation"] = (
        criticalcaregroup["NSW_Role_Delineation"].astype(str).str.strip()
    )
    criticalcaregroup.sort_values(
        by=[
            "area_identifier",
            "facility_identifier",
            "ward_identifier",
            "unit_type",
            "NSW_Role_Delineation",
            "College_Intensive_Care_Medicine_Role_Delineation",
            "PPMWardUnit",
            "CritGroup",
        ],
        inplace=True,
    )
    criticalcaregroup.drop_duplicates(
        subset=[
            "area_identifier",
            "facility_identifier",
            "ward_identifier",
            "ward_name",
            "unit_type",
            "NSW_Role_Delineation",
            "College_Intensive_Care_Medicine_Role_Delineation",
            "PPMWardUnit",
            "CritGroup",
        ],
        keep="last",
        inplace=True,
    )
    criticalcaregroup = criticalcaregroup.replace("<NA>", "", regex=True)
    criticalcaregroup = criticalcaregroup.replace(regex=r"^<NA>$", value="")
    criticalcaregroup = criticalcaregroup.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    criticalcaregroup = criticalcaregroup.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    criticalcaregroup = criticalcaregroup.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    criticalcaregroup.sort_values(
        by=["NSW_Role_Delineation", "College_Intensive_Care_Medicine_Role_Delineation"],
        inplace=True,
    )
    logging.info(
        "criticalcaregroup created with %s records after merging %s records from ./Costing/CriticalCareGroup.csv and %s records from ./temp_transform/query_CriticalCareGroup.csv.",
        len(criticalcaregroup),
        len(df_file_CriticalCareGroup),
        len(df_criticalcaregroup),
    )
    # Access query: Update_X800_On_CriticalCareGroup
    # UPDATE CriticalCareGroup SET CriticalCareGroup.area_identifier = "Q230" WHERE (((CriticalCareGroup.area_identifier)="X800") AND ((CriticalCareGroup.facility_identifier)="Q230"));
    # 26 Aug - Not required
    """
    if lhd_global=='X800':
        if messagebox.askyesno("Update area_identifier", "Do you want to set criticalcaregroup.area_identifier = Q230 where area_identifier=X800 and facility_identifier = Q230?"):
            logging.info('User wants to set criticalcaregroup.area_identifier = Q230 where area_identifier=X800 and facility_identifier = Q230. This will impact %s records in criticalcaregroup.', len(criticalcaregroup[((criticalcaregroup['area_identifier']=='X800') & (criticalcaregroup['facility_identifier']=='Q230'))]))
            criticalcaregroup['area_identifier'] =  np.where(((criticalcaregroup['area_identifier']=='X800') & (criticalcaregroup['facility_identifier']=='Q230')), 'Q230', criticalcaregroup['area_identifier'])
    """
    criticalcaregroup = criticalcaregroup[
        [
            "facility_identifier",
            "ward_identifier",
            "ward_name",
            "unit_type",
            "NSW_Role_Delineation",
            "College_Intensive_Care_Medicine_Role_Delineation",
            "CritGroup",
            "area_identifier",
            "PPMWardUnit",
        ]
    ]
    criticalcaregroup.to_csv(
        "./ExtractorDB/CriticalCareGroup.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    logging.info(
        "%s records saved to ./ExtractorDB/CriticalCareGroup.csv.",
        len(criticalcaregroup),
    )
    cleanup_memory(df_file_CriticalCareGroup)
    cleanup_memory(icu_RoleDelin)
    cleanup_memory(tbl_dbo_days_episode)
    cleanup_memory(tbl_dbo_Facility)
    cleanup_memory(df_criticalcaregroup)
    cleanup_memory(df_ccg_1)
    cleanup_memory(criticalcaregroup)
    logging.info("transform_criticalcaregroup() completed.")


def fn_display_data_in_window(fn_type, csv_file):
    logging.info(
        "User has opened review table to perform %s for %s.", fn_type, csv_file
    )
    """global tbl_dbo_Facility, tbl_dbo_stay, tbl_Patient_Contact_Details, tbl_dbo_episode_ats, tbl_dbo_Ward_Episode, tbl_dbo_episode, \
    tbl_dbo_episode_srg, tbl_dbo_episode_DRG, tbl_dbo_wl_exit, ed_nwau, acute_nwau, tbl_dbo_days_episode, \
    tbl_PPM_transfer_Leave_00, tbl_PPM_transfer_Leave02, tbl_PPM_ICD_diagnoses, tbl_PPM_ICD_procedures, tbl_ppm_ED_Patient, \
    tbl_ppm_ED_Encounter_preclean, df_ED_Diag_Slice, df_ExcludedEncounters, snapApp_CostingExtract, df_AMHCC_extract, \
    df_SNAPRec, snap_NWAU, df_EdRoleDelin, df_ICU_RoleDelin, df_SpecialtyPortalMapping, df_CriticalCareGroup, \
    df_PLA_Role_Table, df_PLA_Mapping_00, df_PLA_AMHCC, df_Class_Descriptions, df_SpecialtyPortalValues, df_MDC, \
    df_Excluded_EpisodeAts, tbl_Episode_ATS_end_date_update, df_Excluded_EpisodeAts_enddate_le_startdate, df_PpmTransferAmo, \
    tbl_PPM_transfer_Leave_00, tbl_PPM_transfer_Leave_02, df_ED_Diag_Slice, df_Excluded_ED_Encounters, tbl_PPM_Patient, \
    criticalcaregroup, specialtyPortalMapping, tbl_PPM_transfer_AMO, tbl_EDRoleDelin, pla_Role_Table, tbl_ExcludedEncounters"""
    display_flag = 1
    # Ref: https://github.com/markmac99/UKmon-shared/blob/8ddecc19428292db06bfaa0ad2d4545e7d7447cf/usermgmt/windows/stationMaint2.py#L231
    # Ref: documentation: https://github.com/ragardner/tksheet/wiki/Version-6
    # Ref: Example Loading Data from Excel: https://github.com/ragardner/tksheet/wiki/Version-6#example-loading-data-from-excel
    # Ref: add new commands: https://github.com/ragardner/tksheet/issues/17
    win = Tk()
    win.geometry("%dx%d+%d+%d" % (1000, 500, center_x1, center_y1))
    win.configure(bg="white")
    win.grid_columnconfigure(0, weight=1)
    win.grid_rowconfigure(0, weight=1)
    frame = Frame(win, bg="white")
    frame.grid_columnconfigure(0, weight=1)
    frame.grid_rowconfigure(0, weight=1)
    if fn_type == "QC":
        caminfo = read_csv_file(
            "./Output/" + csv_file + ".csv",
            encoding="unicode_escape",
            dtype=str,
            keep_default_na=False,
            na_values="",
        )
        if len(caminfo) == 0:
            logging.info(
                "Display of QC. There are no rows to display in ./Output/%s.csv for %s excluding facilities=%s",
                csv_file,
                lhd_global,
                str(facilities_excluded_list_global),
            )
            messagebox.showinfo(
                "QC",
                "There are no rows to display in "
                + csv_file
                + ".csv for "
                + lhd_global
                + " excluding facilities="
                + str(facilities_excluded_list_global),
            )
            display_flag = 0
            win.destroy()
    elif fn_type == "transform":
        """ 
        BEFORE extraction:
        1. filter by area identifier - amo payment status, hith map, ed role delin, specialty portal, sub program role
        2.* for amo payment - i think this is the data from file in costing folder and query records.
        3.* for specialty portal mapping -  all the displayed rows had specialtyportal as null. in transform window, this is not the data from file in the costing folder
        4. for critical hith - all records i saw are  the data from file in the costing folder. if values of nswrole_delineation and CICM Role delineation is null then show  them as 0.
        5. for edrole delin - all records i saw are  the data from file in the costing folder.
        6. for sub program roles -  all records i saw are  the data from file "pla role" in the costing folder.
        """
        # print("fn_type=",fn_type, ". csv_file=", csv_file, ". lhd=", lhd_global, ". facilities excluded=", facilities_excluded_list_global)
        if messagebox.askyesno(
            "Review Tables",
            "Click Yes to review "
            + csv_file
            + " here.\nClick No to review "
            + csv_file
            + " at ./ExtractorDB/"
            + csv_file
            + ".csv",
        ):
            logging.info(
                "Display of Transform-Review Table. User selected the option to review ./ExtractorDB/%s in the application window.",
                csv_file,
            )
            messagebox.showinfo(
                "Review Tables",
                "After making changes to the cells, press Tab before saving your changes.",
            )
            if csv_file == "PLA_Role_Table":
                caminfo = read_csv_file(
                    "./ExtractorDB/" + csv_file + ".csv",
                    encoding="unicode_escape",
                    dtype=str,
                    keep_default_na=False,
                    na_values="",
                )
                caminfo = caminfo[caminfo["LHD"] == lhd_global]
                caminfo = caminfo[
                    caminfo["HospID"].isin(facilities_included_list_global)
                ]
            elif csv_file == "EDRoleDelin":
                caminfo = read_csv_file(
                    "./ExtractorDB/" + csv_file + ".csv",
                    encoding="unicode_escape",
                    dtype=str,
                    keep_default_na=False,
                    na_values="",
                )
                caminfo = caminfo[caminfo["area_identifier"] == lhd_global]
                caminfo = caminfo[
                    caminfo["facility_identifier"].isin(facilities_included_list_global)
                ]
            elif csv_file == "CriticalCareGroup":
                caminfo = read_csv_file(
                    "./ExtractorDB/" + csv_file + ".csv",
                    encoding="unicode_escape",
                    dtype=str,
                    keep_default_na=False,
                    na_values="",
                )
                caminfo = caminfo[caminfo["area_identifier"] == lhd_global]
                caminfo = caminfo[
                    caminfo["facility_identifier"].isin(facilities_included_list_global)
                ]
            elif csv_file == "Tbl_PPM_transfer_AMO":
                caminfo = read_csv_file(
                    "./ExtractorDB/" + csv_file + ".csv",
                    encoding="unicode_escape",
                    dtype=str,
                    keep_default_na=False,
                    na_values="",
                )
                caminfo = caminfo[caminfo["LHD"] == lhd_global]
                caminfo = caminfo[
                    caminfo["facility_identifier"].isin(facilities_included_list_global)
                ]
            elif csv_file == "SpecialityPortalMapping":
                # Add column SpecialtyPortal with a Drop down menu with values from ./Costing/SpecialtyPortal.txt
                caminfo = read_csv_file(
                    "./ExtractorDB/" + csv_file + ".csv",
                    encoding="unicode_escape",
                    dtype=str,
                    keep_default_na=False,
                    na_values="",
                )
                caminfo["Clinic"] = caminfo["Clinic"].astype(str).str.strip()
                caminfo = caminfo[caminfo["area_identifier"] == lhd_global]
                caminfo = caminfo[
                    caminfo["Hospital"].isin(facilities_included_list_global)
                ]
            if len(caminfo) == 0:
                logging.info(
                    "Display of Transform-Review Table. There are no rows to display in ./ExtractorDB/%s.csv for %s excluding facilities=%s",
                    csv_file,
                    lhd_global,
                    str(facilities_excluded_list_global),
                )
                messagebox.showinfo(
                    "Review Tables",
                    "There are no rows to display in "
                    + csv_file
                    + ".csv for "
                    + lhd_global
                    + " excluding facilities="
                    + str(facilities_excluded_list),
                )
        else:
            logging.info(
                "Display of Transform-Review Table. User selected the option to review from./ExtractorDB/%s  instead of reviewing it in the application window.",
                csv_file,
            )
            messagebox.showinfo(
                "Review Tables",
                "This window will now close.\n"
                + csv_file
                + ".csv will open now in Excel.\nAfter making the required changes, please save the csv file as CSV (Comma delimited) (*.csv) and NOT AS CSV UTF-8 (Comma delimited) (*.csv) .",
            )
            display_flag = 0
            win.destroy()
            ############################Launch excel - Start #############
            caminfo = pd.DataFrame()
            # Ref: https://www.tutorialspoint.com/How-to-print-full-path-of-current-file-s-directory-in-Python
            # Ref: https://www.delftstack.com/api/python/python-os-startfile
            # Ref: https://stackoverflow.com/questions/35940748/use-python-to-launch-excel-file
            file_to_open = "ExtractorDB/" + csv_file + ".csv"
            # print(os.path.abspath(file_to_open))
            os.startfile(os.path.abspath(file_to_open))
            #############################Launch excel - Stop #############
    else:
        # reconciliation
        caminfo = read_csv_file(
            "./Output/" + csv_file + ".csv",
            encoding="unicode_escape",
            dtype=str,
            keep_default_na=False,
            na_values="",
        )
    if len(caminfo) > 0:
        caminfo = caminfo.applymap(
            str
        )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
        caminfo = caminfo.applymap(lambda x: x.strip() if isinstance(x, str) else x)
        caminfo = caminfo.apply(
            lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
        )
        caminfo = caminfo.apply(
            lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
        )
    if display_flag:
        data_list = caminfo.values.tolist()
        hdrs = caminfo.columns.tolist()
        # This column was already created in transform_Specialtyportalmapping()
        """if fn_type=='transform' and csv_file == 'SpecialityPortalMapping':
            # append column header SpecialtyPortal
            hdrs.append('SpecialtyPortal')"""
        datachanged = True
        sheet = Sheet(
            frame,
            data=data_list,
            headers=hdrs,
            expand_sheet_if_paste_too_big=True,
            header_font=("Times New Roman", 12, "bold"),
            font=("Times New Roman", 10, "normal"),
        )
        sheet.enable_bindings()
        if fn_type == "transform":
            if csv_file == "SpecialityPortalMapping":
                file_SpecialtyPortalValues = "./Costing/SpecialtyPortal.txt"
                if os.path.isfile(file_SpecialtyPortalValues):
                    try:
                        df_SpecialtyPortalValues_dropdown = read_csv_file(
                            file_SpecialtyPortalValues,
                            encoding="unicode_escape",
                            dtype=str,
                            keep_default_na=False,
                            na_values="",
                        )
                    except Exception as e:
                        logging.exception("Exception occurred")
                        messagebox.showerror(
                            "File Error",
                            "Error extracting SpecialtyPortalValues.\n" + str(e),
                        )
                    else:
                        # drop down. Ref: https://github.com/ragardner/tksheet/wiki/Version-6#example-readme-screenshot-code
                        specialty_portalValues_list = df_SpecialtyPortalValues_dropdown[
                            "Value"
                        ].tolist()
                        for row in range(len(data_list)):
                            # sheet.create_dropdown(r = row, c = 3, text = data_list[row][3], values = [""] + specialty_portalValues_list)
                            sheet.create_dropdown(
                                r=row,
                                c=3,
                                set_value=data_list[row][3],
                                values=[""] + specialty_portalValues_list,
                                set_cell_on_select=True,
                                redraw=True,
                                recreate=True,
                            )
            elif csv_file == "Tbl_PPM_transfer_AMO":
                for row in range(len(data_list)):
                    # sheet.create_dropdown(r = row, c = 4, text = data_list[row][4], values = [""] + ['SS', 'VMO', 'Other'])
                    sheet.create_dropdown(
                        r=row,
                        c=4,
                        set_value=data_list[row][4],
                        values=[""] + ["SS", "VMO", "Other"],
                        set_cell_on_select=True,
                        redraw=True,
                        recreate=True,
                    )
        if fn_type == "QC" or fn_type == "reconciliation":
            sheet.disable_bindings("edit_header", "edit_index", "edit_cell")
        else:
            sheet.disable_bindings("edit_header", "edit_index")
        frame.grid(row=0, column=0, sticky="nswe", padx=10, pady=25)
        sheet.grid(row=0, column=0, sticky="nswe", padx=10, pady=25)
        sheet.set_all_column_widths()
        sheet.set_all_cell_sizes_to_text()

        def doSaveChanges():
            if datachanged is True:
                if messagebox.askyesno(
                    "Save",
                    "This will save "
                    + csv_file
                    + ".csv in ./ExtractorDB/.\nReview Table button will disappear.\nDo you want to continue?",
                ):
                    logging.info(
                        "Display of Transform-Review Table. User selected the option to save the changes in ./ExtractorDB/%s.",
                        csv_file,
                    )
                    newdf = pd.DataFrame(data_list, columns=hdrs)
                    newdf = newdf.applymap(
                        str
                    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
                    newdf = newdf.applymap(
                        lambda x: x.strip() if isinstance(x, str) else x
                    )
                    newdf = newdf.apply(
                        lambda x: x.replace(regex=r"^NaT$", value="")
                        if x.dtype == "object"
                        else x
                    )
                    if fn_type == "transform":
                        try:
                            newdf.to_csv(
                                "./ExtractorDB/" + csv_file + ".csv",
                                index=False,
                                na_rep="",
                                float_format=str,
                                decimal=str,
                                date_format=str,
                            )
                            logging.info(
                                "Display of Transform-Review Table./ExtractorDB/%s.csv generated after user saved the changes",
                                csv_file,
                            )
                        except Exception as e:
                            logging.exception("Exception occurred")
                            logging.info(
                                "Display of Transform-Review Table. There was an error saving /ExtractorDB/%s.csv. %s ",
                                csv_file,
                                str(e),
                            )
                            messagebox.showerror(
                                "Review Tables",
                                "Error Saving "
                                + csv_file
                                + ".csv in ./ExtractorDB/"
                                + str(e),
                            )
                        else:
                            if csv_file == "CriticalCareGroup":
                                button_critical_care.destroy()
                                messagebox.showinfo(
                                    "Transform CriticalCareGroup",
                                    "If you still want to make changes to this mapping table before Finalising Transformations,\nplease edit "
                                    + csv_file
                                    + ".csv in ./ExtractorDB.",
                                )
                            if csv_file == "EDRoleDelin":
                                button_EDRoleDelin.destroy()
                                messagebox.showinfo(
                                    "Transform EDRoleDelin",
                                    "If you still want to make changes to this mapping table before Finalising Transformations,\nplease edit "
                                    + csv_file
                                    + ".csv in ./ExtractorDB.",
                                )
                            if csv_file == "SpecialityPortalMapping":
                                button_Specialtyportalmapping.destroy()
                                messagebox.showinfo(
                                    "Transform SpecialtyPortalMapping",
                                    "If you still want to make changes to this mapping table before Finalising Transformations,\nplease edit "
                                    + csv_file
                                    + ".csv in ./ExtractorDB.",
                                )
                            if csv_file == "PLA_Role_Table":
                                button_SubProgramRole.destroy()
                                messagebox.showinfo(
                                    "Transform PLA_Role_Table",
                                    "If you still want to make changes to this mapping table before Finalising Transformations,\nplease edit "
                                    + csv_file
                                    + ".csv in ./ExtractorDB.",
                                )
                            if csv_file == "Tbl_PPM_transfer_AMO":
                                button_amo_payment.destroy()
                                messagebox.showinfo(
                                    "Transform Tbl_PPM_transfer_AMO",
                                    "If you still want to make changes to this mapping table before Finalising Transformations,\nplease edit "
                                    + csv_file
                                    + ".csv in ./ExtractorDB.",
                                )
                    # If you want to make reconciliation display editable, uncomment below lines
                    """               
                    else:                   
                        try:
                            newdf.to_csv("./Output/"+csv_file+".csv", index=False, na_rep='', float_format=str, decimal=str, date_format=str)
                        except Exception as e:
                            logging.exception("Exception occurred")
                            messagebox.showerror("Reconciliation", "Error Saving "+csv_file+".csv in ./Output/"+str(e))
                    """
            frame.quit()
            win.destroy()

    if display_flag:

        def on_cancel():
            if datachanged is True:
                if messagebox.askyesno("Quit", "Do you want to save changes?"):
                    doSaveChanges()
            # frame.quit()# commented on 28 June 2024
            # win.destroy()# commented on 28 June 2024
            else:  # added else on 28 June 2024
                frame.quit()
                win.destroy()

        def on_closing():
            frame.quit()
            win.destroy()

        if fn_type == "QC" or fn_type == "reconciliation":
            btn_load = Button(win, text="Close", bg="white", command=on_closing)
            btn_load.place(x=525, y=450)
        else:
            # Button to Cancel
            btn_load = Button(win, text="Cancel", bg="white", command=on_cancel)
            btn_load.place(x=525, y=450)
            # Button to save
            btn_save = Button(win, text="Save", bg="white", command=doSaveChanges)
            btn_save.place(x=475, y=450)
        win.resizable(False, False)
        win.mainloop()
        logging.info("User has closed review table after performing %s.", fn_type)


def display_reconciliation(stream):
    if stream == "ed":
        messagebox.showinfo(
            "Under Construction", "Reconcile Ed Patient Data is Under Construction"
        )
        fn_display_data_in_window("reconciliation", "reconcileEdPatientData")
    elif stream == "ip":
        messagebox.showinfo(
            "Under Construction", "Reconcile Inpatient Data is Under Construction"
        )
        # uncomment below line
        # fn_display_data_in_window('reconciliation', 'reconcileInpatientData')


def display_quality_checks(qc_task):
    if qc_task == "wip":
        fn_display_data_in_window("QC", "qualityChecks_Wip3")
    elif qc_task == "ip_los":
        fn_display_data_in_window("QC", "qualityChecks_LosGrt100")
    elif qc_task == "pg_le_50":
        fn_display_data_in_window("QC", "qualityChecks_GerAgeLess50")
    elif qc_task == "ip_ed_transfer":
        fn_display_data_in_window("QC", "qualityChecks_LosLessThan20")
    elif qc_task == "ip_age_null":
        fn_display_data_in_window("QC", "qualityChecks_AgeAbove105")
    elif qc_task == "ip_los_le_2h":
        fn_display_data_in_window("QC", "qualityChecks_L61zLess2Hours")
    elif qc_task == "ip_icu_ge_1000":
        fn_display_data_in_window("QC", "qualityChecks_IcuHoursGt1000")
    elif qc_task == "ed_los_ge_2_ed_visit":
        fn_display_data_in_window("QC", "qualityChecks_EdGt2880")
    elif qc_task == "ed_los_ge_2_days_epi":
        fn_display_data_in_window("QC", "qualityChecks_EdGt2880AdmittedTransfer")
    elif qc_task == "ed_los_le_5m":
        fn_display_data_in_window("QC", "qualityChecks_EdLessThan5Min")
    elif qc_task == "ed_age_null":
        fn_display_data_in_window("QC", "qualityChecks_EdAgeMoreThan105")


def run_quality_checks():
    """global tbl_dbo_Facility, tbl_dbo_stay, tbl_Patient_Contact_Details, tbl_dbo_episode_ats, tbl_dbo_Ward_Episode, tbl_dbo_episode, \
    tbl_dbo_episode_srg, tbl_dbo_episode_DRG, tbl_dbo_wl_exit, ed_nwau, acute_nwau, tbl_dbo_days_episode, \
    tbl_PPM_transfer_Leave_00, tbl_PPM_transfer_Leave02, tbl_PPM_ICD_diagnoses, tbl_PPM_ICD_procedures, tbl_ppm_ED_Patient, \
    tbl_ppm_ED_Encounter_preclean, df_ED_Diag_Slice, df_ExcludedEncounters, snapApp_CostingExtract, df_AMHCC_extract, \
    df_SNAPRec, snap_NWAU, df_EdRoleDelin, df_ICU_RoleDelin, df_SpecialtyPortalMapping, df_CriticalCareGroup, \
    df_PLA_Role_Table, df_PLA_Mapping_00, df_PLA_AMHCC, df_Class_Descriptions, df_SpecialtyPortalValues, df_MDC, \
    df_Excluded_EpisodeAts, tbl_Episode_ATS_end_date_update, df_Excluded_EpisodeAts_enddate_le_startdate, df_PpmTransferAmo, \
    tbl_PPM_transfer_Leave_00, tbl_PPM_transfer_Leave_02, df_ED_Diag_Slice, df_Excluded_ED_Encounters, tbl_PPM_Patient, \
    criticalcaregroup, specialtyPortalMapping, tbl_PPM_transfer_AMO, tbl_EDRoleDelin, pla_Role_Table, tbl_ExcludedEncounters"""
    logging.info("run_quality_checks() - started - to prepare data for QC")
    global start_date, end_date
    # start_date = str(start_date.get())
    # end_date = str(end_date.get())
    end_date = str(end_date)
    start_date = str(start_date)
    end_date = end_date[:10] + " " + "23:59:59"
    start_date = start_date[:10] + " " + "00:00:00"
    logging.info(
        "In run_quality_checks, start_date=%s, end_date=%s",
        str(start_date),
        str(end_date),
    )
    ###############################################################################
    # download OutputEpisodeAts
    file_OutputEpisodeAts = "./ExtractorDB/OutputEpisodeAts.csv"
    if os.path.isfile(file_OutputEpisodeAts):
        try:
            tbl_dbo_episode_ats = read_csv_file(
                file_OutputEpisodeAts,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_dbo_episode_ats from ./ExtractorDB/OutputEpisodeAts.csv.\n"
                + str(e),
            )
            # label_2_sub.configure(text="Failed (tbl_dbo_episode_ats)...",fg='red')
            # label_2_status = 0
            return
        else:
            tbl_dbo_episode_ats = tbl_dbo_episode_ats.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_dbo_episode_ats = tbl_dbo_episode_ats.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_dbo_episode_ats = tbl_dbo_episode_ats.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_episode_ats = tbl_dbo_episode_ats.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_episode_ats = tbl_dbo_episode_ats[
                tbl_dbo_episode_ats["facility_identifier"].isin(
                    facilities_included_list_global
                )
            ]
    else:
        tbl_dbo_episode_ats = pd.DataFrame()
    # download tbl_dbo_stay
    file_tbl_dbo_stay = "./ExtractorDB/OutputStay.csv"
    if os.path.isfile(file_tbl_dbo_stay):
        try:
            tbl_dbo_stay = read_csv_file(
                file_tbl_dbo_stay,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error",
                "Error extracting OutputStay from ./ExtractorDB/OutputStay.csv.\n"
                + str(e),
            )
            # label_2_sub.configure(text="Failed (OutputStay)...",fg='red')
            # label_2_status = 0
            return
        else:
            tbl_dbo_stay = tbl_dbo_stay.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_dbo_stay = tbl_dbo_stay.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_dbo_stay = tbl_dbo_stay.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_stay = tbl_dbo_stay.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
            # 27 July 2024 - stay episode seq number
            tbl_dbo_stay["episode_sequence_number"] = (
                tbl_dbo_stay["episode_sequence_number"]
                .astype(str)
                .str.pad(3, side="left", fillchar="0")
            )
    else:
        tbl_dbo_stay = pd.DataFrame()
    # download tbl_dbo_episode_srg
    file_tbl_dbo_episode_srg = "./ExtractorDB/OutputEpisodeSrg.csv"
    if os.path.isfile(file_tbl_dbo_episode_srg):
        try:
            tbl_dbo_episode_srg = read_csv_file(
                file_tbl_dbo_episode_srg,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error",
                "Error extracting OutputEpisodeSrg from ./ExtractorDB/OutputEpisodeSrg.csv.\n"
                + str(e),
            )
            # label_2_sub.configure(text="Failed (OutputEpisodeSrg)...",fg='red')
            # label_2_status = 0
            return
        else:
            tbl_dbo_episode_srg = tbl_dbo_episode_srg.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_dbo_episode_srg = tbl_dbo_episode_srg.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_dbo_episode_srg = tbl_dbo_episode_srg.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_episode_srg = tbl_dbo_episode_srg.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
    else:
        tbl_dbo_episode_srg = pd.DataFrame()
    # download tbl_dbo_episode_DRG
    file_tbl_dbo_episode_DRG = "./ExtractorDB/OutputEpisodeDrg.csv"
    if os.path.isfile(file_tbl_dbo_episode_DRG):
        try:
            tbl_dbo_episode_DRG = read_csv_file(
                file_tbl_dbo_episode_DRG,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error",
                "Error extracting OutputEpisodeDrg from ./ExtractorDB/OutputEpisodeDrg.csv.\n"
                + str(e),
            )
            # label_2_sub.configure(text="Failed (OutputEpisodeDrg)...",fg='red')
            # label_2_status = 0
            return
        else:
            tbl_dbo_episode_DRG = tbl_dbo_episode_DRG.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_dbo_episode_DRG = tbl_dbo_episode_DRG.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_dbo_episode_DRG = tbl_dbo_episode_DRG.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_episode_DRG = tbl_dbo_episode_DRG.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
    else:
        tbl_dbo_episode_DRG = pd.DataFrame()
    # download OutputDaysEpisode
    file_OutputDaysEpisode = "./ExtractorDB/OutputDaysEpisode.csv"
    if os.path.isfile(file_OutputDaysEpisode):
        try:
            tbl_dbo_days_episode = read_csv_file(
                file_OutputDaysEpisode,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_dbo_days_episode from ./ExtractorDB/OutputDaysEpisode.csv.\n"
                + str(e),
            )
            # label_2_sub.configure(text="Failed (tbl_dbo_days_episode)...",fg='red')
            # label_2_status = 0
            return
        else:
            tbl_dbo_days_episode = tbl_dbo_days_episode.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_dbo_days_episode = tbl_dbo_days_episode.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_dbo_days_episode = tbl_dbo_days_episode.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_days_episode = tbl_dbo_days_episode.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_days_episode = tbl_dbo_days_episode[
                tbl_dbo_days_episode["facility_identifier"].isin(
                    facilities_included_list_global
                )
            ]
    else:
        tbl_dbo_days_episode = pd.DataFrame()
    # import tbl_ppm_ED_Encounter_preclean
    file_tbl_ppm_ED_Encounter_preclean = "./ExtractorDB/PpmEdEncounterPreclean.csv"
    if os.path.isfile(file_tbl_ppm_ED_Encounter_preclean):
        try:
            tbl_ppm_ED_Encounter_preclean = read_csv_file(
                file_tbl_ppm_ED_Encounter_preclean,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            # label_6_status = 0
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_ppm_ED_Encounter_preclean from ./ExtractorDB/PpmEdEncounterPreclean.csv.\n"
                + str(e),
            )
            # label_6_sub.configure(text="Failed (tbl_ppm_ED_Encounter_preclean)...",fg='red')
            # main_screen.update()
            return
        else:
            tbl_ppm_ED_Encounter_preclean = tbl_ppm_ED_Encounter_preclean.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_ppm_ED_Encounter_preclean = tbl_ppm_ED_Encounter_preclean.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_ppm_ED_Encounter_preclean = tbl_ppm_ED_Encounter_preclean.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_ppm_ED_Encounter_preclean = tbl_ppm_ED_Encounter_preclean.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
    else:
        tbl_ppm_ED_Encounter_preclean = pd.DataFrame()
    # import ED_NWAU
    file_ed_NWAU = "./ExtractorDB/OutputEdNwau.csv"
    if os.path.isfile(file_ed_NWAU):
        try:
            ed_NWAU = read_csv_file(
                file_ed_NWAU,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            # label_6_status = 0
            messagebox.showerror(
                "File Error",
                "Error extracting ED_NWAU from ./ExtractorDB/OutputEdNwau.csv.\n"
                + str(e),
            )
            # label_6_sub.configure(text="Failed (ED_NWAU)...",fg='red')
            # main_screen.update()
            return
        else:
            ed_NWAU = ed_NWAU.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            ed_NWAU = ed_NWAU.applymap(lambda x: x.strip() if isinstance(x, str) else x)
            ed_NWAU = ed_NWAU.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            ed_NWAU = ed_NWAU.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
    else:
        ed_NWAU = pd.DataFrame()
    # import Class_Descriptions
    file_Class_Descriptions = "./Costing/Class_Descriptions.csv"
    if os.path.isfile(file_Class_Descriptions):
        try:
            class_Descriptions = read_csv_file(
                file_Class_Descriptions,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            # label_8_status = 0
            messagebox.showerror(
                "File Error",
                "Error extracting Class_Descriptions from ./Costing/Class_Descriptions.csv.\n"
                + str(e),
            )
            # label_8_sub.configure(text="Failed (Class_Descriptions)...",fg='red')
            main_screen.update()
            return
        else:
            class_Descriptions = class_Descriptions[["Code", "Description", "Version"]]
    else:
        class_Descriptions = pd.DataFrame()
    # download tbl_Patient_Contact_Details
    if (
        lhd_global == "X830"
        or lhd_global == "X840"
        or lhd_global == "X850"
        or lhd_global == "X860"
        or lhd_global == "X740"
    ):
        file_tbl_Patient_Contact_Details = "./ExtractorDB/OutputPatient.csv"
    else:
        file_tbl_Patient_Contact_Details = "./ExtractorDB/Patient_contact_details.csv"
    if os.path.isfile(file_tbl_Patient_Contact_Details):
        try:
            tbl_Patient_Contact_Details = read_csv_file(
                file_tbl_Patient_Contact_Details,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            # label_2_status = 0
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_Patient_Contact_Details from "
                + file_tbl_Patient_Contact_Details
                + ".\n"
                + str(e),
            )
            # label_2_sub.configure(text="Failed (tbl_Patient_Contact_Details)...",fg='red')
            main_screen.update()
            return
        # else:
        #    tbl_Patient_Contact_Details = tbl_Patient_Contact_Details[['facility_identifier' ,'area_identifier', 'person_area_uid', 'AUID', 'contact_identifier', 'mrn', 'AUID']]
    else:
        tbl_Patient_Contact_Details = pd.DataFrame()
    if len(tbl_Patient_Contact_Details) > 0:
        tbl_Patient_Contact_Details["AUID"] = np.where(
            tbl_Patient_Contact_Details["AUID"] == "nan",
            "",
            tbl_Patient_Contact_Details["AUID"],
        )
    # import snapApp_CostingExtract
    file_snapApp_CostingExtract = "./ExtractorDB/snapApp_CostingExtract.csv"
    if os.path.isfile(file_snapApp_CostingExtract):
        try:
            snapApp_CostingExtract = read_csv_file(
                file_snapApp_CostingExtract,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            # label_8_status = 0
            messagebox.showerror(
                "File Error",
                "Error extracting snapApp_CostingExtract from ./ExtractorDB/snapApp_CostingExtract.csv.\n"
                + str(e),
            )
            # label_8_sub.configure(text="Failed (Class_Descriptions)...",fg='red')
            main_screen.update()
            return
        else:
            snapApp_CostingExtract = snapApp_CostingExtract.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            snapApp_CostingExtract = snapApp_CostingExtract.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            snapApp_CostingExtract = snapApp_CostingExtract.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            snapApp_CostingExtract = snapApp_CostingExtract.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
            #    snapApp_CostingExtract = snapApp_CostingExtract[['Code','Description','Version']]
    else:
        snapApp_CostingExtract = pd.DataFrame()
    ################################################
    tbl_dbo_episode_ats["episode_start_date"] = (
        tbl_dbo_episode_ats["episode_start_date"].astype(str).str[:10]
    )
    tbl_dbo_episode_ats["episode_start_time"] = (
        tbl_dbo_episode_ats["episode_start_time"].astype(str).str[-8:]
    )
    tbl_dbo_episode_ats["episode_end_date"] = (
        tbl_dbo_episode_ats["episode_end_date"].astype(str).str[:10]
    )
    tbl_dbo_episode_ats["episode_end_time"] = (
        tbl_dbo_episode_ats["episode_end_time"].astype(str).str[-8:]
    )
    tbl_dbo_episode_ats["stay_number"] = (
        tbl_dbo_episode_ats["stay_number"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0")
    )
    tbl_dbo_episode_ats["episode_sequence_number"] = (
        tbl_dbo_episode_ats["episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    tbl_dbo_days_episode["start_date"] = (
        tbl_dbo_days_episode["start_date"].astype(str).str[:10]
    )
    tbl_dbo_days_episode["start_time"] = (
        tbl_dbo_days_episode["start_time"].astype(str).str[-8:]
    )
    tbl_dbo_days_episode["end_date"] = (
        tbl_dbo_days_episode["end_date"].astype(str).str[:10]
    )
    tbl_dbo_days_episode["end_time"] = (
        tbl_dbo_days_episode["end_time"].astype(str).str[-8:]
    )
    tbl_dbo_days_episode["stay_number"] = (
        tbl_dbo_days_episode["stay_number"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0")
    )
    tbl_dbo_days_episode["episode_sequence_number"] = (
        tbl_dbo_days_episode["episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    """
    tbl_dbo_episode['startdate'] = tbl_dbo_episode['startdate'].astype(str).str[:10]
    tbl_dbo_episode['starttime'] = tbl_dbo_episode['starttime'].astype(str).str[-8:]
    tbl_dbo_episode['enddate'] = tbl_dbo_episode['enddate'].astype(str).str[:10]
    tbl_dbo_episode['endtime'] = tbl_dbo_episode['endtime'].astype(str).str[-8:]
    tbl_dbo_episode['stay_number'] = tbl_dbo_episode['stay_number'].astype(str).str.pad(8, side ='left', fillchar ='0')
    tbl_dbo_episode['episode_sequence_number'] = tbl_dbo_episode['episode_sequence_number'].astype(str).str.pad(3, side ='left', fillchar ='0')
    """
    tbl_dbo_stay["stay_number"] = (
        tbl_dbo_stay["stay_number"].astype(str).str.pad(8, side="left", fillchar="0")
    )
    tbl_dbo_stay["person_identifier"] = (
        tbl_dbo_stay["person_identifier"]
        .astype(str)
        .str.pad(10, side="left", fillchar="0")
    )
    # 27 July 2024 - stay episode seq number
    tbl_dbo_stay["episode_sequence_number"] = (
        tbl_dbo_stay["episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    # ValueError: could not convert string to float: ''
    tbl_dbo_stay["age"] = np.where(tbl_dbo_stay["age"] == "", 0, tbl_dbo_stay["age"])
    tbl_ppm_ED_Encounter_preclean["Age"] = np.where(
        tbl_ppm_ED_Encounter_preclean["Age"] == "",
        0,
        tbl_ppm_ED_Encounter_preclean["Age"],
    )
    tbl_dbo_episode_srg["stay_number"] = (
        tbl_dbo_episode_srg["stay_number"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0")
    )
    tbl_dbo_episode_srg["episode_sequence_number"] = (
        tbl_dbo_episode_srg["episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    tbl_dbo_episode_DRG["stay_number"] = (
        tbl_dbo_episode_DRG["stay_number"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0")
    )
    tbl_dbo_episode_DRG["episode_sequence_number"] = (
        tbl_dbo_episode_DRG["episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    tbl_Patient_Contact_Details["contact_identifier"] = (
        tbl_Patient_Contact_Details["contact_identifier"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0")
    )
    tbl_Patient_Contact_Details["AUID"] = np.where(
        tbl_Patient_Contact_Details["AUID"] != "",
        tbl_Patient_Contact_Details["AUID"]
        .astype(str)
        .str.pad(10, side="left", fillchar="0"),
        "",
    )
    tbl_Patient_Contact_Details["mrn"] = np.where(
        tbl_Patient_Contact_Details["mrn"] != "",
        tbl_Patient_Contact_Details["mrn"]
        .astype(str)
        .str.pad(10, side="left", fillchar="0"),
        "",
    )
    tbl_dbo_stay["mrn"] = np.where(
        (tbl_dbo_stay["mrn"] == "-") | (tbl_dbo_stay["mrn"] == "000000000-"),
        "",
        tbl_dbo_stay["mrn"],
    )
    tbl_Patient_Contact_Details["mrn"] = np.where(
        (tbl_Patient_Contact_Details["mrn"] == "-")
        | (tbl_Patient_Contact_Details["mrn"] == "000000000-"),
        "",
        tbl_Patient_Contact_Details["mrn"],
    )
    tbl_dbo_episode_ats["mrn"] = np.where(
        (tbl_dbo_episode_ats["mrn"] == "-")
        | (tbl_dbo_episode_ats["mrn"] == "000000000-"),
        "",
        tbl_dbo_episode_ats["mrn"],
    )
    ################################################
    # Important
    tbl_dbo_episode_DRG["an_drg_version"] = tbl_dbo_episode_DRG[
        "an_drg_version"
    ].astype(str)
    tbl_dbo_episode_DRG["an_drg"] = tbl_dbo_episode_DRG["an_drg"].astype(str)
    ###############################################################################
    # if qc_task == 'wip':
    """ Query that shows acute (episode care type 1 or 5) episodes that have a start date before the costing period and an enddate after the costing period known as WIP 3. These are rare and there is a critical test in the DNR Module that says each LHD/SHN must have less than 10 cases"""
    # Access query name:qry quality WIP 3
    # SELECT tbl_dbo_episode_ats.facility_identifier, tbl_dbo_episode_ats.stay_number, tbl_dbo_episode_ats.episode_sequence_number, tbl_dbo_episode_ats.episode_start_date, tbl_dbo_episode_ats.episode_end_date, tbl_dbo_episode_DRG.an_drg_version, tbl_dbo_episode_DRG.an_drg, [Class Descriptions].Description, tbl_dbo_episode_ats.mrn, tbl_dbo_episode_ats.episode_of_care_type, tbl_dbo_episode_ats.days_in_psych_unit, tbl_dbo_episode_ats.WIP FROM (tbl_dbo_episode_DRG RIGHT JOIN tbl_dbo_episode_ats ON (tbl_dbo_episode_DRG.facility_identifier = tbl_dbo_episode_ats.facility_identifier) AND (tbl_dbo_episode_DRG.stay_number = tbl_dbo_episode_ats.stay_number) AND (tbl_dbo_episode_DRG.episode_sequence_number = tbl_dbo_episode_ats.episode_sequence_number)) LEFT JOIN [Class Descriptions] ON (tbl_dbo_episode_DRG.an_drg = [Class Descriptions].Code) AND (tbl_dbo_episode_DRG.an_drg_version = [Class Descriptions].Version) WHERE (((tbl_dbo_episode_DRG.an_drg_version)="8.0" Or (tbl_dbo_episode_DRG.an_drg_version) Is Null) AND ((tbl_dbo_episode_ats.episode_of_care_type)="1" Or (tbl_dbo_episode_ats.episode_of_care_type)="5") AND ((tbl_dbo_episode_ats.days_in_psych_unit)=0) AND ((tbl_dbo_episode_ats.WIP)="3"));
    # extra rows in python compared to inform8 is because tbl_dbo_episode_DRG RIGHT JOIN tbl_dbo_episode_ats. I think inform8 might have done ats Left join DRG
    # I am changing the join to LEFT from RIGHT to see if it matches inform8
    tbl_dbo_episode_ats["days_in_psych_unit"] = (
        tbl_dbo_episode_ats["days_in_psych_unit"].fillna(0).astype(int, errors="ignore")
    )
    # Ranjit - change from 8.0 to 11.0
    # qualityChecks_Wip3 = pd.merge(tbl_dbo_episode_DRG[(tbl_dbo_episode_DRG['an_drg_version']=='8.0') | (tbl_dbo_episode_DRG['an_drg_version']=='') | (tbl_dbo_episode_DRG['an_drg_version'].isnull())][['an_drg_version', 'an_drg', 'facility_identifier', 'stay_number', 'episode_sequence_number']], tbl_dbo_episode_ats[(tbl_dbo_episode_ats['episode_of_care_type'].isin(['1', '5'])) & (tbl_dbo_episode_ats['days_in_psych_unit'].replace('','0').apply(lambda x: int(float(x)))==0) & (tbl_dbo_episode_ats['WIP']=='3')][['facility_identifier', 'stay_number', 'episode_sequence_number', 'episode_start_date', 'episode_end_date', 'mrn', 'episode_of_care_type', 'days_in_psych_unit', 'WIP']], how='right', on=['facility_identifier', 'stay_number', 'episode_sequence_number'], suffixes=('', '_drop'))
    qualityChecks_Wip3 = pd.merge(
        tbl_dbo_episode_DRG[
            (tbl_dbo_episode_DRG["an_drg_version"] == "11.0")
            | (tbl_dbo_episode_DRG["an_drg_version"] == "")
            | (tbl_dbo_episode_DRG["an_drg_version"].isnull())
        ][
            [
                "an_drg_version",
                "an_drg",
                "facility_identifier",
                "stay_number",
                "episode_sequence_number",
            ]
        ],
        tbl_dbo_episode_ats[
            (tbl_dbo_episode_ats["episode_of_care_type"].isin(["1", "5"]))
            & (
                tbl_dbo_episode_ats["days_in_psych_unit"]
                .replace("", "0")
                .apply(lambda x: int(float(x)))
                == 0
            )
            & (tbl_dbo_episode_ats["WIP"] == "3")
        ][
            [
                "facility_identifier",
                "stay_number",
                "episode_sequence_number",
                "episode_start_date",
                "episode_end_date",
                "mrn",
                "episode_of_care_type",
                "days_in_psych_unit",
                "WIP",
            ]
        ],
        how="right",
        on=["facility_identifier", "stay_number", "episode_sequence_number"],
        suffixes=("", "_drop"),
    )
    #######################
    """
    tbl_dbo_episode_DRG[['an_drg_version', 'an_drg', 'facility_identifier', 'stay_number', 'episode_sequence_number']].to_csv('./Output/tbl_dbo_episode_DRG.csv',index=False)
    tbl_dbo_episode_ats[['facility_identifier', 'stay_number', 'episode_sequence_number', 'episode_start_date', 'episode_end_date', 'mrn', 'episode_of_care_type', 'days_in_psych_unit', 'WIP']].to_csv('./Output/qualityChecks_Wip3_before_replace.csv',index=False)
    qualityChecks_Wip3[['facility_identifier', 'stay_number', 'episode_sequence_number', 'an_drg_version', 'an_drg', 'episode_of_care_type', 'days_in_psych_unit', 'WIP']].to_csv('./Output/qualityChecks_Wip3_before_replace.csv',index=False)
    """
    #######################
    qualityChecks_Wip3 = qualityChecks_Wip3.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    #######################
    """
    qualityChecks_Wip3[['facility_identifier', 'stay_number', 'episode_sequence_number', 'an_drg_version', 'an_drg', 'episode_of_care_type', 'days_in_psych_unit', 'WIP']].to_csv('./Output/qualityChecks_Wip3_after_replace.csv',index=False)
    """
    qualityChecks_Wip3["an_drg_version"] = qualityChecks_Wip3["an_drg_version"].astype(
        str
    )
    qualityChecks_Wip3["an_drg"] = qualityChecks_Wip3["an_drg"].astype(str)
    #######################
    qualityChecks_Wip3 = pd.merge(
        qualityChecks_Wip3,
        class_Descriptions,
        how="left",
        left_on=["an_drg", "an_drg_version"],
        right_on=["Code", "Version"],
        suffixes=("", "_drop"),
    )
    qualityChecks_Wip3 = qualityChecks_Wip3.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    qualityChecks_Wip3 = pd.merge(
        qualityChecks_Wip3,
        tbl_Patient_Contact_Details[
            ["facility_identifier", "contact_identifier", "AUID"]
        ],
        how="left",
        left_on=["facility_identifier", "stay_number"],
        right_on=["facility_identifier", "contact_identifier"],
        suffixes=("", "_drop"),
    )
    qualityChecks_Wip3 = qualityChecks_Wip3.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    # qualityChecks_Wip3 = qualityChecks_Wip3[(((qualityChecks_Wip3['an_drg_version']=='8.0') | (qualityChecks_Wip3['an_drg_version']=='') | (qualityChecks_Wip3['an_drg_version'].isnull())) & ((qualityChecks_Wip3['episode_of_care_type'].isin(['1', '5'])) & (qualityChecks_Wip3['days_in_psych_unit'].replace('','0').apply(lambda x: int(float(x)))==0) & (qualityChecks_Wip3['WIP']=='3')))]
    # Ranjit - Change to v 11
    # qualityChecks_Wip3 = qualityChecks_Wip3[(((qualityChecks_Wip3['an_drg_version']=='8.0') | (qualityChecks_Wip3['an_drg_version']=='') | (qualityChecks_Wip3['an_drg_version'].isnull())) & ((qualityChecks_Wip3['episode_of_care_type'].isin(['1', '5'])) & (qualityChecks_Wip3['days_in_psych_unit']==0) & (qualityChecks_Wip3['WIP']=='3')))]
    qualityChecks_Wip3 = qualityChecks_Wip3[
        (
            (
                (qualityChecks_Wip3["an_drg_version"] == "11.0")
                | (qualityChecks_Wip3["an_drg_version"] == "")
                | (qualityChecks_Wip3["an_drg_version"].isnull())
            )
            & (
                (qualityChecks_Wip3["episode_of_care_type"].isin(["1", "5"]))
                & (qualityChecks_Wip3["days_in_psych_unit"] == 0)
                & (qualityChecks_Wip3["WIP"] == "3")
            )
        )
    ]
    if len(qualityChecks_Wip3) > 0:
        qualityChecks_Wip3 = qualityChecks_Wip3[
            [
                "facility_identifier",
                "stay_number",
                "episode_sequence_number",
                "episode_start_date",
                "episode_end_date",
                "an_drg_version",
                "an_drg",
                "Description",
                "mrn",
                "AUID",
                "episode_of_care_type",
                "days_in_psych_unit",
                "WIP",
            ]
        ]
    else:
        qualityChecks_Wip3 = pd.DataFrame(
            columns=[
                "facility_identifier",
                "stay_number",
                "episode_sequence_number",
                "episode_start_date",
                "episode_end_date",
                "an_drg_version",
                "an_drg",
                "Description",
                "mrn",
                "AUID",
                "episode_of_care_type",
                "days_in_psych_unit",
                "WIP",
            ]
        )
    qualityChecks_Wip3 = qualityChecks_Wip3.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    qualityChecks_Wip3 = qualityChecks_Wip3.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    qualityChecks_Wip3 = qualityChecks_Wip3.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    qualityChecks_Wip3["an_drg_version"] = (
        qualityChecks_Wip3["an_drg_version"].astype(str).str.replace("nan", "")
    )
    qualityChecks_Wip3["an_drg"] = (
        qualityChecks_Wip3["an_drg"].astype(str).str.replace("nan", "")
    )
    qualityChecks_Wip3["Description"] = (
        qualityChecks_Wip3["Description"].astype(str).str.replace("nan", "")
    )
    qualityChecks_Wip3["mrn"] = (
        qualityChecks_Wip3["mrn"].astype(str).str.replace("nan", "")
    )
    qualityChecks_Wip3["AUID"] = (
        qualityChecks_Wip3["AUID"].astype(str).str.replace("nan", "")
    )
    qualityChecks_Wip3["mrn"] = np.where(
        qualityChecks_Wip3["mrn"] != "",
        qualityChecks_Wip3["mrn"].astype(str).str.pad(10, side="left", fillchar="0"),
        "",
    )
    qualityChecks_Wip3["AUID"] = np.where(
        qualityChecks_Wip3["AUID"] != "",
        qualityChecks_Wip3["AUID"].astype(str).str.pad(10, side="left", fillchar="0"),
        "",
    )
    qualityChecks_Wip3["days_in_psych_unit"] = qualityChecks_Wip3[
        "days_in_psych_unit"
    ].astype("Int64", errors="ignore")
    # remove padding
    qualityChecks_Wip3["episode_sequence_number"] = (
        qualityChecks_Wip3["episode_sequence_number"].astype(str).str.lstrip("0")
    )  # .fillna(value='0')
    # dropping duplicate values
    qualityChecks_Wip3.drop_duplicates(keep="last", inplace=True)
    qualityChecks_Wip3.to_csv(
        "./Output/QualityChecks_Wip3.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    logging.info("qualityChecks_Wip3=%s", len(qualityChecks_Wip3))
    # fn_display_data_in_window('QC', 'qualityChecks_Wip3')
    ###############################################################################
    # elif qc_task == 'ip_los':
    """ Query that shows a list of encounters with LOS > 100 days with the DRG Code. Sites should check if there are any coded episodes that look unusual example chestpain, tonsillectomy. Encounters should have a complex drg with a high NWAU weight."""
    # Access query name:qry quality IP LOS gt 100
    # SELECT tbl_dbo_episode_ats.facility_identifier, tbl_dbo_episode_ats.stay_number, tbl_dbo_episode_ats.episode_sequence_number, tbl_dbo_episode_ats.episode_of_care_type, tbl_dbo_episode_ats.episode_start_date, tbl_dbo_episode_ats.episode_end_date, tbl_dbo_episode_ats.episode_length_of_stay, tbl_dbo_episode_DRG.an_drg_version, tbl_dbo_episode_DRG.an_drg, [Class Descriptions].Description,  tbl_dbo_episode_ats.mrn
    # FROM (tbl_dbo_episode_DRG RIGHT JOIN tbl_dbo_episode_ats ON (tbl_dbo_episode_DRG.episode_sequence_number = tbl_dbo_episode_ats.episode_sequence_number) AND (tbl_dbo_episode_DRG.stay_number = tbl_dbo_episode_ats.stay_number) AND (tbl_dbo_episode_DRG.facility_identifier = tbl_dbo_episode_ats.facility_identifier)) LEFT JOIN [Class Descriptions] ON (tbl_dbo_episode_DRG.an_drg = [Class Descriptions].Code) AND (tbl_dbo_episode_DRG.an_drg_version = [Class Descriptions].Version)
    # WHERE (((tbl_dbo_episode_ats.episode_length_of_stay)>100) AND ((tbl_dbo_episode_DRG.an_drg_version)="8.0" Or (tbl_dbo_episode_DRG.an_drg_version) Is Null));
    # qualityChecks_LosGrt100 = pd.merge(tbl_dbo_episode_DRG[(tbl_dbo_episode_DRG['an_drg_version']=='8.0') | (tbl_dbo_episode_DRG['an_drg_version']=='') | (tbl_dbo_episode_DRG['an_drg_version'].isnull())][['an_drg_version', 'an_drg', 'facility_identifier', 'stay_number', 'episode_sequence_number']], tbl_dbo_episode_ats[(tbl_dbo_episode_ats['episode_length_of_stay'].replace('','0').apply(lambda x: int(float(x)))>100)][['facility_identifier', 'stay_number', 'episode_sequence_number', 'episode_start_date', 'episode_end_date', 'mrn', 'episode_of_care_type', 'episode_length_of_stay']], how='right', on=['facility_identifier', 'stay_number', 'episode_sequence_number'], suffixes=('', '_drop'))
    tbl_dbo_episode_ats["episode_length_of_stay"] = (
        tbl_dbo_episode_ats["episode_length_of_stay"]
        .fillna(0)
        .astype(int, errors="ignore")
    )
    # Ranjit - change to 11
    # qualityChecks_LosGrt100 = pd.merge(tbl_dbo_episode_DRG[(tbl_dbo_episode_DRG['an_drg_version']=='8.0') | (tbl_dbo_episode_DRG['an_drg_version']=='') | (tbl_dbo_episode_DRG['an_drg_version'].isnull())][['an_drg_version', 'an_drg', 'facility_identifier', 'stay_number', 'episode_sequence_number']], tbl_dbo_episode_ats[(tbl_dbo_episode_ats['episode_length_of_stay']>100)][['facility_identifier', 'stay_number', 'episode_sequence_number', 'episode_start_date', 'episode_end_date', 'mrn', 'episode_of_care_type', 'episode_length_of_stay', 'episode_start_time','episode_end_time']], how='right', on=['facility_identifier', 'stay_number', 'episode_sequence_number'], suffixes=('', '_drop'))
    qualityChecks_LosGrt100 = pd.merge(
        tbl_dbo_episode_DRG[
            (tbl_dbo_episode_DRG["an_drg_version"] == "11.0")
            | (tbl_dbo_episode_DRG["an_drg_version"] == "")
            | (tbl_dbo_episode_DRG["an_drg_version"].isnull())
        ][
            [
                "an_drg_version",
                "an_drg",
                "facility_identifier",
                "stay_number",
                "episode_sequence_number",
            ]
        ],
        tbl_dbo_episode_ats[(tbl_dbo_episode_ats["episode_length_of_stay"] > 100)][
            [
                "facility_identifier",
                "stay_number",
                "episode_sequence_number",
                "episode_start_date",
                "episode_end_date",
                "mrn",
                "episode_of_care_type",
                "episode_length_of_stay",
                "episode_start_time",
                "episode_end_time",
            ]
        ],
        how="right",
        on=["facility_identifier", "stay_number", "episode_sequence_number"],
        suffixes=("", "_drop"),
    )
    qualityChecks_LosGrt100 = qualityChecks_LosGrt100.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    class_Descriptions["Version"] = class_Descriptions["Version"]
    qualityChecks_LosGrt100["an_drg_version"] = qualityChecks_LosGrt100[
        "an_drg_version"
    ].astype(str)
    qualityChecks_LosGrt100["an_drg"] = qualityChecks_LosGrt100["an_drg"].astype(str)
    qualityChecks_LosGrt100 = pd.merge(
        qualityChecks_LosGrt100,
        class_Descriptions,
        how="left",
        left_on=["an_drg", "an_drg_version"],
        right_on=["Code", "Version"],
        suffixes=("", "_drop"),
    )
    qualityChecks_LosGrt100 = qualityChecks_LosGrt100.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    qualityChecks_LosGrt100 = pd.merge(
        qualityChecks_LosGrt100,
        tbl_Patient_Contact_Details[
            ["facility_identifier", "contact_identifier", "AUID"]
        ],
        how="left",
        left_on=["facility_identifier", "stay_number"],
        right_on=["facility_identifier", "contact_identifier"],
        suffixes=("", "_drop"),
    )
    qualityChecks_LosGrt100 = qualityChecks_LosGrt100.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    # qualityChecks_LosGrt100 = qualityChecks_LosGrt100[(qualityChecks_LosGrt100['episode_length_of_stay'].replace('','0').apply(lambda x: int(float(x)))>100) & ((qualityChecks_LosGrt100['an_drg_version']=='8.0') | ((qualityChecks_LosGrt100['an_drg_version']=='') | (qualityChecks_LosGrt100['an_drg_version'].isnull())))]
    # qualityChecks_LosGrt100 = qualityChecks_LosGrt100[(qualityChecks_LosGrt100['episode_length_of_stay']>100) & ((qualityChecks_LosGrt100['an_drg_version']=='8.0') | ((qualityChecks_LosGrt100['an_drg_version']=='') | (qualityChecks_LosGrt100['an_drg_version'].isnull())))]
    qualityChecks_LosGrt100 = qualityChecks_LosGrt100[
        (qualityChecks_LosGrt100["episode_length_of_stay"] > 100)
        & (
            (qualityChecks_LosGrt100["an_drg_version"] == "11.0")
            | (
                (qualityChecks_LosGrt100["an_drg_version"] == "")
                | (qualityChecks_LosGrt100["an_drg_version"].isnull())
            )
        )
    ]
    qualityChecks_LosGrt100["episode_start_date"] = pd.to_datetime(
        (
            qualityChecks_LosGrt100["episode_start_date"].astype(str).str[:10]
            + " "
            + qualityChecks_LosGrt100["episode_start_time"].astype(str).str[-8:]
        ),
        errors="coerce",
        format="%Y-%m-%d %H:%M:%S",
    )
    qualityChecks_LosGrt100["episode_end_date"] = pd.to_datetime(
        (
            qualityChecks_LosGrt100["episode_end_date"].astype(str).str[:10]
            + " "
            + qualityChecks_LosGrt100["episode_end_time"].astype(str).str[-8:]
        ),
        errors="coerce",
        format="%Y-%m-%d %H:%M:%S",
    )
    if len(qualityChecks_LosGrt100) > 0:
        qualityChecks_LosGrt100 = qualityChecks_LosGrt100[
            [
                "facility_identifier",
                "stay_number",
                "episode_sequence_number",
                "episode_start_date",
                "episode_end_date",
                "an_drg_version",
                "an_drg",
                "Description",
                "mrn",
                "AUID",
                "episode_of_care_type",
                "episode_length_of_stay",
            ]
        ]
    else:
        qualityChecks_LosGrt100 = pd.DataFrame(
            columns=[
                "facility_identifier",
                "stay_number",
                "episode_sequence_number",
                "episode_start_date",
                "episode_end_date",
                "an_drg_version",
                "an_drg",
                "Description",
                "mrn",
                "AUID",
                "episode_of_care_type",
                "episode_length_of_stay",
            ]
        )
    qualityChecks_LosGrt100 = qualityChecks_LosGrt100.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    qualityChecks_LosGrt100 = qualityChecks_LosGrt100.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    qualityChecks_LosGrt100 = qualityChecks_LosGrt100.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    qualityChecks_LosGrt100["an_drg_version"] = (
        qualityChecks_LosGrt100["an_drg_version"].astype(str).str.replace("nan", "")
    )
    qualityChecks_LosGrt100["an_drg"] = (
        qualityChecks_LosGrt100["an_drg"].astype(str).str.replace("nan", "")
    )
    qualityChecks_LosGrt100["Description"] = (
        qualityChecks_LosGrt100["Description"].astype(str).str.replace("nan", "")
    )
    qualityChecks_LosGrt100["mrn"] = (
        qualityChecks_LosGrt100["mrn"].astype(str).str.replace("nan", "")
    )
    qualityChecks_LosGrt100["AUID"] = (
        qualityChecks_LosGrt100["AUID"].astype(str).str.replace("nan", "")
    )
    qualityChecks_LosGrt100["mrn"] = np.where(
        qualityChecks_LosGrt100["mrn"] != "",
        qualityChecks_LosGrt100["mrn"]
        .astype(str)
        .str.pad(10, side="left", fillchar="0"),
        "",
    )
    qualityChecks_LosGrt100["AUID"] = np.where(
        qualityChecks_LosGrt100["AUID"] != "",
        qualityChecks_LosGrt100["AUID"]
        .astype(str)
        .str.pad(10, side="left", fillchar="0"),
        "",
    )
    qualityChecks_LosGrt100["episode_length_of_stay"] = qualityChecks_LosGrt100[
        "episode_length_of_stay"
    ].astype("Int64", errors="ignore")
    # qualityChecks_LosGrt100['episode_start_date'] = qualityChecks_LosGrt100['episode_start_date'].dt.strftime("%d/%m/%Y %H:%M:%S")
    # qualityChecks_LosGrt100['episode_end_date'] = qualityChecks_LosGrt100['episode_end_date'].dt.strftime("%d/%m/%Y %H:%M:%S")
    # remove padding
    qualityChecks_LosGrt100["episode_sequence_number"] = (
        qualityChecks_LosGrt100["episode_sequence_number"].astype(str).str.lstrip("0")
    )  # .fillna(value='0')
    # dropping duplicate values
    qualityChecks_LosGrt100.drop_duplicates(keep="last", inplace=True)
    qualityChecks_LosGrt100.to_csv(
        "./Output/QualityChecks_LosGrt100.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    logging.info("qualityChecks_LosGrt100=%s", len(qualityChecks_LosGrt100))
    # fn_display_data_in_window('QC', 'qualityChecks_LosGrt100')
    ###############################################################################
    # elif qc_task == 'pg_le_50':
    """ Query that shows a list of encounters that with Care type PsychoGeriatric or GEM that should not have an age less than 30 years. There are some exceptions for patients."""
    # Access query name:qry quality age2
    # SELECT tbl_dbo_stay.facility_identifier, tbl_dbo_stay.mrn, tbl_dbo_stay.age, tbl_dbo_episode_ats.episode_of_care_type FROM tbl_dbo_stay INNER JOIN tbl_dbo_episode_ats ON (tbl_dbo_episode_ats.stay_number = tbl_dbo_stay.stay_number) AND (tbl_dbo_stay.facility_identifier = tbl_dbo_episode_ats.facility_identifier) WHERE (((tbl_dbo_stay.age)<50) AND ((tbl_dbo_episode_ats.episode_of_care_type) In ("8","7")));
    # 27 July 2024 - stay episode seq number
    # qualityChecks_GerAgeLess50 = pd.merge(tbl_dbo_stay[(tbl_dbo_stay['age'].astype(float)<50)][['facility_identifier', 'stay_number', 'mrn', 'age']], tbl_dbo_episode_ats[(tbl_dbo_episode_ats['episode_of_care_type'].isin(['8', '7', '8.0', '7.0']))][['facility_identifier', 'stay_number', 'episode_of_care_type']], how='inner', on=['facility_identifier', 'stay_number'], suffixes=('', '_drop'))
    qualityChecks_GerAgeLess50 = pd.merge(
        tbl_dbo_stay[(tbl_dbo_stay["age"].astype(float) < 50)][
            [
                "facility_identifier",
                "stay_number",
                "mrn",
                "age",
                "episode_sequence_number",
            ]
        ],
        tbl_dbo_episode_ats[
            (tbl_dbo_episode_ats["episode_of_care_type"].isin(["8", "7", "8.0", "7.0"]))
        ][
            [
                "facility_identifier",
                "stay_number",
                "episode_of_care_type",
                "episode_sequence_number",
            ]
        ],
        how="inner",
        on=["facility_identifier", "stay_number", "episode_sequence_number"],
        suffixes=("", "_drop"),
    )
    # 27 July 2024 - stay episode seq number
    qualityChecks_GerAgeLess50.drop_duplicates(
        subset=[
            "facility_identifier",
            "stay_number",
            "mrn",
            "age",
            "episode_sequence_number",
            "episode_of_care_type",
        ],
        keep="last",
        inplace=True,
    )
    qualityChecks_GerAgeLess50 = qualityChecks_GerAgeLess50.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    qualityChecks_GerAgeLess50 = pd.merge(
        qualityChecks_GerAgeLess50,
        tbl_Patient_Contact_Details[
            ["facility_identifier", "contact_identifier", "AUID"]
        ],
        how="left",
        left_on=["facility_identifier", "stay_number"],
        right_on=["facility_identifier", "contact_identifier"],
        suffixes=("", "_drop"),
    )
    qualityChecks_GerAgeLess50 = qualityChecks_GerAgeLess50.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    qualityChecks_GerAgeLess50 = qualityChecks_GerAgeLess50[
        (qualityChecks_GerAgeLess50["age"].astype(float) < 50)
        & (
            qualityChecks_GerAgeLess50["episode_of_care_type"].isin(
                ["8", "7", "8.0", "7.0"]
            )
        )
    ]
    if len(qualityChecks_GerAgeLess50) > 0:
        qualityChecks_GerAgeLess50 = qualityChecks_GerAgeLess50[
            [
                "stay_number",
                "facility_identifier",
                "mrn",
                "AUID",
                "age",
                "episode_of_care_type",
            ]
        ]
    else:
        qualityChecks_GerAgeLess50 = pd.DataFrame(
            columns=[
                "stay_number",
                "facility_identifier",
                "mrn",
                "AUID",
                "age",
                "episode_of_care_type",
            ]
        )
    qualityChecks_GerAgeLess50 = qualityChecks_GerAgeLess50.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    qualityChecks_GerAgeLess50 = qualityChecks_GerAgeLess50.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    qualityChecks_GerAgeLess50 = qualityChecks_GerAgeLess50.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    qualityChecks_GerAgeLess50["mrn"] = (
        qualityChecks_GerAgeLess50["mrn"].astype(str).str.replace("nan", "")
    )
    qualityChecks_GerAgeLess50["AUID"] = (
        qualityChecks_GerAgeLess50["AUID"].astype(str).str.replace("nan", "")
    )
    qualityChecks_GerAgeLess50["mrn"] = np.where(
        qualityChecks_GerAgeLess50["mrn"] != "",
        qualityChecks_GerAgeLess50["mrn"]
        .astype(str)
        .str.pad(10, side="left", fillchar="0"),
        "",
    )
    qualityChecks_GerAgeLess50["AUID"] = np.where(
        qualityChecks_GerAgeLess50["AUID"] != "",
        qualityChecks_GerAgeLess50["AUID"]
        .astype(str)
        .str.pad(10, side="left", fillchar="0"),
        "",
    )
    qualityChecks_GerAgeLess50["age"] = qualityChecks_GerAgeLess50["age"].astype(
        "Int64", errors="ignore"
    )
    # dropping duplicate values
    qualityChecks_GerAgeLess50.drop_duplicates(keep="last", inplace=True)
    qualityChecks_GerAgeLess50.to_csv(
        "./Output/QualityChecks_GerAgeLess50.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    logging.info("qualityChecks_GerAgeLess50=%s", len(qualityChecks_GerAgeLess50))
    # fn_display_data_in_window('QC', 'qualityChecks_GerAgeLess50')
    ###############################################################################
    # elif qc_task == 'ip_ed_transfer':
    """ Query that shows a list of encounters that LOS  LOS in ED that is less than 20 minutes (excluding encounters admitted and discharged in ED, patients who died in ED or patients transferred to another facility"""
    # Access query: qry time in ed
    # SELECT tbl_dbo_days_episode.facility_identifier, tbl_dbo_days_episode.stay_number, tbl_dbo_days_episode.episode_sequence_number, tbl_dbo_days_episode.unit_type, Sum(DateDiff("n",[start_date]+TimeValue([start_time]),[end_date]+TimeValue([end_time]))) AS [ED Time] FROM tbl_dbo_days_episode WHERE (((tbl_dbo_days_episode.end_date) Is Not Null))
    # GROUP BY tbl_dbo_days_episode.facility_identifier, tbl_dbo_days_episode.stay_number, tbl_dbo_days_episode.episode_sequence_number, tbl_dbo_days_episode.unit_type HAVING (((tbl_dbo_days_episode.unit_type)="58" Or (tbl_dbo_days_episode.unit_type)="17"));
    qry_time_in_ed = tbl_dbo_days_episode[
        tbl_dbo_days_episode["unit_type"].isin(["58", "17"])
    ][
        [
            "facility_identifier",
            "stay_number",
            "episode_sequence_number",
            "unit_type",
            "start_date",
            "start_time",
            "end_date",
            "end_time",
        ]
    ]
    qry_time_in_ed["ED Time"] = (
        pd.to_datetime(
            (
                qry_time_in_ed["end_date"].astype(str).str[:10]
                + " "
                + qry_time_in_ed["end_time"].astype(str)
            ),
            errors="coerce",
            format="%Y-%m-%d %H:%M:%S",
        )
        - pd.to_datetime(
            (
                qry_time_in_ed["start_date"].astype(str).str[:10]
                + " "
                + qry_time_in_ed["start_time"].astype(str)
            ),
            errors="coerce",
            format="%Y-%m-%d %H:%M:%S",
        )
    ) / pd.Timedelta(minutes=1)
    qry_time_in_ed = (
        qry_time_in_ed.groupby(
            [
                "facility_identifier",
                "stay_number",
                "episode_sequence_number",
                "unit_type",
            ],
            as_index=False,
            dropna=False,
        )
        .agg(ED_Time=("ED Time", "sum"))
        .reset_index()
    )
    # qry_time_in_ed.drop(['ED Time'], axis=1, inplace = True)
    qry_time_in_ed.rename(columns={"ED_Time": "ED Time"}, inplace=True)
    qry_time_in_ed["ED Time"] = np.where(
        (qry_time_in_ed["ED Time"].isnull()) | (qry_time_in_ed["ED Time"] == ""),
        0,
        qry_time_in_ed["ED Time"].astype(float),
    )
    qry_time_in_ed = qry_time_in_ed[
        [
            "facility_identifier",
            "stay_number",
            "episode_sequence_number",
            "unit_type",
            "ED Time",
        ]
    ]
    # Access query name:qry quality IP LOS < 20 mins
    # SELECT tbl_dbo_episode_ats.facility_identifier, tbl_dbo_episode_ats.stay_number, tbl_dbo_episode_ats.episode_sequence_number, tbl_dbo_episode_ats.episode_of_care_type, tbl_dbo_episode_ats.episode_start_date, tbl_dbo_episode_ats.episode_start_time, tbl_dbo_episode_ats.episode_end_date, tbl_dbo_episode_ats.episode_end_time, tbl_dbo_episode_ats.episode_length_of_stay, tbl_dbo_episode_DRG.an_drg_version, tbl_dbo_episode_DRG.an_drg, [Class Descriptions].Description, IIf([tbl_dbo_episode_ats]![episode_end_date] Is Null,Null,IIf([tbl_dbo_episode_ats]![episode_end_time] Is Null,Null,(DateDiff("n",[tbl_dbo_episode_ats]![episode_start_date]+TimeValue([episode_start_time]),[tbl_dbo_episode_ats]![episode_end_date]+TimeValue([episode_end_time])))))-Nz([ed time],0) AS [LOS Mins], tbl_dbo_episode_srg.ed_status, tbl_dbo_episode_ats.mode_of_separation, tbl_dbo_episode_ats.mrn, tbl_dbo_stay.facility_trans_to
    # FROM [qry time in ed] RIGHT JOIN ((((tbl_dbo_episode_DRG INNER JOIN tbl_dbo_episode_ats ON (tbl_dbo_episode_DRG.facility_identifier = tbl_dbo_episode_ats.facility_identifier) AND (tbl_dbo_episode_DRG.stay_number = tbl_dbo_episode_ats.stay_number) AND (tbl_dbo_episode_DRG.episode_sequence_number = tbl_dbo_episode_ats.episode_sequence_number)) INNER JOIN [Class Descriptions] ON (tbl_dbo_episode_DRG.an_drg = [Class Descriptions].Code) AND (tbl_dbo_episode_DRG.an_drg_version = [Class Descriptions].Version)) INNER JOIN tbl_dbo_episode_srg ON (tbl_dbo_episode_ats.facility_identifier = tbl_dbo_episode_srg.facility_identifier) AND (tbl_dbo_episode_ats.stay_number = tbl_dbo_episode_srg.stay_number) AND (tbl_dbo_episode_ats.episode_sequence_number = tbl_dbo_episode_srg.episode_sequence_number)) INNER JOIN tbl_dbo_stay ON (tbl_dbo_episode_ats.stay_number = tbl_dbo_stay.stay_number) AND (tbl_dbo_episode_ats.facility_identifier = tbl_dbo_stay.facility_identifier)) ON ([qry time in ed].episode_sequence_number = tbl_dbo_episode_ats.episode_sequence_number) AND ([qry time in ed].stay_number = tbl_dbo_episode_ats.stay_number) AND ([qry time in ed].facility_identifier = tbl_dbo_episode_ats.facility_identifier)
    # WHERE (((IIf([tbl_dbo_episode_ats]![episode_end_date] Is Null,Null,IIf([tbl_dbo_episode_ats]![episode_end_time] Is Null,Null,(DateDiff("n",[tbl_dbo_episode_ats]![episode_start_date]+TimeValue([episode_start_time]),[tbl_dbo_episode_ats]![episode_end_date]+TimeValue([episode_end_time])))))-Nz([ed time],0))<20) AND ((tbl_dbo_episode_srg.ed_status) Not In ("1","4","04","01")) AND ((tbl_dbo_episode_ats.mode_of_separation) Not In ("6","7")) AND ((tbl_dbo_stay.facility_trans_to)="" Or (tbl_dbo_stay.facility_trans_to) Is Null))
    # ORDER BY IIf([tbl_dbo_episode_ats]![episode_end_date] Is Null,Null,IIf([tbl_dbo_episode_ats]![episode_end_time] Is Null,Null,(DateDiff("n",[tbl_dbo_episode_ats]![episode_start_date]+TimeValue([episode_start_time]),[tbl_dbo_episode_ats]![episode_end_date]+TimeValue([episode_end_time])))))-Nz([ed time],0);
    tbl_dbo_episode_ats["dummy_los"] = np.where(
        (tbl_dbo_episode_ats["episode_end_date"].isnull())
        | (tbl_dbo_episode_ats["episode_end_time"].isnull())
        | (tbl_dbo_episode_ats["episode_end_date"] == "")
        | (tbl_dbo_episode_ats["episode_end_time"] == ""),
        0,
        (
            pd.to_datetime(
                (
                    tbl_dbo_episode_ats["episode_end_date"].astype(str).str[:10]
                    + " "
                    + tbl_dbo_episode_ats["episode_end_time"].astype(str).str[-8:]
                ),
                errors="coerce",
                format="%Y-%m-%d %H:%M:%S",
            )
            - pd.to_datetime(
                (
                    tbl_dbo_episode_ats["episode_start_date"].astype(str).str[:10]
                    + " "
                    + tbl_dbo_episode_ats["episode_start_time"].astype(str).str[-8:]
                ),
                errors="coerce",
                format="%Y-%m-%d %H:%M:%S",
            )
        )
        / pd.Timedelta(minutes=1),
    )
    # tbl_dbo_episode_ats['episode_start_date'] = pd.to_datetime((tbl_dbo_episode_ats['episode_start_date'].astype(str).str[:10] + ' ' + tbl_dbo_episode_ats['episode_start_time'].astype(str).str[-8:]), errors='coerce', format="%Y-%m-%d %H:%M:%S")
    # tbl_dbo_episode_ats['episode_end_date'] = pd.to_datetime((tbl_dbo_episode_ats['episode_end_date'].astype(str).str[:10] + ' ' + tbl_dbo_episode_ats['episode_end_time'].astype(str).str[-8:]), errors='coerce', format="%Y-%m-%d %H:%M:%S")
    # Commented ['mode_of_separation'].isin(['6', '7'] because of difference in HIE and EDW values
    # HIE: http://hird.health.nsw.gov.au/hird/view_domain_values_list.cfm?ItemID=73
    # EDW:http://hird.health.nsw.gov.au/hird/view_domain_values_list.cfm?ItemID=1117 (this link shows that the HIE values have expired)
    # df_query1 = pd.merge(tbl_dbo_episode_DRG[['an_drg', 'an_drg_version', 'facility_identifier', 'stay_number', 'episode_sequence_number']], tbl_dbo_episode_ats[~tbl_dbo_episode_ats['mode_of_separation'].isin(['6', '7'])][['facility_identifier', 'stay_number', 'episode_sequence_number', 'dummy_los', 'episode_of_care_type', 'episode_length_of_stay', 'mode_of_separation', 'mrn', 'episode_start_date',   'episode_start_time', 'episode_end_date', 'episode_end_time']], how='inner', on=['facility_identifier', 'stay_number', 'episode_sequence_number'], suffixes=('', '_drop'))
    # Issue #96 (AQA-361) Modify the logic to extract mode of separation (MOS)
    # df_query1 = pd.merge(tbl_dbo_episode_DRG[['an_drg', 'an_drg_version', 'facility_identifier', 'stay_number', 'episode_sequence_number']], tbl_dbo_episode_ats[~tbl_dbo_episode_ats['mode_of_separation'].isin(['8', '80'])][['facility_identifier', 'stay_number', 'episode_sequence_number', 'dummy_los', 'episode_of_care_type', 'episode_length_of_stay', 'mode_of_separation', 'mrn', 'episode_start_date',   'episode_start_time', 'episode_end_date', 'episode_end_time']], how='inner', on=['facility_identifier', 'stay_number', 'episode_sequence_number'], suffixes=('', '_drop'))
    df_query1 = pd.merge(
        tbl_dbo_episode_DRG[
            [
                "an_drg",
                "an_drg_version",
                "facility_identifier",
                "stay_number",
                "episode_sequence_number",
            ]
        ],
        tbl_dbo_episode_ats[
            ~tbl_dbo_episode_ats["SE_SEP_MODE_NHDD_CD"].isin(["8", "80"])
        ][
            [
                "facility_identifier",
                "stay_number",
                "episode_sequence_number",
                "dummy_los",
                "episode_of_care_type",
                "episode_length_of_stay",
                "mode_of_separation",
                "mrn",
                "episode_start_date",
                "episode_start_time",
                "episode_end_date",
                "episode_end_time",
                "SE_SEP_MODE_NHDD_CD",
            ]
        ],
        how="inner",
        on=["facility_identifier", "stay_number", "episode_sequence_number"],
        suffixes=("", "_drop"),
    )
    df_query1 = df_query1.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    df_query1["an_drg_version"] = df_query1["an_drg_version"].astype(str)
    df_query1["an_drg"] = df_query1["an_drg"].astype(str)
    df_query2 = pd.merge(
        df_query1,
        class_Descriptions,
        how="inner",
        left_on=["an_drg", "an_drg_version"],
        right_on=["Code", "Version"],
        suffixes=("", "_drop"),
    )
    df_query2 = df_query2.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    df_query3 = pd.merge(
        df_query2,
        tbl_dbo_episode_srg[
            ~tbl_dbo_episode_srg["ed_status"].isin(["1", "4", "01", "04"])
        ][
            [
                "facility_identifier",
                "stay_number",
                "episode_sequence_number",
                "ed_status",
            ]
        ],
        how="inner",
        on=["facility_identifier", "stay_number", "episode_sequence_number"],
        suffixes=("", "_drop"),
    )
    df_query3 = df_query3.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    # 27 July 2024 stay 'episode_sequence_number'
    # df_query4 = pd.merge(df_query3, tbl_dbo_stay[(tbl_dbo_stay['facility_trans_to']=='') | (tbl_dbo_stay['facility_trans_to'].isnull())][['facility_identifier', 'stay_number', 'facility_trans_to']], how='inner', on=['facility_identifier', 'stay_number'], suffixes=('', '_drop'))
    df_query4 = pd.merge(
        df_query3,
        tbl_dbo_stay[
            (tbl_dbo_stay["facility_trans_to"] == "")
            | (tbl_dbo_stay["facility_trans_to"].isnull())
        ][
            [
                "facility_identifier",
                "stay_number",
                "facility_trans_to",
                "episode_sequence_number",
            ]
        ],
        how="inner",
        on=["facility_identifier", "stay_number", "episode_sequence_number"],
        suffixes=("", "_drop"),
    )
    df_query4 = df_query4.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    qualityChecks_LosLessThan20 = pd.merge(
        qry_time_in_ed,
        df_query4,
        how="right",
        on=["facility_identifier", "stay_number", "episode_sequence_number"],
        suffixes=("", "_drop"),
    )
    qualityChecks_LosLessThan20 = qualityChecks_LosLessThan20.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    qualityChecks_LosLessThan20["ED Time"] = np.where(
        (qualityChecks_LosLessThan20["ED Time"].isnull())
        | (qualityChecks_LosLessThan20["ED Time"] == ""),
        0,
        qualityChecks_LosLessThan20["ED Time"].astype(float),
    )
    qualityChecks_LosLessThan20["LOS Mins"] = (
        qualityChecks_LosLessThan20["dummy_los"]
        - qualityChecks_LosLessThan20["ED Time"]
    )
    # Commented ['mode_of_separation'].isin(['6', '7'] because of difference in HIE and EDW values
    # HIE: http://hird.health.nsw.gov.au/hird/view_domain_values_list.cfm?ItemID=73
    # EDW:http://hird.health.nsw.gov.au/hird/view_domain_values_list.cfm?ItemID=1117 (this link shows that the HIE values have expired)
    # qualityChecks_LosLessThan20 = qualityChecks_LosLessThan20[~(qualityChecks_LosLessThan20['mode_of_separation'].isin(['6', '7'])) & ~(qualityChecks_LosLessThan20['ed_status'].isin(['1', '4', '01', '04'])) & ((qualityChecks_LosLessThan20['facility_trans_to']=='') | (qualityChecks_LosLessThan20['facility_trans_to'].isnull()))]
    # Issue #96 (AQA-361) Modify the logic to extract mode of separation (MOS)
    # qualityChecks_LosLessThan20 = qualityChecks_LosLessThan20[~(qualityChecks_LosLessThan20['mode_of_separation'].isin(['8', '80'])) & ~(qualityChecks_LosLessThan20['ed_status'].isin(['1', '4', '01', '04'])) & ((qualityChecks_LosLessThan20['facility_trans_to']=='') | (qualityChecks_LosLessThan20['facility_trans_to'].isnull()))]
    qualityChecks_LosLessThan20 = qualityChecks_LosLessThan20[
        ~(qualityChecks_LosLessThan20["SE_SEP_MODE_NHDD_CD"].isin(["8", "80"]))
        & ~(qualityChecks_LosLessThan20["ed_status"].isin(["1", "4", "01", "04"]))
        & (
            (qualityChecks_LosLessThan20["facility_trans_to"] == "")
            | (qualityChecks_LosLessThan20["facility_trans_to"].isnull())
        )
    ]
    qualityChecks_LosLessThan20 = qualityChecks_LosLessThan20[
        (qualityChecks_LosLessThan20["LOS Mins"].astype(float) < 20)
    ]
    qualityChecks_LosLessThan20 = pd.merge(
        qualityChecks_LosLessThan20,
        tbl_Patient_Contact_Details[
            ["facility_identifier", "contact_identifier", "AUID"]
        ],
        how="left",
        left_on=["facility_identifier", "stay_number"],
        right_on=["facility_identifier", "contact_identifier"],
        suffixes=("", "_drop"),
    )
    qualityChecks_LosLessThan20 = qualityChecks_LosLessThan20.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    if len(qualityChecks_LosLessThan20) > 0:
        qualityChecks_LosLessThan20 = qualityChecks_LosLessThan20[
            [
                "facility_identifier",
                "stay_number",
                "episode_sequence_number",
                "episode_start_date",
                "episode_start_time",
                "episode_end_date",
                "episode_end_time",
                "episode_length_of_stay",
                "an_drg_version",
                "an_drg",
                "Description",
                "mrn",
                "AUID",
                "episode_of_care_type",
                "mode_of_separation",
                "ed_status",
                "facility_trans_to",
                "LOS Mins",
            ]
        ]
    else:
        qualityChecks_LosLessThan20 = pd.DataFrame(
            columns=[
                "facility_identifier",
                "stay_number",
                "episode_sequence_number",
                "episode_start_date",
                "episode_start_time",
                "episode_end_date",
                "episode_end_time",
                "episode_length_of_stay",
                "an_drg_version",
                "an_drg",
                "Description",
                "mrn",
                "AUID",
                "episode_of_care_type",
                "mode_of_separation",
                "ed_status",
                "facility_trans_to",
                "LOS Mins",
            ]
        )
    qualityChecks_LosLessThan20 = qualityChecks_LosLessThan20.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    qualityChecks_LosLessThan20 = qualityChecks_LosLessThan20.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    qualityChecks_LosLessThan20 = qualityChecks_LosLessThan20.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    qualityChecks_LosLessThan20["an_drg_version"] = (
        qualityChecks_LosLessThan20["an_drg_version"].astype(str).str.replace("nan", "")
    )
    qualityChecks_LosLessThan20["an_drg"] = (
        qualityChecks_LosLessThan20["an_drg"].astype(str).str.replace("nan", "")
    )
    qualityChecks_LosLessThan20["Description"] = (
        qualityChecks_LosLessThan20["Description"].astype(str).str.replace("nan", "")
    )
    qualityChecks_LosLessThan20["mrn"] = (
        qualityChecks_LosLessThan20["mrn"].astype(str).str.replace("nan", "")
    )
    qualityChecks_LosLessThan20["AUID"] = (
        qualityChecks_LosLessThan20["AUID"].astype(str).str.replace("nan", "")
    )
    qualityChecks_LosLessThan20["mrn"] = np.where(
        qualityChecks_LosLessThan20["mrn"] != "",
        qualityChecks_LosLessThan20["mrn"]
        .astype(str)
        .str.pad(10, side="left", fillchar="0"),
        "",
    )
    qualityChecks_LosLessThan20["AUID"] = np.where(
        qualityChecks_LosLessThan20["AUID"] != "",
        qualityChecks_LosLessThan20["AUID"]
        .astype(str)
        .str.pad(10, side="left", fillchar="0"),
        "",
    )
    qualityChecks_LosLessThan20["LOS Mins"] = qualityChecks_LosLessThan20[
        "LOS Mins"
    ].astype(float)
    qualityChecks_LosLessThan20 = qualityChecks_LosLessThan20[
        (qualityChecks_LosLessThan20["LOS Mins"].astype(float) < 20)
    ]
    # change negative los to 0
    qualityChecks_LosLessThan20["LOS Mins"] = np.where(
        qualityChecks_LosLessThan20["LOS Mins"] < 0,
        0.0,
        qualityChecks_LosLessThan20["LOS Mins"],
    )
    qualityChecks_LosLessThan20 = qualityChecks_LosLessThan20[
        (qualityChecks_LosLessThan20["LOS Mins"].astype(float) > 0)
    ]
    # 29 Oct - set precision to 2. https://abft101.atlassian.net/browse/AQA-245
    qualityChecks_LosLessThan20["LOS Mins"] = qualityChecks_LosLessThan20[
        "LOS Mins"
    ].apply(lambda x: round(x, 2))
    qualityChecks_LosLessThan20["LOS Mins"] = qualityChecks_LosLessThan20[
        "LOS Mins"
    ].astype("Int64", errors="ignore")
    # episode_start_date (Inform8 = 15/07/2022, App2 = 2022-07-15); episode_end_date (Inform8 = 15/07/2022, App2 = 2022-07-15);
    # qualityChecks_LosLessThan20['episode_start_date'] = qualityChecks_LosLessThan20['episode_start_date'].dt.strftime("%d/%m/%Y")
    # qualityChecks_LosLessThan20['episode_end_date'] = qualityChecks_LosLessThan20['episode_end_date'].dt.strftime("%d/%m/%Y")
    # remove padding
    qualityChecks_LosLessThan20["episode_sequence_number"] = (
        qualityChecks_LosLessThan20["episode_sequence_number"]
        .astype(str)
        .str.lstrip("0")
    )  # .fillna(value='0')
    # dropping duplicate values
    qualityChecks_LosLessThan20.drop_duplicates(keep="last", inplace=True)
    # dropping duplicate values
    qualityChecks_LosLessThan20.drop_duplicates(keep="last", inplace=True)
    qualityChecks_LosLessThan20.to_csv(
        "./Output/QualityChecks_LosLessThan20.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    logging.info("qualityChecks_LosLessThan20=%s", len(qualityChecks_LosLessThan20))
    # fn_display_data_in_window('QC', 'qualityChecks_LosLessThan20')
    ###############################################################################
    # elif qc_task == 'ip_age_null':
    """ Query that shows a list of inpatient patients that have age > 105 years"""
    # Access query name:qry quality age1
    # SELECT tbl_dbo_stay.facility_identifier, tbl_dbo_stay.mrn, tbl_dbo_stay.age, tbl_dbo_episode_DRG.stay_number, tbl_dbo_episode_DRG.episode_sequence_number, tbl_dbo_episode_DRG.an_drg, [Class Descriptions].Version, [Class Descriptions].Description
    # FROM tbl_dbo_stay LEFT JOIN (tbl_dbo_episode_DRG LEFT JOIN [Class Descriptions] ON (tbl_dbo_episode_DRG.an_drg = [Class Descriptions].Code) AND (tbl_dbo_episode_DRG.an_drg_version = [Class Descriptions].Version)) ON tbl_dbo_stay.facility_identifier = tbl_dbo_episode_DRG.facility_identifier and tbl_dbo_stay.stay_number = tbl_dbo_episode_DRG.stay_number
    # WHERE (tbl_dbo_stay.age > 105) OR (tbl_dbo_stay.age is Null);
    df_query1 = pd.merge(
        tbl_dbo_episode_DRG[
            [
                "facility_identifier",
                "stay_number",
                "an_drg",
                "an_drg_version",
                "episode_sequence_number",
            ]
        ],
        class_Descriptions,
        how="left",
        left_on=["an_drg", "an_drg_version"],
        right_on=["Code", "Version"],
        suffixes=("", "_drop"),
    )
    df_query1 = df_query1.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    # 27 July 2024 - stay episode seq number
    # qualityChecks_AgeAbove105 = pd.merge(tbl_dbo_stay[(tbl_dbo_stay['age']=='') | (tbl_dbo_stay['age'].isnull()) | (tbl_dbo_stay['age'].astype(float)>105)][['age', 'facility_identifier', 'stay_number', 'mrn']], df_query1, how='left', on=['facility_identifier', 'stay_number'],  suffixes=('', '_drop'))
    qualityChecks_AgeAbove105 = pd.merge(
        tbl_dbo_stay[
            (tbl_dbo_stay["age"] == "")
            | (tbl_dbo_stay["age"].isnull())
            | (tbl_dbo_stay["age"].astype(float) > 105)
        ][
            [
                "age",
                "facility_identifier",
                "stay_number",
                "mrn",
                "episode_sequence_number",
            ]
        ],
        df_query1,
        how="left",
        on=["facility_identifier", "stay_number", "episode_sequence_number"],
        suffixes=("", "_drop"),
    )
    qualityChecks_AgeAbove105 = qualityChecks_AgeAbove105.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    qualityChecks_AgeAbove105 = pd.merge(
        qualityChecks_AgeAbove105,
        tbl_Patient_Contact_Details[
            ["facility_identifier", "contact_identifier", "AUID"]
        ],
        how="left",
        left_on=["facility_identifier", "stay_number"],
        right_on=["facility_identifier", "contact_identifier"],
        suffixes=("", "_drop"),
    )
    qualityChecks_AgeAbove105 = qualityChecks_AgeAbove105.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    qualityChecks_AgeAbove105 = qualityChecks_AgeAbove105[
        (qualityChecks_AgeAbove105["age"] == "")
        | (qualityChecks_AgeAbove105["age"].isnull())
        | (qualityChecks_AgeAbove105["age"].astype(float) > 105)
    ]
    if len(qualityChecks_AgeAbove105) > 0:
        qualityChecks_AgeAbove105 = qualityChecks_AgeAbove105[
            [
                "facility_identifier",
                "mrn",
                "AUID",
                "age",
                "stay_number",
                "episode_sequence_number",
                "an_drg",
                "an_drg_version",
                "Description",
            ]
        ]
    else:
        qualityChecks_AgeAbove105 = pd.DataFrame(
            columns=[
                "facility_identifier",
                "mrn",
                "AUID",
                "age",
                "stay_number",
                "episode_sequence_number",
                "an_drg",
                "an_drg_version",
                "Description",
            ]
        )
    qualityChecks_AgeAbove105 = qualityChecks_AgeAbove105.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    qualityChecks_AgeAbove105 = qualityChecks_AgeAbove105.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    qualityChecks_AgeAbove105 = qualityChecks_AgeAbove105.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    qualityChecks_AgeAbove105["an_drg_version"] = (
        qualityChecks_AgeAbove105["an_drg_version"].astype(str).str.replace("nan", "")
    )
    qualityChecks_AgeAbove105["an_drg"] = (
        qualityChecks_AgeAbove105["an_drg"].astype(str).str.replace("nan", "")
    )
    qualityChecks_AgeAbove105["Description"] = (
        qualityChecks_AgeAbove105["Description"].astype(str).str.replace("nan", "")
    )
    qualityChecks_AgeAbove105["mrn"] = (
        qualityChecks_AgeAbove105["mrn"].astype(str).str.replace("nan", "")
    )
    qualityChecks_AgeAbove105["AUID"] = (
        qualityChecks_AgeAbove105["AUID"].astype(str).str.replace("nan", "")
    )
    qualityChecks_AgeAbove105["episode_sequence_number"] = (
        qualityChecks_AgeAbove105["episode_sequence_number"]
        .astype(str)
        .str.replace("nan", "")
    )
    qualityChecks_AgeAbove105["mrn"] = np.where(
        qualityChecks_AgeAbove105["mrn"] != "",
        qualityChecks_AgeAbove105["mrn"]
        .astype(str)
        .str.pad(10, side="left", fillchar="0"),
        "",
    )
    qualityChecks_AgeAbove105["AUID"] = np.where(
        qualityChecks_AgeAbove105["AUID"] != "",
        qualityChecks_AgeAbove105["AUID"]
        .astype(str)
        .str.pad(10, side="left", fillchar="0"),
        "",
    )
    # remove padding
    qualityChecks_AgeAbove105["episode_sequence_number"] = (
        qualityChecks_AgeAbove105["episode_sequence_number"].astype(str).str.lstrip("0")
    )  # .fillna(value='0')
    # dropping duplicate values
    qualityChecks_AgeAbove105.drop_duplicates(keep="last", inplace=True)
    qualityChecks_AgeAbove105["age"] = qualityChecks_AgeAbove105["age"].astype(
        int, errors="ignore"
    )
    qualityChecks_AgeAbove105.to_csv(
        "./Output/QualityChecks_AgeAbove105.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    logging.info("qualityChecks_AgeAbove105=%s", len(qualityChecks_AgeAbove105))
    # fn_display_data_in_window('QC', 'qualityChecks_AgeAbove105')
    ###############################################################################
    # elif qc_task == 'ip_los_le_2h':
    """Query that shows a list of episodes that have renal dialysis have a LOS less than 120 minutes """
    # Access query name:qry quality L61z less 2 hours
    # SELECT tbl_dbo_episode_ats.facility_identifier, tbl_dbo_episode_ats.stay_number, tbl_dbo_episode_ats.episode_start_date+TimeValue([tbl_dbo_episode_ats]![episode_start_time]) AS episode_start_date, tbl_dbo_episode_ats.episode_end_date++TimeValue([tbl_dbo_episode_ats]![episode_end_time]) AS episode_end_date, tbl_dbo_episode_DRG.an_drg_version, tbl_dbo_episode_DRG.an_drg, [Class Descriptions].Description, tbl_dbo_episode_ats.mrn, tbl_dbo_episode_ats.episode_of_care_type, Avg(Nz(DateDiff("n",[tbl_dbo_episode_ats]![episode_start_date]+TimeValue([tbl_dbo_episode_ats]![episode_start_time]),[tbl_dbo_episode_ats]![episode_end_date]+TimeValue([tbl_dbo_episode_ats]![episode_end_time])),0)) AS minutes
    # FROM (tbl_dbo_episode_DRG RIGHT JOIN tbl_dbo_episode_ats ON (tbl_dbo_episode_DRG.facility_identifier = tbl_dbo_episode_ats.facility_identifier) AND (tbl_dbo_episode_DRG.stay_number = tbl_dbo_episode_ats.stay_number) AND (tbl_dbo_episode_DRG.episode_sequence_number = tbl_dbo_episode_ats.episode_sequence_number))
    # LEFT JOIN [Class Descriptions] ON (tbl_dbo_episode_DRG.an_drg = [Class Descriptions].Code) AND (tbl_dbo_episode_DRG.an_drg_version = [Class Descriptions].Version)
    # GROUP BY tbl_dbo_episode_ats.facility_identifier, tbl_dbo_episode_ats.stay_number, tbl_dbo_episode_ats.episode_start_date+TimeValue([tbl_dbo_episode_ats]![episode_start_time]), tbl_dbo_episode_ats.episode_end_date++TimeValue([tbl_dbo_episode_ats]![episode_end_time]), tbl_dbo_episode_DRG.an_drg_version, tbl_dbo_episode_DRG.an_drg, [Class Descriptions].Description, tbl_dbo_episode_ats.mrn, tbl_dbo_episode_ats.episode_of_care_type, tbl_dbo_episode_ats.episode_sequence_number, tbl_dbo_episode_ats.episode_end_date
    # HAVING (((tbl_dbo_episode_DRG.an_drg)="L61Z") AND ((Avg(Nz(DateDiff("n",[tbl_dbo_episode_ats]![episode_start_date]+TimeValue([tbl_dbo_episode_ats]![episode_start_time]),[tbl_dbo_episode_ats]![episode_end_date]+TimeValue([tbl_dbo_episode_ats]![episode_end_time])),0)))<120))
    # ORDER BY Avg(Nz(DateDiff("n",[tbl_dbo_episode_ats]![episode_start_date]+TimeValue([tbl_dbo_episode_ats]![episode_start_time]),[tbl_dbo_episode_ats]![episode_end_date]+TimeValue([tbl_dbo_episode_ats]![episode_end_time])),0));
    tbl_dbo_episode_ats["dummy_minutes"] = (
        pd.to_datetime(
            (
                tbl_dbo_episode_ats["episode_end_date"].astype(str).str[:10]
                + " "
                + tbl_dbo_episode_ats["episode_end_time"].astype(str).str[-8:]
            ),
            errors="coerce",
            format="%Y-%m-%d %H:%M:%S",
        )
        - pd.to_datetime(
            (
                tbl_dbo_episode_ats["episode_start_date"].astype(str).str[:10]
                + " "
                + tbl_dbo_episode_ats["episode_start_time"].astype(str).str[-8:]
            ),
            errors="coerce",
            format="%Y-%m-%d %H:%M:%S",
        )
    ) / pd.Timedelta(minutes=1)
    tbl_dbo_episode_ats["dummy_minutes"] = np.where(
        (tbl_dbo_episode_ats["dummy_minutes"].isnull())
        | (tbl_dbo_episode_ats["dummy_minutes"] == ""),
        0,
        tbl_dbo_episode_ats["dummy_minutes"].astype(float),
    )
    tbl_dbo_episode_ats["episode_start_date"] = pd.to_datetime(
        (
            tbl_dbo_episode_ats["episode_start_date"].astype(str).str[:10]
            + " "
            + tbl_dbo_episode_ats["episode_start_time"].astype(str).str[-8:]
        ),
        errors="coerce",
        format="%Y-%m-%d %H:%M:%S",
    )
    tbl_dbo_episode_ats["episode_end_date"] = pd.to_datetime(
        (
            tbl_dbo_episode_ats["episode_end_date"].astype(str).str[:10]
            + " "
            + tbl_dbo_episode_ats["episode_end_time"].astype(str).str[-8:]
        ),
        errors="coerce",
        format="%Y-%m-%d %H:%M:%S",
    )
    qualityChecks_L61zLess2Hours = pd.merge(
        tbl_dbo_episode_DRG[(tbl_dbo_episode_DRG["an_drg"] == "L61Z")][
            [
                "an_drg_version",
                "an_drg",
                "facility_identifier",
                "stay_number",
                "episode_sequence_number",
            ]
        ],
        tbl_dbo_episode_ats[
            [
                "facility_identifier",
                "stay_number",
                "episode_sequence_number",
                "episode_start_date",
                "episode_end_date",
                "mrn",
                "episode_of_care_type",
                "dummy_minutes",
                "episode_start_time",
                "episode_end_time",
            ]
        ],
        how="right",
        on=["facility_identifier", "stay_number", "episode_sequence_number"],
        suffixes=("", "_drop"),
    )
    qualityChecks_L61zLess2Hours = qualityChecks_L61zLess2Hours.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    qualityChecks_L61zLess2Hours["an_drg_version"] = qualityChecks_L61zLess2Hours[
        "an_drg_version"
    ].astype(str)
    qualityChecks_L61zLess2Hours["an_drg"] = qualityChecks_L61zLess2Hours[
        "an_drg"
    ].astype(str)
    qualityChecks_L61zLess2Hours = pd.merge(
        qualityChecks_L61zLess2Hours,
        class_Descriptions,
        how="left",
        left_on=["an_drg", "an_drg_version"],
        right_on=["Code", "Version"],
        suffixes=("", "_drop"),
    )
    qualityChecks_L61zLess2Hours = qualityChecks_L61zLess2Hours.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    qualityChecks_L61zLess2Hours = pd.merge(
        qualityChecks_L61zLess2Hours,
        tbl_Patient_Contact_Details[
            ["facility_identifier", "contact_identifier", "AUID"]
        ],
        how="left",
        left_on=["facility_identifier", "stay_number"],
        right_on=["facility_identifier", "contact_identifier"],
        suffixes=("", "_drop"),
    )
    qualityChecks_L61zLess2Hours = qualityChecks_L61zLess2Hours.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    qualityChecks_L61zLess2Hours = qualityChecks_L61zLess2Hours[
        [
            "facility_identifier",
            "stay_number",
            "episode_sequence_number",
            "an_drg",
            "an_drg_version",
            "Description",
            "mrn",
            "AUID",
            "episode_of_care_type",
            "episode_start_date",
            "episode_start_time",
            "episode_end_date",
            "episode_end_time",
            "dummy_minutes",
        ]
    ]
    qualityChecks_L61zLess2Hours = (
        qualityChecks_L61zLess2Hours.groupby(
            [
                "facility_identifier",
                "stay_number",
                "an_drg",
                "an_drg_version",
                "Description",
                "mrn",
                "AUID",
                "episode_of_care_type",
                "episode_start_date",
                "episode_end_date",
                "episode_start_time",
                "episode_end_time",
                "episode_sequence_number",
            ],
            as_index=False,
            dropna=False,
        )
        .agg(minutes=("dummy_minutes", "mean"))
        .reset_index()
    )
    qualityChecks_L61zLess2Hours = qualityChecks_L61zLess2Hours[
        (qualityChecks_L61zLess2Hours["an_drg"] == "L61Z")
        & (qualityChecks_L61zLess2Hours["minutes"] < 120)
    ]
    qualityChecks_L61zLess2Hours = qualityChecks_L61zLess2Hours.sort_values(
        by=["minutes"]
    )
    if len(qualityChecks_L61zLess2Hours) > 0:
        qualityChecks_L61zLess2Hours = qualityChecks_L61zLess2Hours[
            [
                "facility_identifier",
                "stay_number",
                "episode_sequence_number",
                "episode_start_date",
                "episode_end_date",
                "an_drg_version",
                "an_drg",
                "Description",
                "mrn",
                "AUID",
                "episode_of_care_type",
                "minutes",
            ]
        ]
    else:
        qualityChecks_L61zLess2Hours = pd.DataFrame(
            columns=[
                "facility_identifier",
                "stay_number",
                "episode_sequence_number",
                "episode_start_date",
                "episode_end_date",
                "an_drg_version",
                "an_drg",
                "Description",
                "mrn",
                "AUID",
                "episode_of_care_type",
                "minutes",
            ]
        )
    qualityChecks_L61zLess2Hours = qualityChecks_L61zLess2Hours.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    qualityChecks_L61zLess2Hours = qualityChecks_L61zLess2Hours.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    qualityChecks_L61zLess2Hours = qualityChecks_L61zLess2Hours.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    # remove padding
    qualityChecks_L61zLess2Hours["episode_sequence_number"] = (
        qualityChecks_L61zLess2Hours["episode_sequence_number"]
        .astype(str)
        .str.lstrip("0")
    )  # .fillna(value='0')
    # qualityChecks_L61zLess2Hours['episode_start_date'] = qualityChecks_L61zLess2Hours['episode_start_date'].dt.strftime("%d/%m/%Y %H:%M:%S")
    # qualityChecks_L61zLess2Hours['episode_end_date'] = qualityChecks_L61zLess2Hours['episode_end_date'].dt.strftime("%d/%m/%Y %H:%M:%S")
    qualityChecks_L61zLess2Hours["an_drg_version"] = (
        qualityChecks_L61zLess2Hours["an_drg_version"]
        .astype(str)
        .str.replace("nan", "")
    )
    qualityChecks_L61zLess2Hours["an_drg"] = (
        qualityChecks_L61zLess2Hours["an_drg"].astype(str).str.replace("nan", "")
    )
    qualityChecks_L61zLess2Hours["Description"] = (
        qualityChecks_L61zLess2Hours["Description"].astype(str).str.replace("nan", "")
    )
    qualityChecks_L61zLess2Hours["mrn"] = (
        qualityChecks_L61zLess2Hours["mrn"].astype(str).str.replace("nan", "")
    )
    qualityChecks_L61zLess2Hours["AUID"] = (
        qualityChecks_L61zLess2Hours["AUID"].astype(str).str.replace("nan", "")
    )
    qualityChecks_L61zLess2Hours["mrn"] = np.where(
        qualityChecks_L61zLess2Hours["mrn"] != "",
        qualityChecks_L61zLess2Hours["mrn"]
        .astype(str)
        .str.pad(10, side="left", fillchar="0"),
        "",
    )
    qualityChecks_L61zLess2Hours["AUID"] = np.where(
        qualityChecks_L61zLess2Hours["AUID"] != "",
        qualityChecks_L61zLess2Hours["AUID"]
        .astype(str)
        .str.pad(10, side="left", fillchar="0"),
        "",
    )
    qualityChecks_L61zLess2Hours["minutes"] = qualityChecks_L61zLess2Hours[
        "minutes"
    ].astype(float)
    qualityChecks_L61zLess2Hours["minutes"] = qualityChecks_L61zLess2Hours[
        "minutes"
    ].astype("Int64", errors="ignore")
    # dropping duplicate values
    qualityChecks_L61zLess2Hours.drop_duplicates(keep="last", inplace=True)
    qualityChecks_L61zLess2Hours.to_csv(
        "./Output/QualityChecks_L61zLess2Hours.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    logging.info("qualityChecks_L61zLess2Hours=%s", len(qualityChecks_L61zLess2Hours))
    # fn_display_data_in_window('QC', 'qualityChecks_L61zLess2Hours')
    ###############################################################################
    # elif qc_task == 'ip_icu_ge_1000':
    """ Query that shows a list of in ICU Bed  that have a LOS greater than 1000 hours"""
    # Access query name:qr quality ICU hours gt 1000
    # SELECT tbl_dbo_episode_ats.facility_identifier, tbl_dbo_episode_ats.stay_number, tbl_dbo_episode_ats.episode_sequence_number, tbl_dbo_episode_ats.episode_start_date, tbl_dbo_episode_ats.episode_end_date, tbl_dbo_episode_DRG.an_drg_version, tbl_dbo_episode_DRG.an_drg, [Class Descriptions].Description, tbl_dbo_episode_ats.mrn, tbl_dbo_episode_ats.episode_of_care_type, tbl_dbo_episode_ats.days_in_psych_unit, tbl_dbo_episode_ats.hours_in_icu
    # FROM (tbl_dbo_episode_DRG RIGHT JOIN tbl_dbo_episode_ats ON (tbl_dbo_episode_DRG.episode_sequence_number = tbl_dbo_episode_ats.episode_sequence_number) AND (tbl_dbo_episode_DRG.stay_number = tbl_dbo_episode_ats.stay_number) AND (tbl_dbo_episode_DRG.facility_identifier = tbl_dbo_episode_ats.facility_identifier))
    # LEFT JOIN [Class Descriptions] ON (tbl_dbo_episode_DRG.an_drg_version = [Class Descriptions].Version) AND (tbl_dbo_episode_DRG.an_drg = [Class Descriptions].Code)
    # WHERE (((tbl_dbo_episode_DRG.an_drg_version)="8.0" Or (tbl_dbo_episode_DRG.an_drg_version) Is Null) AND ((tbl_dbo_episode_ats.days_in_psych_unit)=0) AND ((tbl_dbo_episode_ats.hours_in_icu)>1000));
    tbl_dbo_episode_ats["episode_start_date"] = pd.to_datetime(
        (
            tbl_dbo_episode_ats["episode_start_date"].astype(str).str[:10]
            + " "
            + tbl_dbo_episode_ats["episode_start_time"].astype(str).str[-8:]
        ),
        errors="coerce",
        format="%Y-%m-%d %H:%M:%S",
    )
    tbl_dbo_episode_ats["episode_end_date"] = pd.to_datetime(
        (
            tbl_dbo_episode_ats["episode_end_date"].astype(str).str[:10]
            + " "
            + tbl_dbo_episode_ats["episode_end_time"].astype(str).str[-8:]
        ),
        errors="coerce",
        format="%Y-%m-%d %H:%M:%S",
    )
    # qualityChecks_IcuHoursGt1000 = pd.merge(tbl_dbo_episode_DRG[(tbl_dbo_episode_DRG['an_drg_version']=='8.0') | (tbl_dbo_episode_DRG['an_drg_version']=='8') | (tbl_dbo_episode_DRG['an_drg_version']=='') | (tbl_dbo_episode_DRG['an_drg_version'].isnull())][['an_drg_version', 'an_drg', 'facility_identifier', 'stay_number', 'episode_sequence_number']], tbl_dbo_episode_ats[(tbl_dbo_episode_ats['days_in_psych_unit'].replace('','0').apply(lambda x: int(float(x)))==0) & (tbl_dbo_episode_ats['hours_in_icu'].astype(float)>1000)][['days_in_psych_unit', 'facility_identifier', 'stay_number', 'episode_sequence_number', 'episode_start_date', 'episode_end_date', 'mrn', 'episode_of_care_type', 'hours_in_icu']], how='right', on=['facility_identifier', 'stay_number', 'episode_sequence_number'], suffixes=('', '_drop'))
    # change to v11
    # qualityChecks_IcuHoursGt1000 = pd.merge(tbl_dbo_episode_DRG[(tbl_dbo_episode_DRG['an_drg_version']=='8.0') | (tbl_dbo_episode_DRG['an_drg_version']=='8') | (tbl_dbo_episode_DRG['an_drg_version']=='') | (tbl_dbo_episode_DRG['an_drg_version'].isnull())][['an_drg_version', 'an_drg', 'facility_identifier', 'stay_number', 'episode_sequence_number']], tbl_dbo_episode_ats[(tbl_dbo_episode_ats['days_in_psych_unit']==0) & (tbl_dbo_episode_ats['hours_in_icu'].astype(float)>1000)][['days_in_psych_unit', 'facility_identifier', 'stay_number', 'episode_sequence_number', 'episode_start_date', 'episode_end_date', 'mrn', 'episode_of_care_type', 'hours_in_icu']], how='right', on=['facility_identifier', 'stay_number', 'episode_sequence_number'], suffixes=('', '_drop'))
    qualityChecks_IcuHoursGt1000 = pd.merge(
        tbl_dbo_episode_DRG[
            (tbl_dbo_episode_DRG["an_drg_version"] == "11.0")
            | (tbl_dbo_episode_DRG["an_drg_version"] == "11")
            | (tbl_dbo_episode_DRG["an_drg_version"] == "")
            | (tbl_dbo_episode_DRG["an_drg_version"].isnull())
        ][
            [
                "an_drg_version",
                "an_drg",
                "facility_identifier",
                "stay_number",
                "episode_sequence_number",
            ]
        ],
        tbl_dbo_episode_ats[
            (tbl_dbo_episode_ats["days_in_psych_unit"] == 0)
            & (tbl_dbo_episode_ats["hours_in_icu"].astype(float) > 1000)
        ][
            [
                "days_in_psych_unit",
                "facility_identifier",
                "stay_number",
                "episode_sequence_number",
                "episode_start_date",
                "episode_end_date",
                "mrn",
                "episode_of_care_type",
                "hours_in_icu",
            ]
        ],
        how="right",
        on=["facility_identifier", "stay_number", "episode_sequence_number"],
        suffixes=("", "_drop"),
    )
    qualityChecks_IcuHoursGt1000 = qualityChecks_IcuHoursGt1000.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    qualityChecks_IcuHoursGt1000["an_drg_version"] = qualityChecks_IcuHoursGt1000[
        "an_drg_version"
    ].astype(str)
    qualityChecks_IcuHoursGt1000["an_drg"] = qualityChecks_IcuHoursGt1000[
        "an_drg"
    ].astype(str)
    qualityChecks_IcuHoursGt1000 = pd.merge(
        qualityChecks_IcuHoursGt1000,
        class_Descriptions,
        how="left",
        left_on=["an_drg", "an_drg_version"],
        right_on=["Code", "Version"],
        suffixes=("", "_drop"),
    )
    qualityChecks_IcuHoursGt1000 = qualityChecks_IcuHoursGt1000.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    qualityChecks_IcuHoursGt1000 = pd.merge(
        qualityChecks_IcuHoursGt1000,
        tbl_Patient_Contact_Details[
            ["facility_identifier", "contact_identifier", "AUID"]
        ],
        how="left",
        left_on=["facility_identifier", "stay_number"],
        right_on=["facility_identifier", "contact_identifier"],
        suffixes=("", "_drop"),
    )
    qualityChecks_IcuHoursGt1000 = qualityChecks_IcuHoursGt1000.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    # qualityChecks_IcuHoursGt1000 = qualityChecks_IcuHoursGt1000[((qualityChecks_IcuHoursGt1000['an_drg_version']=='8.0') | (qualityChecks_IcuHoursGt1000['an_drg_version']=='8') | (qualityChecks_IcuHoursGt1000['an_drg_version']=='') | (qualityChecks_IcuHoursGt1000['an_drg_version'].isnull())) & (qualityChecks_IcuHoursGt1000['days_in_psych_unit'].replace('','0').apply(lambda x: int(float(x)))==0) & (qualityChecks_IcuHoursGt1000['hours_in_icu'].astype(float)>1000)]
    # qualityChecks_IcuHoursGt1000 = qualityChecks_IcuHoursGt1000[((qualityChecks_IcuHoursGt1000['an_drg_version']=='8.0') | (qualityChecks_IcuHoursGt1000['an_drg_version']=='8') | (qualityChecks_IcuHoursGt1000['an_drg_version']=='') | (qualityChecks_IcuHoursGt1000['an_drg_version'].isnull())) & (qualityChecks_IcuHoursGt1000['days_in_psych_unit']==0) & (qualityChecks_IcuHoursGt1000['hours_in_icu'].astype(float)>1000)]
    qualityChecks_IcuHoursGt1000 = qualityChecks_IcuHoursGt1000[
        (
            (qualityChecks_IcuHoursGt1000["an_drg_version"] == "11.0")
            | (qualityChecks_IcuHoursGt1000["an_drg_version"] == "11")
            | (qualityChecks_IcuHoursGt1000["an_drg_version"] == "")
            | (qualityChecks_IcuHoursGt1000["an_drg_version"].isnull())
        )
        & (qualityChecks_IcuHoursGt1000["days_in_psych_unit"] == 0)
        & (qualityChecks_IcuHoursGt1000["hours_in_icu"].astype(float) > 1000)
    ]
    # episode_start_date (Inform8 = 13/08/2022 23:19:00, App2 = 2022-08-13 23:19:00); episode_end_date (Inform8 = 31/10/2022 12:30:00, App2 = 2022-10-31 12:30:00);
    # qualityChecks_IcuHoursGt1000['episode_start_date'] = pd.to_datetime(qualityChecks_IcuHoursGt1000['episode_start_date'], format='%Y-%m-%d %H:%M:%S')
    # qualityChecks_IcuHoursGt1000['episode_start_date'] = qualityChecks_IcuHoursGt1000['episode_start_date'].dt.strftime("%d/%m/%Y %H:%M:%S")
    # qualityChecks_IcuHoursGt1000['episode_end_date'] = qualityChecks_IcuHoursGt1000['episode_end_date'].dt.strftime("%d/%m/%Y %H:%M:%S")
    # remove padding
    qualityChecks_IcuHoursGt1000["episode_sequence_number"] = (
        qualityChecks_IcuHoursGt1000["episode_sequence_number"]
        .astype(str)
        .str.lstrip("0")
    )  # .fillna(value='0')
    if len(qualityChecks_IcuHoursGt1000) > 0:
        qualityChecks_IcuHoursGt1000 = qualityChecks_IcuHoursGt1000[
            [
                "facility_identifier",
                "stay_number",
                "episode_sequence_number",
                "episode_start_date",
                "episode_end_date",
                "an_drg_version",
                "an_drg",
                "Description",
                "mrn",
                "AUID",
                "episode_of_care_type",
                "hours_in_icu",
            ]
        ]
    else:
        qualityChecks_IcuHoursGt1000 = pd.DataFrame(
            columns=[
                "facility_identifier",
                "stay_number",
                "episode_sequence_number",
                "episode_start_date",
                "episode_end_date",
                "an_drg_version",
                "an_drg",
                "Description",
                "mrn",
                "AUID",
                "episode_of_care_type",
                "hours_in_icu",
            ]
        )
    qualityChecks_IcuHoursGt1000 = qualityChecks_IcuHoursGt1000.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    qualityChecks_IcuHoursGt1000 = qualityChecks_IcuHoursGt1000.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    qualityChecks_IcuHoursGt1000 = qualityChecks_IcuHoursGt1000.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    qualityChecks_IcuHoursGt1000["an_drg_version"] = (
        qualityChecks_IcuHoursGt1000["an_drg_version"]
        .astype(str)
        .str.replace("nan", "")
    )
    qualityChecks_IcuHoursGt1000["an_drg"] = (
        qualityChecks_IcuHoursGt1000["an_drg"].astype(str).str.replace("nan", "")
    )
    qualityChecks_IcuHoursGt1000["Description"] = (
        qualityChecks_IcuHoursGt1000["Description"].astype(str).str.replace("nan", "")
    )
    qualityChecks_IcuHoursGt1000["mrn"] = (
        qualityChecks_IcuHoursGt1000["mrn"].astype(str).str.replace("nan", "")
    )
    qualityChecks_IcuHoursGt1000["AUID"] = (
        qualityChecks_IcuHoursGt1000["AUID"].astype(str).str.replace("nan", "")
    )
    qualityChecks_IcuHoursGt1000["mrn"] = np.where(
        qualityChecks_IcuHoursGt1000["mrn"] != "",
        qualityChecks_IcuHoursGt1000["mrn"]
        .astype(str)
        .str.pad(10, side="left", fillchar="0"),
        "",
    )
    qualityChecks_IcuHoursGt1000["AUID"] = np.where(
        qualityChecks_IcuHoursGt1000["AUID"] != "",
        qualityChecks_IcuHoursGt1000["AUID"]
        .astype(str)
        .str.pad(10, side="left", fillchar="0"),
        "",
    )
    qualityChecks_IcuHoursGt1000["hours_in_icu"] = qualityChecks_IcuHoursGt1000[
        "hours_in_icu"
    ].astype(float)
    qualityChecks_IcuHoursGt1000["hours_in_icu"] = qualityChecks_IcuHoursGt1000[
        "hours_in_icu"
    ].astype("Int64", errors="ignore")
    # dropping duplicate values
    qualityChecks_IcuHoursGt1000.drop_duplicates(keep="last", inplace=True)
    qualityChecks_IcuHoursGt1000.to_csv(
        "./Output/QualityChecks_IcuHoursGt1000.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    logging.info("qualityChecks_IcuHoursGt1000=%s", len(qualityChecks_IcuHoursGt1000))
    # fn_display_data_in_window('QC', 'qualityChecks_IcuHoursGt1000')
    ###############################################################################
    # elif qc_task == 'ed_los_ge_2_ed_visit':
    """Query that shows a list of ED Encounters that have a LOS greater than 2 days"""
    # Access query name:qry quality ed gt 2880
    # SELECT tbl_ppm_ED_Encounter_preclean.Hospital, tbl_ppm_ED_Encounter_preclean.Stu AS ed_visit_identifier, tbl_ppm_ED_Encounter_preclean.LengthofStay, ED_NWAU.URG, [Class Descriptions].Description, DateValue([StartDateTime]) AS start, DateValue([EndDateTime]) AS [end], Right([PatientNumber],10) AS mrn1, tbl_ppm_ED_Encounter_preclean.patientnumber, tbl_ppm_ED_Encounter_preclean.[Extra:ModeofSep] FROM (tbl_ppm_ED_Encounter_preclean INNER JOIN ED_NWAU ON (ED_NWAU.ed_visit_identifier = tbl_ppm_ED_Encounter_preclean.Stu) AND (tbl_ppm_ED_Encounter_preclean.Hospital = ED_NWAU.facility_identifier)) LEFT JOIN [Class Descriptions] ON ED_NWAU.URG = [Class Descriptions].Code WHERE (((tbl_ppm_ED_Encounter_preclean.LengthofStay)>2880));
    tbl_ppm_ED_Encounter_preclean["mrn1"] = (
        tbl_ppm_ED_Encounter_preclean["PatientNumber"].astype(str).str.strip()
    )
    tbl_ppm_ED_Encounter_preclean["mrn1"] = tbl_ppm_ED_Encounter_preclean["mrn1"].str[
        -10:
    ]
    # tbl_ppm_ED_Encounter_preclean['LengthofStay'] = np.where(tbl_ppm_ED_Encounter_preclean['LengthofStay']=='', 0, tbl_ppm_ED_Encounter_preclean['LengthofStay'].replace('','0').apply(lambda x: int(float(x)))) # otherwise error: ValueError: could not convert string to float: ''
    tbl_ppm_ED_Encounter_preclean["LengthofStay"] = (
        tbl_ppm_ED_Encounter_preclean["LengthofStay"]
        .fillna(0)
        .astype(int, errors="ignore")
    )
    df_query1 = pd.merge(
        tbl_ppm_ED_Encounter_preclean[
            (tbl_ppm_ED_Encounter_preclean["LengthofStay"] > 2880)
        ][
            [
                "Hospital",
                "Stu",
                "LengthofStay",
                "Extra:ModeofSep",
                "PatientNumber",
                "StartDateTime",
                "EndDateTime",
                "mrn1",
            ]
        ],
        ed_NWAU[["facility_identifier", "ed_visit_identifier", "AECC"]],
        how="inner",
        left_on=["Hospital", "Stu"],
        right_on=["facility_identifier", "ed_visit_identifier"],
        suffixes=("", "_drop"),
    )
    df_query1 = df_query1.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    df_query1["ed_visit_identifier"] = df_query1["Stu"]
    df_query1["start"] = df_query1["StartDateTime"]
    df_query1["end"] = df_query1["EndDateTime"]
    df_query1["ModeofSep"] = df_query1["Extra:ModeofSep"]
    df_query1["AECC"] = df_query1["AECC"].astype(str)
    qualityChecks_EdGt2880 = pd.merge(
        df_query1,
        class_Descriptions,
        how="left",
        left_on=["AECC"],
        right_on=["Code"],
        suffixes=("", "_drop"),
    )
    qualityChecks_EdGt2880 = qualityChecks_EdGt2880.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    qualityChecks_EdGt2880 = qualityChecks_EdGt2880[
        (qualityChecks_EdGt2880["LengthofStay"].astype(float) > 2880)
    ]
    if len(qualityChecks_EdGt2880) > 0:
        qualityChecks_EdGt2880 = qualityChecks_EdGt2880[
            [
                "Hospital",
                "ed_visit_identifier",
                "LengthofStay",
                "AECC",
                "Description",
                "start",
                "end",
                "mrn1",
                "PatientNumber",
                "ModeofSep",
            ]
        ]
    else:
        qualityChecks_EdGt2880 = pd.DataFrame(
            columns=[
                "Hospital",
                "ed_visit_identifier",
                "LengthofStay",
                "AECC",
                "Description",
                "start",
                "end",
                "mrn1",
                "PatientNumber",
                "ModeofSep",
            ]
        )
    qualityChecks_EdGt2880 = qualityChecks_EdGt2880.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    qualityChecks_EdGt2880 = qualityChecks_EdGt2880.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    qualityChecks_EdGt2880 = qualityChecks_EdGt2880.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    qualityChecks_EdGt2880["Description"] = (
        qualityChecks_EdGt2880["Description"].astype(str).str.replace("nan", "")
    )
    qualityChecks_EdGt2880 = qualityChecks_EdGt2880.drop_duplicates(keep="last")
    qualityChecks_EdGt2880["mrn1"] = np.where(
        qualityChecks_EdGt2880["mrn1"] != "",
        qualityChecks_EdGt2880["mrn1"]
        .astype(str)
        .str.pad(10, side="left", fillchar="0"),
        "",
    )
    # dropping duplicate values
    qualityChecks_EdGt2880.drop_duplicates(keep="last", inplace=True)
    qualityChecks_EdGt2880.to_csv(
        "./Output/QualityChecks_EdGt2880.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    logging.info("qualityChecks_EdGt2880=%s", len(qualityChecks_EdGt2880))
    # fn_display_data_in_window('QC', 'qualityChecks_EdGt2880')
    ###############################################################################
    # elif qc_task == 'ed_los_ge_2_days_epi':
    """Query that shows a list of admitted ED Encounters that have a LOS greater than 2 days and compare this data to the admitted ward details to see if there is a data entry in ED data system. """
    # Access query name:qry quality ed gt 2880 admitted transfer
    # SELECT [qry quality ed gt 2880].Hospital, [qry quality ed gt 2880].ed_visit_identifier, [qry quality ed gt 2880].LengthofStay AS [LOS ED in ED Presentation], [qry quality ed gt 2880].[Extra:ModeofSep], [qry quality ed gt 2880].URG, [qry quality ed gt 2880].Description, [qry quality ed gt 2880].mrn1, tbl_dbo_days_episode.episode_sequence_number, tbl_dbo_days_episode.ward_identifier, tbl_dbo_days_episode.unit_type, Sum((DateDiff("n",[start_date]+TimeValue([start_time]),[end_date]+TimeValue([end_time])))) AS [LOS Admitted ED Inpatient Stay], tbl_dbo_days_episode.stay_number, tbl_dbo_stay.mrn
    # FROM ([qry quality ed gt 2880] INNER JOIN tbl_dbo_stay ON (tbl_dbo_stay.mrn = [qry quality ed gt 2880].mrn1) AND ([qry quality ed gt 2880].Hospital = tbl_dbo_stay.facility_identifier)) INNER JOIN tbl_dbo_days_episode ON (tbl_dbo_days_episode.stay_number = tbl_dbo_stay.stay_number) AND (tbl_dbo_stay.facility_identifier = tbl_dbo_days_episode.facility_identifier)
    # WHERE ((([qry quality ed gt 2880].start) Between [admission_date]-1 And [admission_date] Or ([qry quality ed gt 2880].start) Is Null))
    # GROUP BY [qry quality ed gt 2880].Hospital, [qry quality ed gt 2880].ed_visit_identifier, [qry quality ed gt 2880].LengthofStay, [qry quality ed gt 2880].[Extra:ModeofSep], [qry quality ed gt 2880].URG, [qry quality ed gt 2880].Description, [qry quality ed gt 2880].mrn1, tbl_dbo_days_episode.episode_sequence_number, tbl_dbo_days_episode.ward_identifier, tbl_dbo_days_episode.unit_type, tbl_dbo_days_episode.stay_number, tbl_dbo_stay.mrn
    # HAVING (((tbl_dbo_days_episode.episode_sequence_number)=1) AND ((tbl_dbo_days_episode.unit_type)="17"));
    # qualityChecks_EdGt2880['mrn1'] = qualityChecks_EdGt2880['mrn1'].astype('Int64', errors='ignore')
    # tbl_dbo_stay['mrn'] = tbl_dbo_stay['mrn'].astype(str)
    # import qualityChecks_EdGt2880
    file_qualityChecks_EdGt2880 = "./Output/QualityChecks_EdGt2880.csv"
    if os.path.isfile(file_qualityChecks_EdGt2880):
        try:
            qualityChecks_EdGt2880 = read_csv_file(
                file_qualityChecks_EdGt2880,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            # label_6_status = 0
            messagebox.showerror(
                "File Error",
                "Error extracting qualityChecks_EdGt2880 from ./Output/qualityChecks_EdGt2880.csv.\n"
                + str(e),
            )
            return
        else:
            qualityChecks_EdGt2880 = qualityChecks_EdGt2880.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            qualityChecks_EdGt2880 = qualityChecks_EdGt2880.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            qualityChecks_EdGt2880 = qualityChecks_EdGt2880.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            qualityChecks_EdGt2880 = qualityChecks_EdGt2880.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
    else:
        qualityChecks_EdGt2880 = pd.DataFrame(
            columns=[
                "Hospital",
                "ed_visit_identifier",
                "LengthofStay",
                "AECC",
                "Description",
                "start",
                "end",
                "mrn1",
                "PatientNumber",
                "ModeofSep",
            ]
        )
    df_query1 = pd.merge(
        qualityChecks_EdGt2880,
        tbl_dbo_stay[
            [
                "stay_number",
                "mrn",
                "facility_identifier",
                "admission_date",
                "admission_time",
            ]
        ],
        how="inner",
        left_on=["mrn1", "Hospital"],
        right_on=["mrn", "facility_identifier"],
        suffixes=("", "_drop"),
    )
    df_query1 = df_query1.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    # 27 July 2024 - stay episode seq number - remove dup
    df_query1.drop_duplicates(
        subset=[
            "Hospital",
            "ed_visit_identifier",
            "LengthofStay",
            "AECC",
            "Description",
            "start",
            "end",
            "mrn1",
            "PatientNumber",
            "ModeofSep",
            "stay_number",
            "mrn",
            "facility_identifier",
            "admission_date",
            "admission_time",
        ],
        keep="last",
        inplace=True,
    )
    df_query1["admission_date_min_dummy"] = df_query1["admission_date"].astype(str)
    df_query1["admission_date_min_dummy"] = (
        df_query1["admission_date_min_dummy"].str[:10]
        + " "
        + df_query1["admission_time"].astype(str)
    )
    df_query1["admission_date_min_dummy"] = pd.to_datetime(
        df_query1["admission_date_min_dummy"],
        errors="coerce",
        format="%Y-%m-%d %H:%M:%S",
    ) - pd.DateOffset(1)
    df_query1["admission_date_max_dummy"] = df_query1["admission_date"].astype(str)
    df_query1["admission_date_max_dummy"] = pd.to_datetime(
        (
            df_query1["admission_date_max_dummy"].str[:10]
            + " "
            + df_query1["admission_time"].astype(str)
        ),
        errors="coerce",
        format="%Y-%m-%d %H:%M:%S",
    )
    # qualityChecks_EdGt2880AdmittedTransfer = pd.merge(df_query1[((pd.to_datetime(df_query1['start'], errors='coerce', format="%Y-%m-%d %H:%M:%S") >= pd.to_datetime(df_query1['admission_date'], errors='coerce', format="%Y-%m-%d %H:%M:%S")-pd.DateOffset(1)) & (pd.to_datetime(df_query1['start'], errors='coerce', format="%Y-%m-%d %H:%M:%S") <= pd.to_datetime((df_query1['admission_date'].astype(str) + ' ' + df_query1['admission_time'].astype(str)), errors='coerce', format="%Y-%m-%d %H:%M:%S"))) | ((df_query1['start'].isnull()) | (df_query1['start']==''))], tbl_dbo_days_episode[(tbl_dbo_days_episode['episode_sequence_number'].replace('','0').apply(lambda x: int(float(x)))==1) & (tbl_dbo_days_episode['unit_type']=='17')][['ward_identifier', 'unit_type', 'episode_sequence_number', 'stay_number', 'facility_identifier', 'start_date', 'start_time', 'end_date', 'end_time']], how='inner', on=['stay_number', 'facility_identifier'], suffixes=('', '_drop'))
    # qualityChecks_EdGt2880AdmittedTransfer = pd.merge(df_query1[((pd.to_datetime(df_query1['start'], errors='coerce', format="%Y-%m-%d %H:%M:%S") >= df_query1['admission_date_min_dummy']) & (pd.to_datetime(df_query1['start'], errors='coerce', format="%Y-%m-%d %H:%M:%S") <= df_query1['admission_date_max_dummy'])) | ((df_query1['start'].isnull()) | (df_query1['start']==''))], tbl_dbo_days_episode[(tbl_dbo_days_episode['episode_sequence_number'].replace('','0').apply(lambda x: int(float(x)))==1) & (tbl_dbo_days_episode['unit_type']=='17')][['ward_identifier', 'unit_type', 'episode_sequence_number', 'stay_number', 'facility_identifier', 'start_date', 'start_time', 'end_date', 'end_time']], how='inner', on=['stay_number', 'facility_identifier'], suffixes=('', '_drop'))
    tbl_dbo_days_episode["episode_sequence_number"] = (
        tbl_dbo_days_episode["episode_sequence_number"]
        .fillna(0)
        .astype(int, errors="ignore")
    )
    qualityChecks_EdGt2880AdmittedTransfer = pd.merge(
        df_query1[
            (
                (
                    pd.to_datetime(
                        df_query1["start"], errors="coerce", format="%Y-%m-%d %H:%M:%S"
                    )
                    >= df_query1["admission_date_min_dummy"]
                )
                & (
                    pd.to_datetime(
                        df_query1["start"], errors="coerce", format="%Y-%m-%d %H:%M:%S"
                    )
                    <= df_query1["admission_date_max_dummy"]
                )
            )
            | ((df_query1["start"].isnull()) | (df_query1["start"] == ""))
        ],
        tbl_dbo_days_episode[
            (tbl_dbo_days_episode["episode_sequence_number"] == 1)
            & (tbl_dbo_days_episode["unit_type"] == "17")
        ][
            [
                "ward_identifier",
                "unit_type",
                "episode_sequence_number",
                "stay_number",
                "facility_identifier",
                "start_date",
                "start_time",
                "end_date",
                "end_time",
            ]
        ],
        how="inner",
        on=["stay_number", "facility_identifier"],
        suffixes=("", "_drop"),
    )
    qualityChecks_EdGt2880AdmittedTransfer = (
        qualityChecks_EdGt2880AdmittedTransfer.apply(
            lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
        )
    )
    qualityChecks_EdGt2880AdmittedTransfer["LOS Admitted ED Inpatient Stay"] = (
        pd.to_datetime(
            (
                qualityChecks_EdGt2880AdmittedTransfer["end_date"].astype(str).str[:10]
                + " "
                + qualityChecks_EdGt2880AdmittedTransfer["end_time"].astype(str)
            ),
            errors="coerce",
            format="%Y-%m-%d %H:%M:%S",
        )
        - pd.to_datetime(
            (
                qualityChecks_EdGt2880AdmittedTransfer["start_date"]
                .astype(str)
                .str[:10]
                + " "
                + qualityChecks_EdGt2880AdmittedTransfer["start_time"].astype(str)
            ),
            errors="coerce",
            format="%Y-%m-%d %H:%M:%S",
        )
    ) / pd.Timedelta(minutes=1)
    qualityChecks_EdGt2880AdmittedTransfer = qualityChecks_EdGt2880AdmittedTransfer[
        [
            "Hospital",
            "ed_visit_identifier",
            "LengthofStay",
            "AECC",
            "Description",
            "mrn1",
            "PatientNumber",
            "ModeofSep",
            "start",
            "episode_sequence_number",
            "ward_identifier",
            "unit_type",
            "stay_number",
            "LOS Admitted ED Inpatient Stay",
        ]
    ]
    qualityChecks_EdGt2880AdmittedTransfer = (
        qualityChecks_EdGt2880AdmittedTransfer.groupby(
            [
                "Hospital",
                "ed_visit_identifier",
                "LengthofStay",
                "AECC",
                "Description",
                "mrn1",
                "PatientNumber",
                "ModeofSep",
                "start",
                "episode_sequence_number",
                "ward_identifier",
                "unit_type",
                "stay_number",
            ],
            as_index=False,
            dropna=False,
        )
        .agg(LOS_Admitted_ED_Inpatient_Stay=("LOS Admitted ED Inpatient Stay", "sum"))
        .reset_index()
    )
    # qualityChecks_EdGt2880AdmittedTransfer = qualityChecks_EdGt2880AdmittedTransfer[(qualityChecks_EdGt2880AdmittedTransfer['episode_sequence_number'].replace('','0').apply(lambda x: int(float(x)))==1) & (qualityChecks_EdGt2880AdmittedTransfer['unit_type']=='17')] # & (qualityChecks_EdGt2880AdmittedTransfer['LOS_Admitted_ED_Inpatient_Stay']>2880)
    qualityChecks_EdGt2880AdmittedTransfer = qualityChecks_EdGt2880AdmittedTransfer[
        (qualityChecks_EdGt2880AdmittedTransfer["episode_sequence_number"] == 1)
        & (qualityChecks_EdGt2880AdmittedTransfer["unit_type"] == "17")
    ]
    if len(qualityChecks_EdGt2880AdmittedTransfer) > 0:
        qualityChecks_EdGt2880AdmittedTransfer = qualityChecks_EdGt2880AdmittedTransfer[
            [
                "Hospital",
                "ed_visit_identifier",
                "LengthofStay",
                "AECC",
                "Description",
                "mrn1",
                "PatientNumber",
                "ModeofSep",
                "start",
                "episode_sequence_number",
                "ward_identifier",
                "unit_type",
                "stay_number",
                "LOS_Admitted_ED_Inpatient_Stay",
            ]
        ]
    else:
        qualityChecks_EdGt2880AdmittedTransfer = pd.DataFrame(
            columns=[
                "Hospital",
                "ed_visit_identifier",
                "LengthofStay",
                "AECC",
                "Description",
                "mrn1",
                "PatientNumber",
                "ModeofSep",
                "start",
                "episode_sequence_number",
                "ward_identifier",
                "unit_type",
                "stay_number",
                "LOS_Admitted_ED_Inpatient_Stay",
            ]
        )
    # remove padding
    qualityChecks_EdGt2880AdmittedTransfer["episode_sequence_number"] = (
        qualityChecks_EdGt2880AdmittedTransfer["episode_sequence_number"]
        .astype(str)
        .str.lstrip("0")
    )  # .fillna(value='0')
    qualityChecks_EdGt2880AdmittedTransfer["Description"] = (
        qualityChecks_EdGt2880AdmittedTransfer["Description"]
        .astype(str)
        .str.replace("nan", "")
    )
    qualityChecks_EdGt2880AdmittedTransfer = (
        qualityChecks_EdGt2880AdmittedTransfer.applymap(str)
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    qualityChecks_EdGt2880AdmittedTransfer = (
        qualityChecks_EdGt2880AdmittedTransfer.applymap(
            lambda x: x.strip() if isinstance(x, str) else x
        )
    )
    qualityChecks_EdGt2880AdmittedTransfer = (
        qualityChecks_EdGt2880AdmittedTransfer.apply(
            lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
        )
    )
    qualityChecks_EdGt2880AdmittedTransfer["LOS_Admitted_ED_Inpatient_Stay"] = (
        qualityChecks_EdGt2880AdmittedTransfer["LOS_Admitted_ED_Inpatient_Stay"].astype(
            float
        )
    )
    qualityChecks_EdGt2880AdmittedTransfer["LOS_Admitted_ED_Inpatient_Stay"] = (
        qualityChecks_EdGt2880AdmittedTransfer["LOS_Admitted_ED_Inpatient_Stay"].astype(
            "Int64", errors="ignore"
        )
    )
    # 29 Oct - set precision to 2. https://abft101.atlassian.net/browse/AQA-225
    qualityChecks_EdGt2880AdmittedTransfer["LOS_Admitted_ED_Inpatient_Stay"] = (
        qualityChecks_EdGt2880AdmittedTransfer["LOS_Admitted_ED_Inpatient_Stay"].apply(
            lambda x: round(x, 2)
        )
    )
    qualityChecks_EdGt2880AdmittedTransfer["mrn1"] = np.where(
        qualityChecks_EdGt2880AdmittedTransfer["mrn1"] != "",
        qualityChecks_EdGt2880AdmittedTransfer["mrn1"]
        .astype(str)
        .str.pad(10, side="left", fillchar="0"),
        "",
    )
    # dropping duplicate values
    qualityChecks_EdGt2880AdmittedTransfer.drop_duplicates(keep="last", inplace=True)
    qualityChecks_EdGt2880AdmittedTransfer.to_csv(
        "./Output/QualityChecks_EdGt2880AdmittedTransfer.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    logging.info(
        "qualityChecks_EdGt2880AdmittedTransfer=%s",
        len(qualityChecks_EdGt2880AdmittedTransfer),
    )
    # fn_display_data_in_window('QC', 'qualityChecks_EdGt2880AdmittedTransfer')
    ###############################################################################
    # elif qc_task == 'ed_los_le_5m':
    """Query that shows a list of ED Encounters that have a LOS < 5 mins excluding patients who were admitted in previous costing period or discharged in next costing period or deaths, patients who did not wait for treatment or patients transferred to another faciity """
    # Note: INFORM8 has duplicate records.
    # Access query name:qry quality ED <5 mins
    # SELECT tbl_ppm_ED_Encounter_preclean.EncounterNumber, tbl_ppm_ED_Encounter_preclean.LengthofStay, tbl_ppm_ED_Encounter_preclean.[Extra:ModeofSep], tbl_ppm_ED_Encounter_preclean.StartDateTime, tbl_ppm_ED_Encounter_preclean.EndDateTime, tbl_ppm_ED_Encounter_preclean.[Extra:EDVisitType], tbl_ppm_ED_Encounter_preclean.[Extra:TriageCategory], ED_NWAU.URG, [Class Descriptions].Description, Right([PatientNumber],10) AS mrn, tbl_ppm_ED_Encounter_preclean.Hospital
    # FROM [Class Descriptions] INNER JOIN (tbl_ppm_ED_Encounter_preclean INNER JOIN ED_NWAU ON (tbl_ppm_ED_Encounter_preclean.Hospital = ED_NWAU.facility_identifier) AND (tbl_ppm_ED_Encounter_preclean.Stu = ED_NWAU.ed_visit_identifier)) ON [Class Descriptions].Code = ED_NWAU.URG
    # WHERE (((tbl_ppm_ED_Encounter_preclean.LengthofStay)<5) AND ((tbl_ppm_ED_Encounter_preclean.[Extra:ModeofSep]) Not In ('3',"8","6","13","7","12","5","99","9","1","10")) AND ((tbl_ppm_ED_Encounter_preclean.StartDateTime) Between [Forms]![Frm:1-ExtractSetUp]![Start_Date] And [Forms]![Frm:1-ExtractSetUp]![End_Date]) AND ((tbl_ppm_ED_Encounter_preclean.EndDateTime) Between [Forms]![Frm:1-ExtractSetUp]![Start_Date] And [Forms]![Frm:1-ExtractSetUp]![End_Date]) AND ((tbl_ppm_ED_Encounter_preclean.[Extra:EDVisitType])="01")) ORDER BY tbl_ppm_ED_Encounter_preclean.LengthofStay;
    start_date_dt = pd.to_datetime(start_date, format="%Y-%m-%d %H:%M:%S")
    end_date_dt = pd.to_datetime(end_date, format="%Y-%m-%d %H:%M:%S")
    tbl_ppm_ED_Encounter_preclean["mrn1"] = (
        tbl_ppm_ED_Encounter_preclean["PatientNumber"].astype(str).str.strip()
    )
    tbl_ppm_ED_Encounter_preclean["mrn1"] = tbl_ppm_ED_Encounter_preclean["mrn1"].str[
        -10:
    ]
    tbl_ppm_ED_Encounter_preclean["LengthofStay"] = np.where(
        (tbl_ppm_ED_Encounter_preclean["LengthofStay"] == "")
        | (tbl_ppm_ED_Encounter_preclean["LengthofStay"].isnull()),
        0,
        tbl_ppm_ED_Encounter_preclean["LengthofStay"],
    )  # otherwise error: ValueError: could not convert string to float: ''
    tbl_ppm_ED_Encounter_preclean["start_date_dt"] = start_date_dt
    tbl_ppm_ED_Encounter_preclean["Extra:ModeofSep"] = tbl_ppm_ED_Encounter_preclean[
        "Extra:ModeofSep"
    ].astype(str)
    # Note: remove the check where (tbl_ppm_ED_Encounter_preclean['Extra:ModeofSep'].isnull() | tbl_ppm_ED_Encounter_preclean['Extra:ModeofSep']=='') because this cause extra records in Py
    # df_query1 = pd.merge(tbl_ppm_ED_Encounter_preclean[(tbl_ppm_ED_Encounter_preclean['LengthofStay'].astype(float)<5) & ((tbl_ppm_ED_Encounter_preclean['Extra:ModeofSep'].isnull() | tbl_ppm_ED_Encounter_preclean['Extra:ModeofSep']=='') | ~(tbl_ppm_ED_Encounter_preclean['Extra:ModeofSep'].isin(['3','8','6','13','7','12','5','99','9','1','10']))) & ((tbl_ppm_ED_Encounter_preclean['Extra:EDVisitType']=='01') | (tbl_ppm_ED_Encounter_preclean['Extra:EDVisitType']=='1')) & ((pd.to_datetime(tbl_ppm_ED_Encounter_preclean['StartDateTime'], errors='coerce', format="%Y-%m-%d %H:%M:%S") >= start_date_dt) & (pd.to_datetime(tbl_ppm_ED_Encounter_preclean['StartDateTime'], errors='coerce', format="%Y-%m-%d %H:%M:%S") <= end_date_dt)) & (((pd.to_datetime(tbl_ppm_ED_Encounter_preclean['EndDateTime'], errors='coerce', format="%Y-%m-%d %H:%M:%S") >= start_date_dt) & (pd.to_datetime(tbl_ppm_ED_Encounter_preclean['EndDateTime'], errors='coerce', format="%Y-%m-%d %H:%M:%S") <= end_date_dt)) | ((tbl_ppm_ED_Encounter_preclean['EndDateTime'].isnull()) | (tbl_ppm_ED_Encounter_preclean['EndDateTime']=='')))][['EncounterNumber', 'LengthofStay', 'Extra:ModeofSep', 'StartDateTime', 'EndDateTime', 'Extra:EDVisitType', 'Extra:TriageCategory', 'Hospital', 'Stu',   'mrn1', 'PatientNumber']], ed_NWAU[['facility_identifier', 'ed_visit_identifier', 'URG']], how='inner', left_on=['Hospital', 'Stu'], right_on=['facility_identifier', 'ed_visit_identifier'], suffixes=('', '_drop'))
    # Ranjit - 11 Oct mode of separation in EDW is different from HIE.
    # query:  select distinct replace(ltrim(replace(ED_MOS_HIE_CD,'0',' ')),' ','0') as HIE_ModeofSep_code, ED_MOS_HIE as HIE_ModeofSep_descr ,ED_MOS_CD as EDW_ModeofSep_codee, ED_MOS as EDW_ModeofSep_descr  from CRT.v_FACT_ED_SE_FLAT order by replace(ltrim(replace(ED_MOS_HIE_CD,'0',' ')),' ','0')
    # df_query1 = pd.merge(tbl_ppm_ED_Encounter_preclean[(tbl_ppm_ED_Encounter_preclean['LengthofStay'].astype(float)<5) & ((pd.notna(tbl_ppm_ED_Encounter_preclean['Extra:ModeofSep']) & (tbl_ppm_ED_Encounter_preclean['Extra:ModeofSep']!='')) & ~(tbl_ppm_ED_Encounter_preclean['Extra:ModeofSep'].isin(['3','8','6','13','7','12','5','99','9','1','10']))) & ((tbl_ppm_ED_Encounter_preclean['Extra:EDVisitType']=='01') | (tbl_ppm_ED_Encounter_preclean['Extra:EDVisitType']=='1')) & ((pd.to_datetime(tbl_ppm_ED_Encounter_preclean['StartDateTime'], errors='coerce', format="%Y-%m-%d %H:%M:%S") >= start_date_dt) & (pd.to_datetime(tbl_ppm_ED_Encounter_preclean['StartDateTime'], errors='coerce', format="%Y-%m-%d %H:%M:%S") <= end_date_dt)) & (((pd.to_datetime(tbl_ppm_ED_Encounter_preclean['EndDateTime'], errors='coerce', format="%Y-%m-%d %H:%M:%S") >= start_date_dt) & (pd.to_datetime(tbl_ppm_ED_Encounter_preclean['EndDateTime'], errors='coerce', format="%Y-%m-%d %H:%M:%S") <= end_date_dt)) | ((tbl_ppm_ED_Encounter_preclean['EndDateTime'].isnull()) | (tbl_ppm_ED_Encounter_preclean['EndDateTime']=='')))][['EncounterNumber', 'LengthofStay', 'Extra:ModeofSep', 'StartDateTime', 'EndDateTime', 'Extra:EDVisitType', 'Extra:TriageCategory', 'Hospital', 'Stu',   'mrn1', 'PatientNumber']], ed_NWAU[['facility_identifier', 'ed_visit_identifier', 'AECC']], how='inner', left_on=['Hospital', 'Stu'], right_on=['facility_identifier', 'ed_visit_identifier'], suffixes=('', '_drop'))
    df_query1 = pd.merge(
        tbl_ppm_ED_Encounter_preclean[
            (tbl_ppm_ED_Encounter_preclean["LengthofStay"].astype(float) < 5)
            & (
                (
                    pd.notna(tbl_ppm_ED_Encounter_preclean["Extra:ModeofSep"])
                    & (tbl_ppm_ED_Encounter_preclean["Extra:ModeofSep"] != "")
                )
                & ~(
                    tbl_ppm_ED_Encounter_preclean["Extra:ModeofSep"].isin(
                        [
                            "04",
                            "01.06",
                            "03",
                            "02.03",
                            "01.07",
                            "02.04",
                            "01.02",
                            "02.02",
                            "98",
                            "02.05",
                            "01.03",
                            "01",
                            "01.05",
                            "4",
                            "4.0",
                            "1.06",
                            "3",
                            "3.0",
                            "2.03",
                            "1.07",
                            "2.04",
                            "1.02",
                            "2.02",
                            "98",
                            "2.05",
                            "1.03",
                            "1",
                            "1.0",
                            "1.05",
                        ]
                    )
                )
            )
            & (
                (tbl_ppm_ED_Encounter_preclean["Extra:EDVisitType"] == "01")
                | (tbl_ppm_ED_Encounter_preclean["Extra:EDVisitType"] == "1")
            )
            & (
                (
                    pd.to_datetime(
                        tbl_ppm_ED_Encounter_preclean["StartDateTime"],
                        errors="coerce",
                        format="%Y-%m-%d %H:%M:%S",
                    )
                    >= start_date_dt
                )
                & (
                    pd.to_datetime(
                        tbl_ppm_ED_Encounter_preclean["StartDateTime"],
                        errors="coerce",
                        format="%Y-%m-%d %H:%M:%S",
                    )
                    <= end_date_dt
                )
            )
            & (
                (
                    (
                        pd.to_datetime(
                            tbl_ppm_ED_Encounter_preclean["EndDateTime"],
                            errors="coerce",
                            format="%Y-%m-%d %H:%M:%S",
                        )
                        >= start_date_dt
                    )
                    & (
                        pd.to_datetime(
                            tbl_ppm_ED_Encounter_preclean["EndDateTime"],
                            errors="coerce",
                            format="%Y-%m-%d %H:%M:%S",
                        )
                        <= end_date_dt
                    )
                )
                | (
                    (tbl_ppm_ED_Encounter_preclean["EndDateTime"].isnull())
                    | (tbl_ppm_ED_Encounter_preclean["EndDateTime"] == "")
                )
            )
        ][
            [
                "EncounterNumber",
                "LengthofStay",
                "Extra:ModeofSep",
                "StartDateTime",
                "EndDateTime",
                "Extra:EDVisitType",
                "Extra:TriageCategory",
                "Hospital",
                "Stu",
                "mrn1",
                "PatientNumber",
            ]
        ],
        ed_NWAU[["facility_identifier", "ed_visit_identifier", "AECC"]],
        how="inner",
        left_on=["Hospital", "Stu"],
        right_on=["facility_identifier", "ed_visit_identifier"],
        suffixes=("", "_drop"),
    )
    df_query1 = df_query1.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    df_query1["start"] = df_query1["StartDateTime"]
    df_query1["end"] = df_query1["EndDateTime"]
    df_query1["EDVisitType"] = df_query1["Extra:EDVisitType"]
    df_query1["TriageCategory"] = df_query1["Extra:TriageCategory"]
    df_query1["AECC"] = df_query1["AECC"].astype(str)
    qualityChecks_EdLessThan5Min = pd.merge(
        df_query1,
        class_Descriptions,
        how="left",
        right_on=["Code"],
        left_on=["AECC"],
        suffixes=("", "_drop"),
    )
    qualityChecks_EdLessThan5Min = qualityChecks_EdLessThan5Min.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    # Ranjit - 11 Oct mode of separation in EDW is different from HIE.
    # query:  select distinct replace(ltrim(replace(ED_MOS_HIE_CD,'0',' ')),' ','0') as HIE_ModeofSep_code, ED_MOS_HIE as HIE_ModeofSep_descr ,ED_MOS_CD as EDW_ModeofSep_codee, ED_MOS as EDW_ModeofSep_descr  from CRT.v_FACT_ED_SE_FLAT order by replace(ltrim(replace(ED_MOS_HIE_CD,'0',' ')),' ','0')
    # qualityChecks_EdLessThan5Min = qualityChecks_EdLessThan5Min[(qualityChecks_EdLessThan5Min['LengthofStay'].astype(float)<5) & ((qualityChecks_EdLessThan5Min['Extra:ModeofSep'].isnull() | qualityChecks_EdLessThan5Min['Extra:ModeofSep']=='') | ~(qualityChecks_EdLessThan5Min['Extra:ModeofSep'].isin(['3','8','6','13','7','12','5','99','9','1','10']))) & ((qualityChecks_EdLessThan5Min['Extra:EDVisitType']=='01') | (qualityChecks_EdLessThan5Min['Extra:EDVisitType']=='1')) & ((pd.to_datetime(qualityChecks_EdLessThan5Min['StartDateTime'], errors='coerce', format="%Y-%m-%d %H:%M:%S") >= start_date_dt) & (pd.to_datetime(qualityChecks_EdLessThan5Min['StartDateTime'], errors='coerce', format="%Y-%m-%d %H:%M:%S") <= end_date_dt)) & (((pd.to_datetime(qualityChecks_EdLessThan5Min['EndDateTime'], errors='coerce', format="%Y-%m-%d %H:%M:%S") >= start_date_dt) & (pd.to_datetime(qualityChecks_EdLessThan5Min['EndDateTime'], errors='coerce', format="%Y-%m-%d %H:%M:%S") <= end_date_dt)) | ((qualityChecks_EdLessThan5Min['EndDateTime'].isnull()) | (qualityChecks_EdLessThan5Min['EndDateTime']=='')))]
    qualityChecks_EdLessThan5Min = qualityChecks_EdLessThan5Min[
        (qualityChecks_EdLessThan5Min["LengthofStay"].astype(float) < 5)
        & (
            (
                qualityChecks_EdLessThan5Min["Extra:ModeofSep"].isnull()
                | qualityChecks_EdLessThan5Min["Extra:ModeofSep"]
                == ""
            )
            | ~(
                qualityChecks_EdLessThan5Min["Extra:ModeofSep"].isin(
                    [
                        "04",
                        "01.06",
                        "03",
                        "02.03",
                        "01.07",
                        "02.04",
                        "01.02",
                        "02.02",
                        "98",
                        "02.05",
                        "01.03",
                        "01",
                        "01.05",
                        "4",
                        "4.0",
                        "1.06",
                        "3",
                        "3.0",
                        "2.03",
                        "1.07",
                        "2.04",
                        "1.02",
                        "2.02",
                        "98",
                        "2.05",
                        "1.03",
                        "1",
                        "1.0",
                        "1.05",
                    ]
                )
            )
        )
        & (
            (qualityChecks_EdLessThan5Min["Extra:EDVisitType"] == "01")
            | (qualityChecks_EdLessThan5Min["Extra:EDVisitType"] == "1")
        )
        & (
            (
                pd.to_datetime(
                    qualityChecks_EdLessThan5Min["StartDateTime"],
                    errors="coerce",
                    format="%Y-%m-%d %H:%M:%S",
                )
                >= start_date_dt
            )
            & (
                pd.to_datetime(
                    qualityChecks_EdLessThan5Min["StartDateTime"],
                    errors="coerce",
                    format="%Y-%m-%d %H:%M:%S",
                )
                <= end_date_dt
            )
        )
        & (
            (
                (
                    pd.to_datetime(
                        qualityChecks_EdLessThan5Min["EndDateTime"],
                        errors="coerce",
                        format="%Y-%m-%d %H:%M:%S",
                    )
                    >= start_date_dt
                )
                & (
                    pd.to_datetime(
                        qualityChecks_EdLessThan5Min["EndDateTime"],
                        errors="coerce",
                        format="%Y-%m-%d %H:%M:%S",
                    )
                    <= end_date_dt
                )
            )
            | (
                (qualityChecks_EdLessThan5Min["EndDateTime"].isnull())
                | (qualityChecks_EdLessThan5Min["EndDateTime"] == "")
            )
        )
    ]
    qualityChecks_EdLessThan5Min = qualityChecks_EdLessThan5Min.sort_values(
        by=["LengthofStay"]
    )
    if len(qualityChecks_EdLessThan5Min) > 0:
        qualityChecks_EdLessThan5Min = qualityChecks_EdLessThan5Min[
            [
                "Hospital",
                "ed_visit_identifier",
                "LengthofStay",
                "AECC",
                "Description",
                "start",
                "end",
                "mrn1",
                "PatientNumber",
                "EDVisitType",
                "TriageCategory",
            ]
        ]
    else:
        qualityChecks_EdLessThan5Min = pd.DataFrame(
            columns=[
                "Hospital",
                "ed_visit_identifier",
                "LengthofStay",
                "AECC",
                "Description",
                "start",
                "end",
                "mrn1",
                "PatientNumber",
                "EDVisitType",
                "TriageCategory",
            ]
        )
    qualityChecks_EdLessThan5Min = qualityChecks_EdLessThan5Min.drop_duplicates(
        keep="last"
    )
    # edvisittype (Inform8 = 01, App2 = 1)
    # remove padding
    # 29 Oct updte: bring back padding https://abft101.atlassian.net/browse/AQA-227
    # qualityChecks_EdLessThan5Min['EDVisitType'] = qualityChecks_EdLessThan5Min['EDVisitType'].astype(str).str.lstrip('0')#.fillna(value='0')
    qualityChecks_EdLessThan5Min["EDVisitType"] = qualityChecks_EdLessThan5Min[
        "EDVisitType"
    ].astype(str)

    qualityChecks_EdLessThan5Min = qualityChecks_EdLessThan5Min.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    qualityChecks_EdLessThan5Min = qualityChecks_EdLessThan5Min.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    qualityChecks_EdLessThan5Min = qualityChecks_EdLessThan5Min.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    qualityChecks_EdLessThan5Min["Description"] = (
        qualityChecks_EdLessThan5Min["Description"].astype(str).str.replace("nan", "")
    )
    qualityChecks_EdLessThan5Min["mrn1"] = np.where(
        qualityChecks_EdLessThan5Min["mrn1"] != "",
        qualityChecks_EdLessThan5Min["mrn1"]
        .astype(str)
        .str.pad(10, side="left", fillchar="0"),
        "",
    )
    # 29 Oct updte: bring back padding https://abft101.atlassian.net/browse/AQA-227
    # List of columns to pad to two zeros . These do not have any decimal
    columns_to_pad = ["EDVisitType"]
    for col in columns_to_pad:
        qualityChecks_EdLessThan5Min[col] = qualityChecks_EdLessThan5Min[col].apply(
            lambda x: "{:02d}".format(int(float(x)))
            if x.replace(".", "", 1).isdigit() and x != "" and x != -1
            else x
        )
    # dropping duplicate values
    qualityChecks_EdLessThan5Min.drop_duplicates(keep="last", inplace=True)
    qualityChecks_EdLessThan5Min.to_csv(
        "./Output/QualityChecks_EdLessThan5Min.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    logging.info("qualityChecks_EdLessThan5Min=%s", len(qualityChecks_EdLessThan5Min))
    # fn_display_data_in_window('QC', 'qualityChecks_EdLessThan5Min')
    ###############################################################################
    # elif qc_task == 'ed_age_null':
    """Query that shows a list of ED patients that have age > 105 years """
    # Access query name:qry quality age3
    # SELECT tbl_ppm_ED_Encounter_preclean.EncounterNumber, tbl_ppm_ED_Encounter_preclean.Age, tbl_ppm_ED_Encounter_preclean.PatientNumber, tbl_ppm_ED_Encounter_preclean.person_area_uid, tbl_ppm_ED_Encounter_preclean.[Extra:URG], ED_NWAU.URG, [Class Descriptions].Description FROM [Class Descriptions] RIGHT JOIN (tbl_ppm_ED_Encounter_preclean LEFT JOIN ED_NWAU ON (tbl_ppm_ED_Encounter_preclean.Hospital = ED_NWAU.facility_identifier) AND (tbl_ppm_ED_Encounter_preclean.Stu = ED_NWAU.ed_visit_identifier)) ON [Class Descriptions].Code = ED_NWAU.URG WHERE (((tbl_ppm_ED_Encounter_preclean.Age)>105 Or (tbl_ppm_ED_Encounter_preclean.Age) Is Null));
    tbl_ppm_ED_Encounter_preclean["Age"] = np.where(
        tbl_ppm_ED_Encounter_preclean["Age"] == "",
        0,
        tbl_ppm_ED_Encounter_preclean["Age"],
    )
    # df_query1 = pd.merge(tbl_ppm_ED_Encounter_preclean[(tbl_ppm_ED_Encounter_preclean['Age'].astype(float) > 105) | (tbl_ppm_ED_Encounter_preclean['Age'].isnull()) | (tbl_ppm_ED_Encounter_preclean['Age']=='')][['EncounterNumber', 'Age', 'PatientNumber', 'person_area_uid', 'Extra:UDG', 'Hospital', 'Stu']], ed_NWAU[['facility_identifier', 'ed_visit_identifier', 'AECC']], how='left', left_on=['Hospital', 'Stu'], right_on=['facility_identifier', 'ed_visit_identifier'], suffixes=('', '_drop'))
    df_query1 = pd.merge(
        tbl_ppm_ED_Encounter_preclean[
            (tbl_ppm_ED_Encounter_preclean["Age"].astype(float) > 105)
            | (tbl_ppm_ED_Encounter_preclean["Age"].isnull())
            | (tbl_ppm_ED_Encounter_preclean["Age"] == "")
        ][
            [
                "EncounterNumber",
                "Age",
                "PatientNumber",
                "person_area_uid",
                "Hospital",
                "Stu",
            ]
        ],
        ed_NWAU[["facility_identifier", "ed_visit_identifier", "AECC"]],
        how="left",
        left_on=["Hospital", "Stu"],
        right_on=["facility_identifier", "ed_visit_identifier"],
        suffixes=("", "_drop"),
    )
    df_query1 = df_query1.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    df_query1["AECC"] = df_query1["AECC"].astype(str)
    qualityChecks_EdAgeMoreThan105 = pd.merge(
        class_Descriptions,
        df_query1,
        how="right",
        left_on=["Code"],
        right_on=["AECC"],
        suffixes=("", "_drop"),
    )
    qualityChecks_EdAgeMoreThan105 = qualityChecks_EdAgeMoreThan105.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    qualityChecks_EdAgeMoreThan105 = qualityChecks_EdAgeMoreThan105[
        (qualityChecks_EdAgeMoreThan105["Age"].astype(float) > 105)
        | (qualityChecks_EdAgeMoreThan105["Age"].isnull())
        | (qualityChecks_EdAgeMoreThan105["Age"] == "")
    ]
    if len(qualityChecks_EdAgeMoreThan105) > 0:
        # qualityChecks_EdAgeMoreThan105 = qualityChecks_EdAgeMoreThan105[['EncounterNumber', 'Age', 'PatientNumber', 'person_area_uid',  'Extra:UDG', 'AECC', 'Description']]
        qualityChecks_EdAgeMoreThan105 = qualityChecks_EdAgeMoreThan105[
            [
                "EncounterNumber",
                "Age",
                "PatientNumber",
                "person_area_uid",
                "AECC",
                "Description",
            ]
        ]
    else:
        # qualityChecks_EdAgeMoreThan105 = pd.DataFrame(columns=['EncounterNumber',   'Age', 'PatientNumber', 'person_area_uid',  'Extra:UDG', 'AECC', 'Description'])
        qualityChecks_EdAgeMoreThan105 = pd.DataFrame(
            columns=[
                "EncounterNumber",
                "Age",
                "PatientNumber",
                "person_area_uid",
                "AECC",
                "Description",
            ]
        )
    qualityChecks_EdAgeMoreThan105 = qualityChecks_EdAgeMoreThan105.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    qualityChecks_EdAgeMoreThan105 = qualityChecks_EdAgeMoreThan105.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    qualityChecks_EdAgeMoreThan105 = qualityChecks_EdAgeMoreThan105.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    qualityChecks_EdAgeMoreThan105["Description"] = (
        qualityChecks_EdAgeMoreThan105["Description"].astype(str).str.replace("nan", "")
    )
    # dropping duplicate values
    qualityChecks_EdAgeMoreThan105.drop_duplicates(keep="last", inplace=True)
    qualityChecks_EdAgeMoreThan105["Age"] = qualityChecks_EdAgeMoreThan105[
        "Age"
    ].astype(int, errors="ignore")
    qualityChecks_EdAgeMoreThan105.to_csv(
        "./Output/QualityChecks_EdAgeMoreThan105.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    logging.info(
        "qualityChecks_EdAgeMoreThan105=%s", len(qualityChecks_EdAgeMoreThan105)
    )
    # fn_display_data_in_window('QC', 'qualityChecks_EdAgeMoreThan105')
    #########Ranjit: 19 Aug
    cleanup_memory(tbl_dbo_episode_ats)
    cleanup_memory(tbl_dbo_stay)
    cleanup_memory(tbl_dbo_episode_srg)
    cleanup_memory(tbl_dbo_episode_DRG)
    cleanup_memory(tbl_dbo_days_episode)
    cleanup_memory(tbl_ppm_ED_Encounter_preclean)
    cleanup_memory(ed_NWAU)
    cleanup_memory(class_Descriptions)
    cleanup_memory(tbl_Patient_Contact_Details)
    cleanup_memory(snapApp_CostingExtract)
    cleanup_memory(qualityChecks_Wip3)
    cleanup_memory(qualityChecks_LosGrt100)
    cleanup_memory(qualityChecks_GerAgeLess50)
    cleanup_memory(qry_time_in_ed)
    cleanup_memory(df_query1)
    cleanup_memory(df_query2)
    cleanup_memory(df_query3)
    cleanup_memory(df_query4)
    cleanup_memory(qualityChecks_LosLessThan20)
    cleanup_memory(qualityChecks_AgeAbove105)
    cleanup_memory(qualityChecks_L61zLess2Hours)
    cleanup_memory(qualityChecks_IcuHoursGt1000)
    cleanup_memory(qualityChecks_EdGt2880)
    cleanup_memory(qualityChecks_EdGt2880AdmittedTransfer)
    cleanup_memory(qualityChecks_EdLessThan5Min)
    cleanup_memory(qualityChecks_EdAgeMoreThan105)
    #########
    logging.info("run_quality_checks() - completed - preparing data for QC")


def show_qc_window():
    qc_window = Tk()
    # Set the size of the tkinter window
    qc_window.title("Quality Checks")
    qc_window.geometry("%dx%d+%d+%d" % (1000, 700, center_x1, center_y1))
    qc_window.configure(bg="white")
    # define QC buttons
    button_qc_wip = Button(
        qc_window,
        text="1. Work in Progress Encounters Admitted prior and discharged after costing period",
        fg="black",
        font=("Times New Roman", 10),
        command=lambda: display_quality_checks("wip"),
    )
    button_qc_wip.place(relx=0.50, rely=0.08, anchor=CENTER)
    button_qc_ip_los = Button(
        qc_window,
        text="2. Inpatient Encounters Length of Stay > 100 days",
        fg="black",
        font=("Times New Roman", 10),
        command=lambda: display_quality_checks("ip_los"),
    )
    button_qc_ip_los.place(relx=0.50, rely=0.16, anchor=CENTER)
    button_qc_pg_le_50 = Button(
        qc_window,
        text="3. PsychoGeriatric or GEM Encounters Age <50",
        fg="black",
        font=("Times New Roman", 10),
        command=lambda: display_quality_checks("pg_le_50"),
    )
    button_qc_pg_le_50.place(relx=0.50, rely=0.24, anchor=CENTER)
    button_qc_ip_ed_transfer = Button(
        qc_window,
        text="4. Inpatient Encounters Length of Stay < 20 minutes excluding Mode of Sep 6 or 7 \nand transfers to other facilities and minutes in ED",
        fg="black",
        font=("Times New Roman", 10),
        command=lambda: display_quality_checks("ip_ed_transfer"),
    )
    button_qc_ip_ed_transfer.place(relx=0.50, rely=0.32, anchor=CENTER)
    button_qc_ip_age_null = Button(
        qc_window,
        text="5. Inpatient Encounters Age is null or > 105 Years",
        fg="black",
        font=("Times New Roman", 10),
        command=lambda: display_quality_checks("ip_age_null"),
    )
    button_qc_ip_age_null.place(relx=0.50, rely=0.40, anchor=CENTER)
    button_qc_ip_los_le_2h = Button(
        qc_window,
        text="6. Inpatient L61Z Encounters length of stay less than 2 hours",
        fg="black",
        font=("Times New Roman", 10),
        command=lambda: display_quality_checks("ip_los_le_2h"),
    )
    button_qc_ip_los_le_2h.place(relx=0.50, rely=0.48, anchor=CENTER)
    button_qc_ip_icu_ge_1000 = Button(
        qc_window,
        text="7. Inpatients with ICU hours greater than 1000",
        fg="black",
        font=("Times New Roman", 10),
        command=lambda: display_quality_checks("ip_icu_ge_1000"),
    )
    button_qc_ip_icu_ge_1000.place(relx=0.50, rely=0.56, anchor=CENTER)
    button_qc_ed_los_ge_2_ed_visit = Button(
        qc_window,
        text="8. Emergency Encounters Length of Stay > 2 days from ED Visit Table",
        fg="black",
        font=("Times New Roman", 10),
        command=lambda: display_quality_checks("ed_los_ge_2_ed_visit"),
    )
    button_qc_ed_los_ge_2_ed_visit.place(relx=0.50, rely=0.64, anchor=CENTER)
    button_qc_ed_los_ge_2_days_epi = Button(
        qc_window,
        text="9. Admitted Emergency Encounters Length of Stay > 2 days compared to Days Episode Table",
        fg="black",
        font=("Times New Roman", 10),
        command=lambda: display_quality_checks("ed_los_ge_2_days_epi"),
    )
    button_qc_ed_los_ge_2_days_epi.place(relx=0.50, rely=0.72, anchor=CENTER)
    button_qc_ed_los_le_5m = Button(
        qc_window,
        text="10. Emergency Encounters Length of Stay<5 Mins & WIP =4 \nexcl. Did Not Waits, Deaths and Transfers and admissions",
        fg="black",
        font=("Times New Roman", 10),
        command=lambda: display_quality_checks("ed_los_le_5m"),
    )
    button_qc_ed_los_le_5m.place(relx=0.50, rely=0.80, anchor=CENTER)
    button_qc_ed_age_null = Button(
        qc_window,
        text="11. Emergency Encounters Age is null or > 105 Years",
        fg="black",
        font=("Times New Roman", 10),
        command=lambda: display_quality_checks("ed_age_null"),
    )
    button_qc_ed_age_null.place(relx=0.50, rely=0.88, anchor=CENTER)
    button_qc_close = Button(
        qc_window,
        text="Close",
        fg="black",
        font=("Times New Roman", 10),
        command=lambda: qc_window.destroy(),
    )
    button_qc_close.place(relx=0.50, rely=0.96, anchor=CENTER)


def transform_mapping_tables():
    """
    BEFORE extraction:
    1. filter by area identifier - amo payment status, hith map, ed role delin, specialty portal, sub program role
    2.* for amo payment - i think this is the data from file in costing folder and query records.
    3.*  for specialty portal mapping - specialty portal should be a drop down. All the displayed rows had specialty portal as null. In transform window, this is not the data from file in the costing folder
    4. for critical hith - all records i saw are  the data from file in the costing folder. if values of nswrole_delineation and CICM Role delineation is null then show  them as 0.
    5. for edrole delin - all records i saw are  the data from file in the costing folder.
    6. for sub program roles -  all records i saw are  the data from file "pla role" in the costing folder.
    * - triangle orange icon
    =======================
    AFTER extraction:
    1. for amo payment - fetch details of all lhds present in the amo file present costing folder . Append to this, the details of the user provided lhd
    2. for specialty portal mapping - fetch details of all lhds present in the amo file present costing folder .  this is not the data from file in the costing folder
    3. for critical hith - only details of therecords in costing folder and for all lhds
    4. for edrole delin - only details of therecords in costing folder and for all lhds
    5. for sub program roles - only details of therecords in costing folder and for all lhds
    def transform_critical_care():
        # For any new wards with unit type ("12","15","16","25","26","33","34","37")  an critgroup is null sites must enter the critgroup
        # Table name:CriticalCaregroup
    def transform_EDRoleDelin():
        # Any Facility where the emergroledelin is null must have a valid emergroledelin (emergency role delineation)
        # Table name:Tbl_EDRoleDelin
        pass
    def transform_Specialtyportalmapping():
        # All Hospital Clinic combinations must have a valid specialtyportal entered as per the Specialtyportal table. If this is left blank this will cause a critical error in DNR module
        # Table name:Specialtyportalmapping
        pass
    def transform_SubProgramRole():
        # Each Encounter is assigned a subprogram in some cases the subprogram is assigned based on the ward roles please refer to subprogram mapping table in collab space.
        # This rule is primarily used to break down mental health encounters into different subprograms. The acute /sub acute wards have been entered by the ABM team and need to be reviewed
        # Table name:PLA Role Table
        pass
    def transform_amo_payment():
        # Opens the tbl_PPM_transfer_AMO so sites can enter the consultant status for any facility + specialty_unit_code that have a null consultant status
        # Table name:tbl_PPM_transfer_AMO
        pass
    """
    # Extra records in criticalcaregroup is from \temp_transform\query_criticalcaregroup
    # Extra records in criticalcaregroup is tbl_transfer amo is due to duplicate records in inform8
    logging.info(
        "Finalise transformation step - transform_mapping_tables() - to save the mapping tables in ./ExtractorDB to ./Output - STARTED."
    )
    global \
        lhd_global, \
        facilities_excluded_list_global, \
        facilities_included_list_global, \
        roundid, \
        start_date, \
        end_date, \
        nwau_v, \
        icd10_v, \
        drg1_v, \
        drg2_v, \
        drg4_v, \
        snap_v, \
        amhcc_v, \
        cost_weight_v, \
        srg_drg_v
    #########button color change ##############################################
    """
    file_PpmTransferAmo = "./ExtractorDB/Tbl_PPM_transfer_AMO.csv"
    if os.path.isfile(file_PpmTransferAmo):
        try:
            df_file_PpmTransferAmo = read_csv_file(file_PpmTransferAmo, encoding = 'unicode_escape', dtype=str, keep_default_na=False, na_values='')
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror("File Error","Error extracting Tbl_PPM_transfer_AMO.\n"+str(e))
        else:
            if df_file_PpmTransferAmo.Consultant_Status.isnull().sum() > 0 or df_file_PpmTransferAmo.Consultant_Status.isna().sum() > 0 or \
            len(df_file_PpmTransferAmo[df_file_PpmTransferAmo['Consultant_Status'] == '']) > 0:
                button_amo_payment.config(bg='yellow')
            else:
                button_amo_payment.config(bg='#f0f0f0')            
    file_SpecialtyPortalMapping = "./ExtractorDB/SpecialityPortalMapping.csv"
    if os.path.isfile(file_SpecialtyPortalMapping):
        try:
            df_file_SpecialtyPortalMapping = read_csv_file(file_SpecialtyPortalMapping, encoding = 'unicode_escape', dtype=str, keep_default_na=False, na_values='')
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror("File Error","Error extracting SpecialtyPortalMapping.\n"+str(e))
        else:
            if df_file_SpecialtyPortalMapping.SpecialityPortal.isnull().sum() > 0 or df_file_SpecialtyPortalMapping.SpecialityPortal.isna().sum() > 0 or \
            len(df_file_SpecialtyPortalMapping[df_file_SpecialtyPortalMapping['SpecialityPortal'] == '']) > 0:
                button_Specialtyportalmapping.config(bg='yellow')
            else:
                button_Specialtyportalmapping.config(bg='#f0f0f0') 
    """
    #####################################################################
    # If the entire dump of mapping tables irrespective of LHDs have to be exported to output folder, then instead of the present logic, use the logic in the following access queries.
    # Access query: mappingcriticalcaregroup
    # SELECT Sum((IIf([CriticalCareGroup]![CritGroup] Is Null,1,0))) AS Unmapped, 1 AS Test FROM tbl_dbo_Facility INNER JOIN CriticalCareGroup ON tbl_dbo_Facility.facility_identifier = CriticalCareGroup.facility_identifier WHERE (((CriticalCareGroup.facility_identifier)=[tbl_dbo_Facility]![facility_identifier])) GROUP BY 1;
    """
    unmapped1 = DLookup("Unmapped", "mappingcriticalcaregroup", "Test=1")
    If unmapped1 > 0 Then
        MsgBox "The mapping table criticalcaregroup has unmapped values please update"
    End
    """
    # Access query:MappingEmergRoleDelin
    # SELECT Sum((IIf([EmergRoleDelin] Is Null,1,0))) AS Unmapped, 2 AS Test FROM [refTable:Parameters] INNER JOIN tbl_EDRoleDelin ON [refTable:Parameters].value = tbl_EDRoleDelin.area_identifier WHERE ((([refTable:Parameters].code)=9)) GROUP BY 2, tbl_EDRoleDelin.area_identifier;
    """
    unmapped2 = DLookup("Unmapped", "MappingEmergRoleDelin", "Test=2")
    If unmapped2 > 0 Then
        MsgBox "The mapping table EmergRoleDelin has unmapped values please update"
    End
    """
    # Access query:MappingSpecialityPortalMapping
    # SELECT Sum((IIf([SpecialityPortal] Is Null,1,0))) AS UnMapped, 3 AS Test FROM SpecialityPortalMapping INNER JOIN [refTable:Parameters] ON SpecialityPortalMapping.area_identifier = [refTable:Parameters].value WHERE ((([refTable:Parameters].code)=9)) GROUP BY 3;
    """
    unmapped3 = DLookup("Unmapped", "MappingSpecialityPortalMapping", "test=3")
    If unmapped3 > 0 Then
        MsgBox "The mapping table SpecialityPortalMapping has unmapped values please update"
    End
    """
    # Access query:mappingtbl_PPM_transfer_AMO
    # SELECT Sum(((IIf([Consultant_Status] Is Null,1,0)))) AS Unmapped, 4 AS Test FROM tbl_PPM_transfer_AMO INNER JOIN [refTable:Parameters] ON tbl_PPM_transfer_AMO.LHD = [refTable:Parameters].value WHERE ((([refTable:Parameters].code)=9)) GROUP BY 4;
    """
    unmapped4 = DLookup("Unmapped", "mappingtbl_PPM_transfer_AMO", "test=4")
    If unmapped4 > 0 Then
        MsgBox "The mapping table tbl_PPM_transfer_AMO has unmapped values please update"
    End
    """
    """
    Tbl_PPM_transfer_AMO
    """
    label_Tbl_PPM_transfer_AMO_status = 1
    file_PpmTransferAmo = "./ExtractorDB/Tbl_PPM_transfer_AMO.csv"
    if os.path.isfile(file_PpmTransferAmo):
        try:
            df_file_PpmTransferAmo = read_csv_file(
                file_PpmTransferAmo,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error", "Error extracting Tbl_PPM_transfer_AMO.\n" + str(e)
            )
        else:
            # 31 Oct - https://abft101.atlassian.net/browse/AQA-267
            df_file_PpmTransferAmo.columns = [
                "facility_identifier",
                "mo_code",
                "Code",
                "clinician_name",
                "Consultant_Status",
                "LHD",
                "HLTH_ORG_OSP_OSP_ID",
                "MG_AUTH_OSP_OSP_ID",
                "SE_CBK_SK",
                "DIM_RSP_ISP_SK",
            ]
            if (
                df_file_PpmTransferAmo.Consultant_Status.isnull().sum() > 0
                or df_file_PpmTransferAmo.Consultant_Status.isna().sum() > 0
                or len(
                    df_file_PpmTransferAmo[
                        df_file_PpmTransferAmo["Consultant_Status"] == ""
                    ]
                )
                > 0
            ):
                logging.info(
                    "There are records in Tbl_PPM_transfer_AMO with no Consultant_Status."
                )
                if messagebox.askyesno(
                    "Tbl_PPM_transfer_AMO",
                    "There are records in Tbl_PPM_transfer_AMO with no Consultant_Status.\nAre you sure you want to continue?",
                ):
                    df_file_PpmTransferAmo = df_file_PpmTransferAmo.applymap(
                        str
                    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
                    df_file_PpmTransferAmo = df_file_PpmTransferAmo.applymap(
                        lambda x: x.strip() if isinstance(x, str) else x
                    )
                    df_file_PpmTransferAmo = df_file_PpmTransferAmo.apply(
                        lambda x: x.replace(regex=r"^NaT$", value="")
                        if x.dtype == "object"
                        else x
                    )
                    df_file_PpmTransferAmo = df_file_PpmTransferAmo.apply(
                        lambda x: x.replace(regex=r"^nan$", value="")
                        if x.dtype == "object"
                        else x
                    )
                    logging.info(
                        "User has selected the option to save ./Output/Tbl_PPM_transfer_AMO.csv even though there are records in Tbl_PPM_transfer_AMO with no Consultant_Status."
                    )
                    df_file_PpmTransferAmo.to_csv(
                        "./Output/Tbl_PPM_transfer_AMO.csv",
                        index=False,
                        na_rep="",
                        float_format=str,
                        decimal=str,
                        date_format=str,
                    )
                    try:
                        # os.rename('./Costing/Tbl_PPM_transfer_AMO.csv', './Costing/Tbl_PPM_transfer_AMO_temp.csv')
                        dst = "./Costing/Tbl_PPM_transfer_AMO_%s.csv" % strftime(
                            "%Y_%m_%d", gmtime()
                        )
                        os.rename("./Costing/Tbl_PPM_transfer_AMO.csv", dst)
                    except FileExistsError:
                        # os.remove('./Costing/Tbl_PPM_transfer_AMO_temp.csv')
                        # os.rename('./Costing/Tbl_PPM_transfer_AMO.csv', './Costing/Tbl_PPM_transfer_AMO_temp.csv')
                        dst = "./Costing/Tbl_PPM_transfer_AMO_%s.csv" % strftime(
                            "%Y_%m_%d", gmtime()
                        )
                        os.remove(dst)
                        os.rename("./Costing/Tbl_PPM_transfer_AMO.csv", dst)
                    df_file_PpmTransferAmo.to_csv(
                        "./Costing/Tbl_PPM_transfer_AMO.csv",
                        index=False,
                        na_rep="",
                        float_format=str,
                        decimal=str,
                        date_format=str,
                    )
                else:
                    logging.info(
                        "User has selected the option NOT to save ./Output/Tbl_PPM_transfer_AMO.csv because there are records in Tbl_PPM_transfer_AMO with no Consultant_Status."
                    )
                    label_Tbl_PPM_transfer_AMO_status = 0
            else:
                # 31 Oct - https://abft101.atlassian.net/browse/AQA-267
                df_file_PpmTransferAmo.columns = [
                    "facility_identifier",
                    "mo_code",
                    "Code",
                    "clinician_name",
                    "Consultant_Status",
                    "LHD",
                    "HLTH_ORG_OSP_OSP_ID",
                    "MG_AUTH_OSP_OSP_ID",
                    "SE_CBK_SK",
                    "DIM_RSP_ISP_SK",
                ]
                df_file_PpmTransferAmo = df_file_PpmTransferAmo.applymap(
                    str
                )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
                df_file_PpmTransferAmo = df_file_PpmTransferAmo.applymap(
                    lambda x: x.strip() if isinstance(x, str) else x
                )
                df_file_PpmTransferAmo = df_file_PpmTransferAmo.apply(
                    lambda x: x.replace(regex=r"^NaT$", value="")
                    if x.dtype == "object"
                    else x
                )
                logging.info(
                    "User has selected the option to save ./Output/Tbl_PPM_transfer_AMO.csv because there are NO records in Tbl_PPM_transfer_AMO with no Consultant_Status."
                )
                df_file_PpmTransferAmo.to_csv(
                    "./Output/Tbl_PPM_transfer_AMO.csv",
                    index=False,
                    na_rep="",
                    float_format=str,
                    decimal=str,
                    date_format=str,
                )
                try:
                    # os.rename('./Costing/Tbl_PPM_transfer_AMO.csv', './Costing/Tbl_PPM_transfer_AMO_temp.csv')
                    dst = "./Costing/Tbl_PPM_transfer_AMO_%s.csv" % strftime(
                        "%Y_%m_%d", gmtime()
                    )
                    os.rename("./Costing/Tbl_PPM_transfer_AMO.csv", dst)
                except FileExistsError:
                    # os.remove('./Costing/Tbl_PPM_transfer_AMO_temp.csv')
                    # os.rename('./Costing/Tbl_PPM_transfer_AMO.csv', './Costing/Tbl_PPM_transfer_AMO_temp.csv')
                    dst = "./Costing/Tbl_PPM_transfer_AMO_%s.csv" % strftime(
                        "%Y_%m_%d", gmtime()
                    )
                    os.remove(dst)
                    os.rename("./Costing/Tbl_PPM_transfer_AMO.csv", dst)
                df_file_PpmTransferAmo.to_csv(
                    "./Costing/Tbl_PPM_transfer_AMO.csv",
                    index=False,
                    na_rep="",
                    float_format=str,
                    decimal=str,
                    date_format=str,
                )
    """
    SpecialtyPortalMapping
    """
    label_SpecialtyPortalMapping_status = 1
    file_SpecialtyPortalMapping = "./ExtractorDB/SpecialityPortalMapping.csv"
    if os.path.isfile(file_SpecialtyPortalMapping):
        try:
            df_file_SpecialtyPortalMapping = read_csv_file(
                file_SpecialtyPortalMapping,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error", "Error extracting SpecialtyPortalMapping.\n" + str(e)
            )
        else:
            # 31 Oct - https://abft101.atlassian.net/browse/AQA-267
            df_file_SpecialtyPortalMapping.columns = [
                "area_identifier",
                "Hospital",
                "Clinic",
                "SpecialityPortal",
            ]
            if (
                df_file_SpecialtyPortalMapping.SpecialityPortal.isnull().sum() > 0
                or df_file_SpecialtyPortalMapping.SpecialityPortal.isna().sum() > 0
                or len(
                    df_file_SpecialtyPortalMapping[
                        df_file_SpecialtyPortalMapping["SpecialityPortal"] == ""
                    ]
                )
                > 0
            ):
                logging.info(
                    "There are records in SpecialtyPortalMapping with no SpecialityPortal."
                )
                if messagebox.askyesno(
                    "SpecialtyPortalMapping",
                    "There are records in SpecialtyPortalMapping with no SpecialityPortal.\nAre you sure you want to continue?",
                ):
                    df_file_SpecialtyPortalMapping = df_file_SpecialtyPortalMapping.applymap(
                        str
                    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
                    df_file_SpecialtyPortalMapping = (
                        df_file_SpecialtyPortalMapping.applymap(
                            lambda x: x.strip() if isinstance(x, str) else x
                        )
                    )
                    df_file_SpecialtyPortalMapping = (
                        df_file_SpecialtyPortalMapping.apply(
                            lambda x: x.replace(regex=r"^NaT$", value="")
                            if x.dtype == "object"
                            else x
                        )
                    )
                    df_file_SpecialtyPortalMapping = (
                        df_file_SpecialtyPortalMapping.apply(
                            lambda x: x.replace(regex=r"^nan$", value="")
                            if x.dtype == "object"
                            else x
                        )
                    )
                    logging.info(
                        "User has selected the option to save ./Output/SpecialityPortalMapping.csv even though there are records in SpecialtyPortalMapping with no SpecialityPortal."
                    )
                    df_file_SpecialtyPortalMapping.to_csv(
                        "./Output/SpecialityPortalMapping.csv",
                        index=False,
                        na_rep="",
                        float_format=str,
                        decimal=str,
                        date_format=str,
                    )
                    try:
                        # os.rename('./Costing/SpecialityPortalMapping.csv', './Costing/SpecialityPortalMapping_temp.csv')
                        dst = "./Costing/SpecialityPortalMapping_%s.csv" % strftime(
                            "%Y_%m_%d", gmtime()
                        )
                        os.rename("./Costing/SpecialityPortalMapping.csv", dst)
                    except FileExistsError:
                        # os.remove('./Costing/SpecialityPortalMapping_temp.csv')
                        # os.rename('./Costing/SpecialityPortalMapping.csv', './Costing/SpecialityPortalMapping_temp.csv')
                        dst = "./Costing/SpecialityPortalMapping_%s.csv" % strftime(
                            "%Y_%m_%d", gmtime()
                        )
                        os.remove(dst)
                        os.rename("./Costing/SpecialityPortalMapping.csv", dst)
                    df_file_SpecialtyPortalMapping.to_csv(
                        "./Costing/SpecialityPortalMapping.csv",
                        index=False,
                        na_rep="",
                        float_format=str,
                        decimal=str,
                        date_format=str,
                    )
                else:
                    logging.info(
                        "User has selected the option NOT to save ./Output/SpecialityPortalMapping.csv because there are records in SpecialtyPortalMapping with no SpecialityPortal."
                    )
                    label_SpecialtyPortalMapping_status = 0
            else:
                # 31 Oct - https://abft101.atlassian.net/browse/AQA-267
                df_file_SpecialtyPortalMapping.columns = [
                    "area_identifier",
                    "Hospital",
                    "Clinic",
                    "SpecialityPortal",
                ]
                df_file_SpecialtyPortalMapping = df_file_SpecialtyPortalMapping.applymap(
                    str
                )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
                df_file_SpecialtyPortalMapping = (
                    df_file_SpecialtyPortalMapping.applymap(
                        lambda x: x.strip() if isinstance(x, str) else x
                    )
                )
                df_file_SpecialtyPortalMapping = df_file_SpecialtyPortalMapping.apply(
                    lambda x: x.replace(regex=r"^NaT$", value="")
                    if x.dtype == "object"
                    else x
                )
                df_file_SpecialtyPortalMapping = df_file_SpecialtyPortalMapping.apply(
                    lambda x: x.replace(regex=r"^nan$", value="")
                    if x.dtype == "object"
                    else x
                )
                logging.info(
                    "User has selected the option to save ./Output/SpecialityPortalMapping.csv because there are NO records in SpecialtyPortalMapping with no SpecialityPortal."
                )
                df_file_SpecialtyPortalMapping.to_csv(
                    "./Output/SpecialityPortalMapping.csv",
                    index=False,
                    na_rep="",
                    float_format=str,
                    decimal=str,
                    date_format=str,
                )
                try:
                    # os.rename('./Costing/SpecialityPortalMapping.csv', './Costing/SpecialityPortalMapping_temp.csv')
                    dst = "./Costing/SpecialityPortalMapping_%s.csv" % strftime(
                        "%Y_%m_%d", gmtime()
                    )
                    os.rename("./Costing/SpecialityPortalMapping.csv", dst)
                except FileExistsError:
                    # os.remove('./Costing/SpecialityPortalMapping_temp.csv')
                    # os.rename('./Costing/SpecialityPortalMapping.csv', './Costing/SpecialityPortalMapping_temp.csv')
                    dst = "./Costing/SpecialityPortalMapping_%s.csv" % strftime(
                        "%Y_%m_%d", gmtime()
                    )
                    os.remove(dst)
                    os.rename("./Costing/SpecialityPortalMapping.csv", dst)
                df_file_SpecialtyPortalMapping.to_csv(
                    "./Costing/SpecialityPortalMapping.csv",
                    index=False,
                    na_rep="",
                    float_format=str,
                    decimal=str,
                    date_format=str,
                )
    """
    criticalcaregroup
    """
    label_CriticalCareGroup = 1
    file_CriticalCareGroup = "./ExtractorDB/CriticalCareGroup.csv"
    if os.path.isfile(file_CriticalCareGroup):
        try:
            df_file_CriticalCareGroup = read_csv_file(
                file_CriticalCareGroup,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error", "Error extracting CriticalCareGroup.\n" + str(e)
            )
        else:
            # 31 Oct - https://abft101.atlassian.net/browse/AQA-267
            df_file_CriticalCareGroup.columns = [
                "facility_identifier",
                "ward_identifier",
                "ward_name",
                "unit_type",
                "NSW_Role_Delineation",
                "College_Intensive_Care_Medicine_Role_Delineation",
                "CritGroup",
                "area_identifier",
                "PPMWardUnit",
            ]
            if (
                df_file_CriticalCareGroup.CritGroup.isnull().sum() > 0
                or df_file_CriticalCareGroup.NSW_Role_Delineation.isnull().sum() > 0
                or df_file_CriticalCareGroup.College_Intensive_Care_Medicine_Role_Delineation.isnull().sum()
                > 0
                or df_file_CriticalCareGroup.CritGroup.isna().sum() > 0
                or df_file_CriticalCareGroup.NSW_Role_Delineation.isna().sum() > 0
                or df_file_CriticalCareGroup.College_Intensive_Care_Medicine_Role_Delineation.isna().sum()
                > 0
                or len(
                    df_file_CriticalCareGroup[
                        df_file_CriticalCareGroup["CritGroup"] == ""
                    ]
                )
                > 0
                or len(
                    df_file_CriticalCareGroup[
                        df_file_CriticalCareGroup["NSW_Role_Delineation"] == ""
                    ]
                )
                > 0
                or len(
                    df_file_CriticalCareGroup[
                        df_file_CriticalCareGroup[
                            "College_Intensive_Care_Medicine_Role_Delineation"
                        ]
                        == ""
                    ]
                )
                > 0
            ):
                logging.info(
                    "There are records in CriticalCareGroup with no CritGroup OR NSW_Role_Delineation OR College_Intensive_Care_Medicine_Role_Delineation."
                )
                if messagebox.askyesno(
                    "CriticalCareGroup",
                    "There are records in CriticalCareGroup with no CritGroup or NSW_Role_Delineation or College_Intensive_Care_Medicine_Role_Delineation.\nAre you sure you want to continue?",
                ):
                    df_file_CriticalCareGroup = df_file_CriticalCareGroup.applymap(
                        str
                    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
                    df_file_CriticalCareGroup = df_file_CriticalCareGroup.applymap(
                        lambda x: x.strip() if isinstance(x, str) else x
                    )
                    df_file_CriticalCareGroup = df_file_CriticalCareGroup.apply(
                        lambda x: x.replace(regex=r"^NaT$", value="")
                        if x.dtype == "object"
                        else x
                    )
                    df_file_CriticalCareGroup = df_file_CriticalCareGroup.apply(
                        lambda x: x.replace(regex=r"^nan$", value="")
                        if x.dtype == "object"
                        else x
                    )
                    logging.info(
                        "User has selected the option to save ./Output/CriticalCareGroup.csv even though there are records in CriticalCareGroup with no CritGroup OR NSW_Role_Delineation OR College_Intensive_Care_Medicine_Role_Delineation."
                    )
                    df_file_CriticalCareGroup["unit_type"] = df_file_CriticalCareGroup[
                        "unit_type"
                    ].astype(str)
                    df_file_CriticalCareGroup["NSW_Role_Delineation"] = np.where(
                        (df_file_CriticalCareGroup["NSW_Role_Delineation"].isnull())
                        | (df_file_CriticalCareGroup["NSW_Role_Delineation"] == ""),
                        "0",
                        df_file_CriticalCareGroup["NSW_Role_Delineation"],
                    )
                    df_file_CriticalCareGroup[
                        "College_Intensive_Care_Medicine_Role_Delineation"
                    ] = np.where(
                        (
                            df_file_CriticalCareGroup[
                                "College_Intensive_Care_Medicine_Role_Delineation"
                            ].isnull()
                        )
                        | (
                            df_file_CriticalCareGroup[
                                "College_Intensive_Care_Medicine_Role_Delineation"
                            ]
                            == ""
                        ),
                        "0",
                        df_file_CriticalCareGroup[
                            "College_Intensive_Care_Medicine_Role_Delineation"
                        ],
                    )
                    df_file_CriticalCareGroup = df_file_CriticalCareGroup[
                        [
                            "facility_identifier",
                            "ward_identifier",
                            "ward_name",
                            "unit_type",
                            "NSW_Role_Delineation",
                            "College_Intensive_Care_Medicine_Role_Delineation",
                            "CritGroup",
                            "area_identifier",
                            "PPMWardUnit",
                        ]
                    ]
                    df_file_CriticalCareGroup.to_csv(
                        "./Output/CriticalCareGroup.csv",
                        index=False,
                        na_rep="",
                        float_format=str,
                        decimal=str,
                        date_format=str,
                    )
                    try:
                        # os.rename('./Costing/CriticalCareGroup.csv', './Costing/CriticalCareGroup_temp.csv')
                        dst = "./Costing/CriticalCareGroup_%s.csv" % strftime(
                            "%Y_%m_%d", gmtime()
                        )
                        os.rename("./Costing/CriticalCareGroup.csv", dst)
                    except FileExistsError:
                        # os.remove('./Costing/CriticalCareGroup_temp.csv')
                        # os.rename('./Costing/CriticalCareGroup.csv', './Costing/CriticalCareGroup_temp.csv')
                        dst = "./Costing/CriticalCareGroup_%s.csv" % strftime(
                            "%Y_%m_%d", gmtime()
                        )
                        os.remove(dst)
                        os.rename("./Costing/CriticalCareGroup.csv", dst)
                    df_file_CriticalCareGroup.to_csv(
                        "./Costing/CriticalCareGroup.csv",
                        index=False,
                        na_rep="",
                        float_format=str,
                        decimal=str,
                        date_format=str,
                    )
                else:
                    logging.info(
                        "User has selected the option NOT to save ./Output/CriticalCareGroup.csv because there are records in CriticalCareGroup with no CritGroup OR NSW_Role_Delineation OR College_Intensive_Care_Medicine_Role_Delineation."
                    )
                    label_CriticalCareGroup = 0
            else:
                # 31 Oct - https://abft101.atlassian.net/browse/AQA-267
                df_file_CriticalCareGroup.columns = [
                    "facility_identifier",
                    "ward_identifier",
                    "ward_name",
                    "unit_type",
                    "NSW_Role_Delineation",
                    "College_Intensive_Care_Medicine_Role_Delineation",
                    "CritGroup",
                    "area_identifier",
                    "PPMWardUnit",
                ]
                df_file_CriticalCareGroup = df_file_CriticalCareGroup.applymap(
                    str
                )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
                df_file_CriticalCareGroup = df_file_CriticalCareGroup.applymap(
                    lambda x: x.strip() if isinstance(x, str) else x
                )
                df_file_CriticalCareGroup = df_file_CriticalCareGroup.apply(
                    lambda x: x.replace(regex=r"^NaT$", value="")
                    if x.dtype == "object"
                    else x
                )
                df_file_CriticalCareGroup = df_file_CriticalCareGroup.apply(
                    lambda x: x.replace(regex=r"^nan$", value="")
                    if x.dtype == "object"
                    else x
                )
                logging.info(
                    "User has selected the option to save ./Output/CriticalCareGroup.csv because there are NO records in CriticalCareGroup with no Consultant_Status."
                )
                df_file_CriticalCareGroup["NSW_Role_Delineation"] = np.where(
                    (df_file_CriticalCareGroup["NSW_Role_Delineation"].isnull())
                    | (df_file_CriticalCareGroup["NSW_Role_Delineation"] == ""),
                    "0",
                    df_file_CriticalCareGroup["NSW_Role_Delineation"],
                )
                df_file_CriticalCareGroup[
                    "College_Intensive_Care_Medicine_Role_Delineation"
                ] = np.where(
                    (
                        df_file_CriticalCareGroup[
                            "College_Intensive_Care_Medicine_Role_Delineation"
                        ].isnull()
                    )
                    | (
                        df_file_CriticalCareGroup[
                            "College_Intensive_Care_Medicine_Role_Delineation"
                        ]
                        == ""
                    ),
                    "0",
                    df_file_CriticalCareGroup[
                        "College_Intensive_Care_Medicine_Role_Delineation"
                    ],
                )
                df_file_CriticalCareGroup = df_file_CriticalCareGroup[
                    [
                        "facility_identifier",
                        "ward_identifier",
                        "ward_name",
                        "unit_type",
                        "NSW_Role_Delineation",
                        "College_Intensive_Care_Medicine_Role_Delineation",
                        "CritGroup",
                        "area_identifier",
                        "PPMWardUnit",
                    ]
                ]
                df_file_CriticalCareGroup.to_csv(
                    "./Output/CriticalCareGroup.csv",
                    index=False,
                    na_rep="",
                    float_format=str,
                    decimal=str,
                    date_format=str,
                )
                try:
                    # os.rename('./Costing/CriticalCareGroup.csv', './Costing/CriticalCareGroup_temp.csv')
                    dst = "./Costing/CriticalCareGroup_%s.csv" % strftime(
                        "%Y_%m_%d", gmtime()
                    )
                    os.rename("./Costing/CriticalCareGroup.csv", dst)
                except FileExistsError:
                    # os.remove('./Costing/CriticalCareGroup_temp.csv')
                    # os.rename('./Costing/CriticalCareGroup.csv', './Costing/CriticalCareGroup_temp.csv')
                    dst = "./Costing/CriticalCareGroup_%s.csv" % strftime(
                        "%Y_%m_%d", gmtime()
                    )
                    os.remove(dst)
                    os.rename("./Costing/CriticalCareGroup.csv", dst)
                df_file_CriticalCareGroup.to_csv(
                    "./Costing/CriticalCareGroup.csv",
                    index=False,
                    na_rep="",
                    float_format=str,
                    decimal=str,
                    date_format=str,
                )
    """
    EDRoleDelin
    """
    label_EdRoleDelin = 1
    file_EdRoleDelin = "./ExtractorDB/EDRoleDelin.csv"
    if os.path.isfile(file_EdRoleDelin):
        try:
            df_file_EdRoleDelin = read_csv_file(
                file_EdRoleDelin,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error", "Error extracting EDRoleDelin.\n" + str(e)
            )
        else:
            # 31 Oct - https://abft101.atlassian.net/browse/AQA-267
            df_file_EdRoleDelin.columns = [
                "facility_identifier",
                "facility_name",
                "EmergRoleDelin",
                "area_identifier",
            ]
            if (
                df_file_EdRoleDelin.EmergRoleDelin.isnull().sum() > 0
                or df_file_EdRoleDelin.EmergRoleDelin.isna().sum() > 0
                or len(df_file_EdRoleDelin[df_file_EdRoleDelin["EmergRoleDelin"] == ""])
                > 0
            ):
                if messagebox.askyesno(
                    "EDRoleDelin",
                    "There are records in EDRoleDelin with no EmergRoleDelin.\nAre you sure you want to continue?",
                ):
                    df_file_EdRoleDelin = df_file_EdRoleDelin.applymap(
                        str
                    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
                    df_file_EdRoleDelin = df_file_EdRoleDelin.applymap(
                        lambda x: x.strip() if isinstance(x, str) else x
                    )
                    df_file_EdRoleDelin = df_file_EdRoleDelin.apply(
                        lambda x: x.replace(regex=r"^NaT$", value="")
                        if x.dtype == "object"
                        else x
                    )
                    df_file_EdRoleDelin = df_file_EdRoleDelin.apply(
                        lambda x: x.replace(regex=r"^nan$", value="")
                        if x.dtype == "object"
                        else x
                    )
                    logging.info(
                        "User has selected the option to save ./Output/EDRoleDelin.csv even though there are records in EDRoleDelin with no EmergRoleDelin."
                    )
                    df_file_EdRoleDelin = df_file_EdRoleDelin[
                        [
                            "facility_identifier",
                            "facility_name",
                            "EmergRoleDelin",
                            "area_identifier",
                        ]
                    ]
                    df_file_EdRoleDelin.to_csv(
                        "./Output/EDRoleDelin.csv",
                        index=False,
                        na_rep="",
                        float_format=str,
                        decimal=str,
                        date_format=str,
                    )
                    try:
                        # os.rename('./Costing/EDRoleDelin.csv', './Costing/EDRoleDelin_temp.csv')
                        dst = "./Costing/EDRoleDelin_%s.csv" % strftime(
                            "%Y_%m_%d", gmtime()
                        )
                        os.rename("./Costing/EDRoleDelin.csv", dst)
                    except FileExistsError:
                        # os.remove('./Costing/EDRoleDelin_temp.csv')
                        # os.rename('./Costing/EDRoleDelin.csv', './Costing/EDRoleDelin_temp.csv')
                        dst = "./Costing/EDRoleDelin_%s.csv" % strftime(
                            "%Y_%m_%d", gmtime()
                        )
                        os.remove(dst)
                        os.rename("./Costing/EDRoleDelin.csv", dst)
                    df_file_EdRoleDelin.to_csv(
                        "./Costing/EDRoleDelin.csv",
                        index=False,
                        na_rep="",
                        float_format=str,
                        decimal=str,
                        date_format=str,
                    )
                else:
                    logging.info(
                        "User has selected the option NOT to save ./Output/EDRoleDelin.csv because there are records in EDRoleDelin with no EmergRoleDelin."
                    )
                    label_EdRoleDelin = 0
            else:
                # 31 Oct - https://abft101.atlassian.net/browse/AQA-267
                df_file_EdRoleDelin.columns = [
                    "facility_identifier",
                    "facility_name",
                    "EmergRoleDelin",
                    "area_identifier",
                ]
                df_file_EdRoleDelin = df_file_EdRoleDelin.applymap(
                    str
                )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
                df_file_EdRoleDelin = df_file_EdRoleDelin.applymap(
                    lambda x: x.strip() if isinstance(x, str) else x
                )
                df_file_EdRoleDelin = df_file_EdRoleDelin.apply(
                    lambda x: x.replace(regex=r"^NaT$", value="")
                    if x.dtype == "object"
                    else x
                )
                df_file_EdRoleDelin = df_file_EdRoleDelin.apply(
                    lambda x: x.replace(regex=r"^nan$", value="")
                    if x.dtype == "object"
                    else x
                )
                logging.info(
                    "User has selected the option to save ./Output/EDRoleDelin.csv because there are NO records in EDRoleDelin with no EmergRoleDelin."
                )
                df_file_EdRoleDelin = df_file_EdRoleDelin[
                    [
                        "facility_identifier",
                        "facility_name",
                        "EmergRoleDelin",
                        "area_identifier",
                    ]
                ]
                df_file_EdRoleDelin.to_csv(
                    "./Output/EDRoleDelin.csv",
                    index=False,
                    na_rep="",
                    float_format=str,
                    decimal=str,
                    date_format=str,
                )
                try:
                    # os.rename('./Costing/EDRoleDelin.csv', './Costing/EDRoleDelin_temp.csv')
                    dst = "./Costing/EDRoleDelin_%s.csv" % strftime(
                        "%Y_%m_%d", gmtime()
                    )
                    os.rename("./Costing/EDRoleDelin.csv", dst)
                except FileExistsError:
                    # os.remove('./Costing/EDRoleDelin_temp.csv')
                    # os.rename('./Costing/EDRoleDelin.csv', './Costing/EDRoleDelin_temp.csv')
                    dst = "./Costing/EDRoleDelin_%s.csv" % strftime(
                        "%Y_%m_%d", gmtime()
                    )
                    os.remove(dst)
                    os.rename("./Costing/EDRoleDelin.csv", dst)
                df_file_EdRoleDelin.to_csv(
                    "./Costing/EDRoleDelin.csv",
                    index=False,
                    na_rep="",
                    float_format=str,
                    decimal=str,
                    date_format=str,
                )
    """
    PLA_Role_Table
    """
    label_PLA_Role_Table = 1
    file_PLA_Role_Table = "./ExtractorDB/PLA_Role_Table.csv"
    if os.path.isfile(file_PLA_Role_Table):
        try:
            df_file_PLA_Role_Table = read_csv_file(
                file_PLA_Role_Table,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error", "Error extracting PLA_Role_Table.\n" + str(e)
            )
        else:
            """
            if df_file_PLA_Role_Table.Speciality.isnull().sum() > 0 or df_file_PLA_Role_Table.Speciality.isna().sum() > 0 or \
            len(df_file_PLA_Role_Table[df_file_PLA_Role_Table['Speciality'] == '']) > 0:
                if messagebox.askyesno("PLA_Role_Table", "There are records in PLA_Role_Table with no Speciality.\nAre you sure you want to continue?"):
                    df_file_PLA_Role_Table = df_file_PLA_Role_Table.applymap(str)#.apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
                    df_file_PLA_Role_Table = df_file_PLA_Role_Table.applymap(lambda x: x.strip() if isinstance(x, str) else x)
                    df_file_PLA_Role_Table = df_file_PLA_Role_Table.apply(lambda x: x.replace(regex=r'^NaT$', value='') if x.dtype == 'object' else x)
                    df_file_PLA_Role_Table = df_file_PLA_Role_Table.apply(lambda x: x.replace(regex=r'^nan$', value='') if x.dtype == 'object' else x)
                    logging.info('User has selected the option to save ./Output/PLA_Role_Table.csv even though there are records in PLA_Role_Table with no Speciality.')
                    df_file_PLA_Role_Table.to_csv('./Output/PLA_Role_Table.csv', index=False, na_rep='', float_format=str, decimal=str, date_format=str)
                    os.rename('./Costing/PLA_Role_Table.csv', './Costing/PLA_Role_Table_temp.csv')
                    df_file_PLA_Role_Table.to_csv('./Costing/PLA_Role_Table.csv', index=False, na_rep='', float_format=str, decimal=str, date_format=str)
                else:
                    logging.info('User has selected the option NOT to save ./Output/PLA_Role_Table.csv because there are records in PLA_Role_Table with no Speciality.')
                    label_PLA_Role_Table = 0
            else:
                df_file_PLA_Role_Table = df_file_PLA_Role_Table.applymap(str)#.apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
                df_file_PLA_Role_Table = df_file_PLA_Role_Table.applymap(lambda x: x.strip() if isinstance(x, str) else x)
                df_file_PLA_Role_Table = df_file_PLA_Role_Table.apply(lambda x: x.replace(regex=r'^NaT$', value='') if x.dtype == 'object' else x)
                df_file_PLA_Role_Table = df_file_PLA_Role_Table.apply(lambda x: x.replace(regex=r'^nan$', value='') if x.dtype == 'object' else x)
                logging.info('User has selected the option to save ./Output/PLA_Role_Table.csv because there are NO records in PLA_Role_Table with no Speciality.')
                df_file_PLA_Role_Table.to_csv('./Output/PLA_Role_Table.csv', index=False, na_rep='', float_format=str, decimal=str, date_format=str)
                os.rename('./Costing/PLA_Role_Table.csv', './Costing/PLA_Role_Table_temp.csv')
                df_file_PLA_Role_Table.to_csv('./Costing/PLA_Role_Table.csv', index=False, na_rep='', float_format=str, decimal=str, date_format=str)
            """
            # 31 Oct - https://abft101.atlassian.net/browse/AQA-267
            df_file_PLA_Role_Table.columns = [
                "Role",
                "RoleType",
                "HospID",
                "Ward",
                "Speciality",
                "LHD",
            ]
            df_file_PLA_Role_Table = df_file_PLA_Role_Table.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            df_file_PLA_Role_Table = df_file_PLA_Role_Table.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            df_file_PLA_Role_Table = df_file_PLA_Role_Table.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            df_file_PLA_Role_Table = df_file_PLA_Role_Table.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
            logging.info(
                "User has selected the option to save ./Output/PLA_Role_Table.csv because there are NO records in PLA_Role_Table with no Speciality."
            )
            df_file_PLA_Role_Table.to_csv(
                "./Output/PLA_Role_Table.csv",
                index=False,
                na_rep="",
                float_format=str,
                decimal=str,
                date_format=str,
            )
            try:
                # os.rename('./Costing/PLA_Role_Table.csv', './Costing/PLA_Role_Table_temp.csv')
                dst = "./Costing/PLA_Role_Table_%s.csv" % strftime("%Y_%m_%d", gmtime())
                os.rename("./Costing/PLA_Role_Table.csv", dst)
            except FileExistsError:
                # os.remove('./Costing/PLA_Role_Table_temp.csv')
                # os.rename('./Costing/PLA_Role_Table.csv', './Costing/PLA_Role_Table_temp.csv')
                dst = "./Costing/PLA_Role_Table_%s.csv" % strftime("%Y_%m_%d", gmtime())
                os.remove(dst)
                os.rename("./Costing/PLA_Role_Table.csv", dst)
            df_file_PLA_Role_Table.to_csv(
                "./Costing/PLA_Role_Table.csv",
                index=False,
                na_rep="",
                float_format=str,
                decimal=str,
                date_format=str,
            )
    logging.info(
        "Finalise transformation step - transform_mapping_tables() - to save the mapping tables in ./ExtractorDB to ./Output  - COMPLETED."
    )
    #########Ranjit: 19 Aug
    cleanup_memory(df_file_PpmTransferAmo)
    cleanup_memory(df_file_SpecialtyPortalMapping)
    cleanup_memory(df_file_CriticalCareGroup)
    cleanup_memory(df_file_EdRoleDelin)
    cleanup_memory(df_file_PLA_Role_Table)
    #########
    return (
        label_Tbl_PPM_transfer_AMO_status,
        label_SpecialtyPortalMapping_status,
        label_CriticalCareGroup,
        label_EdRoleDelin,
        label_PLA_Role_Table,
    )


def transform_complete():
    (
        label_Tbl_PPM_transfer_AMO_status,
        label_SpecialtyPortalMapping_status,
        label_CriticalCareGroup,
        label_EdRoleDelin,
        label_PLA_Role_Table,
    ) = transform_mapping_tables()
    if (
        label_Tbl_PPM_transfer_AMO_status
        and label_SpecialtyPortalMapping_status
        and label_CriticalCareGroup
        and label_EdRoleDelin
        and label_PLA_Role_Table
    ):
        logging.info(
            "User clicked Finalise transformations button. User reviewed all mapping tables and saved them to ./Output. User can now review reconciliation and quality reports prior to exporting data."
        )
        messagebox.showinfo(
            "Run Transformations",
            "Transformations completed.\nPreparing QC reports for your review, prior to exporting data. Please wait...",
            parent=main_screen,
        )
        # disable extract & transform buttons and enable export button
        button_extract["state"] = DISABLED
        button_transform["state"] = DISABLED
        button_critical_care.destroy()
        button_EDRoleDelin.destroy()
        button_Specialtyportalmapping.destroy()
        button_SubProgramRole.destroy()
        button_amo_payment.destroy()
        button_transform_complete.destroy()
        # Run QC checks
        run_quality_checks()
        # Run reconciliation
        # run_reconciliation()
        # make export button ACTIVE
        button_export["state"] = ACTIVE
        messagebox.showinfo(
            "QC Reports", "QC reports prepared for your review.", parent=main_screen
        )
        ## COMMENT THIS AS RECONCILIATION IS NOW IN EXPORT:
        """
        #button_reconciliation_ip=Button(left_frame, text="Reconciliation Report: Inpatient Data", fg='black', font=("Times New Roman", 10), command=lambda:display_reconciliation('ip'))  
        button_reconciliation_ip.place(relx=0.50, rely=0.80, anchor=CENTER) 
        #button_reconciliation_ed=Button(left_frame, text="Reconciliation Report: ED Data", fg='black', font=("Times New Roman", 10),  command=lambda:display_reconciliation('ed'))
        button_reconciliation_ed.place(relx=0.50, rely=0.88, anchor=CENTER)
        """
        # button_QCcheck=Button(left_frame, text="Quality Checks", fg='black', font=("Times New Roman", 10),  command=lambda:show_qc_window())
        # button_QCcheck.place(relx=0.50, rely=0.96, anchor=CENTER)
        button_QCcheck.place(relx=0.50, rely=0.80, anchor=CENTER)
        main_screen.update()
    else:
        logging.info(
            "User clicked Finalise transformations button. However, because the mapping tables has null values in the mandatory columns, the user has to review & update the mapping tables again to proceed further."
        )
        messagebox.showinfo(
            "Run Transformations",
            "Please update the mapping tables to proceed.",
            parent=main_screen,
        )


def save_present_run(
    lhd,
    facilities_excluded_list,
    facilities_included_list,
    roundid,
    start_date,
    end_date,
    nwau_v,
    icd10_v,
    drg1_v,
    drg2_v,
    drg4_v,
    snap_v,
    amhcc_v,
    cost_weight_v,
    srg_drg_v,
):
    start_date = str(start_date)
    end_date = str(end_date)
    # Ref: https://blog.gitnux.com/code/python-config-file/, https://stackoverflow.com/a/44321913
    config.set("previous_exractor_run", "prev_lhd", str(lhd))
    config.set(
        "previous_exractor_run",
        "prev_excluded_facilities",
        str(facilities_excluded_list),
    )
    config.set(
        "previous_exractor_run",
        "prev_included_facilities",
        str(facilities_included_list),
    )
    config.set("previous_exractor_run", "prev_roundid", str(roundid))
    config.set("previous_exractor_run", "prev_start_dt", start_date[:10])
    config.set("previous_exractor_run", "prev_end_dt", end_date[:10])
    config.set("previous_exractor_run", "prev_nwau", str(nwau_v))
    config.set("previous_exractor_run", "prev_icd10_v", str(icd10_v))
    config.set("previous_exractor_run", "prev_drg1_v", str(drg1_v))
    config.set("previous_exractor_run", "prev_drg2_v", str(drg2_v))
    config.set("previous_exractor_run", "prev_drg4_v", str(drg4_v))
    config.set("previous_exractor_run", "prev_snap_v", str(snap_v))
    config.set("previous_exractor_run", "prev_amhcc_v", str(amhcc_v))
    config.set("previous_exractor_run", "prev_cost_weight_v", str(cost_weight_v))
    config.set("previous_exractor_run", "prev_srg_drg_v", str(srg_drg_v))
    with open("config.ini", "w") as configfile:
        config.write(configfile)
        logging.info(
            "Extraction completed. The following details of the present run are saved in the config.ini file."
        )
        logging.info(
            "LHD=%s, EXCLUDED_FACILITIES=%s, INCLUDED_FACILITIES=%s, ROUND ID=%s,  START DATE=%s, END DATE=%s, NWAU=%s, ICD10=%s. drg1=%s, drg2=%s, drg4=%s, SNAP=%s, AMHCC=%s, COST WEIGHT=%s, SRG DRG=%s",
            str(lhd),
            str(facilities_excluded_list),
            str(facilities_included_list),
            str(roundid),
            str(start_date),
            str(end_date),
            str(nwau_v),
            str(icd10_v),
            str(drg1_v),
            str(drg2_v),
            str(drg4_v),
            str(snap_v),
            str(amhcc_v),
            str(cost_weight_v),
            str(srg_drg_v),
        )


def clear_entry_fields():
    roundid_field.configure(state="normal")
    roundid_field.delete(0, END)
    lhd_field.configure(state="normal")
    lhd_field.delete(0, END)
    start_date_field.configure(state="normal")
    start_date_field.delete(0, END)
    end_date_field.configure(state="normal")
    end_date_field.delete(0, END)
    nwau_v_field.configure(state="normal")
    nwau_v_field.delete(0, END)
    icd10_v_field.configure(state="normal")
    icd10_v_field.delete(0, END)
    drg1_v_field.configure(state="normal")
    drg1_v_field.delete(0, END)
    drg2_v_field.configure(state="normal")
    drg2_v_field.delete(0, END)
    drg4_v_field.configure(state="normal")
    drg4_v_field.delete(0, END)
    snap_v_field.configure(state="normal")
    snap_v_field.delete(0, END)
    amhcc_v_field.configure(state="normal")
    amhcc_v_field.delete(0, END)
    cost_weight_v_field.configure(state="normal")
    cost_weight_v_field.delete(0, END)
    srg_drg_v_field.configure(state="normal")
    srg_drg_v_field.delete(0, END)
    # clear config
    save_present_run("", "", "", "", "", "", "", "", "", "", "", "", "", "")
    # clear files already extracted in this failed run
    directory_path = "./temp_transform/"
    no_of_files = len(os.listdir(directory_path))
    if no_of_files > 0:
        clear_output_dir("./temp_transform")
    directory_path = "./ExtractorDB/"
    no_of_files = len(os.listdir(directory_path))
    if no_of_files > 0:
        clear_output_dir("./ExtractorDB")


def import_snap_amhcc_files(
    extract_type,
    lhd,
    facilities_excluded_list,
    facilities_included_list,
    roundid,
    start_date,
    end_date,
    nwau_v,
    icd10_v,
    drg1_v,
    drg2_v,
    drg4_v,
    snap_v,
    amhcc_v,
    cost_weight_v,
    srg_drg_v,
):
    logging.info("Extract snap and amhcc files started.")
    # commenting below global declaration as a variable cannot be declared global if it is already passed as a parameter in the function.
    # global end_date, start_date, roundid,  nwau_v, icd10_v, drg1_v, drg2_v, drg4_v, snap_v, amhcc_v, cost_weight_v, srg_drg_v
    """global tbl_dbo_Facility, tbl_dbo_stay, tbl_Patient_Contact_Details, tbl_dbo_episode_ats, tbl_dbo_Ward_Episode, tbl_dbo_episode, \
    tbl_dbo_episode_srg, tbl_dbo_episode_DRG, tbl_dbo_wl_exit, ed_nwau, acute_nwau, tbl_dbo_days_episode, \
    tbl_PPM_transfer_Leave_00, tbl_PPM_transfer_Leave02, tbl_PPM_ICD_diagnoses, tbl_PPM_ICD_procedures, tbl_ppm_ED_Patient, \
    tbl_ppm_ED_Encounter_preclean, df_ED_Diag_Slice, df_ExcludedEncounters, snapApp_CostingExtract, df_AMHCC_extract, \
    df_SNAPRec, snap_NWAU, df_EdRoleDelin, df_ICU_RoleDelin, df_SpecialtyPortalMapping, df_CriticalCareGroup, \
    df_PLA_Role_Table, df_PLA_Mapping_00, df_PLA_AMHCC, df_Class_Descriptions, df_SpecialtyPortalValues, df_MDC, \
    df_Excluded_EpisodeAts, tbl_Episode_ATS_end_date_update, df_Excluded_EpisodeAts_enddate_le_startdate, df_PpmTransferAmo, \
    tbl_PPM_transfer_Leave_00, tbl_PPM_transfer_Leave_02, df_ED_Diag_Slice, df_Excluded_ED_Encounters, tbl_PPM_Patient, \
    criticalcaregroup, specialtyPortalMapping, tbl_PPM_transfer_AMO, tbl_EDRoleDelin, pla_Role_Table, tbl_ExcludedEncounters"""
    global lhd_global, facilities_excluded_list_global, facilities_included_list_global
    lhd_global = lhd
    facilities_excluded_list_global = facilities_excluded_list
    facilities_included_list_global = facilities_included_list
    end_date = str(end_date)
    start_date = str(start_date)
    end_date = end_date[:10] + " " + "23:59:59"
    start_date = start_date[:10] + " " + "00:00:00"
    #########################
    file_tbl_ExcludedEncounters = "./ExtractorDB/OutputExcludedEncounters_part1.csv"
    if os.path.isfile(file_tbl_ExcludedEncounters):
        try:
            tbl_ExcludedEncounters = read_csv_file(
                file_tbl_ExcludedEncounters,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_ExcludedEncounters from ./ExtractorDB/OutputExcludedEncounters_part1.csv.\n"
                + str(e),
            )
            # label_map_1_status = 0
            return
        else:
            tbl_ExcludedEncounters = tbl_ExcludedEncounters.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_ExcludedEncounters = tbl_ExcludedEncounters.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_ExcludedEncounters = tbl_ExcludedEncounters.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_ExcludedEncounters = tbl_ExcludedEncounters.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
    ########################################### Import SNAP
    # Set default value of sub-task status to 1
    label_9_status = 1
    """
    SnapCostingExtract (SNAP_CostingExtract.xls) - given
        exclude snap encounters outside costing period
            save excluded encounters
            print how many snap encounters outside costing period excluded
        Cleaning SnapCostingExtract - Removed ? records
    """
    file_SNAP_CostingExtract = "./Costing/SNAP_CostingExtract.xlsx"
    if os.path.isfile(file_SNAP_CostingExtract):
        if extract_type == "new_extract":
            label_9_sub.configure(
                text="In Progress (SNAP_CostingExtract)...", fg="blue"
            )
        try:
            snapApp_CostingExtract = pd.read_excel(
                file_SNAP_CostingExtract, keep_default_na=False
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error", "Error extracting SNAP_CostingExtract.\n" + str(e)
            )
            label_9_status = 0
            snapApp_CostingExtract = pd.DataFrame()
        else:
            # 21 Jan 2025 - commented below and added new code for SNAP from EDW.
            """
            snapApp_CostingExtract['EpisodeStartDate_HIE'] = pd.to_datetime(snapApp_CostingExtract['EpisodeStartDate_HIE'], errors='coerce', format="%d/%m/%Y")
            snapApp_CostingExtract['EpisodeEndDate_HIE'] = pd.to_datetime(snapApp_CostingExtract['EpisodeEndDate_HIE'], errors='coerce', format="%d/%m/%Y")
            snapApp_CostingExtract['EncounterStart'] = pd.to_datetime(snapApp_CostingExtract['EncounterStart'], errors='coerce', format="%d/%m/%Y %H:%M:%S")
            snapApp_CostingExtract['EncounterEnd'] = pd.to_datetime(snapApp_CostingExtract['EncounterEnd'], errors='coerce', format="%d/%m/%Y %H:%M:%S")
            snapApp_CostingExtract['HIE extract Date'] = pd.to_datetime(snapApp_CostingExtract['HIE extract Date'], errors='coerce', format="%d/%m/%Y")
            snapApp_CostingExtract.columns = ['PCSNAP_PhaseID', 'pcPhase', 'PCPhaseStartDate', 'PCPhaseEndDate', 'FacilityCode', 'mrn', 'SNAPEpisodeID', 'SNAPCaseType', 'EpisodeStartDate_HIE', \
            'EpisodeEndDate_HIE', 'EpisodeStartTime_HIE', 'EpisodeEndTime_HIE', 'EpisType', 'TotalSuspensionDays', 'AssessmentOnly', 'PCSymptomScoreStart', 'PCSeverityStart', 'PCPsychSpiritualScoreStart', 'PCFamilyCarerScoreStart', 'MaintType', 'RehImpairmentCode', 'FIMEatingStart', 'FIMEatingEnd', 'FIMGroomingStart', 'FIMGroomingEnd', 'FIMBathingStart', 'FIMBathingEnd', 'FIMDressingUpperStart', 'FIMDressingUpperEnd', 'FIMDressingLowerStart', 'FIMDressingLowerEnd', 'FIMToiletingStart', 'FIMToiletingEnd', 'FIMBladderStart', 'FIMBladderEnd', 'FIMBowelStart', 'FIMBowelEnd', 'FIMXferBedChairWChairStart', 'FIMXferBedChairWChairEnd', 'FIMXferBathShowerStart', 'FIMXferBathShowerEnd', 'FIMXferToiletStart', 'FIMXferToiletEnd', 'FIMWalkWheelChairStart', 'FIMWalkWheelChairEnd', 'FIMStairsStart', 'FIMStairsEnd', 'FIMComprehensionStart', 'FIMComprehensionEnd', 'FIMExpressionStart', 'FIMExpressionEnd', 'FIMSocialInteractionStart', 'FIMSocialInteractionEnd', 'FIMProblemSolvingStart', 'FIMProblemSolvingEnd', 'FIMMemoryStart', 'FIMMemoryEnd', 'AN SNAP V3', 'sa_AN_SNAP_Version', 'HONActivityStart', 'HONActivityEnd', 'HONInjuryStart', 'HONInjuryEnd', 'HONDrinkStart', 'HONDrinkEnd', 'HONCognitStart', 'HONCognitEnd', 'HONDisabStart', 'HONDisabEnd', 'HONHallucStart', 'HONHallucEnd', 'HONDepresStart', 'HONDepresEnd', 'HONOtherStart', 'HONOtherEnd', 'HONRelatStart', 'HONRelatEnd', 'HONAdlStart', 'HONAdlEnd', 'HONLivingStart', 'HONLivingEnd', 'HONOccupStart', 'HONOccupEnd', 'CareFocus', 'stay_number_cost', 'sa_episode_sequence_number', 'sa_nwau_version', 'sa_EpisodeBegReason', 'sa_EpisodeEndReason', 'RUGToiletingStart', 'RUGBedMobilityStart', 'RUGTransferStart', 'RUGEatingStart', 'caretype', 'InterupCare', 'Sequence', 'EncounterNumber', 'EncounterStart', 'EncounterEnd', 'LHD', 'sa_nwau', 'sa_occdays_in_cost_period', 'sa_leave_days_in_cost_period', 'sa_total_los', 'sa_total_leave_days', 'Snap ClassV4', 'Dementia_Flag', 'Delirium_Flag', 'HIE Extract Date', 'Grouped Status']
            snapApp_CostingExtract = snapApp_CostingExtract.applymap(str)#.apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            snapApp_CostingExtract = snapApp_CostingExtract.applymap(lambda x: x.strip() if isinstance(x, str) else x)
            snapApp_CostingExtract = snapApp_CostingExtract.apply(lambda x: x.replace(regex=r'^NaT$', value='') if x.dtype == 'object' else x)
            snapApp_CostingExtract = snapApp_CostingExtract[(pd.notna(snapApp_CostingExtract['FacilityCode'])) & (snapApp_CostingExtract['FacilityCode']!='')]
            snapApp_CostingExtract = snapApp_CostingExtract[snapApp_CostingExtract['FacilityCode'].isin(facilities_included_list)]
            snapApp_CostingExtract['stay_number_cost_dummy'] = snapApp_CostingExtract['stay_number_cost'].astype(str).str.replace('SN' ,'')
            snapApp_CostingExtract['stay_number_cost_dummy'] = snapApp_CostingExtract['stay_number_cost_dummy'].astype(str).str.pad(8, side ='left', fillchar ='0')
            index_names = snapApp_CostingExtract[(snapApp_CostingExtract['FacilityCode'] == '') | (snapApp_CostingExtract['FacilityCode'].isnull())].index
            snapApp_CostingExtract.drop(index_names, inplace = True)
            tbl_ExcludedEncounters_snap_dummy = tbl_ExcludedEncounters.copy()
            tbl_ExcludedEncounters_snap_dummy['stay_number_dummy'] = tbl_ExcludedEncounters_snap_dummy['stay_number'].astype(str).str.pad(8, side ='left', fillchar ='0')
            tbl_ExcludedEncounters_snap_dummy['episode_sequence_number'] = tbl_ExcludedEncounters_snap_dummy['episode_sequence_number'].astype(str).str.pad(3, side ='left', fillchar ='0')
            snapApp_CostingExtract = pd.merge(snapApp_CostingExtract,tbl_ExcludedEncounters_snap_dummy[['facility_identifier','stay_number_dummy', 'episode_sequence_number']], how='left', left_on=['FacilityCode', 'stay_number_cost_dummy',	'sa_episode_sequence_number'], right_on=['facility_identifier','stay_number_dummy', 'episode_sequence_number'], suffixes=('', '_drop'), indicator=True)
            snapApp_CostingExtract = snapApp_CostingExtract[snapApp_CostingExtract['_merge'] == 'left_only']
            snapApp_CostingExtract.drop(columns =['_merge', 'stay_number_cost_dummy'], inplace=True)
            logging.info('snapApp_CostingExtract has %s from ./Costing/SNAP_CostingExtract.xls.', len(snapApp_CostingExtract))
            """
            # 21 Jan SNAP EDW
            snapApp_CostingExtract["EpisodeStartDate_HIE"] = pd.to_datetime(
                snapApp_CostingExtract["EpisodeStartDate_HIE"],
                errors="coerce",
                format="%d-%m-%Y",
            )
            snapApp_CostingExtract["EpisodeEndDate_HIE"] = pd.to_datetime(
                snapApp_CostingExtract["EpisodeEndDate_HIE"],
                errors="coerce",
                format="%d-%m-%Y",
            )
            snapApp_CostingExtract["EncounterStart"] = pd.to_datetime(
                snapApp_CostingExtract["EncounterStart"],
                errors="coerce",
                format="%d-%m-%Y %H:%M:%S",
            )
            snapApp_CostingExtract["EncounterEnd"] = pd.to_datetime(
                snapApp_CostingExtract["EncounterEnd"],
                errors="coerce",
                format="%d-%m-%Y %H:%M:%S",
            )
            snapApp_CostingExtract["HIE extract Date"] = pd.to_datetime(
                snapApp_CostingExtract["HIE extract Date"],
                errors="coerce",
                format="%d-%m-%Y",
            )

            # snapApp_CostingExtract.columns = ['PCSNAP_PhaseID', 'pcPhase', 'PCPhaseStartDate', 'PCPhaseEndDate', 'FacilityCode', 'mrn', 'SNAPEpisodeID', 'SNAPCaseType', 'EpisodeStartDate_HIE', 'EpisodeEndDate_HIE', 'EpisodeStartTime_HIE', 'EpisodeEndTime_HIE', 'EpisType', 'TotalSuspensionDays', 'AssessmentOnly', 'PCSymptomScoreStart', 'PCSeverityStart', 'PCPsychSpiritualScoreStart', 'PCFamilyCarerScoreStart', 'MaintType', 'RehImpairmentCode', 'FIMEatingStart', 'FIMEatingEnd', 'FIMGroomingStart', 'FIMGroomingEnd', 'FIMBathingStart', 'FIMBathingEnd', 'FIMDressingUpperStart', 'FIMDressingUpperEnd', 'FIMDressingLowerStart', 'FIMDressingLowerEnd', 'FIMToiletingStart', 'FIMToiletingEnd', 'FIMBladderStart', 'FIMBladderEnd', 'FIMBowelStart', 'FIMBowelEnd', 'FIMXferBedChairWChairStart', 'FIMXferBedChairWChairEnd', 'FIMXferBathShowerStart', 'FIMXferBathShowerEnd', 'FIMXferToiletStart', 'FIMXferToiletEnd', 'FIMWalkWheelChairStart', 'FIMWalkWheelChairEnd', 'FIMStairsStart', 'FIMStairsEnd', 'FIMComprehensionStart', 'FIMComprehensionEnd', 'FIMExpressionStart', 'FIMExpressionEnd', 'FIMSocialInteractionStart', 'FIMSocialInteractionEnd', 'FIMProblemSolvingStart', 'FIMProblemSolvingEnd', 'FIMMemoryStart', 'FIMMemoryEnd', 'AN SNAP', 'sa_AN_SNAP_Version', 'HONActivityStart', 'HONActivityEnd', 'HONInjuryStart', 'HONInjuryEnd', 'HONDrinkStart', 'HONDrinkEnd', 'HONCognitStart', 'HONCognitEnd', 'HONDisabStart', 'HONDisabEnd', 'HONHallucStart', 'HONHallucEnd', 'HONDepresStart', 'HONDepresEnd', 'HONOtherStart', 'HONOtherEnd', 'HONRelatStart', 'HONRelatEnd', 'HONAdlStart', 'HONAdlEnd', 'HONLivingStart', 'HONLivingEnd', 'HONOccupStart', 'HONOccupEnd', 'CareFocus', 'stay_number_cost', 'sa_episode_sequence_number', 'sa_nwau_version', 'sa_EpisodeBegReason', 'sa_EpisodeEndReason', 'RUGToiletingStart', 'RUGBedMobilityStart', 'RUGTransferStart', 'RUGEatingStart', 'caretype', 'InterupCare', 'Sequence', 'EncounterNumber', 'EncounterStart', 'EncounterEnd', 'LHD', 'sa_nwau', 'sa_occdays_in_cost_period', 'sa_leave_days_in_cost_period', 'sa_total_los', 'sa_total_leave_days', 'Snap ClassV4', 'Dementia_Flag', 'Delirium_Flag', 'HIE Extract Date', 'Grouped Status', 'SE_CBK_SK']

            snapApp_CostingExtract.columns = [
                "pcSNAP_PhaseID",
                "pcPhase",
                "PCPhaseStartDate",
                "PCPhaseEndDate",
                "FacilityCode",
                "MRN",
                "SNAPEpisodeID",
                "SNAPCaseType",
                "EpisodeStartDate_HIE",
                "EpisodeEndDate_HIE",
                "EpisodeStartTime_HIE",
                "EpisodeEndTime_HIE",
                "EpisType",
                "TotalSuspensionDays",
                "AssessmentOnly",
                "PCSymptomScoreStart",
                "PCSeverityStart",
                "PCPsychSpiritualScoreStart",
                "PCFamilyCarerScoreStart",
                "MaintType",
                "RehImpairmentCode",
                "FIMEatingStart",
                "FIMEatingEnd",
                "FIMGroomingStart",
                "FIMGroomingEnd",
                "FIMBathingStart",
                "FIMBathingEnd",
                "FIMDressingUpperStart",
                "FIMDressingUpperEnd",
                "FIMDressingLowerStart",
                "FIMDressingLowerEnd",
                "FIMToiletingStart",
                "FIMToiletingEnd",
                "FIMBladderStart",
                "FIMBladderEnd",
                "FIMBowelStart",
                "FIMBowelEnd",
                "FIMXferBedChairWChairStart",
                "FIMXferBedChairWChairEnd",
                "FIMXferBathShowerStart",
                "FIMXferBathShowerEnd",
                "FIMXferToiletStart",
                "FIMXferToiletEnd",
                "FIMWalkWheelChairStart",
                "FIMWalkWheelChairEnd",
                "FIMStairsStart",
                "FIMStairsEnd",
                "FIMComprehensionStart",
                "FIMComprehensionEnd",
                "FIMExpressionStart",
                "FIMExpressionEnd",
                "FIMSocialInteractionStart",
                "FIMSocialInteractionEnd",
                "FIMProblemSolvingStart",
                "FIMProblemSolvingEnd",
                "FIMMemoryStart",
                "FIMMemoryEnd",
                "AN SNAP V3",
                "sa_AN_SNAP_Version",
                "HONActivityStart",
                "HONActivityEnd",
                "HONInjuryStart",
                "HONInjuryEnd",
                "HONDrinkStart",
                "HONDrinkEnd",
                "HONCognitStart",
                "HONCognitEnd",
                "HONDisabStart",
                "HONDisabEnd",
                "HONHallucStart",
                "HONHallucEnd",
                "HONDepresStart",
                "HONDepresEnd",
                "HONOtherStart",
                "HONOtherEnd",
                "HONRelatStart",
                "HONRelatEnd",
                "HONAdlStart",
                "HONAdlEnd",
                "HONLivingStart",
                "HONLivingEnd",
                "HONOccupStart",
                "HONOccupEnd",
                "CareFocus",
                "stay_number_cost",
                "sa_episode_sequence_number",
                "sa_nwau_version",
                "sa_EpisodeBegReason",
                "sa_EpisodeEndReason",
                "RUGToiletingStart",
                "RUGBedMobilityStart",
                "RUGTransferStart",
                "RUGEatingStart",
                "careType",
                "InterupCare",
                "Sequence",
                "EncounterNumber",
                "EncounterStart",
                "EncounterEnd",
                "LHD",
                "sa_nwau",
                "sa_occdays_in_cost_period",
                "sa_leave_days_in_cost_period",
                "sa_total_los",
                "sa_total_leave_days",
                "Snap ClassV4",
                "Dementia_Flag",
                "Delirium_Flag",
                "HIE extract Date",
                "Grouped Status",
                "SE_CBK_SK",
                "phase_sequence_number",
                "HIE_AUID",
                "is_active",
            ]

            snapApp_CostingExtract.rename(
                columns={
                    "AN SNAP V3": "AN SNAP",
                    "careType": "caretype",
                    "HIE extract Date": "HIE Extract Date",
                    "MRN": "mrn",
                    "pcSNAP_PhaseID": "PCSNAP_PhaseID",
                },
                inplace=True,
            )
            # 03 July 2025 - new code has dd-mm-yyyy
            # snapApp_CostingExtract['PCPhaseStartDate_dummy'] = pd.to_datetime(snapApp_CostingExtract['PCPhaseStartDate'], errors='coerce', format="%d/%m/%Y")
            # snapApp_CostingExtract['PCPhaseEndDate_dummy'] = pd.to_datetime(snapApp_CostingExtract['PCPhaseEndDate'], errors='coerce', format="%d/%m/%Y")

            snapApp_CostingExtract["PCPhaseStartDate_dummy"] = pd.to_datetime(
                snapApp_CostingExtract["PCPhaseStartDate"],
                errors="coerce",
                format="%d-%m-%Y",
            )
            snapApp_CostingExtract["PCPhaseEndDate_dummy"] = pd.to_datetime(
                snapApp_CostingExtract["PCPhaseEndDate"],
                errors="coerce",
                format="%d-%m-%Y",
            )
            # THERE IS A PROBLEM WITH THE SNAP FILE SHARED BY CALLI MILLER ON 21st JAN
            # For pal care:  In the given SNAP file, the Encounter Start and Encounter End fields are populated with Episode Start Date and Episode End Date fields, instead of Phase Start Time and Phase End Time fields.
            # I can make changes in the code before todays release to derive Encounter Start and Encounter End from Phase Start and Phase End for pal care
            # There is a drawback with the above workaround  Phase Start and Phase End date dont have the time component

            # 03 July 2025 - new code does not have this problem. so we can comment below statements
            """
            snapApp_CostingExtract['EncounterStart'] = np.where(((snapApp_CostingExtract['PCSNAP_PhaseID']!= '') & (pd.notna(snapApp_CostingExtract['PCSNAP_PhaseID']))), snapApp_CostingExtract['PCPhaseStartDate_dummy'], snapApp_CostingExtract['EncounterStart'])
            snapApp_CostingExtract['EncounterEnd'] = np.where(((snapApp_CostingExtract['PCSNAP_PhaseID']!= '') & (pd.notna(snapApp_CostingExtract['PCSNAP_PhaseID']))), snapApp_CostingExtract['PCPhaseEndDate_dummy'], snapApp_CostingExtract['EncounterEnd'])
            """

            snapApp_CostingExtract["AN SNAP V3"] = snapApp_CostingExtract["AN SNAP"]

            snapApp_CostingExtract = snapApp_CostingExtract[
                [
                    "PCSNAP_PhaseID",
                    "pcPhase",
                    "PCPhaseStartDate",
                    "PCPhaseEndDate",
                    "FacilityCode",
                    "mrn",
                    "SNAPEpisodeID",
                    "SNAPCaseType",
                    "EpisodeStartDate_HIE",
                    "EpisodeEndDate_HIE",
                    "EpisodeStartTime_HIE",
                    "EpisodeEndTime_HIE",
                    "EpisType",
                    "TotalSuspensionDays",
                    "AssessmentOnly",
                    "PCSymptomScoreStart",
                    "PCSeverityStart",
                    "PCPsychSpiritualScoreStart",
                    "PCFamilyCarerScoreStart",
                    "MaintType",
                    "RehImpairmentCode",
                    "FIMEatingStart",
                    "FIMEatingEnd",
                    "FIMGroomingStart",
                    "FIMGroomingEnd",
                    "FIMBathingStart",
                    "FIMBathingEnd",
                    "FIMDressingUpperStart",
                    "FIMDressingUpperEnd",
                    "FIMDressingLowerStart",
                    "FIMDressingLowerEnd",
                    "FIMToiletingStart",
                    "FIMToiletingEnd",
                    "FIMBladderStart",
                    "FIMBladderEnd",
                    "FIMBowelStart",
                    "FIMBowelEnd",
                    "FIMXferBedChairWChairStart",
                    "FIMXferBedChairWChairEnd",
                    "FIMXferBathShowerStart",
                    "FIMXferBathShowerEnd",
                    "FIMXferToiletStart",
                    "FIMXferToiletEnd",
                    "FIMWalkWheelChairStart",
                    "FIMWalkWheelChairEnd",
                    "FIMStairsStart",
                    "FIMStairsEnd",
                    "FIMComprehensionStart",
                    "FIMComprehensionEnd",
                    "FIMExpressionStart",
                    "FIMExpressionEnd",
                    "FIMSocialInteractionStart",
                    "FIMSocialInteractionEnd",
                    "FIMProblemSolvingStart",
                    "FIMProblemSolvingEnd",
                    "FIMMemoryStart",
                    "FIMMemoryEnd",
                    "AN SNAP V3",
                    "sa_AN_SNAP_Version",
                    "HONActivityStart",
                    "HONActivityEnd",
                    "HONInjuryStart",
                    "HONInjuryEnd",
                    "HONDrinkStart",
                    "HONDrinkEnd",
                    "HONCognitStart",
                    "HONCognitEnd",
                    "HONDisabStart",
                    "HONDisabEnd",
                    "HONHallucStart",
                    "HONHallucEnd",
                    "HONDepresStart",
                    "HONDepresEnd",
                    "HONOtherStart",
                    "HONOtherEnd",
                    "HONRelatStart",
                    "HONRelatEnd",
                    "HONAdlStart",
                    "HONAdlEnd",
                    "HONLivingStart",
                    "HONLivingEnd",
                    "HONOccupStart",
                    "HONOccupEnd",
                    "CareFocus",
                    "stay_number_cost",
                    "sa_episode_sequence_number",
                    "sa_nwau_version",
                    "sa_EpisodeBegReason",
                    "sa_EpisodeEndReason",
                    "RUGToiletingStart",
                    "RUGBedMobilityStart",
                    "RUGTransferStart",
                    "RUGEatingStart",
                    "caretype",
                    "InterupCare",
                    "Sequence",
                    "EncounterNumber",
                    "EncounterStart",
                    "EncounterEnd",
                    "LHD",
                    "sa_nwau",
                    "sa_occdays_in_cost_period",
                    "sa_leave_days_in_cost_period",
                    "sa_total_los",
                    "sa_total_leave_days",
                    "Snap ClassV4",
                    "Dementia_Flag",
                    "Delirium_Flag",
                    "HIE Extract Date",
                    "Grouped Status",
                    "SE_CBK_SK",
                ]
            ]
            # remove records where SE_CBK_SK is blank
            snapApp_CostingExtract = snapApp_CostingExtract[
                (pd.notna(snapApp_CostingExtract["SE_CBK_SK"]))
                & (snapApp_CostingExtract["SE_CBK_SK"] != "")
            ]

            # Derive Encounter Number
            # Example: Palliative (SNAPCaseType = 1): Example: A207_00582212_00001 (FacilityID_SNAPEpisodeID_PhaseID)
            # Example: Non-Pal: When SNAPCaseType = 2,3,4,5: Example: A207_00592334 (FacilityID_EpisodeID)
            # Example: When SNAPCaseType is blank: Example A207-I-05591981-001. has I in EncounterNumber
            # note snapepisodeID padded to 8 and pcSNAP_PhaseID  5 padding

            snapApp_CostingExtract["PCSNAP_PhaseID_dummy"] = (
                snapApp_CostingExtract["PCSNAP_PhaseID"]
                .astype(str)
                .str.pad(11, side="left", fillchar="0")
            )
            snapApp_CostingExtract["stay_number_cost_dummy"] = snapApp_CostingExtract[
                "stay_number_cost"
            ].apply(lambda x: str(x).split("-")[-1].zfill(8))

            snapApp_CostingExtract["stay_number_cost"] = snapApp_CostingExtract[
                "stay_number_cost_dummy"
            ]
            snapApp_CostingExtract["sa_episode_sequence_number"] = (
                snapApp_CostingExtract["sa_episode_sequence_number"]
                .astype(str)
                .str.pad(3, side="left", fillchar="0")
            )
            snapApp_CostingExtract["SNAPEpisodeID_dummy"] = np.where(
                (snapApp_CostingExtract["SNAPEpisodeID"] == "")
                | (snapApp_CostingExtract["SNAPEpisodeID"].isnull()),
                snapApp_CostingExtract["stay_number_cost"].astype(str).str.strip()
                + "_"
                + snapApp_CostingExtract["sa_episode_sequence_number"]
                .astype(str)
                .str.strip(),
                snapApp_CostingExtract["SNAPEpisodeID"]
                .astype(str)
                .str.pad(11, side="left", fillchar="0"),
            )

            condlist = [
                (snapApp_CostingExtract["Grouped Status"] == "Grouped")
                & (
                    (snapApp_CostingExtract["PCSNAP_PhaseID"] == "")
                    | (snapApp_CostingExtract["PCSNAP_PhaseID"].isnull())
                )
                & (
                    (snapApp_CostingExtract["SNAPEpisodeID"] == "")
                    | (snapApp_CostingExtract["SNAPEpisodeID"].isnull())
                ),
                (snapApp_CostingExtract["Grouped Status"] == "Grouped")
                & (
                    (snapApp_CostingExtract["PCSNAP_PhaseID"] == "")
                    | (snapApp_CostingExtract["PCSNAP_PhaseID"].isnull())
                )
                & (
                    (snapApp_CostingExtract["SNAPEpisodeID"] != "")
                    & (pd.notna(snapApp_CostingExtract["SNAPEpisodeID"]))
                ),
                (snapApp_CostingExtract["Grouped Status"] == "Grouped")
                & (
                    (snapApp_CostingExtract["PCSNAP_PhaseID"] != "")
                    & (pd.notna(snapApp_CostingExtract["PCSNAP_PhaseID"]))
                ),
            ]
            choicelist = [
                snapApp_CostingExtract["FacilityCode"].astype(str).str.strip()
                + "-I-"
                + snapApp_CostingExtract["stay_number_cost_dummy"]
                .astype(str)
                .str.strip()
                + "-"
                + snapApp_CostingExtract["sa_episode_sequence_number"]
                .astype(str)
                .str.strip(),
                snapApp_CostingExtract["FacilityCode"].astype(str).str.strip()
                + "_"
                + snapApp_CostingExtract["SNAPEpisodeID_dummy"].astype(str).str.strip(),
                snapApp_CostingExtract["FacilityCode"].astype(str).str.strip()
                + "_"
                + snapApp_CostingExtract["SNAPEpisodeID_dummy"].astype(str).str.strip()
                + "_"
                + snapApp_CostingExtract["PCSNAP_PhaseID_dummy"],
            ]
            snapApp_CostingExtract["EncounterNumber"] = np.select(
                condlist,
                choicelist,
                snapApp_CostingExtract["FacilityCode"].astype(str).str.strip()
                + "-I-"
                + snapApp_CostingExtract["stay_number_cost_dummy"]
                .astype(str)
                .str.strip()
                + "-"
                + snapApp_CostingExtract["sa_episode_sequence_number"]
                .astype(str)
                .str.strip(),
            )

            snapApp_CostingExtract = snapApp_CostingExtract.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            snapApp_CostingExtract = snapApp_CostingExtract.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            snapApp_CostingExtract = snapApp_CostingExtract.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            snapApp_CostingExtract = snapApp_CostingExtract[
                (pd.notna(snapApp_CostingExtract["FacilityCode"]))
                & (snapApp_CostingExtract["FacilityCode"] != "")
            ]
            snapApp_CostingExtract = snapApp_CostingExtract[
                snapApp_CostingExtract["FacilityCode"].isin(facilities_included_list)
            ]

            index_names = snapApp_CostingExtract[
                (snapApp_CostingExtract["FacilityCode"] == "")
                | (snapApp_CostingExtract["FacilityCode"].isnull())
            ].index
            snapApp_CostingExtract.drop(index_names, inplace=True)
            tbl_ExcludedEncounters_snap_dummy = tbl_ExcludedEncounters.copy()
            tbl_ExcludedEncounters_snap_dummy["stay_number_dummy"] = (
                tbl_ExcludedEncounters_snap_dummy["stay_number"]
                .astype(str)
                .str.pad(8, side="left", fillchar="0")
            )
            tbl_ExcludedEncounters_snap_dummy["episode_sequence_number"] = (
                tbl_ExcludedEncounters_snap_dummy["episode_sequence_number"]
                .astype(str)
                .str.pad(3, side="left", fillchar="0")
            )
            snapApp_CostingExtract = pd.merge(
                snapApp_CostingExtract,
                tbl_ExcludedEncounters_snap_dummy[
                    [
                        "facility_identifier",
                        "stay_number_dummy",
                        "episode_sequence_number",
                    ]
                ],
                how="left",
                left_on=[
                    "FacilityCode",
                    "stay_number_cost_dummy",
                    "sa_episode_sequence_number",
                ],
                right_on=[
                    "facility_identifier",
                    "stay_number_dummy",
                    "episode_sequence_number",
                ],
                suffixes=("", "_drop"),
                indicator=True,
            )
            snapApp_CostingExtract = snapApp_CostingExtract[
                snapApp_CostingExtract["_merge"] == "left_only"
            ]
            snapApp_CostingExtract.drop(
                columns=[
                    "_merge",
                    "stay_number_cost_dummy",
                    "PCSNAP_PhaseID_dummy",
                    "SNAPEpisodeID_dummy",
                    "PCPhaseStartDate_dummy",
                    "PCPhaseEndDate_dummy",
                ],
                errors="ignore",
                inplace=True,
            )
            logging.info(
                "snapApp_CostingExtract has %s from ./Costing/SNAP_CostingExtract.xls.",
                len(snapApp_CostingExtract),
            )
            """
            if len(snapApp_CostingExtract[snapApp_CostingExtract['sa_nwau_version']!=nwau_v]) > 0:
                df_SNAP_Excluded_invalid_nwau = snapApp_CostingExtract[snapApp_CostingExtract['sa_nwau_version']!=nwau_v]
                df_SNAP_Excluded_invalid_nwau['ReasonForExclusion'] = 'Snap Nwau Version Is Not Valid For The Selected Round'
                df_SNAP_Excluded_invalid_nwau['ed_identifier'] ='XXXXXXXXXX'
                df_SNAP_Excluded_invalid_nwau['SNAP_encounter'] ='SNAP'
                df_SNAP_Excluded_invalid_nwau['EncounterNumber'] = df_SNAP_Excluded_invalid_nwau['EncounterNumber']
                df_SNAP_Excluded_invalid_nwau['stay_number'] = df_SNAP_Excluded_invalid_nwau['stay_number_cost']
                df_SNAP_Excluded_invalid_nwau['episode_sequence_number'] = df_SNAP_Excluded_invalid_nwau['sa_episode_sequence_number']
                df_SNAP_Excluded_invalid_nwau['facility_identifier'] = df_SNAP_Excluded_invalid_nwau['FacilityCode']
                df_SNAP_Excluded_invalid_nwau = df_SNAP_Excluded_invalid_nwau[['facility_identifier', 'stay_number', 'episode_sequence_number', 'ed_identifier', 'SNAP_encounter', 'ReasonForExclusion', 'EncounterNumber']] 
                df_SNAP_Excluded_invalid_nwau= df_SNAP_Excluded_invalid_nwau.fillna("")
            else:
                df_SNAP_Excluded_invalid_nwau = pd.DataFrame(columns=['facility_identifier', 'stay_number', 'episode_sequence_number', 'ed_identifier', 'SNAP_encounter', 'ReasonForExclusion', 'EncounterNumber'])
            logging.info('%s encounters were excluded from snapApp_CostingExtract where sa_nwau_version not equal to %s.', len(df_SNAP_Excluded_invalid_nwau), nwau_v)
            df_SNAP_Excluded_invalid_nwau.to_csv('./ExtractorDB/SNAP_Excluded_invalid_nwau.csv',index=False)
            #filter by nwau version
            snapApp_CostingExtract = snapApp_CostingExtract[snapApp_CostingExtract['sa_nwau_version']==nwau_v]
            """
            logging.info(
                "snapApp_CostingExtract has %s where sa_nwau_version = %s.",
                len(snapApp_CostingExtract),
                nwau_v,
            )
            # print("snapApp_CostingExtract=",len(snapApp_CostingExtract))
            # label_9_status = 1
    else:
        snapApp_CostingExtract = pd.DataFrame(
            columns=[
                "PCSNAP_PhaseID",
                "pcPhase",
                "PCPhaseStartDate",
                "PCPhaseEndDate",
                "FacilityCode",
                "mrn",
                "SNAPEpisodeID",
                "SNAPCaseType",
                "EpisodeStartDate_HIE",
                "EpisodeEndDate_HIE",
                "EpisodeStartTime_HIE",
                "EpisodeEndTime_HIE",
                "EpisType",
                "TotalSuspensionDays",
                "AssessmentOnly",
                "PCSymptomScoreStart",
                "PCSeverityStart",
                "PCPsychSpiritualScoreStart",
                "PCFamilyCarerScoreStart",
                "MaintType",
                "RehImpairmentCode",
                "FIMEatingStart",
                "FIMEatingEnd",
                "FIMGroomingStart",
                "FIMGroomingEnd",
                "FIMBathingStart",
                "FIMBathingEnd",
                "FIMDressingUpperStart",
                "FIMDressingUpperEnd",
                "FIMDressingLowerStart",
                "FIMDressingLowerEnd",
                "FIMToiletingStart",
                "FIMToiletingEnd",
                "FIMBladderStart",
                "FIMBladderEnd",
                "FIMBowelStart",
                "FIMBowelEnd",
                "FIMXferBedChairWChairStart",
                "FIMXferBedChairWChairEnd",
                "FIMXferBathShowerStart",
                "FIMXferBathShowerEnd",
                "FIMXferToiletStart",
                "FIMXferToiletEnd",
                "FIMWalkWheelChairStart",
                "FIMWalkWheelChairEnd",
                "FIMStairsStart",
                "FIMStairsEnd",
                "FIMComprehensionStart",
                "FIMComprehensionEnd",
                "FIMExpressionStart",
                "FIMExpressionEnd",
                "FIMSocialInteractionStart",
                "FIMSocialInteractionEnd",
                "FIMProblemSolvingStart",
                "FIMProblemSolvingEnd",
                "FIMMemoryStart",
                "FIMMemoryEnd",
                "AN SNAP V3",
                "sa_AN_SNAP_Version",
                "HONActivityStart",
                "HONActivityEnd",
                "HONInjuryStart",
                "HONInjuryEnd",
                "HONDrinkStart",
                "HONDrinkEnd",
                "HONCognitStart",
                "HONCognitEnd",
                "HONDisabStart",
                "HONDisabEnd",
                "HONHallucStart",
                "HONHallucEnd",
                "HONDepresStart",
                "HONDepresEnd",
                "HONOtherStart",
                "HONOtherEnd",
                "HONRelatStart",
                "HONRelatEnd",
                "HONAdlStart",
                "HONAdlEnd",
                "HONLivingStart",
                "HONLivingEnd",
                "HONOccupStart",
                "HONOccupEnd",
                "CareFocus",
                "stay_number_cost",
                "sa_episode_sequence_number",
                "sa_nwau_version",
                "sa_EpisodeBegReason",
                "sa_EpisodeEndReason",
                "RUGToiletingStart",
                "RUGBedMobilityStart",
                "RUGTransferStart",
                "RUGEatingStart",
                "caretype",
                "InterupCare",
                "Sequence",
                "EncounterNumber",
                "EncounterStart",
                "EncounterEnd",
                "LHD",
                "sa_nwau",
                "sa_occdays_in_cost_period",
                "sa_leave_days_in_cost_period",
                "sa_total_los",
                "sa_total_leave_days",
                "Snap ClassV4",
                "Dementia_Flag",
                "Delirium_Flag",
                "HIE Extract Date",
                "Grouped Status",
                "SE_CBK_SK",
            ]
        )
        # Ranjit: as SNAP_CostingExtract is not a mandatory file, no need to show error message
        # messagebox.showerror("File Error","Error extracting SNAP_CostingExtract")
        # label_9_status = 1
    logging.info(
        "snapApp_CostingExtract created with %s records from ./Costing/SNAP_CostingExtract.xls.",
        len(snapApp_CostingExtract),
    )
    # snapApp_CostingExtract.to_csv('./ExtractorDB/snapApp_CostingExtract_initial.csv', index=False, na_rep='', float_format=str, decimal=str, date_format=str)
    """ Ranjit: Query I wrote to exclude SNAP Encounters Outside Costing Period"""
    # Inform8 query
    """
    EpisodeStartDate_HIE >= this.manager.EndDate.AddDays(1.0)
    t.EpisodeEndDate_HIE > empty_date && t.EpisodeEndDate_HIE <= this.manager.StartDate && t.EpisodeStartDate_HIE < this.manager.StartDate;
    if (!(snapCostingExtract.EpisodeEndDate_HIE == this.manager.StartDate) || snapCostingExtract.EpisodeStartTime_HIE.TimeOfDay.TotalMinutes <= 0.0)
    """
    snapApp_CostingExtract_original = snapApp_CostingExtract.copy()
    # Inform8 query:
    """
    foreach (SnapCostingExtract snapCostingExtract in sessionNoServer.AllObjects<SnapCostingExtract>().Where<SnapCostingExtract>((Func<SnapCostingExtract, bool>) (t =>
          {
            if (t.EpisodeStartDate_HIE >= this.manager.EndDate.AddDays(1.0))
              return true;
            return t.EpisodeEndDate_HIE > empty_date && t.EpisodeEndDate_HIE <= this.manager.StartDate && t.EpisodeStartDate_HIE < this.manager.StartDate;
          })))
          {
            if (!(snapCostingExtract.EpisodeEndDate_HIE == this.manager.StartDate) || snapCostingExtract.EpisodeStartTime_HIE.TimeOfDay.TotalMinutes <= 0.0)
            {
              MyLogger.LogLine("EXCLUDED Snap Encounter: " + snapCostingExtract.EncounterNumber + " -> Outside Costing Period.");
    ed_identifier = "XXXXXXXXXX",
    facility_identifier = snapCostingExtract.FacilityCode,
    stay_number = snapCostingExtract.stay_number_cost,
    episode_sequence_number = snapCostingExtract.sa_episode_sequence_number,
    SNAP_encounter = "SNAP",
    EncounterNumber = snapCostingExtract.EncounterNumber,
    ReasonForExclusion = "SNAP Encounter Outside Costing Period"
    """
    # snapApp_CostingExtract = snapApp_CostingExtract[~((pd.to_datetime(snapApp_CostingExtract['EpisodeStartDate_HIE'], errors='coerce', format="%Y-%m-%d %H:%M:%S") > pd.to_datetime(end_date, format="%Y-%m-%d %H:%M:%S")) | ((pd.notna(snapApp_CostingExtract['EpisodeEndDate_HIE'])) & (snapApp_CostingExtract['EpisodeEndDate_HIE']!='') & (pd.to_datetime(snapApp_CostingExtract['EpisodeEndDate_HIE'], errors='coerce', format="%Y-%m-%d %H:%M:%S") < pd.to_datetime(start_date, format="%Y-%m-%d %H:%M:%S")) | (pd.to_datetime(snapApp_CostingExtract['EpisodeStartDate_HIE'], errors='coerce', format="%Y-%m-%d %H:%M:%S") < pd.to_datetime(start_date, format="%Y-%m-%d %H:%M:%S"))))]
    snapApp_CostingExtract = snapApp_CostingExtract[
        ~(
            (
                pd.to_datetime(
                    snapApp_CostingExtract["EpisodeStartDate_HIE"],
                    errors="coerce",
                    format="%Y-%m-%d %H:%M:%S",
                )
                > pd.to_datetime(end_date, format="%Y-%m-%d %H:%M:%S")
            )
            | (
                (pd.notna(snapApp_CostingExtract["EpisodeEndDate_HIE"]))
                & (snapApp_CostingExtract["EpisodeEndDate_HIE"] != "")
                & (
                    pd.to_datetime(
                        snapApp_CostingExtract["EpisodeEndDate_HIE"],
                        errors="coerce",
                        format="%Y-%m-%d %H:%M:%S",
                    )
                    < pd.to_datetime(start_date, format="%Y-%m-%d %H:%M:%S")
                )
                & (
                    pd.to_datetime(
                        snapApp_CostingExtract["EpisodeStartDate_HIE"],
                        errors="coerce",
                        format="%Y-%m-%d %H:%M:%S",
                    )
                    < pd.to_datetime(start_date, format="%Y-%m-%d %H:%M:%S")
                )
            )
        )
    ]
    logging.info(
        "snapApp_CostingExtract has %s records after excluding snap encounters outside costing period.",
        len(snapApp_CostingExtract),
    )
    # df_SNAP_Excluded_enddate_le_startdate =  snapApp_CostingExtract_original[((pd.to_datetime(snapApp_CostingExtract_original['EpisodeStartDate_HIE'], errors='coerce', format="%Y-%m-%d %H:%M:%S") > pd.to_datetime(end_date, format="%Y-%m-%d %H:%M:%S")) | ((pd.notna(snapApp_CostingExtract_original['EpisodeEndDate_HIE'])) & (snapApp_CostingExtract_original['EpisodeEndDate_HIE']!='') & (pd.to_datetime(snapApp_CostingExtract_original['EpisodeEndDate_HIE'], errors='coerce', format="%Y-%m-%d %H:%M:%S") < pd.to_datetime(start_date, format="%Y-%m-%d %H:%M:%S")) | (pd.to_datetime(snapApp_CostingExtract_original['EpisodeStartDate_HIE'], errors='coerce', format="%Y-%m-%d %H:%M:%S") < pd.to_datetime(start_date, format="%Y-%m-%d %H:%M:%S"))))]
    df_SNAP_Excluded_enddate_le_startdate = snapApp_CostingExtract_original[
        (
            (
                pd.to_datetime(
                    snapApp_CostingExtract_original["EpisodeStartDate_HIE"],
                    errors="coerce",
                    format="%Y-%m-%d %H:%M:%S",
                )
                > pd.to_datetime(end_date, format="%Y-%m-%d %H:%M:%S")
            )
            | (
                (pd.notna(snapApp_CostingExtract_original["EpisodeEndDate_HIE"]))
                & (snapApp_CostingExtract_original["EpisodeEndDate_HIE"] != "")
                & (
                    pd.to_datetime(
                        snapApp_CostingExtract_original["EpisodeEndDate_HIE"],
                        errors="coerce",
                        format="%Y-%m-%d %H:%M:%S",
                    )
                    < pd.to_datetime(start_date, format="%Y-%m-%d %H:%M:%S")
                )
                & (
                    pd.to_datetime(
                        snapApp_CostingExtract_original["EpisodeStartDate_HIE"],
                        errors="coerce",
                        format="%Y-%m-%d %H:%M:%S",
                    )
                    < pd.to_datetime(start_date, format="%Y-%m-%d %H:%M:%S")
                )
            )
        )
    ]
    if len(df_SNAP_Excluded_enddate_le_startdate) > 0:
        df_SNAP_Excluded_enddate_le_startdate["ReasonForExclusion"] = (
            "SNAP Encounter Outside Costing Period"
        )
        df_SNAP_Excluded_enddate_le_startdate["ed_identifier"] = "XXXXXXXXXX"
        df_SNAP_Excluded_enddate_le_startdate["SNAP_encounter"] = "SNAP"
        df_SNAP_Excluded_enddate_le_startdate["EncounterNumber"] = (
            df_SNAP_Excluded_enddate_le_startdate["EncounterNumber"]
        )
        df_SNAP_Excluded_enddate_le_startdate["stay_number"] = (
            df_SNAP_Excluded_enddate_le_startdate["stay_number_cost"]
            .astype(str)
            .str.replace("SN", "")
        )
        df_SNAP_Excluded_enddate_le_startdate["episode_sequence_number"] = (
            df_SNAP_Excluded_enddate_le_startdate["sa_episode_sequence_number"]
        )
        df_SNAP_Excluded_enddate_le_startdate["stay_number"] = (
            df_SNAP_Excluded_enddate_le_startdate["stay_number"]
            .astype(str)
            .str.pad(8, side="left", fillchar="0")
        )
        df_SNAP_Excluded_enddate_le_startdate["episode_sequence_number"] = (
            df_SNAP_Excluded_enddate_le_startdate["episode_sequence_number"]
            .astype(str)
            .str.pad(3, side="left", fillchar="0")
        )
        df_SNAP_Excluded_enddate_le_startdate["facility_identifier"] = (
            df_SNAP_Excluded_enddate_le_startdate["FacilityCode"]
        )
        df_SNAP_Excluded_enddate_le_startdate = df_SNAP_Excluded_enddate_le_startdate[
            [
                "facility_identifier",
                "stay_number",
                "episode_sequence_number",
                "ed_identifier",
                "SNAP_encounter",
                "ReasonForExclusion",
                "EncounterNumber",
            ]
        ]
        df_SNAP_Excluded_enddate_le_startdate = (
            df_SNAP_Excluded_enddate_le_startdate.fillna("")
        )
    else:
        df_SNAP_Excluded_enddate_le_startdate = pd.DataFrame(
            columns=[
                "facility_identifier",
                "stay_number",
                "episode_sequence_number",
                "ed_identifier",
                "SNAP_encounter",
                "ReasonForExclusion",
                "EncounterNumber",
            ]
        )
    df_SNAP_Excluded_enddate_le_startdate = df_SNAP_Excluded_enddate_le_startdate[
        df_SNAP_Excluded_enddate_le_startdate["facility_identifier"].isin(
            facilities_included_list_global
        )
    ]
    df_SNAP_Excluded_enddate_le_startdate = (
        df_SNAP_Excluded_enddate_le_startdate.applymap(str)
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    df_SNAP_Excluded_enddate_le_startdate = (
        df_SNAP_Excluded_enddate_le_startdate.applymap(
            lambda x: x.strip() if isinstance(x, str) else x
        )
    )
    df_SNAP_Excluded_enddate_le_startdate = df_SNAP_Excluded_enddate_le_startdate.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    # dropping duplicate values
    df_SNAP_Excluded_enddate_le_startdate.drop_duplicates(keep="last", inplace=True)
    df_SNAP_Excluded_enddate_le_startdate.to_csv(
        "./ExtractorDB/Excluded_SNAP_enddate_less_startdate.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    logging.info(
        "df_SNAP_Excluded_enddate_le_startdate created in ./ExtractorDB/Excluded_SNAP_enddate_less_startdate.csv with %s records.",
        len(df_SNAP_Excluded_enddate_le_startdate),
    )
    # exclude snap encounters that have been excluded,
    # df_SNAP_Excluded_enddate_le_startdate_list = df_SNAP_Excluded_enddate_le_startdate["EncounterNumber"].values.tolist()
    # snapApp_CostingExtract = snapApp_CostingExtract[~snapApp_CostingExtract['EncounterNumber'].isin(df_SNAP_Excluded_enddate_le_startdate_list)]
    # logging.info('snapApp_CostingExtract now has %s records after excluding SNAP Encounters Outside Costing Period.', len(snapApp_CostingExtract))
    """
    SnapNwau (SNAP_NWAU.xls) - given
        Totals records number from SnapNwau file is :
        If The file is missing from the 'Costing' folder, Error importing 'SNAP' Data. 
    """
    file_SNAP_NWAU = "./Costing/SNAP_NWAU.xlsx"
    if os.path.isfile(file_SNAP_NWAU):
        if extract_type == "new_extract":
            label_9_sub.configure(text="In Progress (SNAP_NWAU)...", fg="blue")
        try:
            snap_NWAU = pd.read_excel(file_SNAP_NWAU, keep_default_na=False)
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror("File Error", "Error extracting SNAP_NWAU.\n" + str(e))
            label_9_status = 0
        else:
            # snap_NWAU.columns = ['EncounterNumber', 'LHD', 'FacilityCode', 'stay_number_cost', 'sa_episode_sequence_number', 'SNAPEpisodeID', 'PCSNAP_PhaseID', 'payment_type', 'sa_specialty_code', 'sa_nwau_version', 'sa_nwau', 'sa_base_nwau', 'sa_public_equivalent_nwau', 'sa_indigenous_adj_nwau', 'sa_remoteness_adj_nwau', 'sa_private_service_adj_nwau', 'sa_private_accomm_adj_nwau', 'sa_dialysis_adj_nwau', 'sa_radiotherapy_adj_nwau', 'sa_treatment_remoteness_adj_nwau', 'SE_CBK_SK']
            snap_NWAU.columns = [
                "EncounterNumber",
                "LHD",
                "FacilityCode",
                "stay_number_cost",
                "sa_episode_sequence_number",
                "SNAPEpisodeID",
                "PCSNAP_PhaseID",
                "payment_type",
                "sa_specialty_code",
                "sa_nwau_version",
                "sa_nwau",
                "sa_base_nwau",
                "sa_public_equivalent_nwau",
                "sa_indigenous_adj_nwau",
                "sa_remoteness_adj_nwau",
                "sa_private_service_adj_nwau",
                "sa_private_accomm_adj_nwau",
                "sa_dialysis_adj_nwau",
                "sa_radiotherapy_adj_nwau",
                "sa_treatment_remoteness_adj_nwau",
                "SE_CBK_SK",
                "phase_sequence_number",
                "adm_date",
                "sep_date",
                "Phase_StartDate",
                "Phase_EndDate",
                "is_active",
            ]
            snap_NWAU.rename(columns={"payment_type": "payment type"}, inplace=True)

            snap_NWAU["sa_paediatric_adj_nwau"] = ""
            snap_NWAU = snap_NWAU[
                [
                    "stay_number_cost",
                    "FacilityCode",
                    "PCSNAP_PhaseID",
                    "SNAPEpisodeID",
                    "sa_episode_sequence_number",
                    "sa_base_nwau",
                    "sa_public_equivalent_nwau",
                    "sa_paediatric_adj_nwau",
                    "sa_indigenous_adj_nwau",
                    "sa_remoteness_adj_nwau",
                    "sa_private_service_adj_nwau",
                    "sa_private_accomm_adj_nwau",
                    "sa_radiotherapy_adj_nwau",
                    "payment type",
                    "sa_specialty_code",
                    "sa_nwau",
                    "sa_nwau_version",
                    "LHD",
                    "SE_CBK_SK",
                    "sa_treatment_remoteness_adj_nwau",
                    "sa_dialysis_adj_nwau",
                ]
            ]
            snap_NWAU = snap_NWAU.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            snap_NWAU = snap_NWAU.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            snap_NWAU = snap_NWAU.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )

            # remove records where SE_CBK_SK is blank
            snap_NWAU = snap_NWAU[
                (pd.notna(snap_NWAU["SE_CBK_SK"])) & (snap_NWAU["SE_CBK_SK"] != "")
            ]
            ############## 21 JAN 2025
            """
            snap_NWAU['stay_number_cost'] = snap_NWAU['stay_number_cost'].astype(str).str.pad(8, side ='left', fillchar ='0')
            snap_NWAU['sa_episode_sequence_number'] = snap_NWAU['sa_episode_sequence_number'].astype(str).str.pad(3, side ='left', fillchar ='0')
            """
            snap_NWAU["SNAPEpisodeID_dummy"] = (
                snap_NWAU["SNAPEpisodeID"]
                .astype(str)
                .str.pad(11, side="left", fillchar="0")
            )
            snap_NWAU["PCSNAP_PhaseID_dummy"] = (
                snap_NWAU["PCSNAP_PhaseID"]
                .astype(str)
                .str.pad(11, side="left", fillchar="0")
            )
            snap_NWAU["stay_number_cost_dummy"] = snap_NWAU["stay_number_cost"].apply(
                lambda x: str(x).split("-")[-1].zfill(8)
            )
            snap_NWAU["stay_number_cost"] = snap_NWAU["stay_number_cost_dummy"]
            snap_NWAU["sa_episode_sequence_number"] = (
                snap_NWAU["sa_episode_sequence_number"]
                .astype(str)
                .str.pad(3, side="left", fillchar="0")
            )

            # condlist = [((snapApp_CostingExtract['PCSNAP_PhaseID']== '') | (snapApp_CostingExtract['PCSNAP_PhaseID'].isnull())), ((snapApp_CostingExtract['PCSNAP_PhaseID']!= '') & (pd.notna(snapApp_CostingExtract['PCSNAP_PhaseID'])))]
            # choicelist = [snap_NWAU['FacilityCode'].astype(str).str.strip()+ "_" + snap_NWAU['SNAPEpisodeID_dummy'].astype(str).str.strip(),snap_NWAU['FacilityCode'].astype(str).str.strip()+ "_" + snap_NWAU['SNAPEpisodeID_dummy'].astype(str).str.strip()+ "_" +snap_NWAU['PCSNAP_PhaseID_dummy']]
            # snap_NWAU['EncounterNumber'] = np.select(condlist, choicelist, snap_NWAU['FacilityCode'].astype(str).str.strip()+ "-I-" + snap_NWAU['stay_number_cost_dummy'].astype(str).str.strip()+ "-" + snap_NWAU['sa_episode_sequence_number'].astype(str).str.strip())

            snap_NWAU = pd.merge(
                snap_NWAU,
                snapApp_CostingExtract[
                    [
                        "EncounterNumber",
                        "SNAPEpisodeID",
                        "PCSNAP_PhaseID",
                        "SE_CBK_SK",
                        "stay_number_cost",
                        "sa_episode_sequence_number",
                    ]
                ],
                how="inner",
                on=[
                    "SNAPEpisodeID",
                    "PCSNAP_PhaseID",
                    "SE_CBK_SK",
                    "stay_number_cost",
                    "sa_episode_sequence_number",
                ],
                suffixes=("", "_drop"),
                indicator=False,
            )
            snap_NWAU = snap_NWAU[
                [
                    "stay_number_cost",
                    "FacilityCode",
                    "PCSNAP_PhaseID",
                    "SNAPEpisodeID",
                    "sa_episode_sequence_number",
                    "sa_base_nwau",
                    "sa_public_equivalent_nwau",
                    "sa_paediatric_adj_nwau",
                    "sa_indigenous_adj_nwau",
                    "sa_remoteness_adj_nwau",
                    "sa_private_service_adj_nwau",
                    "sa_private_accomm_adj_nwau",
                    "sa_radiotherapy_adj_nwau",
                    "payment type",
                    "sa_specialty_code",
                    "sa_nwau",
                    "sa_nwau_version",
                    "LHD",
                    "SE_CBK_SK",
                    "EncounterNumber",
                    "sa_treatment_remoteness_adj_nwau",
                    "sa_dialysis_adj_nwau",
                ]
            ]
            ##########################

            # filter by lhd
            snap_NWAU = snap_NWAU[
                snap_NWAU["FacilityCode"].isin(facilities_included_list)
            ]
            snap_NWAU = snap_NWAU[
                pd.notna(snap_NWAU["FacilityCode"]) & (snap_NWAU["FacilityCode"] != "")
            ]
            snap_NWAU["sa_nwau"].fillna(0, inplace=True)
            snap_NWAU["sa_nwau"] = np.where(
                (snap_NWAU["sa_nwau"].isnull()) | (snap_NWAU["sa_nwau"] == ""),
                0,
                snap_NWAU["sa_nwau"],
            )
            tbl_ExcludedEncounters_snap_nwau_dummy = tbl_ExcludedEncounters.copy()
            snap_NWAU = pd.merge(
                snap_NWAU,
                tbl_ExcludedEncounters_snap_nwau_dummy[["EncounterNumber"]],
                how="left",
                on=["EncounterNumber"],
                suffixes=("", "_drop"),
                indicator=True,
            )
            snap_NWAU = snap_NWAU[snap_NWAU["_merge"] == "left_only"]
            snap_NWAU.drop(columns=["_merge"], inplace=True)
            logging.info(
                "SNAP_NWAU has %s records from ./Costing/SNAP_NWAU.xls", len(snap_NWAU)
            )
            # filter by nwau version
            """
            snap_NWAU = snap_NWAU[snap_NWAU['sa_nwau_version']==nwau_v]
            logging.info('SNAP_NWAU has %s records with sa_nwau_version = %s', len(snap_NWAU),nwau_v)
            """
            # print("snap_NWAU=",len(snap_NWAU))
            # label_9_status = 1
    else:
        snap_NWAU = pd.DataFrame(
            columns=[
                "stay_number_cost",
                "FacilityCode",
                "PCSNAP_PhaseID",
                "SNAPEpisodeID",
                "sa_episode_sequence_number",
                "sa_base_nwau",
                "sa_public_equivalent_nwau",
                "sa_paediatric_adj_nwau",
                "sa_indigenous_adj_nwau",
                "sa_remoteness_adj_nwau",
                "sa_private_service_adj_nwau",
                "sa_private_accomm_adj_nwau",
                "sa_radiotherapy_adj_nwau",
                "payment type",
                "sa_specialty_code",
                "sa_nwau",
                "sa_nwau_version",
                "EncounterNumber",
                "LHD",
                "SE_CBK_SK",
                "sa_treatment_remoteness_adj_nwau",
                "sa_dialysis_adj_nwau",
            ]
        )
        # messagebox.showerror("File Error","Error extracting SNAP_NWAU")
        # label_9_status = 1
    logging.info(
        "snap_NWAU created with %s records from ./Costing/SNAP_NWAU.xls.",
        len(snap_NWAU),
    )
    """
    SNAPRec.xls - given
        If The file is missing from the 'Costing' folder, Error importing 'SNAP' Data. 
        Totals records number from SnapRec file is :
    """
    file_SNAPRec = "./Costing/SNAPRec.xls"
    if os.path.isfile(file_SNAPRec):
        if extract_type == "new_extract":
            label_9_sub.configure(text="In Progress (SNAPRec)...", fg="blue")
        try:
            df_SNAPRec = pd.read_excel(file_SNAPRec, keep_default_na=False)
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror("File Error", "Error extracting SNAPRec.\n" + str(e))
            label_9_status = 0
        else:
            df_SNAPRec = df_SNAPRec.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            df_SNAPRec = df_SNAPRec.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            df_SNAPRec = df_SNAPRec.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            # filter by lhd and exclude facilityid
            # print("df_SNAPRec=",len(df_SNAPRec))
            # label_9_status = 1
    # else:
    # messagebox.showerror("File Error","Error extracting SNAPRec")
    # label_9_status = 1
    logging.info(
        "df_SNAPRec created with %s records from ./Costing/SNAPRec.xls.",
        len(df_SNAPRec),
    )
    """
    PLA_Mapping_00 - given,mandatory
        Totals records number from PLA_Mapping_00 file is :
    """
    file_PLA_Mapping_00 = "./Costing/PLA_Mapping_00.csv"
    if os.path.isfile(file_PLA_Mapping_00):
        if extract_type == "new_extract":
            label_9_sub.configure(text="In Progress (PLA_Mapping_00)...", fg="blue")
        try:
            df_PLA_Mapping_00 = read_csv_file(
                file_PLA_Mapping_00,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error", "Error extracting PLA_Mapping_00.\n" + str(e)
            )
            label_9_status = 0
        else:
            df_PLA_Mapping_00 = df_PLA_Mapping_00.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            df_PLA_Mapping_00 = df_PLA_Mapping_00.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            df_PLA_Mapping_00 = df_PLA_Mapping_00.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            df_PLA_Mapping_00 = df_PLA_Mapping_00.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
            # print("df_PLA_Mapping_00=",len(df_PLA_Mapping_00))
    else:
        messagebox.showerror(
            "File Error", "Error extracting PLA_Mapping_00. File is missing."
        )
        label_9_status = 0
    logging.info(
        "df_PLA_Mapping_00 created with %s records from ./Costing/PLA_Mapping_00.csv.",
        len(df_PLA_Mapping_00),
    )
    """
    PLA_AMHCC - given,mandatory
        Totals records number from PLA_AMHCC file is :
    """
    file_PLA_AMHCC = "./Costing/PLA_AMHCC.csv"
    if os.path.isfile(file_PLA_AMHCC):
        if extract_type == "new_extract":
            label_9_sub.configure(text="In Progress (PLA_AMHCC)...", fg="blue")
        try:
            df_PLA_AMHCC = read_csv_file(
                file_PLA_AMHCC,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror("File Error", "Error extracting PLA_AMHCC.\n" + str(e))
            label_9_status = 0
        else:
            df_PLA_AMHCC = df_PLA_AMHCC.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            df_PLA_AMHCC = df_PLA_AMHCC.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            df_PLA_AMHCC = df_PLA_AMHCC.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            df_PLA_AMHCC = df_PLA_AMHCC.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
            # print("df_PLA_AMHCC=",len(df_PLA_AMHCC))
    else:
        messagebox.showerror(
            "File Error", "Error extracting PLA_AMHCC. File is missing."
        )
        label_9_status = 0
    logging.info(
        "df_PLA_AMHCC created with %s records from ./Costing/PLA_AMHCC.csv.",
        len(df_PLA_AMHCC),
    )
    """
    Class_Descriptions - given,mandatory
        Totals records number from Class_Descriptions file is :
    """
    file_Class_Descriptions = "./Costing/Class_Descriptions.csv"
    if os.path.isfile(file_Class_Descriptions):
        if extract_type == "new_extract":
            label_9_sub.configure(text="In Progress (Class_Descriptions)...", fg="blue")
        try:
            df_Class_Descriptions = read_csv_file(
                file_Class_Descriptions,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error", "Error extracting Class_Descriptions.\n" + str(e)
            )
            label_9_status = 0
        else:
            df_Class_Descriptions = df_Class_Descriptions.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            df_Class_Descriptions = df_Class_Descriptions.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            df_Class_Descriptions = df_Class_Descriptions.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            df_Class_Descriptions = df_Class_Descriptions.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
            # print("df_Class_Descriptions=",len(df_Class_Descriptions))
    else:
        messagebox.showerror(
            "File Error", "Error extracting Class_Descriptions. File is missing."
        )
        label_9_status = 0
    logging.info(
        "df_Class_Descriptions created with %s records from ./Costing/Class_Descriptions.csv.",
        len(df_Class_Descriptions),
    )
    """
    SpecialtyPortalValues (SpecialtyPortal.txt) - given,mandatory
        Totals records number from SpecialtyPortalValues file is :
    """
    file_SpecialtyPortalValues = "./Costing/SpecialtyPortal.txt"
    if os.path.isfile(file_SpecialtyPortalValues):
        if extract_type == "new_extract":
            label_9_sub.configure(
                text="In Progress (SpecialtyPortalValues)...", fg="blue"
            )
        try:
            df_SpecialtyPortalValues = read_csv_file(
                file_SpecialtyPortalValues,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error", "Error extracting SpecialtyPortalValues.\n" + str(e)
            )
            label_9_status = 0
        else:
            df_SpecialtyPortalValues = df_SpecialtyPortalValues.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            df_SpecialtyPortalValues = df_SpecialtyPortalValues.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            df_SpecialtyPortalValues = df_SpecialtyPortalValues.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            df_SpecialtyPortalValues = df_SpecialtyPortalValues.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
            # print("df_SpecialtyPortalValues=",len(df_SpecialtyPortalValues))
    else:
        messagebox.showerror(
            "File Error", "Error extracting SpecialtyPortalValues. File is missing."
        )
        label_9_status = 0
    logging.info(
        "df_SpecialtyPortalValues created with %s records from ./Costing/SpecialtyPortal.txt.",
        len(df_SpecialtyPortalValues),
    )
    """
    MDC - given
        Totals records number from MDC file is :
    """
    file_MDC = "./Costing/MDC.csv"
    if os.path.isfile(file_MDC):
        if extract_type == "new_extract":
            label_9_sub.configure(text="In Progress (MDC)...", fg="blue")
        try:
            df_MDC = read_csv_file(
                file_MDC,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror("File Error", "Error extracting MDC.\n" + str(e))
            label_9_status = 0
        else:
            df_MDC = df_MDC.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            df_MDC = df_MDC.applymap(lambda x: x.strip() if isinstance(x, str) else x)
            df_MDC = df_MDC.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            df_MDC = df_MDC.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
            # print("df_MDC=",len(df_MDC))
    else:
        messagebox.showerror("File Error", "Error extracting MDC. File is missing.")
        label_9_status = 0
    logging.info("df_MDC created with %s records from ./Costing/MDC.csv.", len(df_MDC))
    if extract_type == "new_extract":
        # Update Sub task status
        if label_9_status == 0:
            label_9_sub.configure(text="Failed", fg="red")
            main_screen.update()
        else:
            label_9_sub.configure(text="Completed", fg="green")
            logging.info("Extract of snap files completed")
            main_screen.update()
        """label_9_res.configure(text="SNAP_CostingExtract:"+str(len(snapApp_CostingExtract))+",  SNAPRec:"+str(len(df_SNAPRec))+",  SNAP_NWAU:"+str(len(snap_NWAU))+"\nEdRoleDelin:"+str(len(df_EdRoleDelin))+",  ICU_RoleDelin:"+str(len(df_ICU_RoleDelin))+",  SpecialtyPortalMapping:"+str(len(df_SpecialtyPortalMapping))+"\nCriticalCareGroup:"+str(len(df_CriticalCareGroup))+",  PLA_Role:"+str(len(df_PLA_Role_Table))+",  PLA_Mapping:"+str(len(df_PLA_Mapping_00))+"\nPLA_AMHCC:"+str(len(df_PLA_AMHCC))+",  Class_Descriptions:"+str(len(df_Class_Descriptions))+",  SpecialtyPortalValues:"+str(len(df_SpecialtyPortalValues))+",  MDC:"+str(len(df_MDC)), justify=LEFT)"""
        # label_9_res.configure(text="SNAP_CostingExtract:"+str(len(snapApp_CostingExtract))+", SNAPRec:"+str(len(df_SNAPRec))+", SNAP_NWAU:"+str(len(snap_NWAU))+",\nPLA_Mapping:"+str(len(df_PLA_Mapping_00))+", PLA_AMHCC:"+str(len(df_PLA_AMHCC))+",\nClass_Descriptions:"+str(len(df_Class_Descriptions))+", SpecialtyPortalValues:"+str(len(df_SpecialtyPortalValues))+",  MDC:"+str(len(df_MDC)), justify=LEFT)
        main_screen.update()
    ############################ NEW CODE FOR AMHCC - START #######################################
    # Set default value of sub-task status to 1
    label_10_status = 1
    file_AMHCC_extract = "./Costing/AMHCC_extract.csv"
    if os.path.isfile(file_AMHCC_extract):
        if extract_type == "new_extract":
            label_10_sub.configure(text="In Progress (AMHCC_extract)...", fg="blue")
        try:
            df_AMHCC_extract = read_csv_file(
                file_AMHCC_extract,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error", "Error extracting AMHCC_extract.\n" + str(e)
            )
            label_10_status = 0
        else:
            # new AMHCC columns
            #'SE_CBK_SK', 'MRN', 'STAY_NUMBER', 'PHASEOFCARE', 'PHASE_NUMBER', 'STARTDATETIME_COSTING', 'ENDDATETIME_COSTING', 'HONOS1', 'HONOS2', 'HONOS3', 'HONOS4', 'HONOS5', 'HONOS6', 'HONOS7', 'HONOS8', 'HONOS9', 'HONOS10', 'HONOS11', 'HONOS12', 'HONOS65_1', 'HONOS65_2', 'HONOS65_3', 'HONOS65_4', 'HONOS65_5', 'HONOS65_6', 'HONOS65_7', 'HONOS65_8', 'HONOS65_9', 'HONOS65_10', 'HONOS65_11', 'HONOS65_12', 'HONOSCA1', 'HONOSCA2', 'HONOSCA3', 'HONOSCA4', 'HONOSCA5', 'HONOSCA6', 'HONOSCA7', 'HONOSCA8', 'HONOSCA9', 'HONOSCA10', 'HONOSCA11', 'HONOSCA12', 'HONOSCA13', 'HONOSCA14', 'HONOSCA15', 'HON1', 'HON2', 'HON3', 'HON4', 'HON5', 'HON6', 'HON7', 'HON8', 'HON9', 'HON10', 'HON11', 'HON12', 'HON13', 'HON14', 'HON15', 'IHPA_LSP_01', 'IHPA_LSP_02', 'IHPA_LSP_03', 'IHPA_LSP_04', 'IHPA_LSP_05', 'IHPA_LSP_06', 'IHPA_LSP_07', 'IHPA_LSP_08', 'IHPA_LSP_09', 'IHPA_LSP_10', 'IHPA_LSP_11', 'IHPA_LSP_12', 'IHPA_LSP_13', 'IHPA_LSP_14', 'IHPA_LSP_15', 'IHPA_LSP_16', 'HOSPITAL', 'ENCOUNTERNUMBER', 'AUID', 'HIE_SEQUENCE_NUMBER', 'CLASS', 'PHASE_LOS_EXCLUDE_LEAVE', 'PHASE_LEAVEDAYS', 'NWAU23', 'NWAU24', 'NWAU25', 'ExtractDate'
            df_AMHCC_extract.columns = [
                "SE_CBK_SK",
                "MRN",
                "STAY_NUMBER",
                "PHASEOFCARE",
                "PHASE_NUMBER",
                "STARTDATETIME_COSTING",
                "ENDDATETIME_COSTING",
                "HONOS1",
                "HONOS2",
                "HONOS3",
                "HONOS4",
                "HONOS5",
                "HONOS6",
                "HONOS7",
                "HONOS8",
                "HONOS9",
                "HONOS10",
                "HONOS11",
                "HONOS12",
                "HONOS65_1",
                "HONOS65_2",
                "HONOS65_3",
                "HONOS65_4",
                "HONOS65_5",
                "HONOS65_6",
                "HONOS65_7",
                "HONOS65_8",
                "HONOS65_9",
                "HONOS65_10",
                "HONOS65_11",
                "HONOS65_12",
                "HONOSCA1",
                "HONOSCA2",
                "HONOSCA3",
                "HONOSCA4",
                "HONOSCA5",
                "HONOSCA6",
                "HONOSCA7",
                "HONOSCA8",
                "HONOSCA9",
                "HONOSCA10",
                "HONOSCA11",
                "HONOSCA12",
                "HONOSCA13",
                "HONOSCA14",
                "HONOSCA15",
                "HON1",
                "HON2",
                "HON3",
                "HON4",
                "HON5",
                "HON6",
                "HON7",
                "HON8",
                "HON9",
                "HON10",
                "HON11",
                "HON12",
                "HON13",
                "HON14",
                "HON15",
                "IHPA_LSP_01",
                "IHPA_LSP_02",
                "IHPA_LSP_03",
                "IHPA_LSP_04",
                "IHPA_LSP_05",
                "IHPA_LSP_06",
                "IHPA_LSP_07",
                "IHPA_LSP_08",
                "IHPA_LSP_09",
                "IHPA_LSP_10",
                "IHPA_LSP_11",
                "IHPA_LSP_12",
                "IHPA_LSP_13",
                "IHPA_LSP_14",
                "IHPA_LSP_15",
                "IHPA_LSP_16",
                "HOSPITAL",
                "ENCOUNTERNUMBER",
                "AUID",
                "HIE_SEQUENCE_NUMBER",
                "CLASS",
                "PHASE_LOS_EXCLUDE_LEAVE",
                "PHASE_LEAVEDAYS",
                "NWAU23",
                "NWAU24",
                "NWAU25",
                "ExtractDate",
            ]

            # 06 August 2025 fix. AMHCC file may contain NULL values.
            df_AMHCC_extract.replace("NULL", "", inplace=True)

            # Convert nwau_v to string
            nwau_column = f"NWAU{str(nwau_v)}"
            # rename new column names to old AMHCC column names
            df_AMHCC_extract.rename(
                columns={
                    "STARTDATETIME_COSTING": "STARTDATETIME",
                    "ENDDATETIME_COSTING": "ENDDATETIME",
                    "ExtractDate": "EXTRACTDATE",
                    "MRN": "mrn",
                    "STAY_NUMBER": "HIE_STAY_NUMBER",
                    "PHASE_LOS_EXCLUDE_LEAVE": "LENGTHOFSTAY",
                    "PHASE_LEAVEDAYS": "LEAVEDAYS",
                    nwau_column: "NWAU",
                    "PHASE_NUMBER": "PHASESEQNO",
                },
                inplace=True,
            )
            # assign null values to columns missing in new file.
            df_AMHCC_extract["DIM_CLIENT_ID_SK"] = ""
            df_AMHCC_extract["EPISODE_START_DATE"] = (
                ""  # new file does not have Episode start date column.
            )
            df_AMHCC_extract["NWAU_VERSION"] = nwau_v
            df_AMHCC_extract["AMHCC_CLASS_VERSION"] = df_AMHCC_extract["CLASS"]
            df_AMHCC_extract["PHASE_DAYS_IN_PSYCH"] = ""
            df_AMHCC_extract["FINANCIAL_CLASS"] = ""
            # df_AMHCC_extract['EPISODE_START_DATE'] = pd.to_datetime(df_AMHCC_extract['EPISODE_START_DATE'], errors='coerce', format="%d/%m/%Y")
            df_AMHCC_extract["STARTDATETIME"] = pd.to_datetime(
                df_AMHCC_extract["STARTDATETIME"], errors="coerce", format="%d/%m/%Y"
            )
            df_AMHCC_extract["ENDDATETIME"] = pd.to_datetime(
                df_AMHCC_extract["ENDDATETIME"], errors="coerce", format="%d/%m/%Y"
            )
            # df_AMHCC_extract['EXTRACTDATE'] = pd.to_datetime(df_AMHCC_extract['EXTRACTDATE'], errors='coerce', format="%d/%m/%Y %H:%M:%S")
            # new column format
            df_AMHCC_extract["EXTRACTDATE"] = pd.to_datetime(
                df_AMHCC_extract["EXTRACTDATE"],
                errors="coerce",
                format="%d/%m/%Y %H:%M",
            )
            # df_AMHCC_extract['STARTDATETIME'] = pd.to_datetime(df_AMHCC_extract['STARTDATETIME'], errors='coerce', format="%Y-%m-%d")
            # df_AMHCC_extract['ENDDATETIME'] = pd.to_datetime(df_AMHCC_extract['ENDDATETIME'], errors='coerce', format="%Y-%m-%d")

            df_AMHCC_extract = df_AMHCC_extract[
                [
                    "SE_CBK_SK",
                    "DIM_CLIENT_ID_SK",
                    "ENCOUNTERNUMBER",
                    "HOSPITAL",
                    "EPISODE_START_DATE",
                    "STARTDATETIME",
                    "ENDDATETIME",
                    "mrn",
                    "AUID",
                    "HIE_STAY_NUMBER",
                    "HIE_SEQUENCE_NUMBER",
                    "PHASEOFCARE",
                    "CLASS",
                    "LENGTHOFSTAY",
                    "LEAVEDAYS",
                    "HON1",
                    "HON2",
                    "HON3",
                    "HON4",
                    "HON5",
                    "HON6",
                    "HON7",
                    "HON8",
                    "HON9",
                    "HON10",
                    "HON11",
                    "HON12",
                    "HON13",
                    "HON14",
                    "HON15",
                    "HONOS1",
                    "HONOS2",
                    "HONOS3",
                    "HONOS4",
                    "HONOS5",
                    "HONOS6",
                    "HONOS7",
                    "HONOS8",
                    "HONOS9",
                    "HONOS10",
                    "HONOS11",
                    "HONOS12",
                    "HONOS65_1",
                    "HONOS65_2",
                    "HONOS65_3",
                    "HONOS65_4",
                    "HONOS65_5",
                    "HONOS65_6",
                    "HONOS65_7",
                    "HONOS65_8",
                    "HONOS65_9",
                    "HONOS65_10",
                    "HONOS65_11",
                    "HONOS65_12",
                    "HONOSCA1",
                    "HONOSCA2",
                    "HONOSCA3",
                    "HONOSCA4",
                    "HONOSCA5",
                    "HONOSCA6",
                    "HONOSCA7",
                    "HONOSCA8",
                    "HONOSCA9",
                    "HONOSCA10",
                    "HONOSCA11",
                    "HONOSCA12",
                    "HONOSCA13",
                    "HONOSCA14",
                    "HONOSCA15",
                    "IHPA_LSP_01",
                    "IHPA_LSP_02",
                    "IHPA_LSP_03",
                    "IHPA_LSP_04",
                    "IHPA_LSP_05",
                    "IHPA_LSP_06",
                    "IHPA_LSP_07",
                    "IHPA_LSP_08",
                    "IHPA_LSP_09",
                    "IHPA_LSP_10",
                    "IHPA_LSP_11",
                    "IHPA_LSP_12",
                    "IHPA_LSP_13",
                    "IHPA_LSP_14",
                    "IHPA_LSP_15",
                    "IHPA_LSP_16",
                    "NWAU",
                    "NWAU_VERSION",
                    "EXTRACTDATE",
                    "AMHCC_CLASS_VERSION",
                    "PHASESEQNO",
                    "PHASE_DAYS_IN_PSYCH",
                    "FINANCIAL_CLASS",
                ]
            ]
            df_AMHCC_extract = df_AMHCC_extract.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            df_AMHCC_extract = df_AMHCC_extract.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            df_AMHCC_extract = df_AMHCC_extract.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            df_AMHCC_extract = df_AMHCC_extract.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
            df_AMHCC_extract["HIE_STAY_NUMBER"] = (
                df_AMHCC_extract["HIE_STAY_NUMBER"]
                .astype(str)
                .str.pad(8, side="left", fillchar="0")
            )
            df_AMHCC_extract["HIE_SEQUENCE_NUMBER"] = (
                df_AMHCC_extract["HIE_SEQUENCE_NUMBER"]
                .astype(str)
                .str.pad(3, side="left", fillchar="0")
            )
            # filter by lhd
            df_AMHCC_extract = df_AMHCC_extract[
                df_AMHCC_extract["HOSPITAL"].isin(facilities_included_list)
            ]
            logging.info(
                "There are %s records read from ./Costing/AMHCC_extract.csv",
                len(df_AMHCC_extract),
            )
            tbl_ExcludedEncounters_amhcc_dummy = tbl_ExcludedEncounters.copy()
            df_AMHCC_extract = pd.merge(
                df_AMHCC_extract,
                tbl_ExcludedEncounters_amhcc_dummy[["EncounterNumber"]],
                how="left",
                right_on=["EncounterNumber"],
                left_on=["ENCOUNTERNUMBER"],
                suffixes=("", "_drop"),
                indicator=True,
            )
            df_AMHCC_extract = df_AMHCC_extract[
                df_AMHCC_extract["_merge"] == "left_only"
            ]
            df_AMHCC_extract.drop(columns=["_merge"], inplace=True)
            # remove records where SE_CBK_SK is blank
            df_AMHCC_extract = df_AMHCC_extract[
                (pd.notna(df_AMHCC_extract["SE_CBK_SK"]))
                & (df_AMHCC_extract["SE_CBK_SK"] != "")
            ]
    else:
        df_AMHCC_extract = pd.DataFrame(
            columns=[
                "SE_CBK_SK",
                "DIM_CLIENT_ID_SK",
                "ENCOUNTERNUMBER",
                "HOSPITAL",
                "EPISODE_START_DATE",
                "STARTDATETIME",
                "ENDDATETIME",
                "mrn",
                "AUID",
                "HIE_STAY_NUMBER",
                "HIE_SEQUENCE_NUMBER",
                "PHASEOFCARE",
                "CLASS",
                "LENGTHOFSTAY",
                "LEAVEDAYS",
                "HON1",
                "HON2",
                "HON3",
                "HON4",
                "HON5",
                "HON6",
                "HON7",
                "HON8",
                "HON9",
                "HON10",
                "HON11",
                "HON12",
                "HON13",
                "HON14",
                "HON15",
                "HONOS1",
                "HONOS2",
                "HONOS3",
                "HONOS4",
                "HONOS5",
                "HONOS6",
                "HONOS7",
                "HONOS8",
                "HONOS9",
                "HONOS10",
                "HONOS11",
                "HONOS12",
                "HONOS65_1",
                "HONOS65_2",
                "HONOS65_3",
                "HONOS65_4",
                "HONOS65_5",
                "HONOS65_6",
                "HONOS65_7",
                "HONOS65_8",
                "HONOS65_9",
                "HONOS65_10",
                "HONOS65_11",
                "HONOS65_12",
                "HONOSCA1",
                "HONOSCA2",
                "HONOSCA3",
                "HONOSCA4",
                "HONOSCA5",
                "HONOSCA6",
                "HONOSCA7",
                "HONOSCA8",
                "HONOSCA9",
                "HONOSCA10",
                "HONOSCA11",
                "HONOSCA12",
                "HONOSCA13",
                "HONOSCA14",
                "HONOSCA15",
                "IHPA_LSP_01",
                "IHPA_LSP_02",
                "IHPA_LSP_03",
                "IHPA_LSP_04",
                "IHPA_LSP_05",
                "IHPA_LSP_06",
                "IHPA_LSP_07",
                "IHPA_LSP_08",
                "IHPA_LSP_09",
                "IHPA_LSP_10",
                "IHPA_LSP_11",
                "IHPA_LSP_12",
                "IHPA_LSP_13",
                "IHPA_LSP_14",
                "IHPA_LSP_15",
                "IHPA_LSP_16",
                "NWAU",
                "NWAU_VERSION",
                "EXTRACTDATE",
                "AMHCC_CLASS_VERSION",
                "PHASESEQNO",
                "PHASE_DAYS_IN_PSYCH",
                "FINANCIAL_CLASS",
            ]
        )
        # Ranjit: as amhcc is not a mandatory file, no need to show error message, if file is missing
        # messagebox.showerror("File Error","Error extracting AMHCC_extract")
        # label_10_status = 1

    # Access query: AMHCC_Extract
    amhcc_extract = df_AMHCC_extract[
        [
            "SE_CBK_SK",
            "DIM_CLIENT_ID_SK",
            "ENCOUNTERNUMBER",
            "HOSPITAL",
            "EPISODE_START_DATE",
            "STARTDATETIME",
            "ENDDATETIME",
            "mrn",
            "AUID",
            "HIE_STAY_NUMBER",
            "HIE_SEQUENCE_NUMBER",
            "PHASEOFCARE",
            "CLASS",
            "LENGTHOFSTAY",
            "LEAVEDAYS",
            "HON1",
            "HON2",
            "HON3",
            "HON4",
            "HON5",
            "HON6",
            "HON7",
            "HON8",
            "HON9",
            "HON10",
            "HON11",
            "HON12",
            "HON13",
            "HON14",
            "HON15",
            "HONOS1",
            "HONOS2",
            "HONOS3",
            "HONOS4",
            "HONOS5",
            "HONOS6",
            "HONOS7",
            "HONOS8",
            "HONOS9",
            "HONOS10",
            "HONOS11",
            "HONOS12",
            "HONOS65_1",
            "HONOS65_2",
            "HONOS65_3",
            "HONOS65_4",
            "HONOS65_5",
            "HONOS65_6",
            "HONOS65_7",
            "HONOS65_8",
            "HONOS65_9",
            "HONOS65_10",
            "HONOS65_11",
            "HONOS65_12",
            "HONOSCA1",
            "HONOSCA2",
            "HONOSCA3",
            "HONOSCA4",
            "HONOSCA5",
            "HONOSCA6",
            "HONOSCA7",
            "HONOSCA8",
            "HONOSCA9",
            "HONOSCA10",
            "HONOSCA11",
            "HONOSCA12",
            "HONOSCA13",
            "HONOSCA14",
            "HONOSCA15",
            "IHPA_LSP_01",
            "IHPA_LSP_02",
            "IHPA_LSP_03",
            "IHPA_LSP_04",
            "IHPA_LSP_05",
            "IHPA_LSP_06",
            "IHPA_LSP_07",
            "IHPA_LSP_08",
            "IHPA_LSP_09",
            "IHPA_LSP_10",
            "IHPA_LSP_11",
            "IHPA_LSP_12",
            "IHPA_LSP_13",
            "IHPA_LSP_14",
            "IHPA_LSP_15",
            "IHPA_LSP_16",
            "NWAU",
            "NWAU_VERSION",
            "EXTRACTDATE",
            "PHASESEQNO",
        ]
    ]
    amhcc_extract["PhaseSeqNo"] = amhcc_extract["PHASESEQNO"]
    amhcc_extract["NWAUVERSION"] = amhcc_extract["NWAU_VERSION"]
    amhcc_extract = amhcc_extract[
        [
            "SE_CBK_SK",
            "DIM_CLIENT_ID_SK",
            "ENCOUNTERNUMBER",
            "HOSPITAL",
            "EPISODE_START_DATE",
            "STARTDATETIME",
            "ENDDATETIME",
            "mrn",
            "AUID",
            "HIE_STAY_NUMBER",
            "HIE_SEQUENCE_NUMBER",
            "PHASEOFCARE",
            "CLASS",
            "LENGTHOFSTAY",
            "LEAVEDAYS",
            "HON1",
            "HON2",
            "HON3",
            "HON4",
            "HON5",
            "HON6",
            "HON7",
            "HON8",
            "HON9",
            "HON10",
            "HON11",
            "HON12",
            "HON13",
            "HON14",
            "HON15",
            "HONOS1",
            "HONOS2",
            "HONOS3",
            "HONOS4",
            "HONOS5",
            "HONOS6",
            "HONOS7",
            "HONOS8",
            "HONOS9",
            "HONOS10",
            "HONOS11",
            "HONOS12",
            "HONOS65_1",
            "HONOS65_2",
            "HONOS65_3",
            "HONOS65_4",
            "HONOS65_5",
            "HONOS65_6",
            "HONOS65_7",
            "HONOS65_8",
            "HONOS65_9",
            "HONOS65_10",
            "HONOS65_11",
            "HONOS65_12",
            "HONOSCA1",
            "HONOSCA2",
            "HONOSCA3",
            "HONOSCA4",
            "HONOSCA5",
            "HONOSCA6",
            "HONOSCA7",
            "HONOSCA8",
            "HONOSCA9",
            "HONOSCA10",
            "HONOSCA11",
            "HONOSCA12",
            "HONOSCA13",
            "HONOSCA14",
            "HONOSCA15",
            "IHPA_LSP_01",
            "IHPA_LSP_02",
            "IHPA_LSP_03",
            "IHPA_LSP_04",
            "IHPA_LSP_05",
            "IHPA_LSP_06",
            "IHPA_LSP_07",
            "IHPA_LSP_08",
            "IHPA_LSP_09",
            "IHPA_LSP_10",
            "IHPA_LSP_11",
            "IHPA_LSP_12",
            "IHPA_LSP_13",
            "IHPA_LSP_14",
            "IHPA_LSP_15",
            "IHPA_LSP_16",
            "NWAU",
            "NWAUVERSION",
            "EXTRACTDATE",
            "PhaseSeqNo",
        ]
    ]
    logging.info(
        "amhcc_extract created with %s records from ./Costing/AMHCC_extract.csv.",
        len(amhcc_extract),
    )
    amhcc_extract_original = amhcc_extract.copy()
    # Ranjit: Query I wrote to exclude AMHCC Encounters Outside Costing Period
    amhcc_extract = amhcc_extract[
        ~(
            pd.to_datetime(
                amhcc_extract_original["STARTDATETIME"],
                errors="coerce",
                format="%Y-%m-%d %H:%M:%S",
            )
            > pd.to_datetime(end_date, format="%Y-%m-%d %H:%M:%S")
        )
    ]
    # +pd.DateOffset(1)
    logging.info(
        "amhcc_extract now has %s records after excluding AMHCC Encounters Outside Costing Period.",
        len(amhcc_extract),
    )
    # dropping duplicate values
    amhcc_extract.drop_duplicates(keep="last", inplace=True)
    amhcc_extract.to_csv(
        "./ExtractorDB/AMHCC_Extract.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    df_AMHCC_Excluded_enddate_le_startdate = amhcc_extract_original[
        (
            pd.to_datetime(
                amhcc_extract_original["STARTDATETIME"],
                errors="coerce",
                format="%Y-%m-%d %H:%M:%S",
            )
            > pd.to_datetime(end_date, format="%Y-%m-%d %H:%M:%S")
        )
    ]
    # +pd.DateOffset(1)
    if len(df_AMHCC_Excluded_enddate_le_startdate) > 0:
        df_AMHCC_Excluded_enddate_le_startdate["ReasonForExclusion"] = (
            "AMHCC Encounter Outside Costing Period"
        )
        df_AMHCC_Excluded_enddate_le_startdate["ed_identifier"] = "XXXXXXXXXX"
        df_AMHCC_Excluded_enddate_le_startdate["SNAP_encounter"] = "AMHCC"
        df_AMHCC_Excluded_enddate_le_startdate["EncounterNumber"] = (
            df_AMHCC_Excluded_enddate_le_startdate["ENCOUNTERNUMBER"]
        )
        df_AMHCC_Excluded_enddate_le_startdate["stay_number"] = (
            df_AMHCC_Excluded_enddate_le_startdate["HIE_STAY_NUMBER"]
        )
        df_AMHCC_Excluded_enddate_le_startdate["episode_sequence_number"] = (
            df_AMHCC_Excluded_enddate_le_startdate["HIE_SEQUENCE_NUMBER"]
        )
        df_AMHCC_Excluded_enddate_le_startdate["facility_identifier"] = (
            df_AMHCC_Excluded_enddate_le_startdate["HOSPITAL"]
        )
        df_AMHCC_Excluded_enddate_le_startdate = df_AMHCC_Excluded_enddate_le_startdate[
            [
                "facility_identifier",
                "stay_number",
                "episode_sequence_number",
                "ed_identifier",
                "SNAP_encounter",
                "ReasonForExclusion",
                "EncounterNumber",
            ]
        ]
        df_AMHCC_Excluded_enddate_le_startdate = (
            df_AMHCC_Excluded_enddate_le_startdate.fillna("")
        )
    else:
        df_AMHCC_Excluded_enddate_le_startdate = pd.DataFrame(
            columns=[
                "facility_identifier",
                "stay_number",
                "episode_sequence_number",
                "ed_identifier",
                "SNAP_encounter",
                "ReasonForExclusion",
                "EncounterNumber",
            ]
        )
    df_AMHCC_Excluded_enddate_le_startdate = df_AMHCC_Excluded_enddate_le_startdate[
        df_AMHCC_Excluded_enddate_le_startdate["facility_identifier"].isin(
            facilities_included_list_global
        )
    ]
    df_AMHCC_Excluded_enddate_le_startdate = (
        df_AMHCC_Excluded_enddate_le_startdate.applymap(str)
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    df_AMHCC_Excluded_enddate_le_startdate = (
        df_AMHCC_Excluded_enddate_le_startdate.applymap(
            lambda x: x.strip() if isinstance(x, str) else x
        )
    )
    df_AMHCC_Excluded_enddate_le_startdate = (
        df_AMHCC_Excluded_enddate_le_startdate.apply(
            lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
        )
    )
    df_AMHCC_Excluded_enddate_le_startdate["stay_number"] = (
        df_AMHCC_Excluded_enddate_le_startdate["stay_number"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0")
    )
    df_AMHCC_Excluded_enddate_le_startdate["episode_sequence_number"] = (
        df_AMHCC_Excluded_enddate_le_startdate["episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    # dropping duplicate values
    df_AMHCC_Excluded_enddate_le_startdate.drop_duplicates(keep="last", inplace=True)
    df_AMHCC_Excluded_enddate_le_startdate.to_csv(
        "./ExtractorDB/Excluded_AMHCC_enddate_less_startdate.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    logging.info(
        "df_AMHCC_Excluded_enddate_le_startdate created in ./ExtractorDB/Excluded_AMHCC_enddate_less_startdate.csv with %s records.",
        len(df_AMHCC_Excluded_enddate_le_startdate),
    )
    # exclude amhcc encounters that have been excluded,
    # df_AMHCC_Excluded_enddate_le_startdate_list = df_AMHCC_Excluded_enddate_le_startdate["EncounterNumber"].values.tolist()
    # amhcc_extract = amhcc_extract[~amhcc_extract['ENCOUNTERNUMBER'].isin(df_AMHCC_Excluded_enddate_le_startdate_list)]
    # Appends data from the AMHCC_extract Table into the snapApp_CostingExtract table
    # Access query: Append_AMHCC_SNAP_APP_Cost
    # INSERT INTO snapApp_CostingExtract ( ENCOUNTERNUMBER, FacilityCode, EncounterStart, EncounterEnd, MRN, stay_number_cost, sa_episode_sequence_number, pcPhase, [Snap ClassV4], sa_total_los, sa_total_leave_days, HON1, HON2, HON3, HON4, HON5, HON6, HON7, HON8, HON9, HON10, HON11, HON12, HON13, HON14, HON15, [HIE Extract Date], [Grouped Status], PhaseSeqNo ) SELECT AMHCC_Extract.ENCOUNTERNUMBER, AMHCC_Extract.HOSPITAL, AMHCC_Extract.STARTDATETIME, AMHCC_Extract.ENDDATETIME, AMHCC_Extract.MRN, Replace([HIE_STAY_NUMBER],"SN","") AS Expr1, AMHCC_Extract.HIE_SEQUENCE_NUMBER, AMHCC_Extract.PHASEOFCARE, AMHCC_Extract.CLASS, AMHCC_Extract.LENGTHOFSTAY, AMHCC_Extract.LEAVEDAYS, AMHCC_Extract.HON1, AMHCC_Extract.HON2, AMHCC_Extract.HON3, AMHCC_Extract.HON4, AMHCC_Extract.HON5, AMHCC_Extract.HON6, AMHCC_Extract.HON7, AMHCC_Extract.HON8, AMHCC_Extract.HON9, AMHCC_Extract.HON10, AMHCC_Extract.HON11, AMHCC_Extract.HON12, AMHCC_Extract.HON13, AMHCC_Extract.HON14, AMHCC_Extract.HON15, AMHCC_Extract.EXTRACTDATE, "AMHCC" AS Expr2, AMHCC_Extract.PhaseSeqNo FROM AMHCC_Extract INNER JOIN tbl_dbo_Facility ON AMHCC_Extract.HOSPITAL = tbl_dbo_Facility.facility_identifier WHERE (((tbl_dbo_Facility.area_identifier)=Forms![Frm:1-ExtractSetUp]!AHS)) Or (((tbl_dbo_Facility.facility_identifier)=Forms![Frm:1-ExtractSetUp]!AHS));
    # download OutputFacility
    file_OutputFacility = "./ExtractorDB/OutputFacility.csv"
    if os.path.isfile(file_OutputFacility):
        try:
            tbl_dbo_Facility = read_csv_file(
                file_OutputFacility,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_dbo_Facility from ./ExtractorDB/OutputFacility.csv.\n"
                + str(e),
            )
            # label_map_1_status = 0
            return
        else:
            tbl_dbo_Facility = tbl_dbo_Facility.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_dbo_Facility = tbl_dbo_Facility.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_dbo_Facility = tbl_dbo_Facility.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_Facility = tbl_dbo_Facility.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_Facility = tbl_dbo_Facility[
                (tbl_dbo_Facility["area_identifier"] == lhd_global)
                | (tbl_dbo_Facility["facility_identifier"] == lhd_global)
            ]
            tbl_dbo_Facility = tbl_dbo_Facility[
                tbl_dbo_Facility["facility_identifier"].isin(
                    facilities_included_list_global
                )
            ]
            tbl_dbo_Facility.drop_duplicates(
                subset=[
                    "facility_identifier",
                    "area_identifier",
                    "facility_name",
                    "snap_upd_batch_run_no",
                ],
                keep="last",
                inplace=True,
            )
    else:
        tbl_dbo_Facility = pd.DataFrame(
            columns=[
                "facility_identifier",
                "area_identifier",
                "facility_name",
                "snap_upd_batch_run_no",
                "HLTH_ORG_OSP_OSP_ID",
                "MG_AUTH_OSP_OSP_ID",
            ]
        )
    df_AMHCC_Costingextract = pd.DataFrame()
    # 11 Jan 2024 - CREATED FACILITY CHANGE
    # df_AMHCC_Costingextract = pd.merge(amhcc_extract[['SE_CBK_SK', 'DIM_CLIENT_ID_SK', 'ENCOUNTERNUMBER', 'HOSPITAL', 'STARTDATETIME', 'ENDDATETIME', 'mrn', 'HIE_STAY_NUMBER', 'HIE_SEQUENCE_NUMBER', 'PHASEOFCARE', 'CLASS', 'LENGTHOFSTAY', 'LEAVEDAYS', 'HON1', 'HON2', 'HON3', 'HON4', 'HON5', 'HON6', 'HON7', 'HON8', 'HON9', 'HON10', 'HON11', 'HON12', 'HON13', 'HON14', 'HON15', 'HONOS1', 'HONOS2', 'HONOS3', 'HONOS4', 'HONOS5', 'HONOS6', 'HONOS7', 'HONOS8', 'HONOS9', 'HONOS10', 'HONOS11', 'HONOS12', 'HONOS65_1', 'HONOS65_2', 'HONOS65_3', 'HONOS65_4', 'HONOS65_5', 'HONOS65_6', 'HONOS65_7', 'HONOS65_8', 'HONOS65_9', 'HONOS65_10', 'HONOS65_11', 'HONOS65_12', 'HONOSCA1', 'HONOSCA2', 'HONOSCA3', 'HONOSCA4', 'HONOSCA5', 'HONOSCA6', 'HONOSCA7', 'HONOSCA8', 'HONOSCA9', 'HONOSCA10', 'HONOSCA11', 'HONOSCA12', 'HONOSCA13', 'HONOSCA14', 'HONOSCA15', 'IHPA_LSP_01', 'IHPA_LSP_02', 'IHPA_LSP_03', 'IHPA_LSP_04', 'IHPA_LSP_05', 'IHPA_LSP_06', 'IHPA_LSP_07', 'IHPA_LSP_08', 'IHPA_LSP_09', 'IHPA_LSP_10', 'IHPA_LSP_11', 'IHPA_LSP_12', 'IHPA_LSP_13', 'IHPA_LSP_14', 'IHPA_LSP_15', 'IHPA_LSP_16',  'EXTRACTDATE', 'PhaseSeqNo']], tbl_dbo_Facility[['facility_identifier']], how='inner', left_on=['HOSPITAL'], right_on=['facility_identifier'], suffixes=('', '_drop'))
    df_AMHCC_Costingextract = amhcc_extract[
        [
            "SE_CBK_SK",
            "DIM_CLIENT_ID_SK",
            "ENCOUNTERNUMBER",
            "HOSPITAL",
            "STARTDATETIME",
            "ENDDATETIME",
            "mrn",
            "HIE_STAY_NUMBER",
            "HIE_SEQUENCE_NUMBER",
            "PHASEOFCARE",
            "CLASS",
            "LENGTHOFSTAY",
            "LEAVEDAYS",
            "HON1",
            "HON2",
            "HON3",
            "HON4",
            "HON5",
            "HON6",
            "HON7",
            "HON8",
            "HON9",
            "HON10",
            "HON11",
            "HON12",
            "HON13",
            "HON14",
            "HON15",
            "HONOS1",
            "HONOS2",
            "HONOS3",
            "HONOS4",
            "HONOS5",
            "HONOS6",
            "HONOS7",
            "HONOS8",
            "HONOS9",
            "HONOS10",
            "HONOS11",
            "HONOS12",
            "HONOS65_1",
            "HONOS65_2",
            "HONOS65_3",
            "HONOS65_4",
            "HONOS65_5",
            "HONOS65_6",
            "HONOS65_7",
            "HONOS65_8",
            "HONOS65_9",
            "HONOS65_10",
            "HONOS65_11",
            "HONOS65_12",
            "HONOSCA1",
            "HONOSCA2",
            "HONOSCA3",
            "HONOSCA4",
            "HONOSCA5",
            "HONOSCA6",
            "HONOSCA7",
            "HONOSCA8",
            "HONOSCA9",
            "HONOSCA10",
            "HONOSCA11",
            "HONOSCA12",
            "HONOSCA13",
            "HONOSCA14",
            "HONOSCA15",
            "IHPA_LSP_01",
            "IHPA_LSP_02",
            "IHPA_LSP_03",
            "IHPA_LSP_04",
            "IHPA_LSP_05",
            "IHPA_LSP_06",
            "IHPA_LSP_07",
            "IHPA_LSP_08",
            "IHPA_LSP_09",
            "IHPA_LSP_10",
            "IHPA_LSP_11",
            "IHPA_LSP_12",
            "IHPA_LSP_13",
            "IHPA_LSP_14",
            "IHPA_LSP_15",
            "IHPA_LSP_16",
            "EXTRACTDATE",
            "PhaseSeqNo",
        ]
    ]
    df_AMHCC_Costingextract = df_AMHCC_Costingextract.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    df_AMHCC_Costingextract["EncounterNumber"] = df_AMHCC_Costingextract[
        "ENCOUNTERNUMBER"
    ]
    df_AMHCC_Costingextract["FacilityCode"] = df_AMHCC_Costingextract["HOSPITAL"]
    df_AMHCC_Costingextract["EncounterStart"] = df_AMHCC_Costingextract["STARTDATETIME"]
    df_AMHCC_Costingextract["EncounterEnd"] = df_AMHCC_Costingextract["ENDDATETIME"]
    df_AMHCC_Costingextract["stay_number_cost"] = df_AMHCC_Costingextract[
        "HIE_STAY_NUMBER"
    ].replace("SN", "")
    df_AMHCC_Costingextract["stay_number_cost"] = (
        df_AMHCC_Costingextract["stay_number_cost"].astype(str).str.replace("SN", "")
    )
    df_AMHCC_Costingextract["stay_number_cost"] = (
        df_AMHCC_Costingextract["stay_number_cost"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0")
    )
    df_AMHCC_Costingextract["sa_episode_sequence_number"] = df_AMHCC_Costingextract[
        "HIE_SEQUENCE_NUMBER"
    ]
    df_AMHCC_Costingextract["sa_episode_sequence_number"] = (
        df_AMHCC_Costingextract["sa_episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    df_AMHCC_Costingextract["pcPhase"] = df_AMHCC_Costingextract["PHASEOFCARE"]
    df_AMHCC_Costingextract["Snap ClassV4"] = df_AMHCC_Costingextract["CLASS"]
    df_AMHCC_Costingextract["sa_total_los"] = df_AMHCC_Costingextract["LENGTHOFSTAY"]
    df_AMHCC_Costingextract["sa_total_leave_days"] = df_AMHCC_Costingextract[
        "LEAVEDAYS"
    ]
    df_AMHCC_Costingextract["HIE Extract Date"] = df_AMHCC_Costingextract["EXTRACTDATE"]
    df_AMHCC_Costingextract["Grouped Status"] = "AMHCC"
    # df_AMHCC_Costingextract['PhaseSeqNo'] = df_AMHCC_Costingextract['PHASESEQNO']
    # df_AMHCC_Costingextract.drop(['PHASESEQNO'], axis=1, inplace=True, errors='ignore')
    # Ranjit : Dropping the new field DIM_CLIENT_ID_SK
    df_AMHCC_Costingextract = df_AMHCC_Costingextract[
        [
            "SE_CBK_SK",
            "EncounterNumber",
            "FacilityCode",
            "EncounterStart",
            "EncounterEnd",
            "mrn",
            "stay_number_cost",
            "sa_episode_sequence_number",
            "pcPhase",
            "Snap ClassV4",
            "sa_total_los",
            "sa_total_leave_days",
            "HON1",
            "HON2",
            "HON3",
            "HON4",
            "HON5",
            "HON6",
            "HON7",
            "HON8",
            "HON9",
            "HON10",
            "HON11",
            "HON12",
            "HON13",
            "HON14",
            "HON15",
            "HONOS1",
            "HONOS2",
            "HONOS3",
            "HONOS4",
            "HONOS5",
            "HONOS6",
            "HONOS7",
            "HONOS8",
            "HONOS9",
            "HONOS10",
            "HONOS11",
            "HONOS12",
            "HONOS65_1",
            "HONOS65_2",
            "HONOS65_3",
            "HONOS65_4",
            "HONOS65_5",
            "HONOS65_6",
            "HONOS65_7",
            "HONOS65_8",
            "HONOS65_9",
            "HONOS65_10",
            "HONOS65_11",
            "HONOS65_12",
            "HONOSCA1",
            "HONOSCA2",
            "HONOSCA3",
            "HONOSCA4",
            "HONOSCA5",
            "HONOSCA6",
            "HONOSCA7",
            "HONOSCA8",
            "HONOSCA9",
            "HONOSCA10",
            "HONOSCA11",
            "HONOSCA12",
            "HONOSCA13",
            "HONOSCA14",
            "HONOSCA15",
            "IHPA_LSP_01",
            "IHPA_LSP_02",
            "IHPA_LSP_03",
            "IHPA_LSP_04",
            "IHPA_LSP_05",
            "IHPA_LSP_06",
            "IHPA_LSP_07",
            "IHPA_LSP_08",
            "IHPA_LSP_09",
            "IHPA_LSP_10",
            "IHPA_LSP_11",
            "IHPA_LSP_12",
            "IHPA_LSP_13",
            "IHPA_LSP_14",
            "IHPA_LSP_15",
            "IHPA_LSP_16",
            "HIE Extract Date",
            "Grouped Status",
            "PhaseSeqNo",
        ]
    ]
    # dropping duplicate values
    df_AMHCC_Costingextract.drop_duplicates(keep="last", inplace=True)
    df_AMHCC_Costingextract.to_csv(
        "./ExtractorDB/df_AMHCC_Costingextract.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    logging.info(
        "snapApp_CostingExtract has %s records and AMHCC Encounters has %s records.",
        len(snapApp_CostingExtract),
        len(df_AMHCC_Costingextract),
    )

    ############################ NEW CODE FOR AMHCC - STOP #######################################
    snapApp_CostingExtract = pd.concat(
        [snapApp_CostingExtract, df_AMHCC_Costingextract], axis=0
    )
    index_names = snapApp_CostingExtract[
        (snapApp_CostingExtract["FacilityCode"] == "")
        | (snapApp_CostingExtract["FacilityCode"].isnull())
    ].index
    snapApp_CostingExtract.drop(index_names, inplace=True)
    snapApp_CostingExtract = snapApp_CostingExtract.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    snapApp_CostingExtract = snapApp_CostingExtract.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    snapApp_CostingExtract = snapApp_CostingExtract.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    snapApp_CostingExtract = snapApp_CostingExtract.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    logging.info(
        "snapApp_CostingExtract now has %s records after concatenating SNAP & AMHCC Encounters.",
        len(snapApp_CostingExtract),
    )
    # ranjit: uncomment snap costing and amhcc excluding filters
    # filter by nwau version
    """
    snapApp_CostingExtract = snapApp_CostingExtract[snapApp_CostingExtract['sa_nwau_version']==nwau_v]
    logging.info('snapApp_CostingExtract now has %s records after filtering nwau=%s.', len(snapApp_CostingExtract),nwau_v)
    """
    # snapApp_CostingExtract.to_csv('./ExtractorDB/snapApp_CostingExtract_after_amhcc_appended.csv', index=False, na_rep='', float_format=str, decimal=str, date_format=str)
    """ Removes the SN in the stay_number field in the snapApp_CostingExtract table """
    # Access query: Update SNAP Stay Number
    # UPDATE snapApp_CostingExtract SET snapApp_CostingExtract.stay_number_cost = Replace([Stay_number_cost],"SN","");
    snapApp_CostingExtract["stay_number_cost"] = (
        snapApp_CostingExtract.stay_number_cost.str.replace("SN", "")
    )  # snapApp_CostingExtract['stay_number_cost'].replace('SN' ,'')
    snapApp_CostingExtract["stay_number_cost"] = (
        snapApp_CostingExtract["stay_number_cost"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0")
    )
    snapApp_CostingExtract["sa_episode_sequence_number"] = (
        snapApp_CostingExtract["sa_episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    # snapApp_CostingExtract.to_csv('./ExtractorDB/snapApp_CostingExtract_after_replacing_SN_in_stay_number.csv', index=False, na_rep='', float_format=str, decimal=str, date_format=str)
    """ Remove  the hyphen in the  [AN SNAP V3] field """
    # Access query: update snap class
    # UPDATE snapApp_CostingExtract SET snapApp_CostingExtract.[AN SNAP V3] = Replace([AN SNAP V3],"-","");
    snapApp_CostingExtract["AN SNAP V3"] = snapApp_CostingExtract["AN SNAP V3"].replace(
        "-", ""
    )
    snapApp_CostingExtract["AN SNAP V3"] = (
        snapApp_CostingExtract["AN SNAP V3"].astype(str).str.replace("-", "")
    )
    snapApp_CostingExtract["AN SNAP V3"] = np.where(
        snapApp_CostingExtract["AN SNAP V3"] == "nan",
        "",
        snapApp_CostingExtract["AN SNAP V3"],
    )
    """ If the EncounterEnd  is null then the date = forms end date +1  """
    # Access query: Update SNAP SNAPdate
    # UPDATE snapApp_CostingExtract SET snapApp_CostingExtract.Encounterend = IIf([snapApp_CostingExtract]![EncounterEnd] Is Null,DateValue([Forms]![Frm:1-ExtractSetUp]![End_Date])+1,[snapApp_CostingExtract]![EncounterEnd]);
    end_date_dt = pd.to_datetime(end_date, format="%Y-%m-%d %H:%M:%S")
    # snapApp_CostingExtract['EncounterEnd'] = snapApp_CostingExtract['EncounterEnd'] #pd.to_datetime(snapApp_CostingExtract['EncounterEnd'])#, errors='coerce', format="%Y-%m-%d %H:%M:%S")#,format="%Y-%m-%d")
    logging.info(
        "Query: Update SNAP SNAPdate. %s records in snapApp_CostingExtract will be updated. snapApp_CostingExtract now has %s records",
        len(
            snapApp_CostingExtract[
                (
                    (snapApp_CostingExtract["EncounterEnd"].isnull())
                    | (snapApp_CostingExtract["EncounterEnd"] == "")
                )
            ]
        ),
        len(snapApp_CostingExtract),
    )
    # 23 Oct
    snapApp_CostingExtract["EndDateTimeplus1"] = end_date
    snapApp_CostingExtract["EndDateTimeplus1"] = pd.to_datetime(
        snapApp_CostingExtract["EndDateTimeplus1"].astype(str).str[:10],
        errors="coerce",
        format="%Y-%m-%d",
    )
    snapApp_CostingExtract["EndDateTimeplus1"] = snapApp_CostingExtract[
        "EndDateTimeplus1"
    ] + pd.DateOffset(1)
    # snapApp_CostingExtract['EncounterEnd'] = np.where(((snapApp_CostingExtract['EncounterEnd'].isnull()) | (snapApp_CostingExtract['EncounterEnd']=='')), \
    # end_date_dt+pd.DateOffset(1), snapApp_CostingExtract['EncounterEnd'])
    snapApp_CostingExtract["EncounterEnd"] = np.where(
        (
            (snapApp_CostingExtract["EncounterEnd"].isnull())
            | (snapApp_CostingExtract["EncounterEnd"] == "")
        ),
        snapApp_CostingExtract["EndDateTimeplus1"] + pd.DateOffset(1),
        snapApp_CostingExtract["EncounterEnd"],
    )
    snapApp_CostingExtract.drop(["EndDateTimeplus1"], axis=1, inplace=True)
    """ Delete from snapApp_CostingExtract where InterupCare=Y """
    # Access query: qrydel SNAP InterupCare equalY
    # DELETE snapApp_CostingExtract.InterupCare FROM snapApp_CostingExtract WHERE (((snapApp_CostingExtract.InterupCare)="Y"));
    index_names = snapApp_CostingExtract[
        (snapApp_CostingExtract["InterupCare"] == "Y")
    ].index
    snapApp_CostingExtract.drop(index_names, inplace=True)
    logging.info(
        "Query: qrydel SNAP InterupCare equalY completed. After deletingrecords where InterupCare=Y, snapApp_CostingExtract has %s records.",
        len(snapApp_CostingExtract),
    )
    """ If the sa_episode_sequence_number does not equal the value in the tbl_dbo_episode_ats when linked by stay number and HIE dates then update to value in ATS table"""
    # Access query: qr update ESN snapApp_CostingExtract
    # UPDATE snapApp_CostingExtract INNER JOIN tbl_dbo_episode_ats ON (tbl_dbo_episode_ats.episode_end_time = snapApp_CostingExtract.EpisodeEndTime_HIE) AND (tbl_dbo_episode_ats.episode_start_time = snapApp_CostingExtract.EpisodeStartTime_HIE) AND (tbl_dbo_episode_ats.episode_end_date = snapApp_CostingExtract.EpisodeEndDate_HIE) AND (tbl_dbo_episode_ats.episode_start_date = snapApp_CostingExtract.EpisodeStartDate_HIE) AND (snapApp_CostingExtract.stay_number_cost = tbl_dbo_episode_ats.stay_number) AND (snapApp_CostingExtract.FacilityCode = tbl_dbo_episode_ats.facility_identifier) SET snapApp_CostingExtract.sa_episode_sequence_number = [episode_sequence_number] WHERE (((snapApp_CostingExtract.sa_episode_sequence_number)<>[episode_sequence_number]));
    # download OutputEpisodeAts
    file_OutputEpisodeAts = "./ExtractorDB/OutputEpisodeAts.csv"
    if os.path.isfile(file_OutputEpisodeAts):
        try:
            tbl_dbo_episode_ats = read_csv_file(
                file_OutputEpisodeAts,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_dbo_episode_ats from ./ExtractorDB/OutputEpisodeAts.csv.\n"
                + str(e),
            )
            # label_map_1_status = 0
            return
        else:
            tbl_dbo_episode_ats = tbl_dbo_episode_ats.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_dbo_episode_ats = tbl_dbo_episode_ats.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_dbo_episode_ats = tbl_dbo_episode_ats.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_episode_ats = tbl_dbo_episode_ats.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
    snapApp_CostingExtract["EpisodeEndTime_HIE"] = (
        snapApp_CostingExtract["EpisodeEndTime_HIE"].astype(str).str[:5]
    )
    snapApp_CostingExtract["EpisodeStartTime_HIE"] = (
        snapApp_CostingExtract["EpisodeStartTime_HIE"].astype(str).str[:5]
    )
    snapApp_CostingExtract["stay_number_cost"] = (
        snapApp_CostingExtract["stay_number_cost"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0")
    )
    snapApp_CostingExtract["sa_episode_sequence_number"] = (
        snapApp_CostingExtract["sa_episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    tbl_dbo_episode_ats["episode_end_time"] = (
        tbl_dbo_episode_ats["episode_end_time"].astype(str).str[:5]
    )
    tbl_dbo_episode_ats["episode_start_time"] = (
        tbl_dbo_episode_ats["episode_start_time"].astype(str).str[:5]
    )
    tbl_dbo_episode_ats["stay_number"] = (
        tbl_dbo_episode_ats["stay_number"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0")
    )
    tbl_dbo_episode_ats["episode_sequence_number"] = (
        tbl_dbo_episode_ats["episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    # if below does not work, then use: snapApp_CostingExtract['EpisodeEndDate_HIE'].astype(str).str[:10] and tbl_dbo_episode_ats['episode_start_date'].astype(str).str[:10]
    snapApp_CostingExtract["EpisodeEndDate_HIE"] = pd.to_datetime(
        snapApp_CostingExtract["EpisodeEndDate_HIE"],
        errors="coerce",
        format="%Y-%m-%d %H:%M:%S",
    )
    snapApp_CostingExtract["EpisodeStartDate_HIE"] = pd.to_datetime(
        snapApp_CostingExtract["EpisodeStartDate_HIE"],
        errors="coerce",
        format="%Y-%m-%d %H:%M:%S",
    )
    tbl_dbo_episode_ats["episode_end_date"] = pd.to_datetime(
        tbl_dbo_episode_ats["episode_end_date"],
        errors="coerce",
        format="%Y-%m-%d %H:%M:%S",
    )
    tbl_dbo_episode_ats["episode_start_date"] = pd.to_datetime(
        tbl_dbo_episode_ats["episode_start_date"],
        errors="coerce",
        format="%Y-%m-%d %H:%M:%S",
    )
    # logging.info("snapApp_CostingExtract columns = %s", snapApp_CostingExtract.dtypes)
    # logging.info("tbl_dbo_episode_ats columns = %s", tbl_dbo_episode_ats.dtypes)
    # 11 Jan 2024 - CREATED FACILITY CHANGE
    # snapApp_CostingExtract = pd.merge(snapApp_CostingExtract, tbl_dbo_episode_ats[['episode_end_time', 'episode_start_time', 'episode_end_date', 'episode_start_date', 'stay_number', 'facility_identifier', 'episode_sequence_number']], how='left', left_on=['EpisodeEndTime_HIE', 'EpisodeStartTime_HIE', 'EpisodeEndDate_HIE', 'EpisodeStartDate_HIE', 'stay_number_cost', 'FacilityCode'], right_on=['episode_end_time', 'episode_start_time', 'episode_end_date', 'episode_start_date', 'stay_number', 'facility_identifier'], suffixes=('', '_drop'))
    snapApp_CostingExtract = pd.merge(
        snapApp_CostingExtract,
        tbl_dbo_episode_ats[
            [
                "episode_end_time",
                "episode_start_time",
                "episode_end_date",
                "episode_start_date",
                "stay_number",
                "facility_identifier",
                "episode_sequence_number",
                "SE_CBK_SK",
            ]
        ],
        how="left",
        left_on=[
            "EpisodeEndTime_HIE",
            "EpisodeStartTime_HIE",
            "EpisodeEndDate_HIE",
            "EpisodeStartDate_HIE",
            "stay_number_cost",
            "SE_CBK_SK",
        ],
        right_on=[
            "episode_end_time",
            "episode_start_time",
            "episode_end_date",
            "episode_start_date",
            "stay_number",
            "SE_CBK_SK",
        ],
        suffixes=("", "_drop"),
    )
    snapApp_CostingExtract = snapApp_CostingExtract.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    snapApp_CostingExtract["sa_episode_sequence_number"] = np.where(
        (
            snapApp_CostingExtract["sa_episode_sequence_number"]
            != snapApp_CostingExtract["episode_sequence_number"]
        )
        & (
            (pd.notna(snapApp_CostingExtract["episode_sequence_number"]))
            & (snapApp_CostingExtract["episode_sequence_number"] != "")
            & (snapApp_CostingExtract["episode_sequence_number"] != "nan")
            & (snapApp_CostingExtract["episode_sequence_number"] != "000")
        ),
        snapApp_CostingExtract["episode_sequence_number"],
        snapApp_CostingExtract["sa_episode_sequence_number"],
    )
    snapApp_CostingExtract.drop(
        [
            "episode_end_time",
            "episode_start_time",
            "episode_end_date",
            "episode_start_date",
            "stay_number",
            "facility_identifier",
            "episode_sequence_number",
        ],
        axis=1,
        inplace=True,
        errors="ignore",
    )
    # populate 'WIP', 'start', 'end'
    # Access query: Update SNAPaPP_startEnd
    # UPDATE SNAPAPP_CostingExtract SET SNAPAPP_CostingExtract.start = DateValue([encounterstart]), SNAPAPP_CostingExtract.[end] = DateValue([EncounterEnd]);
    snapApp_CostingExtract["start"] = pd.to_datetime(
        snapApp_CostingExtract["EncounterStart"],
        errors="coerce",
        format="%Y-%m-%d %H:%M:%S",
    ).dt.normalize()
    snapApp_CostingExtract["end"] = pd.to_datetime(
        snapApp_CostingExtract["EncounterEnd"],
        errors="coerce",
        format="%Y-%m-%d %H:%M:%S",
    ).dt.normalize()
    snapApp_CostingExtract["WIP"] = ""
    # Access query:  SNAP Update WIP 0
    # UPDATE SNAPAPP_CostingExtract SET SNAPAPP_CostingExtract.WIP = "0" WHERE (((SNAPAPP_CostingExtract.WIP) Is Null) AND ((SNAPAPP_CostingExtract.start)<[Forms]![Frm:1-ExtractSetUp]![Start_Date]) AND ((SNAPAPP_CostingExtract.end)<[Forms]![Frm:1-ExtractSetUp]![End_Date])) OR (((SNAPAPP_CostingExtract.WIP) Is Null) AND ((SNAPAPP_CostingExtract.start)>[Forms]![Frm:1-ExtractSetUp]![End_Date]));
    start_date_dt = pd.to_datetime(start_date, format="%Y-%m-%d %H:%M:%S")
    end_date_dt = pd.to_datetime(end_date, format="%Y-%m-%d %H:%M:%S")
    snapApp_CostingExtract["WIP"] = np.where(
        (
            (
                (
                    (snapApp_CostingExtract["WIP"].isnull())
                    | (snapApp_CostingExtract["WIP"] == "")
                )
                & (snapApp_CostingExtract["start"] < start_date_dt)
                & (snapApp_CostingExtract["end"] < end_date_dt)
            )
            | (
                (
                    (snapApp_CostingExtract["WIP"].isnull())
                    | (snapApp_CostingExtract["WIP"] == "")
                )
                & (snapApp_CostingExtract["start"] > end_date_dt)
            )
        ),
        "0",
        snapApp_CostingExtract["WIP"],
    )
    # Access query:  SNAP Update WIP 1
    # UPDATE SNAPAPP_CostingExtract SET SNAPAPP_CostingExtract.WIP = "1" WHERE (((SNAPAPP_CostingExtract.WIP) Is Null) AND ((SNAPAPP_CostingExtract.start)<DateValue([Forms]![Frm:1-ExtractSetUp]![Start_Date])) AND ((SNAPAPP_CostingExtract.end) Between DateValue([Forms]![Frm:1-ExtractSetUp]![Start_Date]) And DateValue([Forms]![Frm:1-ExtractSetUp]![End_Date])));
    snapApp_CostingExtract["WIP"] = np.where(
        (
            (snapApp_CostingExtract["WIP"].isnull())
            | (snapApp_CostingExtract["WIP"] == "")
        )
        & (snapApp_CostingExtract["start"] < start_date_dt)
        & (snapApp_CostingExtract["end"] >= start_date_dt)
        & (snapApp_CostingExtract["end"] <= end_date_dt),
        "1",
        snapApp_CostingExtract["WIP"],
    )
    # Access query:  SNAP Update WIP 2
    # UPDATE SNAPAPP_CostingExtract SET SNAPAPP_CostingExtract.WIP = "2" WHERE (((SNAPAPP_CostingExtract.WIP) Is Null) AND ((SNAPAPP_CostingExtract.Start) Between [Forms]![Frm:1-ExtractSetUp]![Start_Date] And [Forms]![Frm:1-ExtractSetUp]![End_Date]) AND ((SNAPAPP_CostingExtract.End)>[Forms]![Frm:1-ExtractSetUp]![End_Date] Or (SNAPAPP_CostingExtract.End) Is Null));
    snapApp_CostingExtract["WIP"] = np.where(
        (
            (snapApp_CostingExtract["WIP"].isnull())
            | (snapApp_CostingExtract["WIP"] == "")
        )
        & (
            (snapApp_CostingExtract["start"] >= start_date_dt)
            & (snapApp_CostingExtract["start"] <= end_date_dt)
        )
        & (
            (snapApp_CostingExtract["end"] > end_date_dt)
            | (
                (snapApp_CostingExtract["end"].isnull())
                | (snapApp_CostingExtract["end"] == "")
            )
        ),
        "2",
        snapApp_CostingExtract["WIP"],
    )
    # Access query:  SNAP Update WIP 3
    # UPDATE SNAPAPP_CostingExtract SET SNAPAPP_CostingExtract.WIP = "3" WHERE (((SNAPAPP_CostingExtract.WIP) Is Null) AND ((SNAPAPP_CostingExtract.Start)<[Forms]![Frm:1-ExtractSetUp]![Start_Date]) AND ((SNAPAPP_CostingExtract.End)>[Forms]![Frm:1-ExtractSetUp]![End_Date] Or (SNAPAPP_CostingExtract.End) Is Null));
    snapApp_CostingExtract["WIP"] = np.where(
        (
            (snapApp_CostingExtract["WIP"].isnull())
            | (snapApp_CostingExtract["WIP"] == "")
        )
        & (snapApp_CostingExtract["start"] < start_date_dt)
        & (
            (snapApp_CostingExtract["end"] > end_date_dt)
            | (
                (snapApp_CostingExtract["end"].isnull())
                | (snapApp_CostingExtract["end"] == "")
            )
        ),
        "3",
        snapApp_CostingExtract["WIP"],
    )
    # Access query:  SNAP Update WIP 4
    # UPDATE SNAPAPP_CostingExtract SET SNAPAPP_CostingExtract.WIP = "4" WHERE (((SNAPAPP_CostingExtract.WIP) Is Null) AND ((SNAPAPP_CostingExtract.Start) Between [Forms]![Frm:1-ExtractSetUp]![Start_Date] And [Forms]![Frm:1-ExtractSetUp]![End_Date]) AND ((SNAPAPP_CostingExtract.end) Between [Forms]![Frm:1-ExtractSetUp]![Start_Date] And [Forms]![Frm:1-ExtractSetUp]![End_Date]));
    snapApp_CostingExtract["WIP"] = np.where(
        (
            (snapApp_CostingExtract["WIP"].isnull())
            | (snapApp_CostingExtract["WIP"] == "")
        )
        & (snapApp_CostingExtract["start"] >= start_date_dt)
        & (snapApp_CostingExtract["start"] <= end_date_dt)
        & (snapApp_CostingExtract["end"] >= start_date_dt)
        & (snapApp_CostingExtract["end"] <= end_date_dt),
        "4",
        snapApp_CostingExtract["WIP"],
    )
    snapApp_CostingExtract = snapApp_CostingExtract[
        [
            "PCSNAP_PhaseID",
            "pcPhase",
            "PCPhaseStartDate",
            "PCPhaseEndDate",
            "FacilityCode",
            "mrn",
            "SNAPEpisodeID",
            "SNAPCaseType",
            "EpisodeStartDate_HIE",
            "EpisodeEndDate_HIE",
            "EpisodeStartTime_HIE",
            "EpisodeEndTime_HIE",
            "EpisType",
            "TotalSuspensionDays",
            "AssessmentOnly",
            "PCSymptomScoreStart",
            "PCSeverityStart",
            "PCPsychSpiritualScoreStart",
            "PCFamilyCarerScoreStart",
            "MaintType",
            "RehImpairmentCode",
            "FIMEatingStart",
            "FIMEatingEnd",
            "FIMGroomingStart",
            "FIMGroomingEnd",
            "FIMBathingStart",
            "FIMBathingEnd",
            "FIMDressingUpperStart",
            "FIMDressingUpperEnd",
            "FIMDressingLowerStart",
            "FIMDressingLowerEnd",
            "FIMToiletingStart",
            "FIMToiletingEnd",
            "FIMBladderStart",
            "FIMBladderEnd",
            "FIMBowelStart",
            "FIMBowelEnd",
            "FIMXferBedChairWChairStart",
            "FIMXferBedChairWChairEnd",
            "FIMXferBathShowerStart",
            "FIMXferBathShowerEnd",
            "FIMXferToiletStart",
            "FIMXferToiletEnd",
            "FIMWalkWheelChairStart",
            "FIMWalkWheelChairEnd",
            "FIMStairsStart",
            "FIMStairsEnd",
            "FIMComprehensionStart",
            "FIMComprehensionEnd",
            "FIMExpressionStart",
            "FIMExpressionEnd",
            "FIMSocialInteractionStart",
            "FIMSocialInteractionEnd",
            "FIMProblemSolvingStart",
            "FIMProblemSolvingEnd",
            "FIMMemoryStart",
            "FIMMemoryEnd",
            "AN SNAP V3",
            "sa_AN_SNAP_Version",
            "HONActivityStart",
            "HONActivityEnd",
            "HONInjuryStart",
            "HONInjuryEnd",
            "HONDrinkStart",
            "HONDrinkEnd",
            "HONCognitStart",
            "HONCognitEnd",
            "HONDisabStart",
            "HONDisabEnd",
            "HONHallucStart",
            "HONHallucEnd",
            "HONDepresStart",
            "HONDepresEnd",
            "HONOtherStart",
            "HONOtherEnd",
            "HONRelatStart",
            "HONRelatEnd",
            "HONAdlStart",
            "HONAdlEnd",
            "HONLivingStart",
            "HONLivingEnd",
            "HONOccupStart",
            "HONOccupEnd",
            "CareFocus",
            "stay_number_cost",
            "sa_episode_sequence_number",
            "sa_nwau_version",
            "sa_EpisodeBegReason",
            "sa_EpisodeEndReason",
            "RUGToiletingStart",
            "RUGBedMobilityStart",
            "RUGTransferStart",
            "RUGEatingStart",
            "caretype",
            "InterupCare",
            "Sequence",
            "EncounterNumber",
            "EncounterStart",
            "EncounterEnd",
            "LHD",
            "sa_nwau",
            "sa_occdays_in_cost_period",
            "sa_leave_days_in_cost_period",
            "sa_total_los",
            "sa_total_leave_days",
            "Snap ClassV4",
            "Dementia_Flag",
            "Delirium_Flag",
            "HIE Extract Date",
            "Grouped Status",
            "HON1",
            "HON2",
            "HON3",
            "HON4",
            "HON5",
            "HON6",
            "HON7",
            "HON8",
            "HON9",
            "HON10",
            "HON11",
            "HON12",
            "HON13",
            "HON14",
            "HON15",
            "HONOS1",
            "HONOS2",
            "HONOS3",
            "HONOS4",
            "HONOS5",
            "HONOS6",
            "HONOS7",
            "HONOS8",
            "HONOS9",
            "HONOS10",
            "HONOS11",
            "HONOS12",
            "HONOS65_1",
            "HONOS65_2",
            "HONOS65_3",
            "HONOS65_4",
            "HONOS65_5",
            "HONOS65_6",
            "HONOS65_7",
            "HONOS65_8",
            "HONOS65_9",
            "HONOS65_10",
            "HONOS65_11",
            "HONOS65_12",
            "HONOSCA1",
            "HONOSCA2",
            "HONOSCA3",
            "HONOSCA4",
            "HONOSCA5",
            "HONOSCA6",
            "HONOSCA7",
            "HONOSCA8",
            "HONOSCA9",
            "HONOSCA10",
            "HONOSCA11",
            "HONOSCA12",
            "HONOSCA13",
            "HONOSCA14",
            "HONOSCA15",
            "IHPA_LSP_01",
            "IHPA_LSP_02",
            "IHPA_LSP_03",
            "IHPA_LSP_04",
            "IHPA_LSP_05",
            "IHPA_LSP_06",
            "IHPA_LSP_07",
            "IHPA_LSP_08",
            "IHPA_LSP_09",
            "IHPA_LSP_10",
            "IHPA_LSP_11",
            "IHPA_LSP_12",
            "IHPA_LSP_13",
            "IHPA_LSP_14",
            "IHPA_LSP_15",
            "IHPA_LSP_16",
            "SE_CBK_SK",
            "WIP",
            "start",
            "end",
            "PhaseSeqNo",
        ]
    ]
    # snapApp_CostingExtract = snapApp_CostingExtract[pd.notna(snapApp_CostingExtract['stay_number_cost']) | (snapApp_CostingExtract['stay_number_cost'].isnull())]
    snapApp_CostingExtract = snapApp_CostingExtract.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    snapApp_CostingExtract = snapApp_CostingExtract.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    snapApp_CostingExtract = snapApp_CostingExtract.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    snapApp_CostingExtract["sa_episode_sequence_number"] = (
        snapApp_CostingExtract["sa_episode_sequence_number"]
        .astype(str)
        .str.replace("nan", "")
    )
    # dropping duplicate values
    snapApp_CostingExtract.drop_duplicates(keep="last", inplace=True)
    snapApp_CostingExtract.to_csv(
        "./ExtractorDB/snapApp_CostingExtract.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    logging.info(
        "Query:qr update ESN snapApp_CostingExtract completed. snapApp_CostingExtract with %s records saved to ./ExtractorDB/snapApp_CostingExtract.csv.",
        len(snapApp_CostingExtract),
    )
    """ Appends data from the AMHCC_extract Table into the SNAP NWAU Table"""
    # Access query: Append_AMHCC_SNAP_APP_NWAU
    # INSERT INTO [SNAP NWAU] ( ENCOUNTERNUMBER, FacilityCode, sa_nwau, sa_nwau_version ) SELECT AMHCC_Extract.ENCOUNTERNUMBER, AMHCC_Extract.HOSPITAL, AMHCC_Extract.NWAU, AMHCC_Extract.NWAUVERSION FROM AMHCC_Extract INNER JOIN tbl_dbo_Facility ON AMHCC_Extract.HOSPITAL = tbl_dbo_Facility.facility_identifier WHERE (((tbl_dbo_Facility.area_identifier)=Forms![Frm:1-ExtractSetUp]!AHS)) Or (((tbl_dbo_Facility.facility_identifier)=Forms![Frm:1-ExtractSetUp]!AHS));
    df_AMHCC_NWAU = pd.DataFrame()
    # 11 Jan 2024 - CREATED FACILITY CHANGE
    # df_AMHCC_NWAU = pd.merge(df_AMHCC_extract[['ENCOUNTERNUMBER', 'HOSPITAL', 'NWAU', 'NWAU_VERSION', 'SE_CBK_SK']], tbl_dbo_Facility[['facility_identifier']], how='inner', left_on=['HOSPITAL'], right_on=['facility_identifier'], suffixes=('', '_drop'))
    df_AMHCC_NWAU = df_AMHCC_extract[
        ["ENCOUNTERNUMBER", "HOSPITAL", "NWAU", "NWAU_VERSION", "SE_CBK_SK"]
    ]
    df_AMHCC_NWAU = df_AMHCC_NWAU.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    df_AMHCC_NWAU["EncounterNumber"] = df_AMHCC_NWAU["ENCOUNTERNUMBER"]
    df_AMHCC_NWAU["FacilityCode"] = df_AMHCC_NWAU["HOSPITAL"]
    df_AMHCC_NWAU["sa_nwau"] = df_AMHCC_NWAU["NWAU"]
    df_AMHCC_NWAU["sa_nwau_version"] = df_AMHCC_NWAU["NWAU_VERSION"]
    df_AMHCC_NWAU = df_AMHCC_NWAU[
        ["EncounterNumber", "FacilityCode", "sa_nwau", "sa_nwau_version", "SE_CBK_SK"]
    ]
    df_AMHCC_NWAU = df_AMHCC_NWAU[
        pd.notna(df_AMHCC_NWAU["FacilityCode"]) & (df_AMHCC_NWAU["FacilityCode"] != "")
    ]
    tbl_ExcludedEncounters_amhcc_nwau_dummy = tbl_ExcludedEncounters.copy()
    df_AMHCC_NWAU = pd.merge(
        df_AMHCC_NWAU,
        tbl_ExcludedEncounters_amhcc_nwau_dummy[["EncounterNumber"]],
        how="left",
        on=["EncounterNumber"],
        suffixes=("", "_drop"),
        indicator=True,
    )
    df_AMHCC_NWAU = df_AMHCC_NWAU[df_AMHCC_NWAU["_merge"] == "left_only"]
    df_AMHCC_NWAU.drop(columns=["_merge"], inplace=True)
    df_AMHCC_NWAU["sa_nwau"].fillna(0, inplace=True)
    df_AMHCC_NWAU["sa_nwau"] = np.where(
        (df_AMHCC_NWAU["sa_nwau"].isnull()) | (df_AMHCC_NWAU["sa_nwau"] == ""),
        0,
        df_AMHCC_NWAU["sa_nwau"],
    )
    logging.info(
        "Query: Append_AMHCC_SNAP_APP_NWAU . snap_NWAU has %s records and AMHCC_NWAU has %s records.",
        len(snap_NWAU),
        len(df_AMHCC_NWAU),
    )
    snap_NWAU = pd.concat([snap_NWAU, df_AMHCC_NWAU], axis=0)
    snap_NWAU = snap_NWAU.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    snap_NWAU = snap_NWAU.applymap(lambda x: x.strip() if isinstance(x, str) else x)
    snap_NWAU = snap_NWAU.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    snap_NWAU = snap_NWAU.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    logging.info(
        "Query: Append_AMHCC_SNAP_APP_NWAU completed. snap_NWAU now has %s records.",
        len(snap_NWAU),
    )
    """ Removes the SN in the stay_number field in the snapApp_CostingExtract table """
    # Access query: Update SNAP NWAU Stay Number
    # UPDATE [SNAP NWAU] SET [SNAP NWAU].stay_number_cost = Replace([stay_number_cost],"SN","");
    snap_NWAU["stay_number_cost"] = snap_NWAU["stay_number_cost"].replace("SN", "")
    snap_NWAU["stay_number_cost"] = (
        snap_NWAU["stay_number_cost"].astype(str).str.replace("SN", "")
    )
    snap_NWAU["stay_number_cost"] = np.where(
        snap_NWAU["stay_number_cost"] == "nan", "", snap_NWAU["stay_number_cost"]
    )
    snap_NWAU["stay_number_cost"] = np.where(
        snap_NWAU["stay_number_cost"] != "",
        snap_NWAU["stay_number_cost"].astype(str).str.pad(8, side="left", fillchar="0"),
        "",
    )
    snap_NWAU["sa_episode_sequence_number"] = np.where(
        snap_NWAU["sa_episode_sequence_number"] != "",
        snap_NWAU["sa_episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0"),
        "",
    )
    snap_NWAU["sa_nwau"] = np.where(
        (snap_NWAU["sa_nwau"].isnull()) | (snap_NWAU["sa_nwau"] == ""),
        0,
        snap_NWAU["sa_nwau"],
    )
    """
    snap_NWAU = snap_NWAU[snap_NWAU['sa_nwau_version']==nwau_v] 
    logging.info('snap_NWAU now has %s records with sa_nwau_version=%s', len(snap_NWAU), nwau_v)
    """
    # dropping duplicate values
    snap_NWAU.drop_duplicates(keep="last", inplace=True)
    snap_NWAU.to_csv(
        "./ExtractorDB/SNAP_NWAU.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    logging.info(
        "Query: Update SNAP NWAU Stay Number completed. snap_NWAU created with %s records and saved to ./ExtractorDB/SNAP_NWAU.csv.",
        len(snap_NWAU),
    )
    """Where it appends diagnoses matched by staynumber/seq to tbl_PPM_ICD_diagnoses if they match snapApp_CostingExtract """
    # Access query: Append_to_tbl_PPM_ICD_diagnoses_SNAP
    # INSERT INTO tbl_PPM_ICD_diagnoses ( EncounterNumber, DiagnosisCode, DiagnosisVersion, Sequence, ConditionOnset ) SELECT snapApp_CostingExtract.EncounterNumber, tbl_PPM_ICD_diagnoses.DiagnosisCode, tbl_PPM_ICD_diagnoses.DiagnosisVersion, tbl_PPM_ICD_diagnoses.Sequence, tbl_PPM_ICD_diagnoses.ConditionOnset FROM tbl_PPM_ICD_diagnoses, snapApp_CostingExtract WHERE (((tbl_PPM_ICD_diagnoses.EncounterNumber)=[snapApp_CostingExtract]![FacilityCode] & "-I-" & Format([snapApp_CostingExtract]![stay_number_cost],"00000000") & "-" & Format([snapApp_CostingExtract]![sa_episode_sequence_number],"000") And (tbl_PPM_ICD_diagnoses.EncounterNumber)<>[snapApp_CostingExtract]![EncounterNumber]));
    # download tbl_PPM_ICD_diagnoses
    file_PpmIcdDiagnoses = "./ExtractorDB/PpmIcdDiagnoses.csv"
    if os.path.isfile(file_PpmIcdDiagnoses):
        try:
            tbl_PPM_ICD_diagnoses = read_csv_file(
                file_PpmIcdDiagnoses,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_PPM_ICD_diagnoses from ./ExtractorDB/PpmIcdDiagnoses.csv.\n"
                + str(e),
            )
            return
        else:
            tbl_PPM_ICD_diagnoses = tbl_PPM_ICD_diagnoses.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_PPM_ICD_diagnoses = tbl_PPM_ICD_diagnoses.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_PPM_ICD_diagnoses = tbl_PPM_ICD_diagnoses.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_PPM_ICD_diagnoses = tbl_PPM_ICD_diagnoses.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
    else:
        tbl_PPM_ICD_diagnoses = pd.DataFrame(
            columns=[
                "EncounterNumber",
                "DiagnosisCode",
                "DiagnosisVersion",
                "Sequence",
                "ConditionOnset",
                "HLTH_ORG_OSP_OSP_ID",
                "MG_AUTH_OSP_OSP_ID",
                "SE_CBK_SK",
                "EDW_Enc_Number",
            ]
        )
    tbl_PPM_ICD_diagnoses_copy = tbl_PPM_ICD_diagnoses.copy()
    tbl_PPM_ICD_diagnoses_copy.rename(
        columns={"EncounterNumber": "EncounterNumber_ppm_ICD_diag"}, inplace=True
    )
    # 11 Jan 2024 - CREATED FACILITY CHANGE
    # snapApp_CostingExtract_diagnoses = snapApp_CostingExtract[['EncounterNumber', 'FacilityCode', 'stay_number_cost', 'sa_episode_sequence_number']]
    snapApp_CostingExtract_diagnoses = snapApp_CostingExtract[
        [
            "EncounterNumber",
            "FacilityCode",
            "stay_number_cost",
            "sa_episode_sequence_number",
            "SE_CBK_SK",
        ]
    ]
    snapApp_CostingExtract_diagnoses["stay_number_cost"] = (
        snapApp_CostingExtract_diagnoses["stay_number_cost"].astype(str).str.strip()
    )
    snapApp_CostingExtract_diagnoses["sa_episode_sequence_number"] = (
        snapApp_CostingExtract_diagnoses["sa_episode_sequence_number"]
        .astype(str)
        .str.strip()
    )
    snapApp_CostingExtract_diagnoses["stay_number_cost"] = (
        snapApp_CostingExtract_diagnoses["stay_number_cost"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0")
    )
    snapApp_CostingExtract_diagnoses["sa_episode_sequence_number"] = (
        snapApp_CostingExtract_diagnoses["sa_episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    snapApp_CostingExtract_diagnoses["EncounterNumber_new"] = (
        snapApp_CostingExtract_diagnoses["FacilityCode"].astype(str).str.strip()
        + "-I-"
        + snapApp_CostingExtract_diagnoses["stay_number_cost"].astype(str).str.strip()
        + "-"
        + snapApp_CostingExtract_diagnoses["sa_episode_sequence_number"]
        .astype(str)
        .str.strip()
    )
    # 11 Jan 2024 - CREATED FACILITY CHANGE
    # tbl_PPM_ICD_diagnoses_snap = pd.merge(tbl_PPM_ICD_diagnoses_copy, snapApp_CostingExtract_diagnoses[['EncounterNumber', 'EncounterNumber_new']], how='inner', \
    # left_on=['EncounterNumber_ppm_ICD_diag'], right_on=['EncounterNumber_new'], suffixes=('', '_drop'))
    tbl_PPM_ICD_diagnoses_snap = pd.merge(
        tbl_PPM_ICD_diagnoses_copy,
        snapApp_CostingExtract_diagnoses[
            ["EncounterNumber", "EncounterNumber_new", "SE_CBK_SK"]
        ],
        how="inner",
        left_on=["SE_CBK_SK"],
        right_on=["SE_CBK_SK"],
        suffixes=("", "_drop"),
    )
    tbl_PPM_ICD_diagnoses_snap = tbl_PPM_ICD_diagnoses_snap.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    # print("In import_snap_amhcc_files(), check EncounterNumber in tbl_PPM_ICD_diagnoses columns. THERE SHOULD BE EncounterNumber and EncounterNumber_y=", tbl_PPM_ICD_diagnoses.columns.tolist())
    tbl_PPM_ICD_diagnoses_snap = tbl_PPM_ICD_diagnoses_snap[
        tbl_PPM_ICD_diagnoses_snap["EncounterNumber_ppm_ICD_diag"]
        != tbl_PPM_ICD_diagnoses_snap["EncounterNumber"]
    ]
    tbl_PPM_ICD_diagnoses_snap = tbl_PPM_ICD_diagnoses_snap[
        [
            "EncounterNumber",
            "DiagnosisCode",
            "DiagnosisVersion",
            "Sequence",
            "ConditionOnset",
            "HLTH_ORG_OSP_OSP_ID",
            "MG_AUTH_OSP_OSP_ID",
            "SE_CBK_SK",
            "EDW_Enc_Number",
        ]
    ]
    tbl_PPM_ICD_diagnoses_snap = tbl_PPM_ICD_diagnoses_snap.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    tbl_PPM_ICD_diagnoses_snap = tbl_PPM_ICD_diagnoses_snap.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    tbl_PPM_ICD_diagnoses_snap = tbl_PPM_ICD_diagnoses_snap.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    # dropping duplicate values
    tbl_PPM_ICD_diagnoses_snap.drop_duplicates(keep="last", inplace=True)
    tbl_PPM_ICD_diagnoses_snap.to_csv(
        "./ExtractorDB/tbl_PPM_ICD_diagnoses_snap.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    logging.info(
        "Query: Append_to_tbl_PPM_ICD_diagnoses_SNAP completed. tbl_PPM_ICD_diagnoses_snap created with %s records and saved to ./ExtractorDB/tbl_PPM_ICD_diagnoses_snap.csv.",
        len(tbl_PPM_ICD_diagnoses_snap),
    )
    tbl_PPM_ICD_diagnoses = pd.concat(
        [tbl_PPM_ICD_diagnoses, tbl_PPM_ICD_diagnoses_snap], axis=0
    )
    tbl_PPM_ICD_diagnoses = tbl_PPM_ICD_diagnoses.drop_duplicates(keep="last")
    tbl_PPM_ICD_diagnoses = tbl_PPM_ICD_diagnoses.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    tbl_PPM_ICD_diagnoses = tbl_PPM_ICD_diagnoses.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    tbl_PPM_ICD_diagnoses = tbl_PPM_ICD_diagnoses.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    # dropping duplicate values
    tbl_PPM_ICD_diagnoses.drop_duplicates(keep="last", inplace=True)
    tbl_PPM_ICD_diagnoses.to_csv(
        "./ExtractorDB/tbl_PPM_ICD_diagnoses.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    logging.info(
        "Query: Append_to_tbl_PPM_ICD_diagnoses_SNAP completed. tbl_PPM_ICD_diagnoses created with %s records and saved to ./ExtractorDB/tbl_PPM_ICD_diagnoses.csv.",
        len(tbl_PPM_ICD_diagnoses),
    )
    """Where it appends procedures matched by staynumber/seq to tbl_PPM_ICD_procedures if they match snapApp_CostingExtract """
    # Access query: Append_to_tbl_PPM_ICD_procedures_SNAP
    # INSERT INTO tbl_PPM_ICD_procedures ( EncounterNumber, ProcedureCode, ProcedureVersion, ProcedureDateTime, Sequence ) SELECT snapApp_CostingExtract.EncounterNumber, tbl_PPM_ICD_procedures.ProcedureCode, tbl_PPM_ICD_procedures.ProcedureVersion, tbl_PPM_ICD_procedures.ProcedureDateTime, tbl_PPM_ICD_procedures.Sequence FROM tbl_PPM_ICD_procedures, snapApp_CostingExtract WHERE (((tbl_PPM_ICD_procedures.EncounterNumber)=[snapApp_CostingExtract]![FacilityCode] & "-I-" & Format([snapApp_CostingExtract]![stay_number_cost],"00000000") & "-" & Format([snapApp_CostingExtract]![sa_episode_sequence_number],"000") And (tbl_PPM_ICD_procedures.EncounterNumber)<>[snapApp_CostingExtract]![EncounterNumber]));
    # download tbl_PPM_ICD_diagnoses
    file_PpmIcdProcedures = "./ExtractorDB/PpmIcdProcedures.csv"
    if os.path.isfile(file_PpmIcdProcedures):
        try:
            tbl_PPM_ICD_procedures = read_csv_file(
                file_PpmIcdProcedures,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_PPM_ICD_procedures from ./ExtractorDB/PpmIcdProcedures.csv.\n"
                + str(e),
            )
            return
        else:
            tbl_PPM_ICD_procedures = tbl_PPM_ICD_procedures.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_PPM_ICD_procedures = tbl_PPM_ICD_procedures.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_PPM_ICD_procedures = tbl_PPM_ICD_procedures.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_PPM_ICD_procedures = tbl_PPM_ICD_procedures.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
    else:
        tbl_PPM_ICD_procedures = pd.DataFrame(
            columns=[
                "EncounterNumber",
                "ProcedureCode",
                "ProcedureDateTime",
                "ProcedureVersion",
                "Sequence",
                "HLTH_ORG_OSP_OSP_ID",
                "MG_AUTH_OSP_OSP_ID",
                "SE_CBK_SK",
                "EDW_Enc_Number",
            ]
        )
    tbl_PPM_ICD_procedures_copy = tbl_PPM_ICD_procedures.copy()
    tbl_PPM_ICD_procedures_copy.rename(
        columns={"EncounterNumber": "EncounterNumber_ppm_ICD_proc"}, inplace=True
    )
    # 11 Jan 2024 - CREATED FACILITY CHANGE
    # snapApp_CostingExtract_procedures = snapApp_CostingExtract[['EncounterNumber', 'FacilityCode', 'stay_number_cost', 'sa_episode_sequence_number']]
    snapApp_CostingExtract_procedures = snapApp_CostingExtract[
        [
            "EncounterNumber",
            "FacilityCode",
            "stay_number_cost",
            "sa_episode_sequence_number",
            "SE_CBK_SK",
        ]
    ]
    snapApp_CostingExtract_procedures["stay_number_cost"] = (
        snapApp_CostingExtract_procedures["stay_number_cost"].astype(str).str.strip()
    )
    snapApp_CostingExtract_procedures["sa_episode_sequence_number"] = (
        snapApp_CostingExtract_procedures["sa_episode_sequence_number"]
        .astype(str)
        .str.strip()
    )
    snapApp_CostingExtract_procedures["stay_number_cost"] = (
        snapApp_CostingExtract_procedures["stay_number_cost"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0")
    )
    snapApp_CostingExtract_procedures["sa_episode_sequence_number"] = (
        snapApp_CostingExtract_procedures["sa_episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    snapApp_CostingExtract_procedures["EncounterNumber_new"] = (
        snapApp_CostingExtract_procedures["FacilityCode"].astype(str).str.strip()
        + "-I-"
        + snapApp_CostingExtract_procedures["stay_number_cost"].astype(str).str.strip()
        + "-"
        + snapApp_CostingExtract_procedures["sa_episode_sequence_number"]
        .astype(str)
        .str.strip()
    )
    # 11 Jan 2024 - CREATED FACILITY CHANGE
    # tbl_PPM_ICD_procedures_snap = pd.merge(tbl_PPM_ICD_procedures_copy, snapApp_CostingExtract_procedures[['EncounterNumber', 'EncounterNumber_new']], how='inner', \
    # left_on=['EncounterNumber_ppm_ICD_proc'], right_on=['EncounterNumber_new'], suffixes=(None, '_y'))
    tbl_PPM_ICD_procedures_snap = pd.merge(
        tbl_PPM_ICD_procedures_copy,
        snapApp_CostingExtract_procedures[
            ["EncounterNumber", "EncounterNumber_new", "SE_CBK_SK"]
        ],
        how="inner",
        left_on=["SE_CBK_SK"],
        right_on=["SE_CBK_SK"],
        suffixes=(None, "_y"),
    )
    tbl_PPM_ICD_procedures_snap = tbl_PPM_ICD_procedures_snap.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    tbl_PPM_ICD_procedures_snap = tbl_PPM_ICD_procedures_snap[
        tbl_PPM_ICD_procedures_snap["EncounterNumber_ppm_ICD_proc"]
        != tbl_PPM_ICD_procedures_snap["EncounterNumber"]
    ]
    tbl_PPM_ICD_procedures_snap = tbl_PPM_ICD_procedures_snap[
        [
            "EncounterNumber",
            "ProcedureCode",
            "ProcedureVersion",
            "ProcedureDateTime",
            "Sequence",
            "HLTH_ORG_OSP_OSP_ID",
            "MG_AUTH_OSP_OSP_ID",
            "SE_CBK_SK",
            "EDW_Enc_Number",
        ]
    ]
    tbl_PPM_ICD_procedures_snap = tbl_PPM_ICD_procedures_snap.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    tbl_PPM_ICD_procedures_snap = tbl_PPM_ICD_procedures_snap.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    tbl_PPM_ICD_procedures_snap = tbl_PPM_ICD_procedures_snap.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    # dropping duplicate values
    tbl_PPM_ICD_procedures_snap.drop_duplicates(keep="last", inplace=True)
    tbl_PPM_ICD_procedures_snap.to_csv(
        "./ExtractorDB/tbl_PPM_ICD_procedures_snap.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    logging.info(
        "Query: Append_to_tbl_PPM_ICD_procedures_SNAP completed. tbl_PPM_ICD_procedures_snap created with %s records and saved to ./ExtractorDB/tbl_PPM_ICD_procedures_snap.csv.",
        len(tbl_PPM_ICD_procedures_snap),
    )
    tbl_PPM_ICD_procedures = pd.concat(
        [tbl_PPM_ICD_procedures, tbl_PPM_ICD_procedures_snap], axis=0
    )
    tbl_PPM_ICD_procedures = tbl_PPM_ICD_procedures.drop_duplicates(keep="last")
    tbl_PPM_ICD_procedures = tbl_PPM_ICD_procedures.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    tbl_PPM_ICD_procedures = tbl_PPM_ICD_procedures.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    tbl_PPM_ICD_procedures = tbl_PPM_ICD_procedures.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    # dropping duplicate values
    tbl_PPM_ICD_procedures.drop_duplicates(keep="last", inplace=True)
    tbl_PPM_ICD_procedures.to_csv(
        "./ExtractorDB/tbl_PPM_ICD_procedures.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    logging.info(
        "Query: Append_to_tbl_PPM_ICD_procedures_SNAP completed. tbl_PPM_ICD_procedures created with %s records and saved to ./ExtractorDB/tbl_PPM_ICD_procedures.csv.",
        len(tbl_PPM_ICD_procedures),
    )
    """ Appends data into SNAP stats table showing the minimum and maximum and count of rows for each stay/sequencenumber in the snapApp_CostingExtract Table """
    # Access query: SNAP stats mt
    # SELECT snapApp_CostingExtract.stay_number_cost AS stay_number, snapApp_CostingExtract.sa_episode_sequence_number, Min(snapApp_CostingExtract.Sequence) AS MinOfSequence, Max(snapApp_CostingExtract.Sequence) AS MaxOfSequence, Count(snapApp_CostingExtract.Sequence) AS CountOfSequence INTO [SNAP stats] FROM snapApp_CostingExtract GROUP BY snapApp_CostingExtract.stay_number_cost, snapApp_CostingExtract.sa_episode_sequence_number;
    snap_stats = (
        snapApp_CostingExtract.groupby(
            ["stay_number_cost", "sa_episode_sequence_number"],
            as_index=False,
            dropna=False,
        )
        .agg(
            MinOfSequence=("Sequence", "min"),
            MaxOfSequence=("Sequence", "max"),
            CountOfSequence=("Sequence", "count"),
        )
        .reset_index()
    )
    snap_stats["stay_number"] = snap_stats["stay_number_cost"]
    snap_stats["MinOfSequence"] = np.where(
        snap_stats["MinOfSequence"] == "nan", "", snap_stats["MinOfSequence"]
    )
    snap_stats["MaxOfSequence"] = np.where(
        snap_stats["MaxOfSequence"] == "nan", "", snap_stats["MaxOfSequence"]
    )
    snap_stats = snap_stats[
        [
            "stay_number",
            "sa_episode_sequence_number",
            "MinOfSequence",
            "MaxOfSequence",
            "CountOfSequence",
        ]
    ]
    snap_stats = snap_stats.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    snap_stats = snap_stats.applymap(lambda x: x.strip() if isinstance(x, str) else x)
    snap_stats = snap_stats.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    snap_stats["sa_episode_sequence_number"] = (
        snap_stats["sa_episode_sequence_number"].astype(str).str.replace("nan", "")
    )
    # dropping duplicate values
    snap_stats.drop_duplicates(keep="last", inplace=True)
    snap_stats.to_csv(
        "./ExtractorDB/SNAP_stats.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    logging.info(
        "Query: SNAP stats mt completed. snap_stats created with %s records and saved to ./ExtractorDB/snap_stats.csv.",
        len(snap_stats),
    )
    """ Appends data from the snapApp_CostingExtract Table into  SNAP File 2 01 table. This essentially reformats data and renames fields. 
    This was done to the constant changes in the snap extact data ,it was easier to create a staging table instead of changing various queries."""
    # Access query: SNAP File 2 00
    # SELECT snapApp_CostingExtract.[AN SNAP V3], snapApp_CostingExtract.EncounterNumber, snapApp_CostingExtract.FacilityCode, snapApp_CostingExtract.stay_number_cost AS stay_number, snapApp_CostingExtract.sa_episode_sequence_number, Format$([snapApp_CostingExtract]![SNAPEpisodeID],"00000000")+IIf([snapApp_CostingExtract]![PCSNAP_PhaseID] Is Null,"","-"+Format$([snapApp_CostingExtract]![PCSNAP_PhaseID],"00000")) AS EpiNo, [CASE TYPE MAPPED TO PRODTYPE].ProdType, snapApp_CostingExtract.SNAPCaseType AS CaseType, snapApp_CostingExtract.EpisType, snapApp_CostingExtract.AssessmentOnly AS AssessOnly, Null AS ProvType, snapApp_CostingExtract.PCPhase AS Phase, snapApp_CostingExtract.PCSymptomScoreStart, snapApp_CostingExtract.PCSeverityStart, snapApp_CostingExtract.PCPsychSpiritualScoreStart, snapApp_CostingExtract.PCFamilyCarerScoreStart, snapApp_CostingExtract.MaintType, snapApp_CostingExtract.CareFocus, Null AS SolePract, Null AS MHServ, Null AS SnapDiag, snapApp_CostingExtract.RehImpairmentCode AS Impair, snapApp_CostingExtract.RUGBedMobilityStart AS RugBedBeg, snapApp_CostingExtract.RUGToiletingSTart AS RugToilBeg, snapApp_CostingExtract.RUGTransferStart AS RugXferBeg, snapApp_CostingExtract.RUGEatingStart AS RugEatBeg, snapApp_CostingExtract.[AN SNAP V3] AS SNAP_Class, snapApp_CostingExtract.FIMEatingStart AS FIMEatBeg, snapApp_CostingExtract.FIMEatingend AS FIMEatEnd, snapApp_CostingExtract.FIMGroomingStart AS FIMGroomBeg, snapApp_CostingExtract.FIMGroomingEnd AS FIMGroomEnd, snapApp_CostingExtract.FIMBathingStart AS FIMBathBeg, snapApp_CostingExtract.FIMBathingEnd AS FIMBathEnd, snapApp_CostingExtract.FIMDressingUpperStart AS FIMUpperBeg, snapApp_CostingExtract.FIMDressingUpperEnd AS FIMUpperEnd, snapApp_CostingExtract.FIMDressingLowerStart AS FIMLowerBeg, snapApp_CostingExtract.FIMDressingLowerEnd AS FIMLowerEnd, snapApp_CostingExtract.FIMToiletingStart AS FIMToiletBeg, snapApp_CostingExtract.FIMToiletingEnd AS FIMToiletEnd, snapApp_CostingExtract.FIMBladderStart AS FIMBladderBeg, snapApp_CostingExtract.FIMBladderEnd AS FIMBladderEnd, snapApp_CostingExtract.FIMBowelStart AS FIMBowelBeg, snapApp_CostingExtract.FIMBowelEnd AS FIMBowelEnd, snapApp_CostingExtract.FIMXferBedChairWChairStart AS FIMXferBeg, snapApp_CostingExtract.FIMXferBedChairWChairEnd AS FIMXferEnd, snapApp_CostingExtract.FIMXferToiletStart AS FIMXferToilBeg, snapApp_CostingExtract.FIMXferToiletEnd AS FIMXferToilEnd, snapApp_CostingExtract.FIMXferBathShowerStart AS FIMTubBeg, snapApp_CostingExtract.FIMXferBathShowerEnd AS FIMTubEnd, snapApp_CostingExtract.FIMWalkWheelChairStart AS FIMWalkBeg, snapApp_CostingExtract.FIMWalkWheelChairEnd AS FIMWalkEnd, snapApp_CostingExtract.FIMStairsStart AS FIMStairBeg, snapApp_CostingExtract.FIMStairsEnd AS FIMStairEnd, snapApp_CostingExtract.FIMComprehensionStart AS FIMCompBeg, snapApp_CostingExtract.FIMComprehensionEnd AS FIMCompEnd, snapApp_CostingExtract.FIMExpressionStart AS FIMExpBeg, snapApp_CostingExtract.FIMExpressionEnd AS FIMExpEnd, snapApp_CostingExtract.FIMSocialInteractionStart AS FIMSocialBeg, snapApp_CostingExtract.FIMSocialInteractionEnd AS FIMSocialEnd, snapApp_CostingExtract.FIMProblemSolvingStart AS FIMProbBeg, snapApp_CostingExtract.FIMProblemSolvingEnd AS FIMProbEnd, snapApp_CostingExtract.FIMMemoryStart AS FIMMemoryBeg, snapApp_CostingExtract.FIMMemoryEnd AS FIMMemoryEnd, snapApp_CostingExtract.HONActivityStart AS HonActiveBeg, snapApp_CostingExtract.HONActivityEnd AS HonActiveEnd, snapApp_CostingExtract.HONInjuryStart AS HonInjuryBeg, snapApp_CostingExtract.HONInjuryEnd AS HonInjuryEnd, snapApp_CostingExtract.HONDrinkStart AS HonDrinkBeg, snapApp_CostingExtract.HONDrinkEnd AS HonDrinkEnd, snapApp_CostingExtract.HONCognitStart AS HonCognitBeg, snapApp_CostingExtract.HONCognitEnd AS HonCognitEnd, snapApp_CostingExtract.HONDisabStart AS HonDisabBeg, snapApp_CostingExtract.HONDisabEnd AS HonDisabEnd, snapApp_CostingExtract.HONHallucStart AS HonHallucBeg, snapApp_CostingExtract.HONHallucEnd AS HonHallucEnd, snapApp_CostingExtract.HONDepresStart AS HonDeprsBeg, snapApp_CostingExtract.HONDepresEnd AS HonDeprsEnd, snapApp_CostingExtract.HONOtherStart AS HonOtherBeg, snapApp_CostingExtract.HONOtherEnd AS HonOtherEnd, snapApp_CostingExtract.HONRelatStart AS HonRelatBeg, snapApp_CostingExtract.HONRelatEnd AS HonRelatEnd, snapApp_CostingExtract.HONAdlStart AS HonADLBeg, snapApp_CostingExtract.HONAdlEnd AS HonADLEnd, snapApp_CostingExtract.HONLivingStart AS HonLivingBeg, snapApp_CostingExtract.HONLivingEnd AS HonLivingEnd, snapApp_CostingExtract.HONOccupStart AS HonOccupBeg, snapApp_CostingExtract.HONOccupEnd AS HonOccupEnd, snapApp_CostingExtract.sa_nwau, snapApp_CostingExtract.sa_nwau_version, snapApp_CostingExtract.sa_occdays_in_cost_period, snapApp_CostingExtract.sa_leave_days_in_cost_period, snapApp_CostingExtract.sa_AN_SNAP_Version, snapApp_CostingExtract.sa_EpisodeBegReason, snapApp_CostingExtract.sa_EpisodeEndReason, snapApp_CostingExtract.sa_total_los, snapApp_CostingExtract.sa_total_leave_days, snapApp_CostingExtract.[Snap ClassV4], snapApp_CostingExtract.Dementia_Flag, snapApp_CostingExtract.Delirium_Flag INTO [SNAP File 2 01] FROM snapApp_CostingExtract LEFT JOIN [CASE TYPE MAPPED TO PRODTYPE] ON snapApp_CostingExtract.SNAPCaseType = [CASE TYPE MAPPED TO PRODTYPE].Code;
    # create a dataframe CASE TYPE MAPPED TO PRODTYPE
    # 20 Feb 2025 - Calli mentioned that SNAPCaseType cannot be relied. Better use CareType
    # if the word SNAP is in the column name title, that normally indicates that field value comes from the Synaptix database specifically and should not be confused with the same data elements/domains that may also be available in EDW.  Wherever possible we would always use the EDW value as the source of truth in preference to any other first.
    # Many of the SNAPCaseType values are missing because no Synaptix record exists  as noted above.
    # The values in the CareType field are the NSW Health values which are slightly different to the national values (we have a couple more) which are completely different from the SNAPCaseType values (values in Synaptix)
    # Heres the link but I have pasted a screenshot of the values below http://hird.health.nsw.gov.au/hird/view_domain_values_list.cfm?ItemID=14150
    """
    data = [['1', 'PC'], ['2', 'RH'], ['3', 'PG'], ['4', 'GM'], ['5', 'MA']]
    case_type_mapped_to_prodtype = pd.DataFrame(data, columns=['Code', 'ProdType'])
    snapFile201 = pd.merge(snapApp_CostingExtract, case_type_mapped_to_prodtype[['Code', 'ProdType']], how='left', left_on=['SNAPCaseType'], right_on=['Code'], suffixes=('', '_drop'))
    """
    data = [["3", "PC"], ["2", "RH"], ["8", "PG"], ["7", "GM"], ["4", "MA"]]
    case_type_mapped_to_prodtype = pd.DataFrame(data, columns=["Code", "ProdType"])
    snapFile201 = pd.merge(
        snapApp_CostingExtract,
        case_type_mapped_to_prodtype[["Code", "ProdType"]],
        how="left",
        left_on=["caretype"],
        right_on=["Code"],
        suffixes=("", "_drop"),
    )
    snapFile201 = snapFile201.apply(
        lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
    )
    snapFile201["SolePract"] = ""
    snapFile201["MHServ"] = ""
    snapFile201["SnapDiag"] = ""
    snapFile201["ProvType"] = ""
    snapFile201["SNAPEpisodeID"] = np.where(
        (snapFile201["SNAPEpisodeID"].isnull()) | (snapFile201["SNAPEpisodeID"] == ""),
        "",
        snapFile201["SNAPEpisodeID"].astype(str).str.strip(),
    )
    snapFile201["PCSNAP_PhaseID"] = np.where(
        (snapFile201["PCSNAP_PhaseID"].isnull())
        | (snapFile201["PCSNAP_PhaseID"] == ""),
        "",
        snapFile201["PCSNAP_PhaseID"].astype(str).str.strip(),
    )
    condlist = [
        (
            (snapFile201["PCSNAP_PhaseID"].isnull())
            | (snapFile201["PCSNAP_PhaseID"] == "")
        )
        & (pd.notna(snapFile201["SNAPEpisodeID"]))
        & (snapFile201["SNAPEpisodeID"] != ""),
        (pd.notna(snapFile201["PCSNAP_PhaseID"]))
        & (pd.notna(snapFile201["SNAPEpisodeID"]))
        & (snapFile201["PCSNAP_PhaseID"] != "")
        & (snapFile201["SNAPEpisodeID"] != ""),
    ]
    choicelist = [
        snapFile201["SNAPEpisodeID"].astype(str).str.pad(8, side="left", fillchar="0"),
        snapFile201["SNAPEpisodeID"].astype(str).str.pad(8, side="left", fillchar="0")
        + "-"
        + snapFile201["PCSNAP_PhaseID"]
        .astype(str)
        .str.pad(5, side="left", fillchar="0"),
    ]
    snapFile201["EpiNo"] = np.select(condlist, choicelist, "")

    snapFile201["Phase"] = snapFile201["pcPhase"]
    snapFile201["stay_number"] = snapFile201["stay_number_cost"]
    snapFile201["CaseType"] = snapFile201["SNAPCaseType"]
    snapFile201["AssessOnly"] = snapFile201["AssessmentOnly"]
    snapFile201["Impair"] = snapFile201["RehImpairmentCode"]
    snapFile201["RugBedBeg"] = snapFile201["RUGBedMobilityStart"]
    snapFile201["RugToilBeg"] = snapFile201["RUGToiletingStart"]
    snapFile201["RugXferBeg"] = snapFile201["RUGTransferStart"]
    snapFile201["RugEatBeg"] = snapFile201["RUGEatingStart"]
    snapFile201["SNAP_Class"] = snapFile201["AN SNAP V3"]
    snapFile201["FIMEatBeg"] = snapFile201["FIMEatingStart"]
    snapFile201["FIMEatEnd"] = snapFile201["FIMEatingEnd"]
    snapFile201["FIMGroomBeg"] = snapFile201["FIMGroomingStart"]
    snapFile201["FIMGroomEnd"] = snapFile201["FIMGroomingEnd"]
    snapFile201["FIMBathBeg"] = snapFile201["FIMBathingStart"]
    snapFile201["FIMBathEnd"] = snapFile201["FIMBathingEnd"]
    snapFile201["FIMUpperBeg"] = snapFile201["FIMDressingUpperStart"]
    snapFile201["FIMUpperEnd"] = snapFile201["FIMDressingUpperEnd"]
    snapFile201["FIMLowerBeg"] = snapFile201["FIMDressingLowerStart"]
    snapFile201["FIMLowerEnd"] = snapFile201["FIMDressingLowerEnd"]
    snapFile201["FIMToiletBeg"] = snapFile201["FIMToiletingStart"]
    snapFile201["FIMToiletEnd"] = snapFile201["FIMToiletingEnd"]
    snapFile201["FIMBladderBeg"] = snapFile201["FIMBladderStart"]
    snapFile201["FIMBladderEnd"] = snapFile201["FIMBladderEnd"]
    snapFile201["FIMBowelBeg"] = snapFile201["FIMBowelStart"]
    snapFile201["FIMBowelEnd"] = snapFile201["FIMBowelEnd"]
    snapFile201["FIMXferBeg"] = snapFile201["FIMXferBedChairWChairStart"]
    snapFile201["FIMXferEnd"] = snapFile201["FIMXferBedChairWChairEnd"]
    snapFile201["FIMXferToilBeg"] = snapFile201["FIMXferToiletStart"]
    snapFile201["FIMXferToilEnd"] = snapFile201["FIMXferToiletEnd"]
    snapFile201["FIMTubBeg"] = snapFile201["FIMXferBathShowerStart"]
    snapFile201["FIMTubEnd"] = snapFile201["FIMXferBathShowerEnd"]
    snapFile201["FIMWalkBeg"] = snapFile201["FIMWalkWheelChairStart"]
    snapFile201["FIMWalkEnd"] = snapFile201["FIMWalkWheelChairEnd"]
    snapFile201["FIMStairBeg"] = snapFile201["FIMStairsStart"]
    snapFile201["FIMStairEnd"] = snapFile201["FIMStairsEnd"]
    snapFile201["FIMCompBeg"] = snapFile201["FIMComprehensionStart"]
    snapFile201["FIMCompEnd"] = snapFile201["FIMComprehensionEnd"]
    snapFile201["FIMExpBeg"] = snapFile201["FIMExpressionStart"]
    snapFile201["FIMExpEnd"] = snapFile201["FIMExpressionEnd"]
    snapFile201["FIMSocialBeg"] = snapFile201["FIMSocialInteractionStart"]
    snapFile201["FIMSocialEnd"] = snapFile201["FIMSocialInteractionEnd"]
    snapFile201["FIMProbBeg"] = snapFile201["FIMProblemSolvingStart"]
    snapFile201["FIMProbEnd"] = snapFile201["FIMProblemSolvingEnd"]
    snapFile201["FIMMemoryBeg"] = snapFile201["FIMMemoryStart"]
    snapFile201["FIMMemoryEnd"] = snapFile201["FIMMemoryEnd"]
    snapFile201["HonActiveBeg"] = snapFile201["HONActivityStart"]
    snapFile201["HonActiveEnd"] = snapFile201["HONActivityEnd"]
    snapFile201["HonInjuryBeg"] = snapFile201["HONInjuryStart"]
    snapFile201["HonInjuryEnd"] = snapFile201["HONInjuryEnd"]
    snapFile201["HonDrinkBeg"] = snapFile201["HONDrinkStart"]
    snapFile201["HonDrinkEnd"] = snapFile201["HONDrinkEnd"]
    snapFile201["HonCognitBeg"] = snapFile201["HONCognitStart"]
    snapFile201["HonCognitEnd"] = snapFile201["HONCognitEnd"]
    snapFile201["HonDisabBeg"] = snapFile201["HONDisabStart"]
    snapFile201["HonDisabEnd"] = snapFile201["HONDisabEnd"]
    snapFile201["HonHallucBeg"] = snapFile201["HONHallucStart"]
    snapFile201["HonHallucEnd"] = snapFile201["HONHallucEnd"]
    snapFile201["HonDeprsBeg"] = snapFile201["HONDepresStart"]
    snapFile201["HonDeprsEnd"] = snapFile201["HONDepresEnd"]
    snapFile201["HonOtherBeg"] = snapFile201["HONOtherStart"]
    snapFile201["HonOtherEnd"] = snapFile201["HONOtherEnd"]
    snapFile201["HonRelatBeg"] = snapFile201["HONRelatStart"]
    snapFile201["HonRelatEnd"] = snapFile201["HONRelatEnd"]
    snapFile201["HonADLBeg"] = snapFile201["HONAdlStart"]
    snapFile201["HonADLEnd"] = snapFile201["HONAdlEnd"]
    snapFile201["HonLivingBeg"] = snapFile201["HONLivingStart"]
    snapFile201["HonLivingEnd"] = snapFile201["HONLivingEnd"]
    snapFile201["HonOccupBeg"] = snapFile201["HONOccupStart"]
    snapFile201["HonOccupEnd"] = snapFile201["HONOccupEnd"]
    # 11 Jan 2024 - CREATED FACILITY CHANGE - added SE_CBK_SK, PCSNAP_PhaseID,  SNAPEpisodeID - NO NEED TO add the last two as encounternumber will suffice
    snapFile201 = snapFile201[
        [
            "AN SNAP V3",
            "EncounterNumber",
            "FacilityCode",
            "stay_number",
            "sa_episode_sequence_number",
            "EpiNo",
            "ProdType",
            "CaseType",
            "EpisType",
            "AssessOnly",
            "ProvType",
            "Phase",
            "PCSymptomScoreStart",
            "PCSeverityStart",
            "PCPsychSpiritualScoreStart",
            "PCFamilyCarerScoreStart",
            "MaintType",
            "CareFocus",
            "SolePract",
            "MHServ",
            "SnapDiag",
            "Impair",
            "RugBedBeg",
            "RugToilBeg",
            "RugXferBeg",
            "RugEatBeg",
            "SNAP_Class",
            "FIMEatBeg",
            "FIMEatEnd",
            "FIMGroomBeg",
            "FIMGroomEnd",
            "FIMBathBeg",
            "FIMBathEnd",
            "FIMUpperBeg",
            "FIMUpperEnd",
            "FIMLowerBeg",
            "FIMLowerEnd",
            "FIMToiletBeg",
            "FIMToiletEnd",
            "FIMBladderBeg",
            "FIMBladderEnd",
            "FIMBowelBeg",
            "FIMBowelEnd",
            "FIMXferBeg",
            "FIMXferEnd",
            "FIMXferToilBeg",
            "FIMXferToilEnd",
            "FIMTubBeg",
            "FIMTubEnd",
            "FIMWalkBeg",
            "FIMWalkEnd",
            "FIMStairBeg",
            "FIMStairEnd",
            "FIMCompBeg",
            "FIMCompEnd",
            "FIMExpBeg",
            "FIMExpEnd",
            "FIMSocialBeg",
            "FIMSocialEnd",
            "FIMProbBeg",
            "FIMProbEnd",
            "FIMMemoryBeg",
            "FIMMemoryEnd",
            "HonActiveBeg",
            "HonActiveEnd",
            "HonInjuryBeg",
            "HonInjuryEnd",
            "HonDrinkBeg",
            "HonDrinkEnd",
            "HonCognitBeg",
            "HonCognitEnd",
            "HonDisabBeg",
            "HonDisabEnd",
            "HonHallucBeg",
            "HonHallucEnd",
            "HonDeprsBeg",
            "HonDeprsEnd",
            "HonOtherBeg",
            "HonOtherEnd",
            "HonRelatBeg",
            "HonRelatEnd",
            "HonADLBeg",
            "HonADLEnd",
            "HonLivingBeg",
            "HonLivingEnd",
            "HonOccupBeg",
            "HonOccupEnd",
            "sa_nwau",
            "sa_nwau_version",
            "sa_occdays_in_cost_period",
            "sa_leave_days_in_cost_period",
            "sa_AN_SNAP_Version",
            "sa_EpisodeBegReason",
            "sa_EpisodeEndReason",
            "sa_total_los",
            "sa_total_leave_days",
            "Snap ClassV4",
            "Dementia_Flag",
            "Delirium_Flag",
            "SE_CBK_SK",
        ]
    ]
    snapFile201 = snapFile201.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    snapFile201 = snapFile201.applymap(lambda x: x.strip() if isinstance(x, str) else x)
    snapFile201 = snapFile201.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    snapFile201["ProdType"] = snapFile201["ProdType"].astype(str).str.replace("nan", "")
    # dropping duplicate values
    snapFile201.drop_duplicates(keep="last", inplace=True)
    snapFile201.to_csv(
        "./ExtractorDB/SnapFile201.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    logging.info(
        "Query: SNAP File 2 00 completed. snapFile201 created with %s records and saved to ./ExtractorDB/SnapFile201.csv.",
        len(snapFile201),
    )
    file_tbl_ExcludedEncounters = "./ExtractorDB/OutputExcludedEncounters_part1.csv"
    if os.path.isfile(file_tbl_ExcludedEncounters):
        try:
            tbl_ExcludedEncounters = read_csv_file(
                file_tbl_ExcludedEncounters,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error",
                "Error extracting tbl_ExcludedEncounters from ./ExtractorDB/OutputExcludedEncounters.csv.\n"
                + str(e),
            )
            # label_map_1_status = 0
            return
        else:
            tbl_ExcludedEncounters = tbl_ExcludedEncounters.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_ExcludedEncounters = tbl_ExcludedEncounters.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_ExcludedEncounters = tbl_ExcludedEncounters.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_ExcludedEncounters = tbl_ExcludedEncounters.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
    logging.info(
        "df_SNAP_Excluded_enddate_le_startdate has %s encounters. df_AMHCC_Excluded_enddate_le_startdate has %s encounters.",
        len(df_SNAP_Excluded_enddate_le_startdate),
        len(df_AMHCC_Excluded_enddate_le_startdate),
    )
    """
    logging.info('df_SNAP_Excluded_enddate_le_startdate has %s encounters. df_AMHCC_Excluded_enddate_le_startdate has %s encounters. df_SNAP_Excluded_invalid_nwau has  %s encounters. df_AMHCC_extract_Excluded_invalid_nwau has %s encounters', len(df_SNAP_Excluded_enddate_le_startdate), len(df_AMHCC_Excluded_enddate_le_startdate), len(df_SNAP_Excluded_invalid_nwau), len(df_AMHCC_extract_Excluded_invalid_nwau))
    if len(df_SNAP_Excluded_invalid_nwau) >0:
        tbl_ExcludedEncounters = pd.concat([tbl_ExcludedEncounters, df_SNAP_Excluded_invalid_nwau], axis=0)
    if len(df_AMHCC_extract_Excluded_invalid_nwau) >0:
        tbl_ExcludedEncounters = pd.concat([tbl_ExcludedEncounters, df_AMHCC_extract_Excluded_invalid_nwau], axis=0)
    """
    if len(df_SNAP_Excluded_enddate_le_startdate) > 0:
        tbl_ExcludedEncounters = pd.concat(
            [tbl_ExcludedEncounters, df_SNAP_Excluded_enddate_le_startdate], axis=0
        )
    if len(df_AMHCC_Excluded_enddate_le_startdate) > 0:
        tbl_ExcludedEncounters = pd.concat(
            [tbl_ExcludedEncounters, df_AMHCC_Excluded_enddate_le_startdate], axis=0
        )
    tbl_ExcludedEncounters = tbl_ExcludedEncounters.sort_values(
        by=[
            "facility_identifier",
            "stay_number",
            "episode_sequence_number",
            "ed_identifier",
            "SNAP_encounter",
            "ReasonForExclusion",
            "EncounterNumber",
        ]
    )
    tbl_ExcludedEncounters = tbl_ExcludedEncounters.drop_duplicates(keep="last")
    # tbl_ExcludedEncounters.drop_duplicates(subset=['facility_identifier',  'stay_number',  'episode_sequence_number', 'ed_identifier', 'SNAP_encounter', 'ReasonForExclusion', 'EncounterNumber'],keep = 'last', inplace = True)
    # Ranjit : commenting this
    # tbl_ExcludedEncounters.drop_duplicates(subset=['EncounterNumber'],keep = 'last', inplace = True)
    # commenting below code as it it results in encounter number = snap encounter when snap_encounter is not null which is always the case.
    # access query: qry tbl_excludedencounters_updateencounternumber
    # UPDATE tbl_ExcludedEncounters SET tbl_ExcludedEncounters.EncounterNumber = IIf([snap_encounter] Is Not Null,[snap_encounter],[facility_identifier] & "-" & "I" & "-" & Format$([stay_number],"00000000") & "-" & Format$([episode_sequence_number],"000"));
    tbl_ExcludedEncounters["stay_number"] = (
        tbl_ExcludedEncounters["stay_number"].astype(str).str.strip()
    )
    tbl_ExcludedEncounters["episode_sequence_number"] = (
        tbl_ExcludedEncounters["episode_sequence_number"].astype(str).str.strip()
    )
    # tbl_ExcludedEncounters['stay_number_dummy'] = tbl_ExcludedEncounters['stay_number'].astype(str).str.pad(8, side ='left', fillchar ='0')
    # tbl_ExcludedEncounters['episode_sequence_number_dummy'] = tbl_ExcludedEncounters['episode_sequence_number'].astype(str).str.pad(3, side ='left', fillchar ='0')
    # tbl_ExcludedEncounters['EncounterNumber'] = np.where(pd.notna(tbl_ExcludedEncounters['SNAP_encounter']), tbl_ExcludedEncounters['SNAP_encounter'], tbl_ExcludedEncounters['facility_identifier'].astype(str).str.strip()+"-I-"+tbl_ExcludedEncounters['stay_number_dummy']+"-"+tbl_ExcludedEncounters['episode_sequence_number_dummy'])
    # tbl_ExcludedEncounters.drop(['stay_number_dummy', 'episode_sequence_number_dummy'], axis=1, inplace=True, errors='ignore')
    tbl_ExcludedEncounters = tbl_ExcludedEncounters.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    tbl_ExcludedEncounters = tbl_ExcludedEncounters.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    tbl_ExcludedEncounters = tbl_ExcludedEncounters.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    # dropping duplicate values
    tbl_ExcludedEncounters.drop_duplicates(keep="last", inplace=True)
    tbl_ExcludedEncounters.to_csv(
        "./ExtractorDB/OutputExcludedEncounters.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    logging.info(
        "Query: qry tbl_excludedencounters_updateencounternumber completed. tbl_ExcludedEncounters created with %s records and saved to ./ExtractorDB/OutputExcludedEncounters.csv.",
        len(tbl_ExcludedEncounters),
    )
    if extract_type == "new_extract":
        # Update Sub task status
        if label_10_status == 0:
            label_10_sub.configure(text="Failed", fg="red")
            main_screen.update()
        else:
            label_10_sub.configure(text="Completed", fg="green")
            main_screen.update()
        # label_10_res.configure(text="AMHCC_extract:"+str(len(amhcc_extract)))
        main_screen.update()
    button_transform["state"] = DISABLED
    logging.info("Extract snap and amhcc files completed.")
    ############Ranjit: 19 Aug
    cleanup_memory(snapApp_CostingExtract)
    cleanup_memory(df_SNAP_Excluded_enddate_le_startdate)
    cleanup_memory(snap_NWAU)
    cleanup_memory(df_SNAPRec)
    cleanup_memory(df_PLA_Mapping_00)
    cleanup_memory(df_PLA_AMHCC)
    cleanup_memory(df_Class_Descriptions)
    cleanup_memory(df_SpecialtyPortalValues)
    cleanup_memory(df_MDC)
    cleanup_memory(df_AMHCC_extract)
    cleanup_memory(amhcc_extract)
    cleanup_memory(df_AMHCC_Excluded_enddate_le_startdate)
    cleanup_memory(tbl_dbo_Facility)
    cleanup_memory(df_AMHCC_Costingextract)
    cleanup_memory(tbl_dbo_episode_ats)
    cleanup_memory(df_AMHCC_NWAU)
    cleanup_memory(snapApp_CostingExtract_diagnoses)
    cleanup_memory(tbl_PPM_ICD_diagnoses)
    cleanup_memory(tbl_PPM_ICD_procedures)
    cleanup_memory(snapApp_CostingExtract_procedures)
    cleanup_memory(snap_stats)
    cleanup_memory(snapFile201)
    cleanup_memory(tbl_ExcludedEncounters)
    ############
    return label_9_status, label_10_status


def extract_complete(
    extract_type,
    lhd,
    facilities_excluded_list,
    facilities_included_list,
    roundid,
    start_date,
    end_date,
    nwau_v,
    icd10_v,
    drg1_v,
    drg2_v,
    drg4_v,
    snap_v,
    amhcc_v,
    cost_weight_v,
    srg_drg_v,
):
    # save present run's details to config file for the next run.
    save_present_run(
        lhd,
        facilities_excluded_list,
        facilities_included_list,
        roundid,
        start_date,
        end_date,
        nwau_v,
        icd10_v,
        drg1_v,
        drg2_v,
        drg4_v,
        snap_v,
        amhcc_v,
        cost_weight_v,
        srg_drg_v,
    )
    if extract_type != "new_extract":
        label_9_status, label_10_status = import_snap_amhcc_files(
            "prev_extract",
            lhd,
            facilities_excluded_list,
            facilities_included_list,
            roundid,
            start_date,
            end_date,
            nwau_v,
            icd10_v,
            drg1_v,
            drg2_v,
            drg4_v,
            snap_v,
            amhcc_v,
            cost_weight_v,
            srg_drg_v,
        )
    """if label_9_status and label_10_status:"""  # No need IF clause as SNAP, AMHCC are not mandatory
    """
    logging.info('All data has been successfully extracted. User can now run transformations.')
    messagebox.showinfo("Data Extraction", "All data has been successfully extracted.\nYou can now run transformations.")
    # disable extract button and enable transform button
    button_extract['state'] = DISABLED
    button_transform['state'] = ACTIVE
    main_screen.update()
    # cannot declare a variable as global if it is already passed as a parameter.
    global lhd_global, facilities_excluded_list_global#, roundid, start_date, end_date, nwau_v, icd10_v, drg1_v, drg2_v, drg4_v, snap_v, amhcc_v, cost_weight_v, srg_drg_v
    lhd_global = lhd
    facilities_excluded_list_global = facilities_excluded_list
    # This self assigning is probably redundant, but I am not sure how the global keyword work sometimes.  
    roundid= str(roundid)
    start_date= str(start_date)
    end_date= str(end_date)
    nwau_v= str(nwau_v)
    icd10_v= str(icd10_v)
    drg1_v= str(drg1_v)
    drg2_v= str(drg2_v)
    drg4_v= str(drg4_v)
    snap_v= str(snap_v)
    amhcc_v= str(amhcc_v)
    cost_weight_v=str(cost_weight_v)
    srg_drg_v= str(srg_drg_v)
    # Fetch mapping files
    transform_ppm_transform_amo()
    transform_criticalcaregroup()
    transform_specialtyportalmapping()
    transform_edroledelin()
    transform_pla_role_table()
    """
    # Ranjit - 26 Aug
    # messagebox.showinfo("Data Extraction", "Please wait for a few minutes while the extractions are finalised.")
    messagebox.showinfo(
        "Data Extraction",
        "Please wait for a few minutes while the extractions are finalised.",
        parent=main_screen,
    )
    # cannot declare a variable as global if it is already passed as a parameter.
    global lhd_global, facilities_excluded_list_global, facilities_included_list_global  # , roundid, start_date, end_date, nwau_v, icd10_v, drg1_v, drg2_v, drg4_v, snap_v, amhcc_v, cost_weight_v, srg_drg_v
    lhd_global = lhd
    facilities_excluded_list_global = facilities_excluded_list
    facilities_included_list_global = facilities_included_list
    # This self assigning is probably redundant, but I am not sure how the global keyword work sometimes.
    roundid = str(roundid)
    start_date = str(start_date)
    end_date = str(end_date)
    nwau_v = str(nwau_v)
    icd10_v = str(icd10_v)
    drg1_v = str(drg1_v)
    drg2_v = str(drg2_v)
    drg4_v = str(drg4_v)
    snap_v = str(snap_v)
    amhcc_v = str(amhcc_v)
    cost_weight_v = str(cost_weight_v)
    srg_drg_v = str(srg_drg_v)
    # Fetch mapping files
    logging.info("All data has been successfully extracted. Fetch mapping files.")
    transform_ppm_transform_amo()
    transform_criticalcaregroup()
    transform_specialtyportalmapping()
    transform_edroledelin()
    transform_pla_role_table()
    # change button color for mapping tables
    ########################################
    file_PpmTransferAmo = "./ExtractorDB/Tbl_PPM_transfer_AMO.csv"
    if os.path.isfile(file_PpmTransferAmo):
        try:
            df_file_PpmTransferAmo = read_csv_file(
                file_PpmTransferAmo,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error", "Error extracting Tbl_PPM_transfer_AMO.\n" + str(e)
            )
        else:
            if (
                df_file_PpmTransferAmo.Consultant_Status.isnull().sum() > 0
                or df_file_PpmTransferAmo.Consultant_Status.isna().sum() > 0
                or len(
                    df_file_PpmTransferAmo[
                        df_file_PpmTransferAmo["Consultant_Status"] == ""
                    ]
                )
                > 0
            ):
                button_amo_payment.config(bg="yellow")
            else:
                button_amo_payment.config(bg="#f0f0f0")
    else:
        button_amo_payment.config(bg="#f0f0f0")
    file_SpecialtyPortalMapping = "./ExtractorDB/SpecialityPortalMapping.csv"
    if os.path.isfile(file_SpecialtyPortalMapping):
        try:
            df_file_SpecialtyPortalMapping = read_csv_file(
                file_SpecialtyPortalMapping,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error", "Error extracting SpecialtyPortalMapping.\n" + str(e)
            )
        else:
            if (
                df_file_SpecialtyPortalMapping.SpecialityPortal.isnull().sum() > 0
                or df_file_SpecialtyPortalMapping.SpecialityPortal.isna().sum() > 0
                or len(
                    df_file_SpecialtyPortalMapping[
                        df_file_SpecialtyPortalMapping["SpecialityPortal"] == ""
                    ]
                )
                > 0
            ):
                button_Specialtyportalmapping.config(bg="yellow")
            else:
                button_Specialtyportalmapping.config(bg="#f0f0f0")
    else:
        button_Specialtyportalmapping.config(bg="#f0f0f0")
    ########################################
    logging.info(
        "All data has been successfully extracted. User can now run transformations."
    )
    # Ranjit - 26 Aug
    # messagebox.showinfo("Data Extraction", "All data has been successfully extracted.\nYou can now run transformations.")
    messagebox.showinfo(
        "Data Extraction",
        "All data has been successfully extracted.\nYou can now run transformations.",
        parent=main_screen,
    )
    # disable extract button and enable transform button
    button_extract["state"] = DISABLED
    button_transform["state"] = ACTIVE
    main_screen.update()


def start_extraction(
    lhd,
    facilities_excluded,
    facilities_excluded_list,
    facilities_included,
    facilities_included_list,
    roundid,
    start_date,
    end_date,
    nwau_v,
    icd10_v,
    drg1_v,
    drg2_v,
    drg4_v,
    snap_v,
    amhcc_v,
    cost_weight_v,
    srg_drg_v,
):
    # end_date = end_date+' '+'00:00:00'
    # start_date=start_date+' '+'00:00:00'
    logging.info("Data extraction has now started.")
    logging.info(
        "From GUI. source=%s, lhd=%s, excl. facilites=%s, incl. facilities=%s, roundid=%s, start_date=%s, end_date=%s, nwau_v=%s, icd10_v=%s, drg1_v=%s,\
    drg2_v=%s, drg4_v=%s, snap_v=%s, amhcc_v=%s, cost_weight_v=%s, srg_drg_v=%s",
        source,
        lhd,
        facilities_excluded_list,
        facilities_included_list,
        roundid,
        start_date,
        end_date,
        nwau_v,
        icd10_v,
        drg1_v,
        drg2_v,
        drg4_v,
        snap_v,
        amhcc_v,
        cost_weight_v,
        srg_drg_v,
    )
    global lhd_global, facilities_excluded_list_global, facilities_included_list_global
    lhd_global = lhd
    facilities_excluded_list_global = facilities_excluded_list
    facilities_included_list_global = facilities_included_list
    global \
        tbl_dbo_Facility, \
        tbl_dbo_stay, \
        tbl_Patient_Contact_Details, \
        tbl_dbo_episode_ats, \
        tbl_dbo_Ward_Episode, \
        tbl_dbo_episode, \
        tbl_dbo_episode_srg, \
        tbl_dbo_episode_DRG, \
        tbl_dbo_wl_exit, \
        ed_nwau, \
        acute_nwau, \
        tbl_dbo_days_episode, \
        tbl_PPM_transfer_Leave_00, \
        tbl_PPM_transfer_Leave02, \
        tbl_PPM_ICD_diagnoses, \
        tbl_PPM_ICD_procedures, \
        tbl_ppm_ED_Patient, \
        tbl_ppm_ED_Encounter_preclean, \
        df_ED_Diag_Slice, \
        df_ExcludedEncounters, \
        snapApp_CostingExtract, \
        df_AMHCC_extract, \
        df_SNAPRec, \
        snap_NWAU, \
        df_EdRoleDelin, \
        df_ICU_RoleDelin, \
        df_SpecialtyPortalMapping, \
        df_CriticalCareGroup, \
        df_PLA_Role_Table, \
        df_PLA_Mapping_00, \
        df_PLA_AMHCC, \
        df_Class_Descriptions, \
        df_SpecialtyPortalValues, \
        df_MDC, \
        df_Excluded_EpisodeAts, \
        tbl_Episode_ATS_end_date_update, \
        df_Excluded_EpisodeAts_enddate_le_startdate, \
        df_PpmTransferAmo, \
        tbl_PPM_transfer_Leave_00, \
        tbl_PPM_transfer_Leave_02, \
        df_ED_Diag_Slice, \
        df_Excluded_ED_Encounters, \
        tbl_PPM_Patient, \
        criticalcaregroup, \
        specialtyPortalMapping, \
        tbl_PPM_transfer_AMO, \
        tbl_EDRoleDelin, \
        pla_Role_Table, \
        tbl_ExcludedEncounters
    if len(os.listdir("./temp_transform/")) > 0:
        if messagebox.askyesno(
            "Delete files",
            "This will delete all output files from \ temp_transform\ and \ ExtractorDB\ directory, generated from the previous run.\nDo you wish to proceed?",
        ):
            clear_output_dir("./temp_transform")
            clear_output_dir("./ExtractorDB")
        else:
            return
    """
    if len(os.listdir('./ExtractorDB/')) > 0:
        if messagebox.askyesno("Delete files", "This will delete all output files from \ ExtractorDB\ directory, generated from the previous run.\nDo you wish to proceed?"):
            clear_output_dir('./ExtractorDB')
        else:
            return
    """
    """
    if messagebox.askyesno("Delete files", "This will delete all output files from \ temp_transform\ and \ExtractorDB\ directory, generated from the previous run.\nDo you wish to proceed?"):
        clear_output_dir('./temp_transform')
        clear_output_dir('./ExtractorDB')
    else:
        return
    """
    ######################################### STAGING TABLE - SUB TASK 0 #######################################
    # Set default value of first task status to 1
    """
    label_1_status = 1
    if source == "EDW":
        label_1_sub.configure(text="In Progress (Staging Tables)...",fg='blue')
        main_screen.update()
        logging.info("create_staging_table STARTED")
        create_staging_table(cursor, lhd, facilities_excluded_list, roundid, start_date, end_date, nwau_v, icd10_v, drg1_v, drg2_v, drg4_v, snap_v, amhcc_v, cost_weight_v, srg_drg_v)
        logging.info("create_staging_table COMPLETED")
        conn_staging = sqlite3.connect('./Staging/edw_staging.db')
    """
    ######################################### EXTRACT DATA - SUB TASK 1 #######################################
    # Set default value of first task status to 1
    label_1_status = 1
    # OutputFacility
    # columns = facility_identifier,area_identifier,facility_name,snap_upd_batch_run_no
    # Access query = Append to tbl_dbo_Dacility
    # snap_upd_batch_run_no = IIf(lhd='X800' And dbo.FACILITY.facility_identifier>'Q206',1,0)
    label_1_sub.configure(text="In Progress (Facility)...", fg="blue")
    main_screen.update()
    if source == "HIE":
        if len(facilities_excluded_list) > 0:
            query_facility = (
                """SELECT dbo.FACILITY.facility_identifier, dbo.FACILITY.area_identifier, dbo.FACILITY.facility_name, dbo.FACILITY.snap_upd_batch_run_no, '' as HLTH_ORG_OSP_OSP_ID, '' as MG_AUTH_OSP_OSP_ID FROM dbo.FACILITY WHERE ((((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.FACILITY.snap_curr_indicator)='Y')) OR (((dbo.FACILITY.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.FACILITY.snap_curr_indicator)='Y')))  AND dbo.FACILITY.facility_identifier NOT IN ("""
                + facilities_excluded
                + """);"""
            )
        else:
            query_facility = (
                """SELECT dbo.FACILITY.facility_identifier, dbo.FACILITY.area_identifier, dbo.FACILITY.facility_name, dbo.FACILITY.snap_upd_batch_run_no, '' as HLTH_ORG_OSP_OSP_ID, '' as MG_AUTH_OSP_OSP_ID FROM dbo.FACILITY WHERE ((((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.FACILITY.snap_curr_indicator)='Y')) OR (((dbo.FACILITY.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.FACILITY.snap_curr_indicator)='Y')));"""
            )
    elif source == "EDW":
        if len(facilities_included_list) > 0:
            query_facility = (
                """SELECT DISTINCT case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != ''  then OSP_HIE_FAC_ID else HLTH_ORG_OSP_HIE_FAC_ID end as facility_identifier, MG_AUTH_OSP_HIE_FAC_ID as area_identifier, HLTH_ORG_OSP_FULL_NM as facility_name, 0 as snap_upd_batch_run_no,case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_ID else HLTH_ORG_OSP_OSP_ID end as HLTH_ORG_OSP_OSP_ID,MG_AUTH_OSP_OSP_ID FROM CRT.v_DIM_OSP WHERE (MG_AUTH_OSP_HIE_FAC_ID = '"""
                + lhd
                + """' OR (case when OSP_TYP_CD in ('35.01', '35.02', '35.03'
			, '35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_HIE_FAC_ID else HLTH_ORG_OSP_HIE_FAC_ID end) = '"""
                + lhd
                + """') and ((MG_AUTH_OSP_HLTH_SECTOR_CD IN ('1','3')) and (HLTH_ORG_OSP_HLTH_SECTOR_CD IN ('1','3'))) AND HLTH_ORG_OSP_HIE_FAC_ID != '-1' AND HLTH_ORG_OSP_HIE_FAC_ID != '' AND (case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_HIE_FAC_ID else HLTH_ORG_OSP_HIE_FAC_ID end) IN ("""
                + facilities_included
                + """) AND DIM_CURR_IND_FG = 1;"""
            )
    retry_flag = True
    retry_count = 0
    while retry_flag and retry_count < 5:
        try:
            logging.info(query_facility)
            tbl_dbo_Facility = pd.read_sql(query_facility, cnxn)
            retry_flag = False
        except Exception as e:
            retry_count = retry_count + 1
            time.sleep(5)
            if retry_count == 5:
                logging.exception("Exception occurred")
                label_1_status = 0
                messagebox.showerror(
                    "SQL Error", "Error extracting Facility details\n" + str(e)
                )
                label_1_sub.configure(text="Failed (Facility)...", fg="red")
                main_screen.update()
                tbl_dbo_Facility = pd.DataFrame(
                    columns=[
                        "facility_identifier",
                        "area_identifier",
                        "facility_name",
                        "snap_upd_batch_run_no",
                        "HLTH_ORG_OSP_OSP_ID",
                        "MG_AUTH_OSP_OSP_ID",
                    ]
                )
                return
        else:
            tbl_dbo_Facility = tbl_dbo_Facility.fillna("")
            tbl_dbo_Facility = tbl_dbo_Facility[
                tbl_dbo_Facility["area_identifier"] == lhd_global
            ]
            tbl_dbo_Facility = tbl_dbo_Facility[
                tbl_dbo_Facility["facility_identifier"].isin(
                    facilities_included_list_global
                )
            ]
            tbl_dbo_Facility = tbl_dbo_Facility.applymap(
                str
            )  # .strip)#.apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_dbo_Facility = tbl_dbo_Facility.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_dbo_Facility = tbl_dbo_Facility.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_Facility = tbl_dbo_Facility.apply(
                lambda x: x.replace(regex=r"NULL", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_Facility = tbl_dbo_Facility.apply(
                lambda x: x.replace(regex=r"null", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_Facility = tbl_dbo_Facility.apply(
                lambda x: x.replace(regex=r"Null", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_Facility = tbl_dbo_Facility[
                [
                    "facility_identifier",
                    "area_identifier",
                    "facility_name",
                    "snap_upd_batch_run_no",
                    "HLTH_ORG_OSP_OSP_ID",
                    "MG_AUTH_OSP_OSP_ID",
                ]
            ]
            tbl_dbo_Facility.drop_duplicates(
                subset=[
                    "facility_identifier",
                    "area_identifier",
                    "facility_name",
                    "snap_upd_batch_run_no",
                ],
                keep="last",
                inplace=True,
            )
            # dropping duplicate values
            tbl_dbo_Facility.drop_duplicates(keep="last", inplace=True)
            tbl_dbo_Facility.to_csv(
                "./ExtractorDB/OutputFacility.csv",
                index=False,
                na_rep="",
                float_format=str,
                decimal=str,
                date_format=str,
            )
            logging.info("tbl_dbo_Facility=%s", len(tbl_dbo_Facility))
    # OutputStay
    # columns = facility_identifier,stay_number,person_identifier,indigenous_status,birth_date,country_of_birth,marital_status,preferred_language,sex,admission_date,admission_time,discharge_date,discharge_time,mo_code1,mo_code2,emergency_status,readmitted_within_28_days,readmit_this_hosp_28_days,ambulance_client_number,referred_to_on_separation,stay_discharge_intention,infant_start_weight,infant_end_weight,hospital_insurance,stay_leave_days_total,length_of_stay_total,age,age_grouping,facility_trans_to,facility_trans_from,collabrtve_care_facility,contract_status,collabrtve_care_role,collabrtve_care_type,prev_diag_of_carcinoma,practice_identifier1,practice_identifier2,patient_suburb,patient_postcode,mrn,medicare_number,medicare_expiry_date,dva_card_type,dva_card_number,centrelink_client_number,insurance_fund,insurance_fund_master,insurance_fund_number,religion_local,religion_ascrg,presenting_problem,indicator_procedure_code,claim_against_health_fund,last_psych_admission_date,medicare_eligibility_status,election_status_on_admit,sla_version,area_of_usual_residence,state_of_usual_residence,country_of_usual_residence,dpid_of_usual_residence,longitude,latitude,census_collection_district,health_insurance_on_admit,abs_preferred_language,preferred_language_ascl,assccs_country_of_birth,country_of_birth_sacc,marital_status_nhdd,prev_specialised_treatment,type_of_usual_accom,consent_flag,estimated_birth_date_flag,age_at_separation,day_stay_los,mothers_mrn,mothers_person_identifier,mothers_stay_number,birth_plurality,employment_status,medical_discharge_date,medical_discharge_time,medical_disch_datetime,reason_discharge_delay,intention_to_readmit,acute_care_cert_expiry_date,expected_discharge_date,reason_no_health_claim,days_in_psych_unit,hours_in_psych_unit,source_of_referral,asgc_version,LHD_of_Usual_residence
    # Access query = qry_dbo_stay
    label_1_sub.configure(text="In Progress (Stay)...", fg="blue")
    main_screen.update()
    if source == "HIE":
        if len(facilities_excluded_list) > 0:
            query_stay = (
                """SELECT dbo.STAY.facility_identifier, dbo.STAY.stay_number, dbo.STAY.person_identifier, dbo.STAY.indigenous_status, dbo.STAY.birth_date, dbo.STAY.country_of_birth, dbo.STAY.marital_status, dbo.STAY.preferred_language, dbo.STAY.sex, dbo.STAY.admission_date, dbo.STAY.admission_time, dbo.STAY.discharge_date, dbo.STAY.discharge_time, dbo.STAY.mo_code1, dbo.STAY.mo_code2, dbo.STAY.emergency_status, dbo.STAY.readmitted_within_28_days, dbo.STAY.readmit_this_hosp_28_days, dbo.STAY.ambulance_client_number, dbo.STAY.referred_to_on_separation, dbo.STAY.stay_discharge_intention, dbo.STAY.infant_start_weight, dbo.STAY.infant_end_weight, dbo.STAY.hospital_insurance, dbo.STAY.stay_leave_days_total, dbo.STAY.length_of_stay_total, dbo.STAY.age, dbo.STAY.age_grouping, dbo.STAY.facility_trans_to, dbo.STAY.facility_trans_from, dbo.STAY.collabrtve_care_facility, dbo.STAY.contract_status, dbo.STAY.collabrtve_care_role, dbo.STAY.collabrtve_care_type, dbo.STAY.prev_diag_of_carcinoma, dbo.STAY.practice_identifier1, dbo.STAY.practice_identifier2, dbo.STAY.patient_suburb, dbo.STAY.patient_postcode, dbo.STAY.mrn, dbo.STAY.medicare_number, dbo.STAY.medicare_expiry_date, dbo.STAY.dva_card_type, dbo.STAY.dva_card_number, dbo.STAY.centrelink_client_number, dbo.STAY.insurance_fund, dbo.STAY.insurance_fund_master, dbo.STAY.insurance_fund_number, dbo.STAY.religion_local, dbo.STAY.religion_ascrg, dbo.STAY.presenting_problem, dbo.STAY.indicator_procedure_code, dbo.STAY.claim_against_health_fund, dbo.STAY.last_psych_admission_date, dbo.STAY.medicare_eligibility_status, dbo.STAY.election_status_on_admit, dbo.STAY.sla_version, dbo.STAY.area_of_usual_residence, dbo.STAY.state_of_usual_residence, dbo.STAY.country_of_usual_residence, dbo.STAY.dpid_of_usual_residence, dbo.STAY.longitude, dbo.STAY.latitude, dbo.STAY.census_collection_district, dbo.STAY.health_insurance_on_admit, dbo.STAY.abs_preferred_language, dbo.STAY.preferred_language_ascl, dbo.STAY.assccs_country_of_birth, dbo.STAY.country_of_birth_sacc, dbo.STAY.marital_status_nhdd, dbo.STAY.prev_specialised_treatment, dbo.STAY.type_of_usual_accom, dbo.STAY.consent_flag, dbo.STAY.estimated_birth_date_flag, dbo.STAY.age_at_separation, dbo.STAY.day_stay_los, dbo.STAY.mothers_mrn, dbo.STAY.mothers_person_identifier, dbo.STAY.mothers_stay_number, dbo.STAY.birth_plurality, dbo.STAY.employment_status, dbo.STAY.medical_discharge_date, dbo.STAY.medical_discharge_time, dbo.STAY.medical_disch_datetime, dbo.STAY.reason_discharge_delay, dbo.STAY.intention_to_readmit, dbo.STAY.acute_care_cert_expiry_date, dbo.STAY.expected_discharge_date, dbo.STAY.reason_no_health_claim, dbo.STAY.days_in_psych_unit, dbo.STAY.hours_in_psych_unit, dbo.STAY.source_of_referral, dbo.STAY.asgc_version, dbo.SLA_AREA.area_identifier AS LHD_of_Usual_residence, '' as HLTH_ORG_OSP_OSP_ID, '' as MG_AUTH_OSP_OSP_ID, '' as SE_CBK_SK, '' as CL_ID_EUID, '' AS CL_ID_IHI,'' as AUID
            FROM dbo.SLA_AREA INNER JOIN (dbo.STAY INNER JOIN dbo.FACILITY ON dbo.STAY.facility_identifier = dbo.FACILITY.facility_identifier) ON (dbo.SLA_AREA.sla_code = dbo.STAY.area_of_usual_residence) AND (dbo.SLA_AREA.sla_version = dbo.STAY.sla_version) WHERE (((dbo.STAY.admission_date)<=('"""
                + end_date
                + """')) And ((dbo.STAY.discharge_date)>=('"""
                + start_date
                + """')) And ((dbo.STAY.snap_curr_indicator)="Y") And ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') And ((dbo.FACILITY.snap_curr_indicator)="Y") And ((dbo.SLA_AREA.current_flag)="Y" Or (dbo.SLA_AREA.current_flag) Is Null) And ((dbo.SLA_AREA.snap_curr_indicator)="Y" Or (dbo.SLA_AREA.snap_curr_indicator) Is Null)) Or (((dbo.STAY.admission_date)<='"""
                + end_date
                + """') And ((dbo.STAY.discharge_date) Is Null) And ((dbo.STAY.snap_curr_indicator)="Y") And ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') And ((dbo.FACILITY.snap_curr_indicator)="Y") And ((dbo.SLA_AREA.current_flag)="Y" Or (dbo.SLA_AREA.current_flag) Is Null) And ((dbo.SLA_AREA.snap_curr_indicator)="Y" Or (dbo.SLA_AREA.snap_curr_indicator) Is Null)) Or (((dbo.STAY.facility_identifier)='"""
                + lhd
                + """') And ((dbo.STAY.admission_date)<=('"""
                + end_date
                + """')) And ((dbo.STAY.discharge_date)>=('"""
                + start_date
                + """')) And ((dbo.STAY.snap_curr_indicator)="Y") And ((dbo.FACILITY.snap_curr_indicator)="Y") And ((dbo.SLA_AREA.current_flag)="Y" Or (dbo.SLA_AREA.current_flag) Is Null) And ((dbo.SLA_AREA.snap_curr_indicator)="Y" Or (dbo.SLA_AREA.snap_curr_indicator) Is Null)) Or (((dbo.STAY.facility_identifier)='"""
                + lhd
                + """') And ((dbo.STAY.admission_date)<='"""
                + end_date
                + """') And ((dbo.STAY.discharge_date) Is Null) And ((dbo.STAY.snap_curr_indicator)="Y") And ((dbo.FACILITY.snap_curr_indicator)="Y") And ((dbo.SLA_AREA.current_flag)="Y" Or (dbo.SLA_AREA.current_flag) Is Null) And ((dbo.SLA_AREA.snap_curr_indicator)="Y" Or (dbo.SLA_AREA.snap_curr_indicator) Is Null))  AND dbo.FACILITY.facility_identifier NOT IN ("""
                + facilities_excluded
                + """);"""
            )
        else:
            query_stay = (
                """SELECT dbo.STAY.facility_identifier, dbo.STAY.stay_number, dbo.STAY.person_identifier, dbo.STAY.indigenous_status, dbo.STAY.birth_date, dbo.STAY.country_of_birth, dbo.STAY.marital_status, dbo.STAY.preferred_language, dbo.STAY.sex, dbo.STAY.admission_date, dbo.STAY.admission_time, dbo.STAY.discharge_date, dbo.STAY.discharge_time, dbo.STAY.mo_code1, dbo.STAY.mo_code2, dbo.STAY.emergency_status, dbo.STAY.readmitted_within_28_days, dbo.STAY.readmit_this_hosp_28_days, dbo.STAY.ambulance_client_number, dbo.STAY.referred_to_on_separation, dbo.STAY.stay_discharge_intention, dbo.STAY.infant_start_weight, dbo.STAY.infant_end_weight, dbo.STAY.hospital_insurance, dbo.STAY.stay_leave_days_total, dbo.STAY.length_of_stay_total, dbo.STAY.age, dbo.STAY.age_grouping, dbo.STAY.facility_trans_to, dbo.STAY.facility_trans_from, dbo.STAY.collabrtve_care_facility, dbo.STAY.contract_status, dbo.STAY.collabrtve_care_role, dbo.STAY.collabrtve_care_type, dbo.STAY.prev_diag_of_carcinoma, dbo.STAY.practice_identifier1, dbo.STAY.practice_identifier2, dbo.STAY.patient_suburb, dbo.STAY.patient_postcode, dbo.STAY.mrn, dbo.STAY.medicare_number, dbo.STAY.medicare_expiry_date, dbo.STAY.dva_card_type, dbo.STAY.dva_card_number, dbo.STAY.centrelink_client_number, dbo.STAY.insurance_fund, dbo.STAY.insurance_fund_master, dbo.STAY.insurance_fund_number, dbo.STAY.religion_local, dbo.STAY.religion_ascrg, dbo.STAY.presenting_problem, dbo.STAY.indicator_procedure_code, dbo.STAY.claim_against_health_fund, dbo.STAY.last_psych_admission_date, dbo.STAY.medicare_eligibility_status, dbo.STAY.election_status_on_admit, dbo.STAY.sla_version, dbo.STAY.area_of_usual_residence, dbo.STAY.state_of_usual_residence, dbo.STAY.country_of_usual_residence, dbo.STAY.dpid_of_usual_residence, dbo.STAY.longitude, dbo.STAY.latitude, dbo.STAY.census_collection_district, dbo.STAY.health_insurance_on_admit, dbo.STAY.abs_preferred_language, dbo.STAY.preferred_language_ascl, dbo.STAY.assccs_country_of_birth, dbo.STAY.country_of_birth_sacc, dbo.STAY.marital_status_nhdd, dbo.STAY.prev_specialised_treatment, dbo.STAY.type_of_usual_accom, dbo.STAY.consent_flag, dbo.STAY.estimated_birth_date_flag, dbo.STAY.age_at_separation, dbo.STAY.day_stay_los, dbo.STAY.mothers_mrn, dbo.STAY.mothers_person_identifier, dbo.STAY.mothers_stay_number, dbo.STAY.birth_plurality, dbo.STAY.employment_status, dbo.STAY.medical_discharge_date, dbo.STAY.medical_discharge_time, dbo.STAY.medical_disch_datetime, dbo.STAY.reason_discharge_delay, dbo.STAY.intention_to_readmit, dbo.STAY.acute_care_cert_expiry_date, dbo.STAY.expected_discharge_date, dbo.STAY.reason_no_health_claim, dbo.STAY.days_in_psych_unit, dbo.STAY.hours_in_psych_unit, dbo.STAY.source_of_referral, dbo.STAY.asgc_version, dbo.SLA_AREA.area_identifier AS LHD_of_Usual_residence , '' as HLTH_ORG_OSP_OSP_ID, '' as MG_AUTH_OSP_OSP_ID, '' as SE_CBK_SK, '' as CL_ID_EUID, '' AS CL_ID_IHI,'' as AUID
            FROM dbo.SLA_AREA INNER JOIN (dbo.STAY INNER JOIN dbo.FACILITY ON dbo.STAY.facility_identifier = dbo.FACILITY.facility_identifier) ON (dbo.SLA_AREA.sla_code = dbo.STAY.area_of_usual_residence) AND (dbo.SLA_AREA.sla_version = dbo.STAY.sla_version) WHERE (((dbo.STAY.admission_date)<=('"""
                + end_date
                + """')) And ((dbo.STAY.discharge_date)>=('"""
                + start_date
                + """')) And ((dbo.STAY.snap_curr_indicator)="Y") And ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') And ((dbo.FACILITY.snap_curr_indicator)="Y") And ((dbo.SLA_AREA.current_flag)="Y" Or (dbo.SLA_AREA.current_flag) Is Null) And ((dbo.SLA_AREA.snap_curr_indicator)="Y" Or (dbo.SLA_AREA.snap_curr_indicator) Is Null)) Or (((dbo.STAY.admission_date)<='"""
                + end_date
                + """') And ((dbo.STAY.discharge_date) Is Null) And ((dbo.STAY.snap_curr_indicator)="Y") And ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') And ((dbo.FACILITY.snap_curr_indicator)="Y") And ((dbo.SLA_AREA.current_flag)="Y" Or (dbo.SLA_AREA.current_flag) Is Null) And ((dbo.SLA_AREA.snap_curr_indicator)="Y" Or (dbo.SLA_AREA.snap_curr_indicator) Is Null)) Or (((dbo.STAY.facility_identifier)='"""
                + lhd
                + """') And ((dbo.STAY.admission_date)<=('"""
                + end_date
                + """')) And ((dbo.STAY.discharge_date)>=('"""
                + start_date
                + """')) And ((dbo.STAY.snap_curr_indicator)="Y") And ((dbo.FACILITY.snap_curr_indicator)="Y") And ((dbo.SLA_AREA.current_flag)="Y" Or (dbo.SLA_AREA.current_flag) Is Null) And ((dbo.SLA_AREA.snap_curr_indicator)="Y" Or (dbo.SLA_AREA.snap_curr_indicator) Is Null)) Or (((dbo.STAY.facility_identifier)='"""
                + lhd
                + """') And ((dbo.STAY.admission_date)<='"""
                + end_date
                + """') And ((dbo.STAY.discharge_date) Is Null) And ((dbo.STAY.snap_curr_indicator)="Y") And ((dbo.FACILITY.snap_curr_indicator)="Y") And ((dbo.SLA_AREA.current_flag)="Y" Or (dbo.SLA_AREA.current_flag) Is Null) And ((dbo.SLA_AREA.snap_curr_indicator)="Y" Or (dbo.SLA_AREA.snap_curr_indicator) Is Null)) ;"""
            )
    elif source == "EDW":
        if len(facilities_included_list) > 0:
            query_stay = (
                """SELECT DISTINCT K.facility_identifier,RIGHT(CONCAT('00000000', ISNULL(SUBSTRING(a.SRV_ENC_REC_ID,charindex('-',a.SRV_ENC_REC_ID)+1,8),'')), 8) as stay_number,case when A.CL_ID_MASKED = 'Unknown/Invalid' then A.CL_ID_MASKED else RIGHT(CONCAT('0000000000', ISNULL(TRIM(A.CL_ID_MASKED),'')),10) end as person_identifier,A.CL_INDIGENOUS_STAT_CD as indigenous_status,A.CL_DOB as birth_date,A.CL_CTRY_OF_BIRTH_CD as country_of_birth,A.CL_MARITAL_STAT_CD as marital_status,A.CL_PREFERRED_LANG_CD as preferred_language,A.CL_SEX_CD as sex,CAST(a.FRML_ADM_DTTM as date) as admission_date,CAST(a.FRML_ADM_DTTM as time(0)) as admission_time,CAST(a.FRML_DISCH_DTTM as date) as discharge_date,CAST(a.FRML_DISCH_DTTM as time(0)) as discharge_time,G.mo_code1 as mo_code1
			,G.mo_code2 as mo_code2,A.FRML_ADM_URGENCY_CD as emergency_status,A.FRML_READM_STAT_CD as readmitted_within_28_days,A.FRML_READM_STAT_CD as readmit_this_hosp_28_days,'' as ambulance_client_number,ISNULL(SUBSTRING(A.REFL_TRGT_TYPE_CD_SET,charindex('|',A.REFL_TRGT_TYPE_CD_SET)+1,5),'') as referred_to_on_separation,S.FRML_ADM_INTND_LOS_CD as stay_discharge_intention,REPLICATE('0', 4 - LEN(CAST(F.WGT_AT_SE_ST_GMS AS VARCHAR))) + CAST(F.WGT_AT_SE_ST_GMS AS VARCHAR) as infant_start_weight,'' as infant_end_weight,'' as hospital_insurance,a.CT_TOT_SE_LEAVE_D_CT as stay_leave_days_total,q.LOS as length_of_stay_total,A.AGE_AT_ST_YRS as age,CASE WHEN A.AGE_AT_ST_YRS < 5 THEN 1 
			WHEN A.AGE_AT_ST_YRS >= 5 AND A.AGE_AT_ST_YRS < 10 THEN 2
			WHEN A.AGE_AT_ST_YRS >= 10 AND A.AGE_AT_ST_YRS < 15 THEN 3
			WHEN A.AGE_AT_ST_YRS >= 15 AND A.AGE_AT_ST_YRS < 20 THEN 4
			WHEN A.AGE_AT_ST_YRS >= 20 AND A.AGE_AT_ST_YRS < 25 THEN 5
			WHEN A.AGE_AT_ST_YRS >= 25 AND A.AGE_AT_ST_YRS < 30 THEN 6
			WHEN A.AGE_AT_ST_YRS >= 30 AND A.AGE_AT_ST_YRS < 35 THEN 7
			WHEN A.AGE_AT_ST_YRS >= 35 AND A.AGE_AT_ST_YRS < 40 THEN 8
			WHEN A.AGE_AT_ST_YRS >= 40 AND A.AGE_AT_ST_YRS < 45 THEN 9
			WHEN A.AGE_AT_ST_YRS >= 45 AND A.AGE_AT_ST_YRS < 50 THEN 10
			WHEN A.AGE_AT_ST_YRS >= 50 AND A.AGE_AT_ST_YRS < 55 THEN 11
			WHEN A.AGE_AT_ST_YRS >= 55 AND A.AGE_AT_ST_YRS < 60 THEN 12
			WHEN A.AGE_AT_ST_YRS >= 60 AND A.AGE_AT_ST_YRS < 65 THEN 13
			WHEN A.AGE_AT_ST_YRS >= 65 AND A.AGE_AT_ST_YRS < 70 THEN 14
			WHEN A.AGE_AT_ST_YRS >= 70 AND A.AGE_AT_ST_YRS < 75 THEN 15
			WHEN A.AGE_AT_ST_YRS >= 75 AND A.AGE_AT_ST_YRS < 80 THEN 16
			WHEN A.AGE_AT_ST_YRS >= 80 AND A.AGE_AT_ST_YRS < 85 THEN 17
			WHEN A.AGE_AT_ST_YRS >= 85 THEN 18
			ELSE NULL END as age_grouping,A.OB_TSF_OSP_HIE_FACIL_ID as facility_trans_to,A.IB_TSF_OSP_HIE_FACIL_ID as facility_trans_from,A.FST_CLB_OSP_HIE_FACIL_ID as collabrtve_care_facility,F.COLLAB_CARE_STAT_CD as contract_status,A.FST_CLB_OSP_TYP_GRP_CD as collabrtve_care_role,A.FST_CLB_OSP_TYP_CD as collabrtve_care_type,'' as prev_diag_of_carcinoma,'' as practice_identifier1,'' as practice_identifier2,concat(upper(substring(trim(A.CLN_SUBURB_LOCITY),1,1)),lower(substring(trim(A.CLN_SUBURB_LOCITY),2,len(trim(A.CLN_SUBURB_LOCITY))))) as patient_suburb,A.CLN_POSTCODE as patient_postcode,case when A.CL_ID in ('-1','Unknown/Invalid','') then A.CL_ID  when len(A.CL_ID) > 10 then right(A.CL_ID,10) when len(A.CL_ID) < 10 then RIGHT(CONCAT('0000000000', ISNULL(TRIM(A.CL_ID),'')),10) else '' end as mrn,'' as medicare_number,NULL as medicare_expiry_date,a.CL_DVA_HLTHCARE_POLICY_TYP_CD as dva_card_type,a.CL_DVA_HLTHCARE_FILE_ID as dva_card_number,'' as centrelink_client_number,a.CL_HOSP_INSUR_FUND_CD as insurance_fund,a.CL_HOSP_INSUR_FUND as insurance_fund_master,a.CL_HOSP_INSUR_MBR_ID as insurance_fund_number,'' as religion_local,'' as religion_ascrg,'' as presenting_problem,'' as indicator_procedure_code,'' as claim_against_health_fund,NULL as last_psych_admission_date,A.CL_MC_ELIG as medicare_eligibility_status,F.LST_AP_ELCTN_STAT_CD as election_status_on_admit,'' as sla_version,case when '"""
                + roundid
                + """' IN ('V27', 'V28', 'V28.0', 'V28.25', 'V28.5', 'V28.50', 'V28.75') then A.ASGS_SA_L2_16_CD else A.CL_URES_ADDR_ASGS21_SA_L2_CD end as area_of_usual_residence,A.CLN_STT_ABBR as state_of_usual_residence,A.CLN_CTRY_CD as country_of_usual_residence,'' as dpid_of_usual_residence,A.GNAF_LONG as longitude,A.GNAF_LAT as latitude,'' as census_collection_district,a.SRV_ENC_INSUR_CLAIM_FG as health_insurance_on_admit,'' as abs_preferred_language,A.CL_PREFERRED_LANG_CD as preferred_language_ascl,A.CL_CTRY_OF_BIRTH_CD as assccs_country_of_birth,A.CL_CTRY_OF_BIRTH_CD as country_of_birth_sacc,A.CL_MARITAL_STAT_CD as marital_status_nhdd,'' as prev_specialised_treatment,A.CL_USUAL_ACCOM_TYP_CD as type_of_usual_accom,'' as consent_flag,'' as estimated_birth_date_flag,'' as age_at_separation,ROUND(a.CT_TOT_SE_BED_HRS,0) as day_stay_los,case when N.CL_ID in ('-1','Unknown/Invalid','') then N.CL_ID when len(N.CL_ID) > 10 then RIGHT(N.CL_ID,10) when len(N.CL_ID) < 10 then RIGHT(CONCAT('0000000000',ISNULL(TRIM(N.CL_ID),'')),10) else '' end as mothers_mrn,case when N.CL_ID_MASKED = 'Unknown/Invalid' then N.CL_ID_MASKED when N.CL_ID_MASKED is NULL then N.CL_ID_MASKED else RIGHT(CONCAT('0000000000', ISNULL(TRIM(N.CL_ID_MASKED),'')),10) end as mothers_person_identifier,case when N.SRV_ENC_REC_ID is NULL then '' else RIGHT(CONCAT('00000000', ISNULL(SUBSTRING(N.SRV_ENC_REC_ID,charindex('-',N.SRV_ENC_REC_ID)+1,8),'')), 8) end as mothers_stay_number,case when f.RLTD_SE_MTHR_TO_NWB1_SE_CBK_SK is not null and f.RLTD_SE_MTHR_TO_NWB2_SE_CBK_SK is null
			  and f.RLTD_SE_MTHR_TO_NWB3_SE_CBK_SK is null and f.RLTD_SE_MTHR_TO_NWB4_SE_CBK_SK is null then 1 
			 when f.RLTD_SE_MTHR_TO_NWB1_SE_CBK_SK is not null and f.RLTD_SE_MTHR_TO_NWB2_SE_CBK_SK is not null
			  and f.RLTD_SE_MTHR_TO_NWB3_SE_CBK_SK is null and f.RLTD_SE_MTHR_TO_NWB4_SE_CBK_SK is null then 2				 
			 when f.RLTD_SE_MTHR_TO_NWB1_SE_CBK_SK is not null and f.RLTD_SE_MTHR_TO_NWB2_SE_CBK_SK is not null
			  and f.RLTD_SE_MTHR_TO_NWB3_SE_CBK_SK is not null and f.RLTD_SE_MTHR_TO_NWB4_SE_CBK_SK is null then 3 
			 when f.RLTD_SE_MTHR_TO_NWB1_SE_CBK_SK is not null and f.RLTD_SE_MTHR_TO_NWB2_SE_CBK_SK is not null
			  and f.RLTD_SE_MTHR_TO_NWB3_SE_CBK_SK is not null and f.RLTD_SE_MTHR_TO_NWB4_SE_CBK_SK is not null then 4 ELSE '' end as birth_plurality,A.CL_EMPLOY_STUS_CD as employment_status,NULL as medical_discharge_date,NULL as medical_discharge_time,NULL as medical_disch_datetime,'' as reason_discharge_delay,'' as intention_to_readmit,NULL as acute_care_cert_expiry_date,f.SRV_ENC_LST_EXPCT_DISCH_DT as expected_discharge_date,'' as reason_no_health_claim,a.CT_TOT_SE_PSYC_BED_D_CT as days_in_psych_unit,round(a.CT_TOT_SE_PSYC_BED_HRS,0) as hours_in_psych_unit,A.SE_REQ_SRC_TYP_CD as source_of_referral,'' as asgc_version,case when (P.MG_AUTH_OSP_HIE_FAC_ID = '' or P.MG_AUTH_OSP_HIE_FAC_ID IS NULL) then A.GNAF_LHD_HLTH_JURIS_ID else P.MG_AUTH_OSP_HIE_FAC_ID end as LHD_of_Usual_residence,K.OSP_ID as HLTH_ORG_OSP_OSP_ID,K.MG_AUTH_OSP_OSP_ID,A.SE_CBK_SK,A.CL_ID_EUID,A.CL_ID_IHI ,A.SEQ_AP_SE_IN_ENC as episode_sequence_number
			,A.CT_TOT_SE_BED_D_CT as episode_length_of_stay,(CASE WHEN A.CL_ID_AUID in ('-1','Unknown/Invalid','') then A.CL_ID_AUID WHEN len(A.CL_ID_AUID) <= 10 THEN right('0000000000'+A.CL_ID_AUID,10) WHEN len(A.CL_ID_AUID) > 10 THEN right('0000000000'+A.CL_ID_AUID,10) ELSE '-' end) as AUID 
			,A.ASGS_SA_L2_16_CD, A.CL_URES_ADDR_ASGS21_SA_L2_CD FROM CRT.V_FACT_AP_SE_FLAT AS A LEFT JOIN (SELECT DISTINCT SE_CBK_SK,DIM_CL_INSUR_SK,SRV_ENC_REC_ID,RLTD_SE_NWB_TO_MTHR_SE_CBK_SK,WGT_AT_SE_ST_GMS,COLLAB_CARE_STAT_CD,SRV_ENC_LST_EXPCT_DISCH_DT,RLTD_SE_MTHR_TO_NWB1_SE_CBK_SK ,RLTD_SE_MTHR_TO_NWB2_SE_CBK_SK,RLTD_SE_MTHR_TO_NWB3_SE_CBK_SK,RLTD_SE_MTHR_TO_NWB4_SE_CBK_SK,LST_AP_ELCTN_STAT_CD,DIM_SE_ST_CL_URES_ADDR_SK FROM CRT.v_FACT_AP_SE) as f on a.SE_CBK_SK = f.SE_CBK_SK LEFT JOIN (SELECT SE_CBK_SK,max(case when seq = 1 then mo_clinician else '' end)  as mo_code1,max(case when seq = 2 then mo_clinician else '' end)  as mo_code2 FROM (select c.SE_CBK_SK,mo_clinician,ROW_NUMBER() OVER (PARTITION BY SE_CBK_SK ORDER BY SE_CBK_SK) as seq from CRT.V_FACT_AP_SE AS c LEFT JOIN (SELECT DIM_RSP_ISP_SK,case when ISP_MED_AHPRA_ID != '-1' then ISP_MED_AHPRA_ID	when ISP_DENT_AHPRA_ID != '-1' then ISP_DENT_AHPRA_ID else '-1' end as mo_clinician FROM CRT.v_DIM_RSP_ISP) as b on (C.DIM_LST_RSP_ISP_SK = B.DIM_RSP_ISP_SK) or (C.DIM_FST_RSP_ISP_SK = B.DIM_RSP_ISP_SK) INNER JOIN (SELECT DIM_OSP_SK, HLTH_ORG_OSP_OSP_ID, MG_AUTH_OSP_OSP_ID, OSP_HIE_FAC_ID, MG_AUTH_OSP_HIE_FAC_ID,MG_AUTH_OSP_HLTH_SECTOR_CD,HLTH_ORG_OSP_HLTH_SECTOR_CD, OSP_TYP_CD,HLTH_ORG_OSP_HIE_FAC_ID,case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_HIE_FAC_ID else HLTH_ORG_OSP_HIE_FAC_ID end as facility_identifier,OSP_ID FROM CRT.v_DIM_OSP WHERE (MG_AUTH_OSP_HLTH_SECTOR_CD in('1','3')) and (HLTH_ORG_OSP_HLTH_SECTOR_CD in ('1','3')) AND HLTH_ORG_OSP_HIE_FAC_ID != '-1' AND HLTH_ORG_OSP_HIE_FAC_ID != '') AS K ON C.DIM_OSP_CREATED_SK = K.DIM_OSP_SK WHERE 
			(C.DIM_DT_FRML_ADM_SK <='"""
                + end_date
                + """' AND C.DIM_DT_FRML_ADM_SK != '1111-01-01') AND (C.DIM_DT_FRML_DISCH_SK >='"""
                + start_date
                + """' or C.DIM_DT_FRML_DISCH_SK is NULL OR C.DIM_DT_FRML_DISCH_SK = '1111-01-01') and (K.MG_AUTH_OSP_HIE_FAC_ID='"""
                + lhd
                + """' or K.facility_identifier ='"""
                + lhd
                + """')) as z GROUP by SE_CBK_SK) AS G on  G.SE_CBK_SK = f.SE_CBK_SK	LEFT JOIN (SELECT DISTINCT SE_CBK_SK,CL_ID,CL_ID_MASKED,SRV_ENC_REC_ID FROM CRT.v_FACT_AP_SE_FLAT) AS N on f.RLTD_SE_NWB_TO_MTHR_SE_CBK_SK = N.SE_CBK_SK LEFT JOIN (SELECT DISTINCT MG_AUTH_OSP_OSP_ID, MG_AUTH_OSP_FULL_NM, MG_AUTH_OSP_HIE_FAC_ID FROM CRT.v_DIM_OSP) AS P ON P.MG_AUTH_OSP_OSP_ID = STUFF(A.GNAF_LHD_HLTH_JURIS_ID,4,1,'0') LEFT JOIN (SELECT DISTINCT SRV_ENC_REC_ID, sum(CT_TOT_SE_BED_D_CT) as LOS FROM CRT.V_FACT_AP_SE_FLAT group by SRV_ENC_REC_ID) as q on a.SRV_ENC_REC_ID = q.SRV_ENC_REC_ID LEFT JOIN (SELECT DISTINCT SE_CBK_SK,DIM_AP_SE_PRF_SK FROM CRT.V_FACT_AP_SE) as R on A.SE_CBK_SK = R.SE_CBK_SK LEFT JOIN
			(SELECT DISTINCT DIM_AP_SE_PRF_SK, FRML_ADM_INTND_LOS_CD FROM CRT.v_DIM_AP_SE_PRF) as S on R.DIM_AP_SE_PRF_SK = S.DIM_AP_SE_PRF_SK INNER JOIN (SELECT DISTINCT DIM_OSP_SK, OSP_HIE_FAC_ID,HLTH_ORG_OSP_OSP_ID, MG_AUTH_OSP_HLTH_SECTOR_CD, HLTH_ORG_OSP_HLTH_SECTOR_CD, OSP_TYP_CD,HLTH_ORG_OSP_HIE_FAC_ID, MG_AUTH_OSP_HIE_FAC_ID, MG_AUTH_OSP_OSP_ID,case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_HIE_FAC_ID else HLTH_ORG_OSP_HIE_FAC_ID end as facility_identifier, case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_ID else HLTH_ORG_OSP_OSP_ID end as OSP_ID FROM CRT.v_DIM_OSP WHERE ((MG_AUTH_OSP_HLTH_SECTOR_CD IN ('1','3')) and (HLTH_ORG_OSP_HLTH_SECTOR_CD IN ('1','3'))) AND HLTH_ORG_OSP_HIE_FAC_ID != '-1' AND HLTH_ORG_OSP_HIE_FAC_ID != '') AS K ON a.DIM_OSP_CREATED_SK = K.DIM_OSP_SK WHERE (A.DIM_DT_FRML_ADM_SK <='"""
                + end_date
                + """' AND A.DIM_DT_FRML_ADM_SK != '1111-01-01') AND (A.DIM_DT_FRML_DISCH_SK >='"""
                + start_date
                + """' or A.DIM_DT_FRML_DISCH_SK is NULL OR A.DIM_DT_FRML_DISCH_SK = '1111-01-01') and K.MG_AUTH_OSP_HIE_FAC_ID='"""
                + lhd
                + """' and K.facility_identifier IN 
			("""
                + facilities_included
                + """);"""
            )
    retry_flag = True
    retry_count = 0
    while retry_flag and retry_count < 5:
        try:
            logging.info(query_stay)
            tbl_dbo_stay = pd.read_sql(query_stay, cnxn)
            retry_flag = False
        except Exception as e:
            retry_count = retry_count + 1
            time.sleep(5)
            if retry_count == 5:
                logging.exception("Exception occurred")
                label_1_status = 0
                messagebox.showerror(
                    "SQL Error", "Error extracting Stay details\n" + str(e)
                )
                label_1_sub.configure(text="Failed (Stay)...", fg="red")
                main_screen.update()
                tbl_dbo_stay = pd.DataFrame(
                    columns=[
                        "facility_identifier",
                        "stay_number",
                        "person_identifier",
                        "indigenous_status",
                        "birth_date",
                        "country_of_birth",
                        "marital_status",
                        "preferred_language",
                        "sex",
                        "admission_date",
                        "admission_time",
                        "discharge_date",
                        "discharge_time",
                        "mo_code1",
                        "mo_code2",
                        "emergency_status",
                        "readmitted_within_28_days",
                        "readmit_this_hosp_28_days",
                        "ambulance_client_number",
                        "referred_to_on_separation",
                        "stay_discharge_intention",
                        "infant_start_weight",
                        "infant_end_weight",
                        "hospital_insurance",
                        "stay_leave_days_total",
                        "length_of_stay_total",
                        "age",
                        "age_grouping",
                        "facility_trans_to",
                        "facility_trans_from",
                        "collabrtve_care_facility",
                        "contract_status",
                        "collabrtve_care_role",
                        "collabrtve_care_type",
                        "prev_diag_of_carcinoma",
                        "practice_identifier1",
                        "practice_identifier2",
                        "patient_suburb",
                        "patient_postcode",
                        "mrn",
                        "medicare_number",
                        "medicare_expiry_date",
                        "dva_card_type",
                        "dva_card_number",
                        "centrelink_client_number",
                        "insurance_fund",
                        "insurance_fund_master",
                        "insurance_fund_number",
                        "religion_local",
                        "religion_ascrg",
                        "presenting_problem",
                        "indicator_procedure_code",
                        "claim_against_health_fund",
                        "last_psych_admission_date",
                        "medicare_eligibility_status",
                        "election_status_on_admit",
                        "sla_version",
                        "area_of_usual_residence",
                        "state_of_usual_residence",
                        "country_of_usual_residence",
                        "dpid_of_usual_residence",
                        "longitude",
                        "latitude",
                        "census_collection_district",
                        "health_insurance_on_admit",
                        "abs_preferred_language",
                        "preferred_language_ascl",
                        "assccs_country_of_birth",
                        "country_of_birth_sacc",
                        "marital_status_nhdd",
                        "prev_specialised_treatment",
                        "type_of_usual_accom",
                        "consent_flag",
                        "estimated_birth_date_flag",
                        "age_at_separation",
                        "day_stay_los",
                        "mothers_mrn",
                        "mothers_person_identifier",
                        "mothers_stay_number",
                        "birth_plurality",
                        "employment_status",
                        "medical_discharge_date",
                        "medical_discharge_time",
                        "medical_disch_datetime",
                        "reason_discharge_delay",
                        "intention_to_readmit",
                        "acute_care_cert_expiry_date",
                        "expected_discharge_date",
                        "reason_no_health_claim",
                        "days_in_psych_unit",
                        "hours_in_psych_unit",
                        "source_of_referral",
                        "asgc_version",
                        "LHD_of_Usual_residence",
                        "HLTH_ORG_OSP_OSP_ID",
                        "MG_AUTH_OSP_OSP_ID",
                        "SE_CBK_SK",
                        "CL_ID_EUID",
                        "CL_ID_IHI",
                        "episode_sequence_number",
                        "AUID",
                        "ASGS_SA_L2_16_CD",
                        "CL_URES_ADDR_ASGS21_SA_L2_CD",
                    ]
                )
                return
        else:
            tbl_dbo_stay = tbl_dbo_stay.fillna("")
            tbl_dbo_stay = tbl_dbo_stay[
                tbl_dbo_stay["facility_identifier"].isin(
                    facilities_included_list_global
                )
            ]
            tbl_dbo_stay = tbl_dbo_stay.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_dbo_stay = tbl_dbo_stay.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_dbo_stay = tbl_dbo_stay.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_stay = tbl_dbo_stay.apply(
                lambda x: x.replace(regex=r"NULL", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_stay = tbl_dbo_stay.apply(
                lambda x: x.replace(regex=r"null", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_stay = tbl_dbo_stay.apply(
                lambda x: x.replace(regex=r"Null", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_stay["stay_number"] = (
                tbl_dbo_stay["stay_number"]
                .astype(str)
                .str.pad(8, side="left", fillchar="0")
            )
            # 27 July 2024 - stay episode seq number
            tbl_dbo_stay["episode_sequence_number"] = (
                tbl_dbo_stay["episode_sequence_number"]
                .astype(str)
                .str.pad(3, side="left", fillchar="0")
            )
            tbl_dbo_stay = tbl_dbo_stay[
                [
                    "facility_identifier",
                    "stay_number",
                    "person_identifier",
                    "indigenous_status",
                    "birth_date",
                    "country_of_birth",
                    "marital_status",
                    "preferred_language",
                    "sex",
                    "admission_date",
                    "admission_time",
                    "discharge_date",
                    "discharge_time",
                    "mo_code1",
                    "mo_code2",
                    "emergency_status",
                    "readmitted_within_28_days",
                    "readmit_this_hosp_28_days",
                    "ambulance_client_number",
                    "referred_to_on_separation",
                    "stay_discharge_intention",
                    "infant_start_weight",
                    "infant_end_weight",
                    "hospital_insurance",
                    "stay_leave_days_total",
                    "length_of_stay_total",
                    "age",
                    "age_grouping",
                    "facility_trans_to",
                    "facility_trans_from",
                    "collabrtve_care_facility",
                    "contract_status",
                    "collabrtve_care_role",
                    "collabrtve_care_type",
                    "prev_diag_of_carcinoma",
                    "practice_identifier1",
                    "practice_identifier2",
                    "patient_suburb",
                    "patient_postcode",
                    "mrn",
                    "medicare_number",
                    "medicare_expiry_date",
                    "dva_card_type",
                    "dva_card_number",
                    "centrelink_client_number",
                    "insurance_fund",
                    "insurance_fund_master",
                    "insurance_fund_number",
                    "religion_local",
                    "religion_ascrg",
                    "presenting_problem",
                    "indicator_procedure_code",
                    "claim_against_health_fund",
                    "last_psych_admission_date",
                    "medicare_eligibility_status",
                    "election_status_on_admit",
                    "sla_version",
                    "area_of_usual_residence",
                    "state_of_usual_residence",
                    "country_of_usual_residence",
                    "dpid_of_usual_residence",
                    "longitude",
                    "latitude",
                    "census_collection_district",
                    "health_insurance_on_admit",
                    "abs_preferred_language",
                    "preferred_language_ascl",
                    "assccs_country_of_birth",
                    "country_of_birth_sacc",
                    "marital_status_nhdd",
                    "prev_specialised_treatment",
                    "type_of_usual_accom",
                    "consent_flag",
                    "estimated_birth_date_flag",
                    "age_at_separation",
                    "day_stay_los",
                    "mothers_mrn",
                    "mothers_person_identifier",
                    "mothers_stay_number",
                    "birth_plurality",
                    "employment_status",
                    "medical_discharge_date",
                    "medical_discharge_time",
                    "medical_disch_datetime",
                    "reason_discharge_delay",
                    "intention_to_readmit",
                    "acute_care_cert_expiry_date",
                    "expected_discharge_date",
                    "reason_no_health_claim",
                    "days_in_psych_unit",
                    "hours_in_psych_unit",
                    "source_of_referral",
                    "asgc_version",
                    "LHD_of_Usual_residence",
                    "HLTH_ORG_OSP_OSP_ID",
                    "MG_AUTH_OSP_OSP_ID",
                    "SE_CBK_SK",
                    "CL_ID_EUID",
                    "CL_ID_IHI",
                    "episode_sequence_number",
                    "AUID",
                    "ASGS_SA_L2_16_CD",
                    "CL_URES_ADDR_ASGS21_SA_L2_CD",
                ]
            ]
            # dropping duplicate values
            tbl_dbo_stay.drop_duplicates(keep="last", inplace=True)
            tbl_dbo_stay.to_csv(
                "./ExtractorDB/OutputStay.csv",
                index=False,
                na_rep="",
                float_format=str,
                decimal=str,
                date_format=str,
            )
            logging.info("tbl_dbo_stay=%s", len(tbl_dbo_stay))
    # lhds = "X830", "X840",  "X850"  "X860" use the AUID in there PatientNumber so data must be extracted from the dbo_PATIENT_CONTACT_DETAILS which contains the AUID
    # Other LHDs use the MRN in there PatientNumber and this is contained in the stay table/Episode ATS
    # OutputPatient
    # columns = facility_identifier,area_identifier,person_area_uid,contact_identifier,mrn
    # Access query = Append_tbl_Patient_Contact_Details
    # SELECT dbo_PATIENT_CONTACT_DETAILS.facility_identifier, dbo_PATIENT_CONTACT_DETAILS.area_identifier, IIf(Len([dbo_PATIENT_CONTACT_DETAILS]![person_area_uid])>10,Right([dbo_PATIENT_CONTACT_DETAILS]![person_area_uid],10),"-") AS Expr1, dbo_PATIENT_CONTACT_DETAILS.contact_identifier, dbo_PATIENT_CONTACT_DETAILS.mrn FROM dbo_PATIENT_CONTACT_DETAILS GROUP BY dbo_PATIENT_CONTACT_DETAILS.facility_identifier, dbo_PATIENT_CONTACT_DETAILS.area_identifier, IIf(Len([dbo_PATIENT_CONTACT_DETAILS]![person_area_uid])>10,Right([dbo_PATIENT_CONTACT_DETAILS]![person_area_uid],10),"-"), dbo_PATIENT_CONTACT_DETAILS.contact_identifier, dbo_PATIENT_CONTACT_DETAILS.mrn, dbo_PATIENT_CONTACT_DETAILS.snap_curr_indicator, dbo_PATIENT_CONTACT_DETAILS.service_type HAVING (((dbo_PATIENT_CONTACT_DETAILS.area_identifier)=[Forms]![Frm:1-ExtractSetUp]![AHS]) AND ((dbo_PATIENT_CONTACT_DETAILS.snap_curr_indicator)="Y") AND ((dbo_PATIENT_CONTACT_DETAILS.service_type)="AP"));
    label_1_sub.configure(text="In Progress (Patient)...", fg="blue")
    main_screen.update()
    if source == "HIE":
        if (
            lhd == "X830"
            or lhd == "X840"
            or lhd == "X850"
            or lhd == "X860"
            or lhd_global == "X740"
        ):
            logging.info(
                "Extracting Patient AUID - %s use AUID in PatientNumber, so data must be extracted from dbo_PATIENT_CONTACT_DETAILS which contains the AUID",
                lhd,
            )
        else:
            logging.info(
                "Extracting Patient NOT AUID - %s use MRN in PatientNumber, and this is contained in the Stay table/Episode ATS",
                lhd,
            )
        if len(facilities_excluded_list) > 0:
            query_patient = (
                """SELECT dbo.PATIENT_CONTACT_DETAILS.facility_identifier, dbo.PATIENT_CONTACT_DETAILS.area_identifier, 
            (CASE WHEN len(dbo.PATIENT_CONTACT_DETAILS.person_area_uid) > 10 THEN right(dbo.PATIENT_CONTACT_DETAILS.person_area_uid,10) ELSE '-' end) AS person_area_uid, 
            dbo.PATIENT_CONTACT_DETAILS.contact_identifier, dbo.PATIENT_CONTACT_DETAILS.mrn, '' as HLTH_ORG_OSP_OSP_ID, '' as MG_AUTH_OSP_OSP_ID, '' as SE_CBK_SK, '' as CL_ID_EUID, '' AS CL_ID_IHI FROM dbo.PATIENT_CONTACT_DETAILS WHERE service_type = 'AP' AND snap_curr_indicator='Y' AND area_identifier='"""
                + lhd
                + """' AND dbo.PATIENT_CONTACT_DETAILS.facility_identifier NOT IN ("""
                + facilities_excluded
                + """) 
            GROUP BY dbo.PATIENT_CONTACT_DETAILS.facility_identifier, dbo.PATIENT_CONTACT_DETAILS.area_identifier,(CASE WHEN len(dbo.PATIENT_CONTACT_DETAILS.person_area_uid) > 10 THEN right(dbo.PATIENT_CONTACT_DETAILS.person_area_uid,10) ELSE '-' end), dbo.PATIENT_CONTACT_DETAILS.contact_identifier, dbo.PATIENT_CONTACT_DETAILS.mrn, dbo.PATIENT_CONTACT_DETAILS.snap_curr_indicator, dbo.PATIENT_CONTACT_DETAILS.service_type 
            HAVING (((dbo.PATIENT_CONTACT_DETAILS.area_identifier)='"""
                + lhd
                + """') AND ((dbo.PATIENT_CONTACT_DETAILS.snap_curr_indicator)="Y") AND ((dbo.PATIENT_CONTACT_DETAILS.service_type)="AP") AND dbo.PATIENT_CONTACT_DETAILS.facility_identifier NOT IN ("""
                + facilities_excluded
                + """));"""
            )
        else:
            query_patient = (
                """SELECT dbo.PATIENT_CONTACT_DETAILS.facility_identifier, dbo.PATIENT_CONTACT_DETAILS.area_identifier,
            (CASE WHEN len(dbo.PATIENT_CONTACT_DETAILS.person_area_uid) > 10 THEN right(dbo.PATIENT_CONTACT_DETAILS.person_area_uid,10) ELSE '-' end) AS person_area_uid,      
            dbo.PATIENT_CONTACT_DETAILS.contact_identifier, dbo.PATIENT_CONTACT_DETAILS.mrn , '' as HLTH_ORG_OSP_OSP_ID, '' as MG_AUTH_OSP_OSP_ID, '' as SE_CBK_SK, '' as CL_ID_EUID, '' AS CL_ID_IHI FROM dbo.PATIENT_CONTACT_DETAILS WHERE service_type = 'AP' AND snap_curr_indicator='Y' AND area_identifier='"""
                + lhd
                + """' GROUP BY dbo.PATIENT_CONTACT_DETAILS.facility_identifier, dbo.PATIENT_CONTACT_DETAILS.area_identifier,(CASE WHEN len(dbo.PATIENT_CONTACT_DETAILS.person_area_uid) > 10 THEN right(dbo.PATIENT_CONTACT_DETAILS.person_area_uid,10) ELSE '-' end), dbo.PATIENT_CONTACT_DETAILS.contact_identifier, dbo.PATIENT_CONTACT_DETAILS.mrn, dbo.PATIENT_CONTACT_DETAILS.snap_curr_indicator, dbo.PATIENT_CONTACT_DETAILS.service_type 
            HAVING (((dbo.PATIENT_CONTACT_DETAILS.area_identifier)='"""
                + lhd
                + """') AND ((dbo.PATIENT_CONTACT_DETAILS.snap_curr_indicator)="Y") AND ((dbo.PATIENT_CONTACT_DETAILS.service_type)="AP"));"""
            )
    elif source == "EDW":
        if len(facilities_included_list) > 0:
            query_patient = (
                """SELECT K.facility_identifier,K.MG_AUTH_OSP_HIE_FAC_ID as area_identifier,(CASE WHEN B.CL_ID_AUID in ('-1','Unknown/Invalid','') then B.CL_ID_AUID WHEN len(B.CL_ID_AUID) <= 10 THEN right('0000000000'+B.CL_ID_AUID,10) WHEN len(B.CL_ID_AUID) > 10 THEN right('0000000000'+B.CL_ID_AUID,10) ELSE '-' end) as person_area_uid,ISNULL(SUBSTRING(B.SRV_ENC_REC_ID,charindex('-',B.SRV_ENC_REC_ID)+1,8),'') as contact_identifier,case when B.CL_ID in ('-1','Unknown/Invalid','') then B.CL_ID when len(B.CL_ID) > 10 then RIGHT(B.CL_ID,10) when len(B.CL_ID) < 10 then RIGHT(CONCAT('0000000000',ISNULL(TRIM(B.CL_ID),'')),10) else '' end  as mrn,K.OSP_ID AS HLTH_ORG_OSP_OSP_ID,K.MG_AUTH_OSP_OSP_ID,B.SE_CBK_SK,B.CL_ID_EUID,B.CL_ID_IHI FROM CRT.v_FACT_AP_SE_FLAT AS B 
			INNER JOIN (SELECT DIM_OSP_SK, HLTH_ORG_OSP_OSP_ID,MG_AUTH_OSP_OSP_ID, MG_AUTH_OSP_HIE_FAC_ID,OSP_TYP_CD, OSP_HIE_FAC_ID,HLTH_ORG_OSP_HIE_FAC_ID, MG_AUTH_OSP_HLTH_SECTOR_CD, HLTH_ORG_OSP_HLTH_SECTOR_CD,case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_ID else HLTH_ORG_OSP_OSP_ID end as OSP_ID,case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_HIE_FAC_ID else HLTH_ORG_OSP_HIE_FAC_ID end as facility_identifier FROM CRT.v_DIM_OSP	WHERE ((MG_AUTH_OSP_HLTH_SECTOR_CD IN ('1','3')) and (HLTH_ORG_OSP_HLTH_SECTOR_CD IN ('1','3'))) AND HLTH_ORG_OSP_HIE_FAC_ID != '-1' AND HLTH_ORG_OSP_HIE_FAC_ID != '') AS K ON B.DIM_OSP_CREATED_SK = K.DIM_OSP_SK WHERE K.MG_AUTH_OSP_HIE_FAC_ID ='"""
                + lhd
                + """' AND K.facility_identifier IN ("""
                + facilities_included
                + """) GROUP BY K.OSP_HIE_FAC_ID,K.facility_identifier, K.MG_AUTH_OSP_HIE_FAC_ID, K.HLTH_ORG_OSP_HIE_FAC_ID,K.OSP_TYP_CD,(CASE WHEN B.CL_ID_AUID in ('-1'	,'Unknown/Invalid','') then B.CL_ID_AUID WHEN len(B.CL_ID_AUID) <= 10 THEN right('0000000000'+B.CL_ID_AUID,10) WHEN len(B.CL_ID_AUID) > 10 THEN right('0000000000'+B.CL_ID_AUID,10) ELSE '-' end)
			,ISNULL(SUBSTRING(B.SRV_ENC_REC_ID,charindex('-',B.SRV_ENC_REC_ID)+1,8),''),K.OSP_ID,K.MG_AUTH_OSP_OSP_ID,B.SE_CBK_SK,B.CL_ID,B.CL_ID_EUID,B.CL_ID_IHI;"""
            )
    retry_flag = True
    retry_count = 0
    while retry_flag and retry_count < 5:
        try:
            logging.info(query_patient)
            tbl_Patient_Contact_Details = pd.read_sql(query_patient, cnxn)
            retry_flag = False
        except Exception as e:
            retry_count = retry_count + 1
            time.sleep(5)
            if retry_count == 5:
                logging.exception("Exception occurred")
                label_1_status = 0
                messagebox.showerror(
                    "SQL Error", "Error extracting Patient details\n" + str(e)
                )
                label_1_sub.configure(text="Failed (Patient)...", fg="red")
                main_screen.update()
                tbl_Patient_Contact_Details = pd.DataFrame(
                    columns=[
                        "facility_identifier",
                        "area_identifier",
                        "person_area_uid",
                        "AUID",
                        "contact_identifier",
                        "mrn",
                        "HLTH_ORG_OSP_OSP_ID",
                        "MG_AUTH_OSP_OSP_ID",
                        "SE_CBK_SK",
                        "CL_ID_EUID",
                        "CL_ID_IHI",
                    ]
                )
                return
        else:
            tbl_Patient_Contact_Details = tbl_Patient_Contact_Details.fillna("")
            tbl_Patient_Contact_Details = tbl_Patient_Contact_Details[
                tbl_Patient_Contact_Details["area_identifier"] == lhd_global
            ]
            tbl_Patient_Contact_Details = tbl_Patient_Contact_Details[
                tbl_Patient_Contact_Details["facility_identifier"].isin(
                    facilities_included_list_global
                )
            ]
            tbl_Patient_Contact_Details["AUID"] = tbl_Patient_Contact_Details[
                "person_area_uid"
            ]
            tbl_Patient_Contact_Details = tbl_Patient_Contact_Details[
                [
                    "facility_identifier",
                    "area_identifier",
                    "person_area_uid",
                    "AUID",
                    "contact_identifier",
                    "mrn",
                    "HLTH_ORG_OSP_OSP_ID",
                    "MG_AUTH_OSP_OSP_ID",
                    "SE_CBK_SK",
                    "CL_ID_EUID",
                    "CL_ID_IHI",
                ]
            ]
            # dropping duplicate values
            tbl_Patient_Contact_Details.drop_duplicates(keep="last", inplace=True)
            if source == "HIE" or source == "EDW":
                if (
                    lhd == "X830"
                    or lhd == "X840"
                    or lhd == "X850"
                    or lhd == "X860"
                    or lhd_global == "X740"
                ):
                    tbl_Patient_Contact_Details = tbl_Patient_Contact_Details.applymap(
                        str
                    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
                    tbl_Patient_Contact_Details = tbl_Patient_Contact_Details.applymap(
                        lambda x: x.strip() if isinstance(x, str) else x
                    )
                    tbl_Patient_Contact_Details = tbl_Patient_Contact_Details.apply(
                        lambda x: x.replace(regex=r"^NaT$", value="")
                        if x.dtype == "object"
                        else x
                    )
                    tbl_Patient_Contact_Details = tbl_Patient_Contact_Details.apply(
                        lambda x: x.replace(regex=r"NULL", value="")
                        if x.dtype == "object"
                        else x
                    )
                    tbl_Patient_Contact_Details = tbl_Patient_Contact_Details.apply(
                        lambda x: x.replace(regex=r"Null", value="")
                        if x.dtype == "object"
                        else x
                    )
                    tbl_Patient_Contact_Details = tbl_Patient_Contact_Details.apply(
                        lambda x: x.replace(regex=r"null", value="")
                        if x.dtype == "object"
                        else x
                    )
                    tbl_Patient_Contact_Details.to_csv(
                        "./ExtractorDB/OutputPatient.csv",
                        index=False,
                        na_rep="",
                        float_format=str,
                        decimal=str,
                        date_format=str,
                    )
                    logging.info(
                        "tbl_Patient_Contact_Details=%s",
                        len(tbl_Patient_Contact_Details),
                    )
                else:
                    tbl_Patient_Contact_Details = tbl_Patient_Contact_Details.applymap(
                        str
                    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
                    tbl_Patient_Contact_Details = tbl_Patient_Contact_Details.applymap(
                        lambda x: x.strip() if isinstance(x, str) else x
                    )
                    tbl_Patient_Contact_Details = tbl_Patient_Contact_Details.apply(
                        lambda x: x.replace(regex=r"^NaT$", value="")
                        if x.dtype == "object"
                        else x
                    )
                    tbl_Patient_Contact_Details = tbl_Patient_Contact_Details.apply(
                        lambda x: x.replace(regex=r"NULL", value="")
                        if x.dtype == "object"
                        else x
                    )
                    tbl_Patient_Contact_Details = tbl_Patient_Contact_Details.apply(
                        lambda x: x.replace(regex=r"Null", value="")
                        if x.dtype == "object"
                        else x
                    )
                    tbl_Patient_Contact_Details = tbl_Patient_Contact_Details.apply(
                        lambda x: x.replace(regex=r"null", value="")
                        if x.dtype == "object"
                        else x
                    )
                    tbl_Patient_Contact_Details.to_csv(
                        "./ExtractorDB/Patient_contact_details.csv",
                        index=False,
                        na_rep="",
                        float_format=str,
                        decimal=str,
                        date_format=str,
                    )
                    logging.info(
                        "tbl_Patient_Contact_Details=%s",
                        len(tbl_Patient_Contact_Details),
                    )
    # Update Sub task 1 status
    if label_1_status == 0:
        label_1_sub.configure(text="Failed", fg="red")
        main_screen.update()
    else:
        label_1_sub.configure(text="Completed", fg="green")
        main_screen.update()
    # label_1_res.configure(text="Facility:"+str(len(tbl_dbo_Facility))+",  Stay:"+str(len(tbl_dbo_stay))+",  Patient:"+str(len(tbl_Patient_Contact_Details)))
    main_screen.update()
    ######################################### EXTRACT DATA - SUB TASK 2 #######################################
    # Set default value of sub-task status to 1
    label_2_status = 1
    # OutputEdNwau
    # columns = facility_identifier,ed_visit_identifier,arrival_date,nwau_type,nwau_type_value,nwau_base,indigenous_adj,remoteness_area_adj,nwau_final,compensable_nwau,nwau_version,nwau_calc_date,snap_from_date,snap_to_date,snap_curr_indicator,snap_load_date,snap_batch_run_no,snap_upd_batch_run_no,snap_record_status,UDG,URG,nwau_urg_mdb_value,nwau_urg_ed_diagnosis_mapped,nwau_base_UDG,indigenous_adj_UDG,remoteness_area_adj_UDG,nwau_final_UDG,compensable_nwau_UDG,nwau_version_UDG
    # Access query = Append_to_tbl_ED_NWAU
    # SELECT dbo_ED_NWAU.ed_visit_identifier, dbo_FACILITY.snap_curr_indicator, dbo_ED_NWAU.facility_identifier, dbo_ED_NWAU_1.nwau_type_value AS URG, dbo_ED_NWAU.nwau_type_value AS UDG, dbo_ED_NWAU_1.nwau_final, Max(((IIf([dbo_ED_NWAU]![nwau_urg_mdb_value] Is Null,Null,[dbo_ED_NWAU_1]![nwau_urg_mdb_value])))) AS Expr4, dbo_ED_NWAU_1.indigenous_adj, dbo_ED_NWAU_1.compensable_nwau, dbo_ED_NWAU_1.nwau_base, Max([dbo_ED_NWAU_1]![nwau_urg_ed_diagnosis_mapped]) AS Expr5, dbo_ED_NWAU_1.nwau_version, dbo_ED_NWAU.nwau_version, dbo_ED_NWAU.nwau_base, dbo_ED_NWAU.indigenous_adj, dbo_ED_NWAU.remoteness_area_adj, dbo_ED_NWAU.nwau_final, dbo_ED_NWAU.compensable_nwau, dbo_ED_VISIT.arrival_date
    # Original Inform8 query: SELECT dbo.ED_NWAU.ed_visit_identifier, dbo.FACILITY.snap_curr_indicator, dbo.ED_NWAU.facility_identifier, ED_NWAU_1.nwau_type_value AS URG, dbo.ED_NWAU.nwau_type_value AS UDG, ED_NWAU_1.nwau_final, Max(dbo.ED_NWAU.nwau_urg_mdb_value) AS calculated_1, Max(ED_NWAU_1.nwau_urg_mdb_value) AS calculated_2, ED_NWAU_1.indigenous_adj, ED_NWAU_1.compensable_nwau, ED_NWAU_1.nwau_base, Max(ED_NWAU_1.nwau_urg_ed_diagnosis_mapped) AS nwau_urg_ed_diagnosis_mapped, ED_NWAU_1.nwau_version, dbo.ED_NWAU.nwau_version AS nwau_version_UDG, dbo.ED_NWAU.nwau_base AS nwau_base_UDG, dbo.ED_NWAU.indigenous_adj AS indigenous_adj_UDG, dbo.ED_NWAU.remoteness_area_adj AS remoteness_area_adj_UDG, dbo.ED_NWAU.nwau_final AS nwau_final_UDG, dbo.ED_NWAU.compensable_nwau AS compensable_nwau_UDG, dbo.ED_VISIT.arrival_date FROM ((dbo.ED_NWAU INNER JOIN dbo.ED_VISIT ON (dbo.ED_NWAU.ed_visit_identifier = dbo.ED_VISIT.ed_visit_identifier) AND (dbo.ED_NWAU.facility_identifier = dbo.ED_VISIT.facility_identifier)) INNER JOIN dbo.ED_NWAU AS ED_NWAU_1 ON (dbo.ED_VISIT.facility_identifier = ED_NWAU_1.facility_identifier) AND (dbo.ED_VISIT.ed_visit_identifier = ED_NWAU_1.ed_visit_identifier)) INNER JOIN dbo.FACILITY ON dbo.ED_VISIT.facility_identifier = dbo.FACILITY.facility_identifier WHERE ((((dbo.ED_NWAU.nwau_type)='UDG') AND ((ED_NWAU_1.nwau_type)='URG')) OR (((dbo.ED_NWAU.nwau_type)='UDG') AND ((ED_NWAU_1.nwau_type)='URG')) OR (((dbo.ED_NWAU.nwau_type)='UDG') AND ((ED_NWAU_1.nwau_type)='URG')) OR (((dbo.ED_NWAU.nwau_type)='UDG') AND ((ED_NWAU_1.nwau_type)='URG'))) GROUP BY dbo.ED_NWAU.ed_visit_identifier, dbo.FACILITY.snap_curr_indicator, dbo.ED_NWAU.facility_identifier, ED_NWAU_1.nwau_type_value, dbo.ED_NWAU.nwau_type_value, ED_NWAU_1.nwau_final, ED_NWAU_1.indigenous_adj, ED_NWAU_1.compensable_nwau, ED_NWAU_1.nwau_base, ED_NWAU_1.nwau_version, dbo.ED_NWAU.nwau_version, dbo.ED_NWAU.nwau_base, dbo.ED_NWAU.indigenous_adj, dbo.ED_NWAU.remoteness_area_adj, dbo.ED_NWAU.nwau_final, dbo.ED_NWAU.compensable_nwau, dbo.ED_VISIT.arrival_date, dbo.ED_VISIT.snap_curr_indicator, ED_NWAU_1.snap_curr_indicator, dbo.ED_NWAU.snap_curr_indicator, dbo.FACILITY.area_identifier, dbo.ED_VISIT.actual_departure_date, dbo.ED_VISIT.departure_ready_date
    label_2_sub.configure(text="In Progress (EdNwau)...", fg="blue")
    main_screen.update()
    if source == "HIE":
        if len(facilities_excluded_list) == 0:
            query_EdNwau = (
                """SELECT dbo.ED_NWAU.facility_identifier, dbo.ED_NWAU.ed_visit_identifier, dbo.ED_VISIT.arrival_date, '' AS nwau_type, '' AS nwau_type_value, ED_NWAU_1.nwau_base, ED_NWAU_1.indigenous_adj, ED_NWAU_1.remoteness_area_adj, ED_NWAU_1.nwau_final, ED_NWAU_1.compensable_nwau, ED_NWAU_1.nwau_version, '' AS nwau_calc_date, 
            '' AS snap_from_date, '' AS snap_to_date, dbo.FACILITY.snap_curr_indicator, '' AS snap_load_date, '' AS snap_batch_run_no, '' AS snap_upd_batch_run_no, '' AS snap_record_status, ED_NWAU_1.nwau_type_value as AECC, dbo.ED_NWAU.nwau_type_value AS UDG, '' AS URG, 
            Max(Case dbo.ED_NWAU.nwau_urg_mdb_value when Null then Null else ED_NWAU_1.nwau_urg_mdb_value end) AS nwau_urg_mdb_value,
            Max(ED_NWAU_1.nwau_urg_ed_diagnosis_mapped) AS nwau_urg_ed_diagnosis_mapped, dbo.ED_NWAU.nwau_base AS nwau_base_UDG, dbo.ED_NWAU.indigenous_adj AS indigenous_adj_UDG, dbo.ED_NWAU.remoteness_area_adj AS remoteness_area_adj_UDG, dbo.ED_NWAU.nwau_final AS nwau_final_UDG, dbo.ED_NWAU.compensable_nwau AS compensable_nwau_UDG, dbo.ED_NWAU.nwau_version AS nwau_version_UDG , '' as HLTH_ORG_OSP_OSP_ID, '' as MG_AUTH_OSP_OSP_ID, '' as SE_CBK_SK
            FROM ((dbo.ED_NWAU INNER JOIN dbo.ED_VISIT ON (dbo.ED_NWAU.ed_visit_identifier = dbo.ED_VISIT.ed_visit_identifier) AND (dbo.ED_NWAU.facility_identifier = dbo.ED_VISIT.facility_identifier)) INNER JOIN dbo.ED_NWAU AS ED_NWAU_1 ON (dbo.ED_VISIT.facility_identifier = ED_NWAU_1.facility_identifier) AND (dbo.ED_VISIT.ed_visit_identifier = ED_NWAU_1.ed_visit_identifier)) INNER JOIN dbo.FACILITY ON dbo.ED_VISIT.facility_identifier = dbo.FACILITY.facility_identifier 
            WHERE ((((dbo.ED_NWAU.nwau_type)='UDG') AND ((ED_NWAU_1.nwau_type)='AECC')) OR (((dbo.ED_NWAU.nwau_type)='UDG') AND ((ED_NWAU_1.nwau_type)='AECC')) OR (((dbo.ED_NWAU.nwau_type)='UDG') AND ((ED_NWAU_1.nwau_type)='AECC')) OR (((dbo.ED_NWAU.nwau_type)='UDG') AND ((ED_NWAU_1.nwau_type)='AECC'))) 
            GROUP BY dbo.ED_NWAU.ed_visit_identifier, dbo.FACILITY.snap_curr_indicator, dbo.ED_NWAU.facility_identifier, ED_NWAU_1.nwau_type_value, dbo.ED_NWAU.nwau_type_value, ED_NWAU_1.nwau_final, ED_NWAU_1.indigenous_adj, ED_NWAU_1.compensable_nwau, ED_NWAU_1.nwau_base, ED_NWAU_1.nwau_version, dbo.ED_NWAU.nwau_version, dbo.ED_NWAU.nwau_base, dbo.ED_NWAU.indigenous_adj, dbo.ED_NWAU.remoteness_area_adj, ED_NWAU_1.remoteness_area_adj, dbo.ED_NWAU.nwau_final, dbo.ED_NWAU.compensable_nwau, dbo.ED_VISIT.arrival_date, dbo.ED_VISIT.snap_curr_indicator, ED_NWAU_1.snap_curr_indicator, dbo.ED_NWAU.snap_curr_indicator, dbo.FACILITY.area_identifier, dbo.ED_VISIT.actual_departure_date, dbo.ED_VISIT.departure_ready_date HAVING (((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.ED_NWAU.facility_identifier)<>"D311" And (dbo.ED_NWAU.facility_identifier)<>"Q230") AND ((ED_NWAU_1.nwau_version)='"""
                + nwau_v
                + """') AND ((dbo.ED_NWAU.nwau_version)='"""
                + nwau_v
                + """') AND ((dbo.ED_VISIT.arrival_date)<=('"""
                + end_date
                + """')) AND ((dbo.ED_VISIT.snap_curr_indicator)='Y') AND ((ED_NWAU_1.snap_curr_indicator)='Y') AND ((dbo.ED_NWAU.snap_curr_indicator)='Y') AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.ED_VISIT.actual_departure_date)>=('"""
                + start_date
                + """') And (dbo.ED_VISIT.actual_departure_date)<=('"""
                + end_date
                + """'))) OR (((dbo.FACILITY.snap_curr_indicator)='Y') AND ((ED_NWAU_1.nwau_version)='"""
                + nwau_v
                + """') AND ((dbo.ED_NWAU.nwau_version)='"""
                + nwau_v
                + """') AND ((dbo.ED_VISIT.arrival_date)>=('"""
                + start_date
                + """') And (dbo.ED_VISIT.arrival_date)<=('"""
                + end_date
                + """')) AND ((dbo.ED_VISIT.snap_curr_indicator)='Y') AND ((ED_NWAU_1.snap_curr_indicator)='Y') AND ((dbo.ED_NWAU.snap_curr_indicator)='Y') AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.ED_VISIT.actual_departure_date) Is Null Or (dbo.ED_VISIT.actual_departure_date)>=('"""
                + start_date
                + """')) AND ((dbo.ED_VISIT.departure_ready_date)>='"""
                + start_date
                + """')) OR (((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.ED_NWAU.facility_identifier)='"""
                + lhd
                + """') AND ((ED_NWAU_1.nwau_version)='"""
                + nwau_v
                + """') AND ((dbo.ED_NWAU.nwau_version)='"""
                + nwau_v
                + """') AND ((dbo.ED_VISIT.arrival_date)<=('"""
                + end_date
                + """')) AND ((dbo.ED_VISIT.snap_curr_indicator)='Y') AND ((ED_NWAU_1.snap_curr_indicator)='Y') AND ((dbo.ED_NWAU.snap_curr_indicator)='Y') AND ((dbo.ED_VISIT.actual_departure_date)>=('"""
                + start_date
                + """') And (dbo.ED_VISIT.actual_departure_date)<=('"""
                + end_date
                + """'))) OR (((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.ED_NWAU.facility_identifier)='"""
                + lhd
                + """') AND ((ED_NWAU_1.nwau_version)='"""
                + nwau_v
                + """') AND ((dbo.ED_NWAU.nwau_version)='"""
                + nwau_v
                + """') AND ((dbo.ED_VISIT.arrival_date)>=('"""
                + start_date
                + """') And (dbo.ED_VISIT.arrival_date)<=('"""
                + end_date
                + """')) AND ((dbo.ED_VISIT.snap_curr_indicator)='Y') AND ((ED_NWAU_1.snap_curr_indicator)='Y') AND ((dbo.ED_NWAU.snap_curr_indicator)='Y') AND ((dbo.ED_VISIT.actual_departure_date) Is Null Or (dbo.ED_VISIT.actual_departure_date)>=('"""
                + start_date
                + """')) AND ((dbo.ED_VISIT.departure_ready_date)>='"""
                + start_date
                + """'));"""
            )
        else:
            query_EdNwau = (
                """SELECT dbo.ED_NWAU.facility_identifier, dbo.ED_NWAU.ed_visit_identifier, dbo.ED_VISIT.arrival_date, '' AS nwau_type, '' AS nwau_type_value, ED_NWAU_1.nwau_base, ED_NWAU_1.indigenous_adj, ED_NWAU_1.remoteness_area_adj, ED_NWAU_1.nwau_final, ED_NWAU_1.compensable_nwau, ED_NWAU_1.nwau_version, '' AS nwau_calc_date, 
            '' AS snap_from_date, '' AS snap_to_date, dbo.FACILITY.snap_curr_indicator, '' AS snap_load_date, '' AS snap_batch_run_no, '' AS snap_upd_batch_run_no, '' AS snap_record_status, ED_NWAU_1.nwau_type_value as AECC, dbo.ED_NWAU.nwau_type_value AS UDG, '' AS URG, 
            Max(Case dbo.ED_NWAU.nwau_urg_mdb_value when Null then Null else ED_NWAU_1.nwau_urg_mdb_value end) AS nwau_urg_mdb_value,
            Max(ED_NWAU_1.nwau_urg_ed_diagnosis_mapped) AS nwau_urg_ed_diagnosis_mapped, dbo.ED_NWAU.nwau_base AS nwau_base_UDG, dbo.ED_NWAU.indigenous_adj AS indigenous_adj_UDG, dbo.ED_NWAU.remoteness_area_adj AS remoteness_area_adj_UDG, dbo.ED_NWAU.nwau_final AS nwau_final_UDG, dbo.ED_NWAU.compensable_nwau AS compensable_nwau_UDG, dbo.ED_NWAU.nwau_version AS nwau_version_UDG, '' as HLTH_ORG_OSP_OSP_ID, '' as MG_AUTH_OSP_OSP_ID, '' as SE_CBK_SK 
            FROM ((dbo.ED_NWAU INNER JOIN dbo.ED_VISIT ON (dbo.ED_NWAU.ed_visit_identifier = dbo.ED_VISIT.ed_visit_identifier) AND (dbo.ED_NWAU.facility_identifier = dbo.ED_VISIT.facility_identifier)) INNER JOIN dbo.ED_NWAU AS ED_NWAU_1 ON (dbo.ED_VISIT.facility_identifier = ED_NWAU_1.facility_identifier) AND (dbo.ED_VISIT.ed_visit_identifier = ED_NWAU_1.ed_visit_identifier)) INNER JOIN dbo.FACILITY ON dbo.ED_VISIT.facility_identifier = dbo.FACILITY.facility_identifier 
            WHERE ((((dbo.ED_NWAU.nwau_type)='UDG') AND ((ED_NWAU_1.nwau_type)='AECC')) OR (((dbo.ED_NWAU.nwau_type)='UDG') AND ((ED_NWAU_1.nwau_type)='AECC')) OR (((dbo.ED_NWAU.nwau_type)='UDG') AND ((ED_NWAU_1.nwau_type)='AECC')) OR (((dbo.ED_NWAU.nwau_type)='UDG') AND ((ED_NWAU_1.nwau_type)='AECC'))) AND dbo.FACILITY.facility_identifier NOT IN ("""
                + facilities_excluded
                + """) 
            GROUP BY dbo.ED_NWAU.ed_visit_identifier, dbo.FACILITY.snap_curr_indicator, dbo.ED_NWAU.facility_identifier, ED_NWAU_1.nwau_type_value, dbo.ED_NWAU.nwau_type_value, ED_NWAU_1.nwau_final, ED_NWAU_1.indigenous_adj, ED_NWAU_1.compensable_nwau, ED_NWAU_1.nwau_base, ED_NWAU_1.nwau_version, dbo.ED_NWAU.nwau_version, dbo.ED_NWAU.nwau_base, dbo.ED_NWAU.indigenous_adj, dbo.ED_NWAU.remoteness_area_adj, ED_NWAU_1.remoteness_area_adj, dbo.ED_NWAU.nwau_final, dbo.ED_NWAU.compensable_nwau, dbo.ED_VISIT.arrival_date, dbo.ED_VISIT.snap_curr_indicator, ED_NWAU_1.snap_curr_indicator, dbo.ED_NWAU.snap_curr_indicator, dbo.FACILITY.area_identifier, dbo.ED_VISIT.actual_departure_date, dbo.ED_VISIT.departure_ready_date HAVING (((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.ED_NWAU.facility_identifier)<>"D311" And (dbo.ED_NWAU.facility_identifier)<>"Q230") AND ((ED_NWAU_1.nwau_version)='"""
                + nwau_v
                + """') AND ((dbo.ED_NWAU.nwau_version)='"""
                + nwau_v
                + """') AND ((dbo.ED_VISIT.arrival_date)<=('"""
                + end_date
                + """')) AND ((dbo.ED_VISIT.snap_curr_indicator)='Y') AND ((ED_NWAU_1.snap_curr_indicator)='Y') AND ((dbo.ED_NWAU.snap_curr_indicator)='Y') AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.ED_VISIT.actual_departure_date)>=('"""
                + start_date
                + """') And (dbo.ED_VISIT.actual_departure_date)<=('"""
                + end_date
                + """'))) OR (((dbo.FACILITY.snap_curr_indicator)='Y') AND ((ED_NWAU_1.nwau_version)='"""
                + nwau_v
                + """') AND ((dbo.ED_NWAU.nwau_version)='"""
                + nwau_v
                + """') AND ((dbo.ED_VISIT.arrival_date)>=('"""
                + start_date
                + """') And (dbo.ED_VISIT.arrival_date)<=('"""
                + end_date
                + """')) AND ((dbo.ED_VISIT.snap_curr_indicator)='Y') AND ((ED_NWAU_1.snap_curr_indicator)='Y') AND ((dbo.ED_NWAU.snap_curr_indicator)='Y') AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.ED_VISIT.actual_departure_date) Is Null Or (dbo.ED_VISIT.actual_departure_date)>=('"""
                + start_date
                + """')) AND ((dbo.ED_VISIT.departure_ready_date)>='"""
                + start_date
                + """')) OR (((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.ED_NWAU.facility_identifier)='"""
                + lhd
                + """') AND ((ED_NWAU_1.nwau_version)='"""
                + nwau_v
                + """') AND ((dbo.ED_NWAU.nwau_version)='"""
                + nwau_v
                + """') AND ((dbo.ED_VISIT.arrival_date)<=('"""
                + end_date
                + """')) AND ((dbo.ED_VISIT.snap_curr_indicator)='Y') AND ((ED_NWAU_1.snap_curr_indicator)='Y') AND ((dbo.ED_NWAU.snap_curr_indicator)='Y') AND ((dbo.ED_VISIT.actual_departure_date)>=('"""
                + start_date
                + """') And (dbo.ED_VISIT.actual_departure_date)<=('"""
                + end_date
                + """'))) OR (((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.ED_NWAU.facility_identifier)='"""
                + lhd
                + """') AND ((ED_NWAU_1.nwau_version)='"""
                + nwau_v
                + """') AND ((dbo.ED_NWAU.nwau_version)='"""
                + nwau_v
                + """') AND ((dbo.ED_VISIT.arrival_date)>=('"""
                + start_date
                + """') And (dbo.ED_VISIT.arrival_date)<=('"""
                + end_date
                + """')) AND ((dbo.ED_VISIT.snap_curr_indicator)='Y') AND ((ED_NWAU_1.snap_curr_indicator)='Y') AND ((dbo.ED_NWAU.snap_curr_indicator)='Y') AND ((dbo.ED_VISIT.actual_departure_date) Is Null Or (dbo.ED_VISIT.actual_departure_date)>=('"""
                + start_date
                + """')) AND ((dbo.ED_VISIT.departure_ready_date)>='"""
                + start_date
                + """'));"""
            )
    elif source == "EDW":
        if len(facilities_included_list) > 0:
            # use WAU_CLASS_DOM_NM = 'Australian Emergency Care Classification Code' instead of URG ( 'Emergency Department Urgency Related Group Class Code (EDW)')
            query_EdNwau = (
                """WITH FilteredWAU AS (SELECT SE_CBK_SK, SRV_ENC_REC_ID, DIM_DT_SE_ST_SK, DIM_DT_SE_END_SK,WAU_BASE, WAU_ADJ_INDIGENOUS, WAU_ADJ_PT_RES_REMT_AREA, WAU_FINAL,WAU_COMPENSABLE_FINAL, URG_MDB_CD, WAU_ADJ_PT_TX_REMT_AREA, NWAU_DIAG_CD,DIM_WAU_VER_SK, DIM_WAU_CLASS_SK, DIM_OSP_CREATED_SK FROM CRT.v_FACT_ED_SE_WAU WHERE DIM_DT_SE_ST_SK <= '"""
                + end_date
                + """' AND DIM_DT_SE_ST_SK != '1111-01-01' AND ((DIM_DT_SE_END_SK >= '"""
                + start_date
                + """' AND DIM_DT_SE_END_SK <= '"""
                + end_date
                + """') OR (DIM_DT_SE_ST_SK BETWEEN '"""
                + start_date
                + """' AND '"""
                + end_date
                + """' AND (DIM_DT_SE_END_SK IS NULL OR DIM_DT_SE_END_SK >= '"""
                + start_date
                + """' OR DIM_DT_SE_END_SK = '1111-01-01')))),FilteredFlat AS (SELECT SE_CBK_SK, CAST(SB_E_FST_PT_DEP_RDY_DTTM AS DATE) AS SB_E_FST_PT_DEP_RDY_DT FROM CRT.v_FACT_ED_SE_FLAT WHERE CAST(SB_E_FST_PT_DEP_RDY_DTTM AS DATE) >= '"""
                + start_date
                + """'),WAUVer AS (SELECT DIM_WAU_VER_SK, WAU_VER FROM CRT.v_DIM_WAU_VER WHERE WAU_VER = 'NWAU'+'"""
                + nwau_v
                + """'),WAUClass AS (SELECT DIM_WAU_CLASS_SK, WAU_CLASS_DOM_NM, WAU_CLASS_CD FROM CRT.v_DIM_WAU_CLASS),FilteredOSP AS (SELECT DIM_OSP_SK, HLTH_ORG_OSP_OSP_ID, MG_AUTH_OSP_OSP_ID, MG_AUTH_OSP_HIE_FAC_ID,CASE WHEN OSP_TYP_CD IN ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10', '10.02', '10.08', '10.03', '2.08', '10.07') AND OSP_HIE_FAC_ID NOT IN ('-1', '') THEN OSP_HIE_FAC_ID ELSE HLTH_ORG_OSP_HIE_FAC_ID END AS facility_identifier,CASE WHEN OSP_TYP_CD IN ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10', '10.02', '10.08', '10.03', '2.08', '10.07') AND OSP_HIE_FAC_ID NOT IN ('-1', '') THEN OSP_ID ELSE HLTH_ORG_OSP_OSP_ID END AS OSP_ID FROM CRT.v_DIM_OSP WHERE MG_AUTH_OSP_HLTH_SECTOR_CD IN ('1', '3') AND HLTH_ORG_OSP_HLTH_SECTOR_CD IN ('1', '3') AND HLTH_ORG_OSP_HIE_FAC_ID NOT IN ('-1', '')) SELECT F.facility_identifier,ISNULL(SUBSTRING(B.SRV_ENC_REC_ID, CHARINDEX('-', B.SRV_ENC_REC_ID) + 1, 10), '') AS ed_visit_identifier,B.DIM_DT_SE_ST_SK AS arrival_date,'' AS nwau_type, '' AS nwau_type_value,
			MAX(CASE WHEN D.WAU_CLASS_DOM_NM = 'Australian Emergency Care Classification Code' THEN B.WAU_BASE END) AS nwau_base,
			MAX(CASE WHEN D.WAU_CLASS_DOM_NM = 'Australian Emergency Care Classification Code' THEN B.WAU_ADJ_INDIGENOUS END) AS indigenous_adj,
			MAX(CASE WHEN D.WAU_CLASS_DOM_NM = 'Australian Emergency Care Classification Code' THEN B.WAU_ADJ_PT_RES_REMT_AREA END) AS remoteness_area_adj,
			MAX(CASE WHEN D.WAU_CLASS_DOM_NM = 'Australian Emergency Care Classification Code' THEN B.WAU_FINAL END) AS nwau_final,
		  MAX(CASE WHEN D.WAU_CLASS_DOM_NM = 'Australian Emergency Care Classification Code' THEN B.WAU_COMPENSABLE_FINAL END) AS compensable_nwau,
		  MAX(CASE WHEN D.WAU_CLASS_DOM_NM = 'Australian Emergency Care Classification Code' THEN SUBSTRING(C.WAU_VER, 5, 2) END) AS nwau_version,
		  '' AS nwau_calc_date,  '' AS snap_from_date,  '' AS snap_to_date,  '' AS snap_curr_indicator,  '' AS snap_load_date,  '' AS snap_batch_run_no,  '' AS snap_upd_batch_run_no,'' AS snap_record_status
		  ,MAX(CASE WHEN D.WAU_CLASS_DOM_NM = 'Australian Emergency Care Classification Code' THEN D.WAU_CLASS_CD END) AS AECC
		  ,MAX(RIGHT(CONCAT('00', ISNULL(CASE WHEN D.WAU_CLASS_DOM_NM = 'Emergency Department Urgency Disposition Groups (UDG) Class Code (EDW)' THEN D.WAU_CLASS_CD END, '')), 2)) AS UDG,'' AS URG,
		  MAX(CASE WHEN D.WAU_CLASS_DOM_NM = 'Emergency Department Urgency Related Group Class Code (EDW)' THEN B.URG_MDB_CD END) AS nwau_urg_mdb_value,
		  MAX(CASE WHEN D.WAU_CLASS_DOM_NM = 'Australian Emergency Care Classification Code' THEN B.NWAU_DIAG_CD END) AS nwau_urg_ed_diagnosis_mapped,
		  MAX(CASE WHEN D.WAU_CLASS_DOM_NM = 'Emergency Department Urgency Disposition Groups (UDG) Class Code (EDW)' THEN B.WAU_BASE END) AS nwau_base_UDG,
		  MAX(CASE WHEN D.WAU_CLASS_DOM_NM = 'Emergency Department Urgency Disposition Groups (UDG) Class Code (EDW)' THEN B.WAU_ADJ_INDIGENOUS END) AS indigenous_adj_UDG,
		  MAX(CASE WHEN D.WAU_CLASS_DOM_NM = 'Emergency Department Urgency Disposition Groups (UDG) Class Code (EDW)' THEN B.WAU_ADJ_PT_RES_REMT_AREA END) AS remoteness_area_adj_UDG,
		  MAX(CASE WHEN D.WAU_CLASS_DOM_NM = 'Emergency Department Urgency Disposition Groups (UDG) Class Code (EDW)' THEN B.WAU_FINAL END) AS nwau_final_UDG,
		  MAX(CASE WHEN D.WAU_CLASS_DOM_NM = 'Emergency Department Urgency Disposition Groups (UDG) Class Code (EDW)' THEN B.WAU_COMPENSABLE_FINAL END) AS compensable_nwau_UDG,
		  MAX(CASE WHEN D.WAU_CLASS_DOM_NM = 'Emergency Department Urgency Disposition Groups (UDG) Class Code (EDW)' THEN SUBSTRING(C.WAU_VER, 5, 2) END) AS nwau_version_UDG,
		  F.OSP_ID AS HLTH_ORG_OSP_OSP_ID,  F.MG_AUTH_OSP_OSP_ID,  B.SE_CBK_SK,
		  MAX(CASE WHEN D.WAU_CLASS_DOM_NM = 'Australian Emergency Care Classification Code' THEN B.WAU_ADJ_PT_TX_REMT_AREA END) AS WAU_ADJ_PT_TX_REMT_AREA
		FROM FilteredWAU as B LEFT JOIN FilteredFlat as A ON B.SE_CBK_SK = A.SE_CBK_SK INNER JOIN WAUVer as C ON B.DIM_WAU_VER_SK = C.DIM_WAU_VER_SK LEFT JOIN WAUClass as D ON B.DIM_WAU_CLASS_SK = D.DIM_WAU_CLASS_SK INNER JOIN FilteredOSP as F ON B.DIM_OSP_CREATED_SK = F.DIM_OSP_SK WHERE F.facility_identifier IN ("""
                + facilities_included
                + """) AND (F.MG_AUTH_OSP_HIE_FAC_ID = '"""
                + lhd
                + """' or F.facility_identifier='"""
                + lhd
                + """') GROUP BY F.facility_identifier, ISNULL(SUBSTRING(B.SRV_ENC_REC_ID, CHARINDEX('-', B.SRV_ENC_REC_ID) + 1, 10), ''), B.DIM_DT_SE_ST_SK,F.OSP_ID,F.MG_AUTH_OSP_OSP_ID,
		B.SE_CBK_SK;"""
            )
    retry_flag = True
    retry_count = 0
    while retry_flag and retry_count < 5:
        try:
            logging.info(query_EdNwau)
            ed_nwau = pd.read_sql(query_EdNwau, cnxn)
            retry_flag = False
        except Exception as e:
            retry_count = retry_count + 1
            time.sleep(5)
            if retry_count == 5:
                logging.exception("Exception occurred")
                label_2_status = 0
                messagebox.showerror(
                    "SQL Error", "Error extracting EdNwau details\n" + str(e)
                )
                label_2_sub.configure(text="Failed (EdNwau)...", fg="red")
                main_screen.update()
                ed_nwau = pd.DataFrame(
                    columns=[
                        "facility_identifier",
                        "ed_visit_identifier",
                        "arrival_date",
                        "nwau_type",
                        "nwau_type_value",
                        "nwau_base",
                        "indigenous_adj",
                        "remoteness_area_adj",
                        "nwau_final",
                        "compensable_nwau",
                        "nwau_version",
                        "nwau_calc_date",
                        "snap_from_date",
                        "snap_to_date",
                        "snap_curr_indicator",
                        "snap_load_date",
                        "snap_batch_run_no",
                        "snap_upd_batch_run_no",
                        "snap_record_status",
                        "AECC",
                        "UDG",
                        "URG",
                        "nwau_urg_mdb_value",
                        "nwau_urg_ed_diagnosis_mapped",
                        "nwau_base_UDG",
                        "indigenous_adj_UDG",
                        "remoteness_area_adj_UDG",
                        "nwau_final_UDG",
                        "compensable_nwau_UDG",
                        "nwau_version_UDG",
                        "HLTH_ORG_OSP_OSP_ID",
                        "MG_AUTH_OSP_OSP_ID",
                        "SE_CBK_SK",
                        "WAU_ADJ_PT_TX_REMT_AREA",
                    ]
                )
                return
        else:
            ed_nwau = ed_nwau.fillna("")
            ed_nwau = ed_nwau[
                ed_nwau["facility_identifier"].isin(facilities_included_list_global)
            ]
            ed_nwau = ed_nwau.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            ed_nwau = ed_nwau.applymap(lambda x: x.strip() if isinstance(x, str) else x)
            ed_nwau = ed_nwau.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            ed_nwau = ed_nwau.apply(
                lambda x: x.replace(regex=r"NULL", value="")
                if x.dtype == "object"
                else x
            )
            ed_nwau = ed_nwau.apply(
                lambda x: x.replace(regex=r"null", value="")
                if x.dtype == "object"
                else x
            )
            ed_nwau = ed_nwau.apply(
                lambda x: x.replace(regex=r"Null", value="")
                if x.dtype == "object"
                else x
            )
            ed_nwau = ed_nwau[
                [
                    "facility_identifier",
                    "ed_visit_identifier",
                    "arrival_date",
                    "nwau_type",
                    "nwau_type_value",
                    "nwau_base",
                    "indigenous_adj",
                    "remoteness_area_adj",
                    "nwau_final",
                    "compensable_nwau",
                    "nwau_version",
                    "nwau_calc_date",
                    "snap_from_date",
                    "snap_to_date",
                    "snap_curr_indicator",
                    "snap_load_date",
                    "snap_batch_run_no",
                    "snap_upd_batch_run_no",
                    "snap_record_status",
                    "AECC",
                    "UDG",
                    "URG",
                    "nwau_urg_mdb_value",
                    "nwau_urg_ed_diagnosis_mapped",
                    "nwau_base_UDG",
                    "indigenous_adj_UDG",
                    "remoteness_area_adj_UDG",
                    "nwau_final_UDG",
                    "compensable_nwau_UDG",
                    "nwau_version_UDG",
                    "HLTH_ORG_OSP_OSP_ID",
                    "MG_AUTH_OSP_OSP_ID",
                    "SE_CBK_SK",
                    "WAU_ADJ_PT_TX_REMT_AREA",
                ]
            ]
            # dropping duplicate values
            ed_nwau.drop_duplicates(keep="last", inplace=True)
            ed_nwau.to_csv(
                "./ExtractorDB/OutputEdNwau.csv",
                index=False,
                na_rep="",
                float_format=str,
                decimal=str,
                date_format=str,
            )
            logging.info("ed_nwau=%s", len(ed_nwau))
    # OutputAcuteNwau
    # columns = facility_identifier,stay_number,episode_sequence_number,episode_start_date,episode_end_date,nwau_base,paediatric_adj,sp_psy_age_adj,indigenous_adj,remoteness_area_adj,icu_adj,private_service_adj,private_accom_adj,nwau_final,public_equiv_nwau,compensable_nwau,nwau_version,snap_from_date,snap_to_date,snap_curr_indicator,snap_load_date,snap_batch_run_no,snap_upd_batch_run_no,snap_record_status,radiotherapy_adj
    # Access query = Append_to_tbl_episode_NWAU
    # SELECT dbo_EPISODE_NWAU.facility_identifier, dbo_EPISODE_NWAU.stay_number, dbo_EPISODE_NWAU.nwau_final, dbo_EPISODE_NWAU.episode_sequence_number, dbo_EPISODE_NWAU.nwau_base, dbo_EPISODE_NWAU.paediatric_adj, dbo_EPISODE_NWAU.icu_adj, dbo_EPISODE_NWAU.indigenous_adj, dbo_EPISODE_NWAU.private_accom_adj, dbo_EPISODE_NWAU.private_service_adj, dbo_EPISODE_NWAU.remoteness_area_adj, dbo_EPISODE_NWAU.public_equiv_nwau, dbo_EPISODE_NWAU.nwau_version, dbo_EPISODE_NWAU.snap_curr_indicator, dbo_EPISODE_NWAU.sp_psy_age_adj, dbo_EPISODE_NWAU.compensable_nwau, dbo_EPISODE_NWAU.radiotherapy_adj
    label_2_sub.configure(text="In Progress (AcuteNwau)...", fg="blue")
    main_screen.update()
    if source == "HIE":
        if len(facilities_excluded_list) == 0:
            query_AcuteNwau = (
                """SELECT dbo.EPISODE_NWAU.facility_identifier, dbo.EPISODE_NWAU.stay_number, dbo.EPISODE_NWAU.nwau_final, dbo.EPISODE_NWAU.episode_sequence_number, dbo.EPISODE_NWAU.nwau_base, dbo.EPISODE_NWAU.paediatric_adj, dbo.EPISODE_NWAU.icu_adj, dbo.EPISODE_NWAU.indigenous_adj, dbo.EPISODE_NWAU.private_accom_adj, dbo.EPISODE_NWAU.private_service_adj, dbo.EPISODE_NWAU.remoteness_area_adj, dbo.EPISODE_NWAU.public_equiv_nwau, dbo.EPISODE_NWAU.nwau_version, dbo.EPISODE_NWAU.snap_curr_indicator, dbo.EPISODE_NWAU.sp_psy_age_adj, dbo.EPISODE_NWAU.compensable_nwau, dbo.EPISODE_NWAU.radiotherapy_adj , '' as HLTH_ORG_OSP_OSP_ID, '' as MG_AUTH_OSP_OSP_ID, '' as SE_CBK_SK FROM (dbo.EPISODE_ATS INNER JOIN dbo.EPISODE_NWAU ON (dbo.EPISODE_ATS.episode_sequence_number = dbo.EPISODE_NWAU.episode_sequence_number) AND (dbo.EPISODE_ATS.stay_number = dbo.EPISODE_NWAU.stay_number) AND (dbo.EPISODE_ATS.facility_identifier = dbo.EPISODE_NWAU.facility_identifier)) INNER JOIN dbo.FACILITY ON dbo.EPISODE_ATS.facility_identifier = dbo.FACILITY.facility_identifier WHERE ((((dbo.EPISODE_NWAU.nwau_version)='"""
                + nwau_v
                + """') AND ((dbo.EPISODE_NWAU.snap_curr_indicator)='Y') AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((dbo.EPISODE_NWAU.facility_identifier)<>"D311" And (dbo.EPISODE_NWAU.facility_identifier)<>"Q230")) OR (((dbo.EPISODE_NWAU.nwau_version)='"""
                + nwau_v
                + """') AND ((dbo.EPISODE_NWAU.snap_curr_indicator)='Y') AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((dbo.EPISODE_NWAU.facility_identifier)<>"D311" And (dbo.EPISODE_NWAU.facility_identifier)<>"Q230")) OR (((dbo.EPISODE_NWAU.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_NWAU.nwau_version)='"""
                + nwau_v
                + """') AND ((dbo.EPISODE_NWAU.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y')) OR (((dbo.EPISODE_NWAU.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_NWAU.nwau_version)='"""
                + nwau_v
                + """') AND ((dbo.EPISODE_NWAU.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y')));"""
            )
        else:
            query_AcuteNwau = (
                """SELECT dbo.EPISODE_NWAU.facility_identifier, dbo.EPISODE_NWAU.stay_number, dbo.EPISODE_NWAU.nwau_final, dbo.EPISODE_NWAU.episode_sequence_number, dbo.EPISODE_NWAU.nwau_base, dbo.EPISODE_NWAU.paediatric_adj, dbo.EPISODE_NWAU.icu_adj, dbo.EPISODE_NWAU.indigenous_adj, dbo.EPISODE_NWAU.private_accom_adj, dbo.EPISODE_NWAU.private_service_adj, dbo.EPISODE_NWAU.remoteness_area_adj, dbo.EPISODE_NWAU.public_equiv_nwau, dbo.EPISODE_NWAU.nwau_version, dbo.EPISODE_NWAU.snap_curr_indicator, dbo.EPISODE_NWAU.sp_psy_age_adj, dbo.EPISODE_NWAU.compensable_nwau, dbo.EPISODE_NWAU.radiotherapy_adj , '' as HLTH_ORG_OSP_OSP_ID, '' as MG_AUTH_OSP_OSP_ID, '' as SE_CBK_SK FROM (dbo.EPISODE_ATS INNER JOIN dbo.EPISODE_NWAU ON (dbo.EPISODE_ATS.episode_sequence_number = dbo.EPISODE_NWAU.episode_sequence_number) AND (dbo.EPISODE_ATS.stay_number = dbo.EPISODE_NWAU.stay_number) AND (dbo.EPISODE_ATS.facility_identifier = dbo.EPISODE_NWAU.facility_identifier)) INNER JOIN dbo.FACILITY ON dbo.EPISODE_ATS.facility_identifier = dbo.FACILITY.facility_identifier WHERE ((((dbo.EPISODE_NWAU.nwau_version)='"""
                + nwau_v
                + """') AND ((dbo.EPISODE_NWAU.snap_curr_indicator)='Y') AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((dbo.EPISODE_NWAU.facility_identifier)<>"D311" And (dbo.EPISODE_NWAU.facility_identifier)<>"Q230")) OR (((dbo.EPISODE_NWAU.nwau_version)='"""
                + nwau_v
                + """') AND ((dbo.EPISODE_NWAU.snap_curr_indicator)='Y') AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((dbo.EPISODE_NWAU.facility_identifier)<>"D311" And (dbo.EPISODE_NWAU.facility_identifier)<>"Q230")) OR (((dbo.EPISODE_NWAU.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_NWAU.nwau_version)='"""
                + nwau_v
                + """') AND ((dbo.EPISODE_NWAU.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y')) OR (((dbo.EPISODE_NWAU.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_NWAU.nwau_version)='"""
                + nwau_v
                + """') AND ((dbo.EPISODE_NWAU.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y'))) AND dbo.FACILITY.facility_identifier NOT IN ("""
                + facilities_excluded
                + """);"""
            )
    elif source == "EDW":
        if len(facilities_included_list) > 0:
            query_AcuteNwau = (
                """SELECT DISTINCT C.facility_identifier,RIGHT(CONCAT('00000000', ISNULL(SUBSTRING(B.SRV_ENC_REC_ID,charindex('-',B.SRV_ENC_REC_ID)+1,8),'')), 8) as stay_number,B.WAU_FINAL_WITHOUT_HAC_ADJ as nwau_final,B.SEQ_AP_SE_IN_ENC as episode_sequence_number,B.WAU_BASE as nwau_base,B.WAU_ADJ_PAEDIATRIC as paediatric_adj,B.WAU_ADJ_ICU as icu_adj,B.WAU_ADJ_INDIGENOUS as indigenous_adj,B.WAU_ADJ_PRIVATE_ACCOM as private_accom_adj,B.WAU_ADJ_PRIVATE_SRV as private_service_adj,B.WAU_ADJ_PT_RES_REMT_AREA as remoteness_area_adj,B.WAU_PUBLIC_EQUIV as public_equiv_nwau,right(B.WAU_VER,2) as nwau_version,'' as snap_curr_indicator,B.WAU_ADJ_SPEC_PSYCH as sp_psy_age_adj,B.WAU_COMPENSABLE_FINAL as compensable_nwau,B.WAU_ADJ_RTHX as radiotherapy_adj,C.OSP_ID as HLTH_ORG_OSP_OSP_ID,C.MG_AUTH_OSP_OSP_ID,B.SE_CBK_SK,B.WAU_ADJ_PT_TX_REMT_AREA,B.WAU_ADJ_DIALYSIS,B.WAU_ADJ_COVID19,B.WAU_ADJ_HAC FROM CRT.v_FACT_AP_SE_WAU_FLAT as b INNER JOIN (SELECT DISTINCT DIM_OSP_SK, OSP_HIE_FAC_ID,HLTH_ORG_OSP_OSP_ID, MG_AUTH_OSP_HLTH_SECTOR_CD, HLTH_ORG_OSP_HLTH_SECTOR_CD, OSP_TYP_CD,HLTH_ORG_OSP_HIE_FAC_ID, MG_AUTH_OSP_HIE_FAC_ID, MG_AUTH_OSP_OSP_ID, case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_ID else HLTH_ORG_OSP_OSP_ID end as OSP_ID,case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_HIE_FAC_ID else HLTH_ORG_OSP_HIE_FAC_ID end as facility_identifier FROM CRT.v_DIM_OSP where ((MG_AUTH_OSP_HLTH_SECTOR_CD IN ('1','3')) and (HLTH_ORG_OSP_HLTH_SECTOR_CD IN ('1','3'))) AND HLTH_ORG_OSP_HIE_FAC_ID != '-1' AND HLTH_ORG_OSP_HIE_FAC_ID != '') AS C ON B.DIM_OSP_CREATED_SK = C.DIM_OSP_SK WHERE ((B.WAU_VER='NWAU'+'"""
                + nwau_v
                + """') AND (C.MG_AUTH_OSP_HIE_FAC_ID ='"""
                + lhd
                + """' or (C.facility_identifier)='"""
                + lhd
                + """') AND (B.DIM_DT_SE_ST_SK <= '"""
                + end_date
                + """' AND B.DIM_DT_SE_ST_SK != '1111-01-01') AND (B.DIM_DT_SE_END_SK >= '"""
                + start_date
                + """' OR B.DIM_DT_SE_END_SK is NULL OR B.DIM_DT_SE_END_SK = '1111-01-01')) AND C.facility_identifier IN ("""
                + facilities_included
                + """);"""
            )
    retry_flag = True
    retry_count = 0
    while retry_flag and retry_count < 5:
        try:
            logging.info(query_AcuteNwau)
            acute_nwau = pd.read_sql(query_AcuteNwau, cnxn)
            retry_flag = False
        except Exception as e:
            retry_count = retry_count + 1
            time.sleep(5)
            if retry_count == 5:
                logging.exception("Exception occurred")
                label_2_status = 0
                messagebox.showerror(
                    "SQL Error", "Error extracting AcuteNwau details\n" + str(e)
                )
                label_2_sub.configure(text="Failed (AcuteNwau)...", fg="red")
                main_screen.update()
                acute_nwau = pd.DataFrame(
                    columns=[
                        "facility_identifier",
                        "stay_number",
                        "nwau_final",
                        "episode_sequence_number",
                        "nwau_base",
                        "paediatric_adj",
                        "icu_adj",
                        "indigenous_adj",
                        "private_accom_adj",
                        "private_service_adj",
                        "remoteness_area_adj",
                        "public_equiv_nwau",
                        "nwau_version",
                        "snap_curr_indicator",
                        "sp_psy_age_adj",
                        "compensable_nwau",
                        "radiotherapy_adj",
                        "HLTH_ORG_OSP_OSP_ID",
                        "MG_AUTH_OSP_OSP_ID",
                        "SE_CBK_SK",
                        "WAU_ADJ_PT_TX_REMT_AREA",
                        "WAU_ADJ_DIALYSIS",
                        "WAU_ADJ_COVID19",
                        "WAU_ADJ_HAC",
                    ]
                )
                return
        else:
            acute_nwau = acute_nwau.fillna("")
            acute_nwau = acute_nwau[
                acute_nwau["facility_identifier"].isin(facilities_included_list_global)
            ]
            acute_nwau = acute_nwau.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            acute_nwau = acute_nwau.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            acute_nwau = acute_nwau.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            acute_nwau = acute_nwau.apply(
                lambda x: x.replace(regex=r"NULL", value="")
                if x.dtype == "object"
                else x
            )
            acute_nwau = acute_nwau.apply(
                lambda x: x.replace(regex=r"null", value="")
                if x.dtype == "object"
                else x
            )
            acute_nwau = acute_nwau.apply(
                lambda x: x.replace(regex=r"Null", value="")
                if x.dtype == "object"
                else x
            )
            acute_nwau["stay_number"] = (
                acute_nwau["stay_number"]
                .astype(str)
                .str.pad(8, side="left", fillchar="0")
            )
            acute_nwau["episode_sequence_number"] = (
                acute_nwau["episode_sequence_number"]
                .astype(str)
                .str.pad(3, side="left", fillchar="0")
            )
            acute_nwau = acute_nwau[
                [
                    "facility_identifier",
                    "stay_number",
                    "nwau_final",
                    "episode_sequence_number",
                    "nwau_base",
                    "paediatric_adj",
                    "icu_adj",
                    "indigenous_adj",
                    "private_accom_adj",
                    "private_service_adj",
                    "remoteness_area_adj",
                    "public_equiv_nwau",
                    "nwau_version",
                    "snap_curr_indicator",
                    "sp_psy_age_adj",
                    "compensable_nwau",
                    "radiotherapy_adj",
                    "HLTH_ORG_OSP_OSP_ID",
                    "MG_AUTH_OSP_OSP_ID",
                    "SE_CBK_SK",
                    "WAU_ADJ_PT_TX_REMT_AREA",
                    "WAU_ADJ_DIALYSIS",
                    "WAU_ADJ_COVID19",
                    "WAU_ADJ_HAC",
                ]
            ]
            # dropping duplicate values
            acute_nwau.drop_duplicates(keep="last", inplace=True)
            acute_nwau.to_csv(
                "./ExtractorDB/OutputAcuteNwau.csv",
                index=False,
                na_rep="",
                float_format=str,
                decimal=str,
                date_format=str,
            )
            logging.info("acute_nwau=%s", len(acute_nwau))
    # NWAU21_Inpatient
    # Access query: qry_NWAU21_Inpatient
    # INSERT INTO NWAU21_Inpatient ( facility_identifier, nwau_final, nwau_version, stay_number, episode_sequence_number, EncounterNumber, nwau_base, paediatric_adj, indigenous_adj, remoteness_area_adj, icu_adj, private_service_adj, private_accom_adj, public_equiv_nwau, compensable_nwau, sp_psy_age_adj, radiotherapy_adj )
    # SELECT dbo_EPISODE_ATS.facility_identifier, Round([dbo_EPISODE_NWAU]![nwau_final],4) AS nwau_final, dbo_EPISODE_NWAU.nwau_version, "SN" & Trim([dbo_EPISODE_ATS]![stay_number]) AS Expr1, dbo_EPISODE_ATS.episode_sequence_number, [dbo_EPISODE_ATS]![facility_identifier] & "-I-" & Format([dbo_EPISODE_ATS]![stay_number],"00000000") & "-" & Format([dbo_EPISODE_ATS]![episode_sequence_number],"000") AS EncounterNumber, Round([dbo_EPISODE_NWAU]![nwau_base],4) AS nwau_base, Round([dbo_EPISODE_NWAU]![paediatric_adj],4) AS paediatric_adj, Round([dbo_EPISODE_NWAU]![indigenous_adj],4) AS indigenous_adj, Round([dbo_EPISODE_NWAU]![remoteness_area_adj],4) AS remoteness_area_adj, dbo_EPISODE_NWAU.icu_adj, Round([dbo_EPISODE_NWAU]![private_service_adj]) AS private_service_adj, Round([dbo_EPISODE_NWAU]![private_accom_adj]) AS private_accom_adj, Round([dbo_EPISODE_NWAU]![public_equiv_nwau]) AS public_equiv_nwau, Round([dbo_EPISODE_NWAU]![compensable_nwau]) AS compensable_nwau, Round([dbo_EPISODE_NWAU]![sp_psy_age_adj]) AS sp_psy_age_adj, Round([dbo_EPISODE_NWAU]![radiotherapy_adj]) AS radiotherapy_adj
    # FROM dbo_EPISODE_ATS INNER JOIN dbo_EPISODE_NWAU ON (dbo_EPISODE_ATS.facility_identifier = dbo_EPISODE_NWAU.facility_identifier) AND (dbo_EPISODE_ATS.stay_number = dbo_EPISODE_NWAU.stay_number) AND (dbo_EPISODE_ATS.episode_sequence_number = dbo_EPISODE_NWAU.episode_sequence_number)
    # WHERE (((dbo_EPISODE_NWAU.nwau_version)=[Forms]![Form1]![NWAUVersion]) AND ((dbo_EPISODE_ATS.episode_start_date) Between #7/1/2022# And #6/30/2023#) AND ((dbo_EPISODE_ATS.snap_curr_indicator)="Y") AND ((dbo_EPISODE_NWAU.snap_curr_indicator)="Y")) OR (((dbo_EPISODE_NWAU.nwau_version)=[Forms]![Form1]![NWAUVersion]) AND ((dbo_EPISODE_ATS.snap_curr_indicator)="Y") AND ((dbo_EPISODE_NWAU.snap_curr_indicator)="Y") AND ((dbo_EPISODE_ATS.episode_end_date) Between #7/1/2022# And #6/30/2023#)) OR (((dbo_EPISODE_NWAU.nwau_version)=[Forms]![Form1]![NWAUVersion]) AND ((dbo_EPISODE_ATS.episode_start_date)<#7/1/2022#) AND ((dbo_EPISODE_ATS.snap_curr_indicator)="Y") AND ((dbo_EPISODE_NWAU.snap_curr_indicator)="Y") AND ((dbo_EPISODE_ATS.episode_end_date) Is Null Or (dbo_EPISODE_ATS.episode_end_date)>#6/30/2023#));
    # if str(roundid) in aecc_round_id_list_OLD:
    if str(roundid) in aecc_round_id_list:
        label_2_sub.configure(text="In Progress (NWAU Inpatient)...", fg="blue")
        main_screen.update()
        nwau21_Inpatient = acute_nwau.copy()
        nwau21_Inpatient["stay_number"] = (
            nwau21_Inpatient["stay_number"].astype(str).str.strip()
        )
        nwau21_Inpatient["episode_sequence_number"] = (
            nwau21_Inpatient["episode_sequence_number"].astype(str).str.strip()
        )
        nwau21_Inpatient["stay_number"] = (
            nwau21_Inpatient["stay_number"]
            .astype(str)
            .str.pad(8, side="left", fillchar="0")
        )
        nwau21_Inpatient["episode_sequence_number"] = (
            nwau21_Inpatient["episode_sequence_number"]
            .astype(str)
            .str.pad(3, side="left", fillchar="0")
        )
        nwau21_Inpatient["EncounterNumber"] = (
            nwau21_Inpatient["facility_identifier"].astype(str).str.strip()
            + "-I-"
            + nwau21_Inpatient["stay_number"].astype(str).str.strip()
            + "-"
            + nwau21_Inpatient["episode_sequence_number"].astype(str).str.strip()
        )
        nwau21_Inpatient["stay_number"] = (
            "SN" + nwau21_Inpatient["stay_number"].astype(str).str.strip()
        )
        nwau21_Inpatient = nwau21_Inpatient[
            [
                "facility_identifier",
                "nwau_final",
                "nwau_version",
                "stay_number",
                "episode_sequence_number",
                "EncounterNumber",
                "nwau_base",
                "paediatric_adj",
                "indigenous_adj",
                "remoteness_area_adj",
                "icu_adj",
                "private_service_adj",
                "private_accom_adj",
                "public_equiv_nwau",
                "compensable_nwau",
                "sp_psy_age_adj",
                "radiotherapy_adj",
                "HLTH_ORG_OSP_OSP_ID",
                "MG_AUTH_OSP_OSP_ID",
                "SE_CBK_SK",
            ]
        ]
    else:
        nwau21_Inpatient = pd.DataFrame(
            columns=[
                "facility_identifier",
                "nwau_final",
                "nwau_version",
                "stay_number",
                "episode_sequence_number",
                "EncounterNumber",
                "nwau_base",
                "paediatric_adj",
                "indigenous_adj",
                "remoteness_area_adj",
                "icu_adj",
                "private_service_adj",
                "private_accom_adj",
                "public_equiv_nwau",
                "compensable_nwau",
                "sp_psy_age_adj",
                "radiotherapy_adj",
                "HLTH_ORG_OSP_OSP_ID",
                "MG_AUTH_OSP_OSP_ID",
                "SE_CBK_SK",
            ]
        )
    # dropping duplicate values
    nwau21_Inpatient.drop_duplicates(keep="last", inplace=True)
    nwau21_Inpatient.to_csv(
        "./ExtractorDB/nwau21_Inpatient.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    logging.info("nwau21_Inpatient=%s", len(nwau21_Inpatient))
    # Update Sub task status
    if label_2_status == 0:
        label_2_sub.configure(text="Failed", fg="red")
        main_screen.update()
    else:
        label_2_sub.configure(text="Completed", fg="green")
        main_screen.update()
    # label_2_res.configure(text="EdNwau:"+str(len(ed_nwau))+",  AcuteNwau:"+str(len(acute_nwau))+", NWAU_Inpatient:"+str(len(nwau21_Inpatient)))
    main_screen.update()
    ######################################### EXTRACT DATA - SUB TASK 3 #######################################
    # Set default value of sub-task status to 1
    label_3_status = 1
    # OutputExcludedEncounters
    # Access query = Exclusions qry_dbo_episode_ats
    # INSERT INTO tbl_ExcludedEncounters ( facility_identifier, stay_number, episode_sequence_number, ReasonForExclusion, Ed_identifier ) SELECT dbo.EPISODE_ATS.facility_identifier, dbo.EPISODE_ATS.stay_number, dbo.EPISODE_ATS.episode_sequence_number, IIf(dbo.EPISODE_ATS.facility_identifier="D311","D311 Contracted Hospital -Episodes not Costed at patient level",IIf(dbo.EPISODE_ATS.episode_of_care_type="0","Boarders","Invalid Episode of Care Type")) AS Expr1, "XXXXXXXXXX" AS Expr2 FROM (dbo.EPISODE_ATS INNER JOIN dbo.Facility ON dbo.EPISODE_ATS.facility_identifier = dbo.Facility.facility_identifier) LEFT JOIN dbo.EPISODE ON (dbo.EPISODE_ATS.facility_identifier = dbo.EPISODE.facility_identifier) AND (dbo.EPISODE_ATS.stay_number = dbo.EPISODE.stay_number) AND (dbo.EPISODE_ATS.episode_sequence_number = dbo.EPISODE.episode_sequence_number) WHERE (((dbo.EPISODE_ATS.facility_identifier)="D311") AND ((dbo.Facility.area_identifier)='"""+lhd+"""') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""+end_date+"""') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""+start_date+"""')) OR (((dbo.EPISODE_ATS.facility_identifier)="D311") AND ((dbo.Facility.area_identifier)='"""+lhd+"""') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""+end_date+"""') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null)) OR (((dbo.EPISODE_ATS.facility_identifier)<>"D311" And (dbo.EPISODE_ATS.facility_identifier)<>"Q230") AND ((dbo.Facility.area_identifier)='"""+lhd+"""') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""+end_date+"""') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""+start_date+"""') AND ((dbo.EPISODE_ATS.episode_of_care_type)="0") AND ((dbo.EPISODE_ATS.mode_of_separation) Not In ("06","6","07","7"))) OR (((dbo.EPISODE_ATS.facility_identifier)<>"D311" And (dbo.EPISODE_ATS.facility_identifier)<>"Q230") AND ((dbo.Facility.area_identifier)='"""+lhd+"""') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""+end_date+"""') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.EPISODE_ATS.episode_of_care_type)="0") AND ((dbo.EPISODE_ATS.mode_of_separation) Not In ("06","6","07","7"))) OR (((dbo.EPISODE_ATS.facility_identifier)<>"D311" And (dbo.EPISODE_ATS.facility_identifier)<>"Q230") AND ((dbo.Facility.area_identifier)='"""+lhd+"""') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""+end_date+"""') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""+start_date+"""') AND ((dbo.EPISODE_ATS.episode_of_care_type)="" Or (dbo.EPISODE_ATS.episode_of_care_type) Is Null) AND ((dbo.EPISODE.episode_of_care_type)="" Or (dbo.EPISODE.episode_of_care_type) Is Null Or (dbo.EPISODE.episode_of_care_type)="0")) OR (((dbo.EPISODE_ATS.facility_identifier)<>"D311" And (dbo.EPISODE_ATS.facility_identifier)<>"Q230") AND ((dbo.Facility.area_identifier)='"""+lhd+"""') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""+end_date+"""') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.EPISODE_ATS.episode_of_care_type)="" Or (dbo.EPISODE_ATS.episode_of_care_type) Is Null) AND ((dbo.EPISODE.episode_of_care_type)="" Or (dbo.EPISODE.episode_of_care_type) Is Null Or (dbo.EPISODE.episode_of_care_type)="0")) OR (((dbo.EPISODE_ATS.facility_identifier)='"""+lhd+"""') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""+end_date+"""') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""+start_date+"""') AND ((dbo.EPISODE_ATS.episode_of_care_type)="0") AND ((dbo.EPISODE_ATS.mode_of_separation) Not In ("06","6","07","7"))) OR (((dbo.EPISODE_ATS.facility_identifier)='"""+lhd+"""') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""+end_date+"""') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.EPISODE_ATS.episode_of_care_type)="0") AND ((dbo.EPISODE_ATS.mode_of_separation) Not In ("06","6","07","7"))) OR (((dbo.EPISODE_ATS.facility_identifier)='"""+lhd+"""') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""+end_date+"""') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.EPISODE_ATS.episode_of_care_type)="" Or (dbo.EPISODE_ATS.episode_of_care_type) Is Null) AND ((dbo.EPISODE.episode_of_care_type)="" Or (dbo.EPISODE.episode_of_care_type) Is Null Or (dbo.EPISODE.episode_of_care_type)="0")) OR (((dbo.EPISODE_ATS.facility_identifier)='"""+lhd+"""') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""+end_date+"""') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""+start_date+"""') AND ((dbo.EPISODE_ATS.episode_of_care_type)="" Or (dbo.EPISODE_ATS.episode_of_care_type) Is Null) AND ((dbo.EPISODE.episode_of_care_type)="" Or (dbo.EPISODE.episode_of_care_type) Is Null Or (dbo.EPISODE.episode_of_care_type)="0"));
    # Original Inform8 query = SELECT dbo_EPISODE_ATS.facility_identifier, dbo_EPISODE_ATS.stay_number, dbo_EPISODE_ATS.episode_sequence_number, dbo_EPISODE_ATS.episode_of_care_type AS calculated_1 FROM dbo_EPISODE_ATS INNER JOIN dbo_FACILITY ON dbo_EPISODE_ATS.facility_identifier = dbo_FACILITY.facility_identifier
    label_3_sub.configure(text="In Progress (ExcludedEncounters)...", fg="blue")
    main_screen.update()
    if source == "HIE":
        if len(facilities_excluded_list) == 0:
            query_Excluded_EpisodeAts = (
                """SELECT dbo.EPISODE_ATS.facility_identifier, dbo.EPISODE_ATS.stay_number, dbo.EPISODE_ATS.episode_sequence_number, 'XXXXXXXXXX' AS ed_identifier, 'XXXX_XXXXXXXX' AS SNAP_encounter, 
            (CASE WHEN dbo.EPISODE_ATS.facility_identifier='D311' Then 'D311 Contracted Hospital - Episodes not Costed at patient level'
            ELSE (CASE WHEN dbo.EPISODE_ATS.episode_of_care_type='0' THEN 'Boarders' ELSE 'Invalid Episode of Care Type' END)
            END) AS ReasonForExclusion,
            (TRIM(STRING(dbo.EPISODE_ATS.facility_identifier)) + "-I-" + RIGHT(TRIM(STRING('00000000', dbo.EPISODE_ATS.stay_number)),8) + "-" + RIGHT(TRIM(STRING('000', dbo.EPISODE_ATS.episode_sequence_number)),3)) AS EncounterNumber, '' as HLTH_ORG_OSP_OSP_ID, '' as MG_AUTH_OSP_OSP_ID, '' as SE_CBK_SK
            FROM (dbo.EPISODE_ATS INNER JOIN dbo.Facility ON dbo.EPISODE_ATS.facility_identifier = dbo.Facility.facility_identifier) LEFT JOIN dbo.EPISODE ON (dbo.EPISODE_ATS.facility_identifier = dbo.EPISODE.facility_identifier) AND (dbo.EPISODE_ATS.stay_number = dbo.EPISODE.stay_number) AND (dbo.EPISODE_ATS.episode_sequence_number = dbo.EPISODE.episode_sequence_number) WHERE (((dbo.EPISODE_ATS.facility_identifier)="D311") AND ((dbo.Facility.area_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""
                + start_date
                + """')) OR (((dbo.EPISODE_ATS.facility_identifier)="D311") AND ((dbo.Facility.area_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null)) OR (((dbo.EPISODE_ATS.facility_identifier)<>"D311" And (dbo.EPISODE_ATS.facility_identifier)<>"Q230") AND ((dbo.Facility.area_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.EPISODE_ATS.episode_of_care_type)="0") AND ((dbo.EPISODE_ATS.mode_of_separation) Not In ("06","6","07","7"))) OR (((dbo.EPISODE_ATS.facility_identifier)<>"D311" And (dbo.EPISODE_ATS.facility_identifier)<>"Q230") AND ((dbo.Facility.area_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.EPISODE_ATS.episode_of_care_type)="0") AND ((dbo.EPISODE_ATS.mode_of_separation) Not In ("06","6","07","7"))) OR (((dbo.EPISODE_ATS.facility_identifier)<>"D311" And (dbo.EPISODE_ATS.facility_identifier)<>"Q230") AND ((dbo.Facility.area_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.EPISODE_ATS.episode_of_care_type)="" Or (dbo.EPISODE_ATS.episode_of_care_type) Is Null) AND ((dbo.EPISODE.episode_of_care_type)="" Or (dbo.EPISODE.episode_of_care_type) Is Null Or (dbo.EPISODE.episode_of_care_type)="0")) OR (((dbo.EPISODE_ATS.facility_identifier)<>"D311" And (dbo.EPISODE_ATS.facility_identifier)<>"Q230") AND ((dbo.Facility.area_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.EPISODE_ATS.episode_of_care_type)="" Or (dbo.EPISODE_ATS.episode_of_care_type) Is Null) AND ((dbo.EPISODE.episode_of_care_type)="" Or (dbo.EPISODE.episode_of_care_type) Is Null Or (dbo.EPISODE.episode_of_care_type)="0")) OR (((dbo.EPISODE_ATS.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.EPISODE_ATS.episode_of_care_type)="0") AND ((dbo.EPISODE_ATS.mode_of_separation) Not In ("06","6","07","7"))) OR (((dbo.EPISODE_ATS.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.EPISODE_ATS.episode_of_care_type)="0") AND ((dbo.EPISODE_ATS.mode_of_separation) Not In ("06","6","07","7"))) OR (((dbo.EPISODE_ATS.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.EPISODE_ATS.episode_of_care_type)="" Or (dbo.EPISODE_ATS.episode_of_care_type) Is Null) AND ((dbo.EPISODE.episode_of_care_type)="" Or (dbo.EPISODE.episode_of_care_type) Is Null Or (dbo.EPISODE.episode_of_care_type)="0")) OR (((dbo.EPISODE_ATS.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.EPISODE_ATS.episode_of_care_type)="" Or (dbo.EPISODE_ATS.episode_of_care_type) Is Null) AND ((dbo.EPISODE.episode_of_care_type)="" Or (dbo.EPISODE.episode_of_care_type) Is Null Or (dbo.EPISODE.episode_of_care_type)="0"));"""
            )
        else:
            query_Excluded_EpisodeAts = (
                """SELECT dbo.EPISODE_ATS.facility_identifier, dbo.EPISODE_ATS.stay_number, dbo.EPISODE_ATS.episode_sequence_number, 'XXXXXXXXXX' AS ed_identifier, 'XXXX_XXXXXXXX' AS SNAP_encounter, 
            (CASE WHEN dbo.EPISODE_ATS.facility_identifier='D311' Then 'D311 Contracted Hospital - Episodes not Costed at patient level'
            ELSE (CASE WHEN dbo.EPISODE_ATS.episode_of_care_type='0' THEN 'Boarders' ELSE 'Invalid Episode of Care Type' END)
            END) AS ReasonForExclusion,
            (TRIM(STRING(dbo.EPISODE_ATS.facility_identifier)) + "-I-" + RIGHT(TRIM(STRING('00000000', dbo.EPISODE_ATS.stay_number)),8) + "-" + RIGHT(TRIM(STRING('000', dbo.EPISODE_ATS.episode_sequence_number)),3)) AS EncounterNumber, '' as HLTH_ORG_OSP_OSP_ID, '' as MG_AUTH_OSP_OSP_ID, '' as SE_CBK_SK FROM (dbo.EPISODE_ATS INNER JOIN dbo.Facility ON dbo.EPISODE_ATS.facility_identifier = dbo.Facility.facility_identifier) LEFT JOIN dbo.EPISODE ON (dbo.EPISODE_ATS.facility_identifier = dbo.EPISODE.facility_identifier) AND (dbo.EPISODE_ATS.stay_number = dbo.EPISODE.stay_number) AND (dbo.EPISODE_ATS.episode_sequence_number = dbo.EPISODE.episode_sequence_number) WHERE (((dbo.EPISODE_ATS.facility_identifier)="D311") AND ((dbo.Facility.area_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""
                + start_date
                + """')) OR (((dbo.EPISODE_ATS.facility_identifier)="D311") AND ((dbo.Facility.area_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null)) OR (((dbo.EPISODE_ATS.facility_identifier)<>"D311" And (dbo.EPISODE_ATS.facility_identifier)<>"Q230") AND ((dbo.Facility.area_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.EPISODE_ATS.episode_of_care_type)="0") AND ((dbo.EPISODE_ATS.mode_of_separation) Not In ("06","6","07","7"))) OR (((dbo.EPISODE_ATS.facility_identifier)<>"D311" And (dbo.EPISODE_ATS.facility_identifier)<>"Q230") AND ((dbo.Facility.area_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.EPISODE_ATS.episode_of_care_type)="0") AND ((dbo.EPISODE_ATS.mode_of_separation) Not In ("06","6","07","7"))) OR (((dbo.EPISODE_ATS.facility_identifier)<>"D311" And (dbo.EPISODE_ATS.facility_identifier)<>"Q230") AND ((dbo.Facility.area_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.EPISODE_ATS.episode_of_care_type)="" Or (dbo.EPISODE_ATS.episode_of_care_type) Is Null) AND ((dbo.EPISODE.episode_of_care_type)="" Or (dbo.EPISODE.episode_of_care_type) Is Null Or (dbo.EPISODE.episode_of_care_type)="0")) OR (((dbo.EPISODE_ATS.facility_identifier)<>"D311" And (dbo.EPISODE_ATS.facility_identifier)<>"Q230") AND ((dbo.Facility.area_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.EPISODE_ATS.episode_of_care_type)="" Or (dbo.EPISODE_ATS.episode_of_care_type) Is Null) AND ((dbo.EPISODE.episode_of_care_type)="" Or (dbo.EPISODE.episode_of_care_type) Is Null Or (dbo.EPISODE.episode_of_care_type)="0")) OR (((dbo.EPISODE_ATS.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.EPISODE_ATS.episode_of_care_type)="0") AND ((dbo.EPISODE_ATS.mode_of_separation) Not In ("06","6","07","7"))) OR (((dbo.EPISODE_ATS.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.EPISODE_ATS.episode_of_care_type)="0") AND ((dbo.EPISODE_ATS.mode_of_separation) Not In ("06","6","07","7"))) OR (((dbo.EPISODE_ATS.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.EPISODE_ATS.episode_of_care_type)="" Or (dbo.EPISODE_ATS.episode_of_care_type) Is Null) AND ((dbo.EPISODE.episode_of_care_type)="" Or (dbo.EPISODE.episode_of_care_type) Is Null Or (dbo.EPISODE.episode_of_care_type)="0")) OR (((dbo.EPISODE_ATS.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.EPISODE_ATS.episode_of_care_type)="" Or (dbo.EPISODE_ATS.episode_of_care_type) Is Null) AND ((dbo.EPISODE.episode_of_care_type)="" Or (dbo.EPISODE.episode_of_care_type) Is Null Or (dbo.EPISODE.episode_of_care_type)="0")) AND dbo.FACILITY.facility_identifier NOT IN ("""
                + facilities_excluded
                + """);"""
            )
    elif source == "EDW":
        if len(facilities_included_list) > 0:
            query_Excluded_EpisodeAts = (
                """SELECT DISTINCT C.facility_identifier, RIGHT(CONCAT('00000000', ISNULL(SUBSTRING(a.SRV_ENC_REC_ID,charindex('-',a.SRV_ENC_REC_ID)+1,8),'')), 8) as stay_number,A.SEQ_AP_SE_IN_ENC as episode_sequence_number, 'XXXXXXXXXX' as ed_identifier, 'XXXX_XXXXXXXX' as SNAP_encounter, (CASE WHEN (C.facility_identifier)='D311' Then 'D311 Contracted Hospital - Episodes NOT Costed at patient level' ELSE (CASE WHEN A.SE_SRV_CATEGORY_CD = '0' THEN 'Boarders' ELSE 'Invalid Episode of Care Type' END) END) as ReasonForExclusion, (TRIM(C.facility_identifier) + '-I-' + RIGHT(CONCAT('00000000', ISNULL(SUBSTRING(a.SRV_ENC_REC_ID,charindex('-',a.SRV_ENC_REC_ID)+1,8),'')), 8)+ '-' + RIGHT(CONCAT('000', ISNULL(TRIM(cast(A.SEQ_AP_SE_IN_ENC as varchar)),'')),3)) as 
			EncounterNumber,C.OSP_ID as HLTH_ORG_OSP_OSP_ID,C.MG_AUTH_OSP_OSP_ID,A.SE_CBK_SK FROM CRT.V_FACT_AP_SE_FLAT as a INNER JOIN (SELECT DISTINCT DIM_OSP_SK, OSP_HIE_FAC_ID,HLTH_ORG_OSP_OSP_ID, MG_AUTH_OSP_HLTH_SECTOR_CD, HLTH_ORG_OSP_HLTH_SECTOR_CD, OSP_TYP_CD,HLTH_ORG_OSP_HIE_FAC_ID, MG_AUTH_OSP_HIE_FAC_ID, MG_AUTH_OSP_OSP_ID,case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_ID else HLTH_ORG_OSP_OSP_ID end as OSP_ID,case when OSP_TYP_CD in ('35.01', '35.02', '35.03', 
			'35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_HIE_FAC_ID else HLTH_ORG_OSP_HIE_FAC_ID end as facility_identifier FROM CRT.v_DIM_OSP where ((MG_AUTH_OSP_HLTH_SECTOR_CD IN ('1','3')) and (HLTH_ORG_OSP_HLTH_SECTOR_CD IN ('1','3'))) AND HLTH_ORG_OSP_HIE_FAC_ID != '-1' AND HLTH_ORG_OSP_HIE_FAC_ID != '') AS C ON A.DIM_OSP_CREATED_SK = C.DIM_OSP_SK WHERE (((C.MG_AUTH_OSP_HIE_FAC_ID='"""
                + lhd
                + """' OR (C.facility_identifier)='"""
                + lhd
                + """') AND (CAST(A.SE_ST_DTTM as date) <= '"""
                + end_date
                + """') AND (CAST(A.SE_END_DTTM as date) >= '"""
                + start_date
                + """' OR A.SE_END_DTTM is NULL) AND (A.SE_SRV_CATEGORY_CD = '0') AND (A.SE_SEP_MODE_NHDD_CD Not In ('8','80'))) OR ((C.MG_AUTH_OSP_HIE_FAC_ID='"""
                + lhd
                + """' OR (C.facility_identifier)='"""
                + lhd
                + """') AND (CAST(A.SE_ST_DTTM as date) <= '"""
                + end_date
                + """') AND (CAST(A.SE_END_DTTM as date) >= '"""
                + start_date
                + """' OR A.SE_END_DTTM 
			is NULL) AND (A.SE_SRV_CATEGORY_CD=''))) AND (C.facility_identifier) IN ("""
                + facilities_included
                + """);"""
            )
    retry_flag = True
    retry_count = 0
    while retry_flag and retry_count < 5:
        try:
            logging.info(query_Excluded_EpisodeAts)
            df_Excluded_EpisodeAts = pd.read_sql(query_Excluded_EpisodeAts, cnxn)
            retry_flag = False
        except Exception as e:
            retry_count = retry_count + 1
            time.sleep(5)
            if retry_count == 5:
                logging.exception("Exception occurred")
                label_3_status = 0
                messagebox.showerror(
                    "SQL Error",
                    "Error extracting Exclusions EPISODE_ATS details\n" + str(e),
                )
                label_3_sub.configure(
                    text="Failed (Exclusions EPISODE_ATS)...", fg="red"
                )
                main_screen.update()
                df_Excluded_EpisodeAts = pd.DataFrame(
                    columns=[
                        "facility_identifier",
                        "stay_number",
                        "episode_sequence_number",
                        "ed_identifier",
                        "SNAP_encounter",
                        "ReasonForExclusion",
                        "EncounterNumber",
                        "HLTH_ORG_OSP_OSP_ID",
                        "MG_AUTH_OSP_OSP_ID",
                        "SE_CBK_SK",
                    ]
                )
                return  # stop extraction
        else:
            df_Excluded_EpisodeAts = df_Excluded_EpisodeAts.fillna("")
            df_Excluded_EpisodeAts = df_Excluded_EpisodeAts[
                [
                    "facility_identifier",
                    "stay_number",
                    "episode_sequence_number",
                    "ed_identifier",
                    "SNAP_encounter",
                    "ReasonForExclusion",
                    "EncounterNumber",
                    "HLTH_ORG_OSP_OSP_ID",
                    "MG_AUTH_OSP_OSP_ID",
                    "SE_CBK_SK",
                ]
            ]
            df_Excluded_EpisodeAts = df_Excluded_EpisodeAts[
                df_Excluded_EpisodeAts["facility_identifier"].isin(
                    facilities_included_list_global
                )
            ]
            df_Excluded_EpisodeAts = df_Excluded_EpisodeAts.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            df_Excluded_EpisodeAts = df_Excluded_EpisodeAts.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            df_Excluded_EpisodeAts = df_Excluded_EpisodeAts.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            df_Excluded_EpisodeAts = df_Excluded_EpisodeAts.apply(
                lambda x: x.replace(regex=r"NULL", value="")
                if x.dtype == "object"
                else x
            )
            df_Excluded_EpisodeAts = df_Excluded_EpisodeAts.apply(
                lambda x: x.replace(regex=r"null", value="")
                if x.dtype == "object"
                else x
            )
            df_Excluded_EpisodeAts = df_Excluded_EpisodeAts.apply(
                lambda x: x.replace(regex=r"Null", value="")
                if x.dtype == "object"
                else x
            )
            df_Excluded_EpisodeAts["stay_number"] = (
                df_Excluded_EpisodeAts["stay_number"]
                .astype(str)
                .str.pad(8, side="left", fillchar="0")
            )
            df_Excluded_EpisodeAts["episode_sequence_number"] = (
                df_Excluded_EpisodeAts["episode_sequence_number"]
                .astype(str)
                .str.pad(3, side="left", fillchar="0")
            )
            # dropping duplicate values
            df_Excluded_EpisodeAts.drop_duplicates(keep="last", inplace=True)
            # Badari had converted an old version of HIE query to EDW. As a result all episodes in OutputEpisodeAts would also come under the Excluded Episode ATS dataset
            # Therefore, I am deleting all records in EDW query resultset until the issue is fixed in a future release. See above for updated EDW query.
            """
            if source == "EDW":
                df_Excluded_EpisodeAts = pd.DataFrame(columns=['facility_identifier', 'stay_number', 'episode_sequence_number', 'ed_identifier', 'SNAP_encounter', 'ReasonForExclusion', 'EncounterNumber', 'HLTH_ORG_OSP_OSP_ID', 'MG_AUTH_OSP_OSP_ID', 'SE_CBK_SK']) 
            """
            df_Excluded_EpisodeAts.to_csv(
                "./ExtractorDB/OutputExcluded_EpisodeAts.csv",
                index=False,
                na_rep="",
                float_format=str,
                decimal=str,
                date_format=str,
            )  # Concatenate later with ED Excluded Encounters
            logging.info("df_Excluded_EpisodeAts=%s", len(df_Excluded_EpisodeAts))
    # OutputEpisodeAts
    # columns = facility_identifier,stay_number,episode_sequence_number,person_identifier,episode_start_date,episode_end_date,mo_code2,episode_of_care_type,an_drg,major_diagnostic_category,mode_of_separation,source_of_referral,financial_program,episode_leave_days_total,episode_length_of_stay,first_psych_admission_flag,days_in_psych_unit,hours_in_psych_unit,hours_in_icu,place_of_occurrence,external_cause_code_1,external_cause_code_2,unplanned_theatre,palliative_care_status,unqual_baby_bed_days,unqualified_bed_days,unqualified_bed_time,qualified_bed_days,qualified_bed_time,legal_status_on_admit,pension_status,payment_status_on_sep,unit_type_on_admission,mrn,practice_identifier1,practice_identifier2,snap_upd_batch_run_no,clinical_codeset_1,clinical_codeset_2,clinical_codeset_3,an_drg_orig,an_drg_orig_version,mdc_orig,an_drg_orig_return_cd,an_drg_orig_pccl,external_cause_code_3,an_drg_version,episode_create_date,episode_update_date,involuntary_days_in_psych,episode_sequence_number_ats,episode_start_time,episode_end_time,financial_class,financial_class_local,source_system,upd_source_system,infant_start_weight,hours_on_mech_ventilation,hours_on_mech_vent_num,drg_mode_of_separation,drg_mhealth_legal_status,an_drg_current,an_drg_current_version,mdc_current,an_drg_current_return_cd,an_drg_current_pccl,financial_sub_program,episode_day_stay_los,clinical_coding_audit,clinical_coding_audit_date,area_identifier,area_code,facility_type,mo_code1,getdate,WIP
    # Access query = qry_dbo_episode_ats
    # SELECT dbo_EPISODE_ATS.facility_identifier, dbo_EPISODE_ATS.stay_number, dbo_EPISODE_ATS.episode_sequence_number, dbo_EPISODE_ATS.person_identifier, dbo_EPISODE_ATS.episode_start_date, dbo_EPISODE_ATS.episode_end_date, dbo_EPISODE_ATS.mo_code1, dbo_EPISODE_ATS.mo_code2, dbo_EPISODE_ATS.episode_of_care_type, dbo_EPISODE_ATS.mode_of_separation, dbo_EPISODE_ATS.source_of_referral, dbo_EPISODE_ATS.episode_leave_days_total, dbo_EPISODE_ATS.episode_length_of_stay, dbo_EPISODE_ATS.days_in_psych_unit, dbo_EPISODE_ATS.hours_in_psych_unit, dbo_EPISODE_ATS.hours_in_icu, dbo_EPISODE_ATS.unplanned_theatre, dbo_EPISODE_ATS.unqualified_bed_days, dbo_EPISODE_ATS.qualified_bed_days, dbo_EPISODE_ATS.legal_status_on_admit, dbo_EPISODE_ATS.payment_status_on_sep, dbo_EPISODE_ATS.mrn, dbo_EPISODE_ATS.episode_start_time, dbo_EPISODE_ATS.episode_end_time, dbo_EPISODE_ATS.financial_class, dbo_EPISODE_ATS.infant_start_weight, dbo_EPISODE_ATS.hours_on_mech_vent_num, dbo_EPISODE_ATS.drg_mode_of_separation, dbo_FACILITY.area_identifier, dbo_FACILITY.facility_type, dbo_EPISODE_ATS.financial_program, Now() AS Expr1, dbo_EPISODE_ATS.qualified_bed_time
    label_3_sub.configure(text="In Progress (EpisodeAts)...", fg="blue")
    main_screen.update()
    # In query_EpisodeAts, I changed dbo.EPISODE_ATS.episode_start_date (& episode_end_date) to select cast(episode_start_date as date) AS episode_start_date;
    if source == "HIE":
        if len(facilities_excluded_list) == 0:
            # cast(dbo.EPISODE_ATS.episode_start_date as date) AS episode_start_date, cast(dbo.EPISODE_ATS.episode_end_date as date) AS episode_end_date,
            query_EpisodeAts = (
                """SELECT dbo.EPISODE_ATS.facility_identifier, dbo.EPISODE_ATS.stay_number, dbo.EPISODE_ATS.episode_sequence_number, dbo.EPISODE_ATS.person_identifier, dbo.EPISODE_ATS.episode_start_date, dbo.EPISODE_ATS.episode_end_date, dbo.EPISODE_ATS.mo_code2, dbo.EPISODE_ATS.episode_of_care_type, dbo.EPISODE_ATS.an_drg, dbo.EPISODE_ATS.major_diagnostic_category, dbo.EPISODE_ATS.mode_of_separation, dbo.EPISODE_ATS.source_of_referral, dbo.EPISODE_ATS.financial_program, dbo.EPISODE_ATS.episode_leave_days_total, dbo.EPISODE_ATS.episode_length_of_stay, dbo.EPISODE_ATS.first_psych_admission_flag, dbo.EPISODE_ATS.days_in_psych_unit, dbo.EPISODE_ATS.hours_in_psych_unit, dbo.EPISODE_ATS.hours_in_icu, dbo.EPISODE_ATS.place_of_occurrence, dbo.EPISODE_ATS.external_cause_code_1, dbo.EPISODE_ATS.external_cause_code_2, dbo.EPISODE_ATS.unplanned_theatre, dbo.EPISODE_ATS.palliative_care_status, dbo.EPISODE_ATS.unqual_baby_bed_days, dbo.EPISODE_ATS.unqualified_bed_days, dbo.EPISODE_ATS.unqualified_bed_time, dbo.EPISODE_ATS.qualified_bed_days, dbo.EPISODE_ATS.qualified_bed_time, dbo.EPISODE_ATS.legal_status_on_admit, dbo.EPISODE_ATS.pension_status, dbo.EPISODE_ATS.payment_status_on_sep, dbo.EPISODE_ATS.unit_type_on_admission, dbo.EPISODE_ATS.mrn, dbo.EPISODE_ATS.practice_identifier1, dbo.EPISODE_ATS.practice_identifier2, dbo.EPISODE_ATS.snap_upd_batch_run_no, dbo.EPISODE_ATS.clinical_codeset_1, dbo.EPISODE_ATS.clinical_codeset_2, dbo.EPISODE_ATS.clinical_codeset_3, dbo.EPISODE_ATS.an_drg_orig, dbo.EPISODE_ATS.an_drg_orig_version, dbo.EPISODE_ATS.mdc_orig, dbo.EPISODE_ATS.an_drg_orig_return_cd, dbo.EPISODE_ATS.an_drg_orig_pccl, dbo.EPISODE_ATS.external_cause_code_3, dbo.EPISODE_ATS.an_drg_version, dbo.EPISODE_ATS.episode_create_date, dbo.EPISODE_ATS.episode_update_date, dbo.EPISODE_ATS.involuntary_days_in_psych, dbo.EPISODE_ATS.episode_sequence_number_ats, dbo.EPISODE_ATS.episode_start_time, dbo.EPISODE_ATS.episode_end_time, dbo.EPISODE_ATS.financial_class, dbo.EPISODE_ATS.financial_class_local, dbo.EPISODE_ATS.source_system, dbo.EPISODE_ATS.upd_source_system, dbo.EPISODE_ATS.infant_start_weight, dbo.EPISODE_ATS.hours_on_mech_ventilation, dbo.EPISODE_ATS.hours_on_mech_vent_num, dbo.EPISODE_ATS.drg_mode_of_separation, dbo.EPISODE_ATS.drg_mhealth_legal_status, dbo.EPISODE_ATS.an_drg_current, dbo.EPISODE_ATS.an_drg_current_version, dbo.EPISODE_ATS.mdc_current, dbo.EPISODE_ATS.an_drg_current_return_cd, dbo.EPISODE_ATS.an_drg_current_pccl, dbo.EPISODE_ATS.financial_sub_program, dbo.EPISODE_ATS.episode_day_stay_los, dbo.EPISODE_ATS.clinical_coding_audit, dbo.EPISODE_ATS.clinical_coding_audit_date,
            dbo.FACILITY.area_identifier, '' AS area_code, dbo.FACILITY.facility_type, dbo.EPISODE_ATS.mo_code1, DATEFORMAT(now(), 'YYYY-MM-DD HH:NN:SS') AS getdate, 
            (case when dbo.EPISODE_ATS.episode_end_date Is Null And date(dbo.EPISODE_ATS.episode_start_date)<CAST('"""
                + start_date
                + """' AS DATE ) then 3
            when dbo.EPISODE_ATS.episode_end_date Is Null then 2
            when date(dbo.EPISODE_ATS.episode_start_date)<CAST('"""
                + start_date
                + """' AS DATE) And date(dbo.EPISODE_ATS.episode_end_date)<(CAST('"""
                + end_date
                + """' AS DATE )+1) then 1
            when date(dbo.EPISODE_ATS.episode_start_date)>=CAST('"""
                + start_date
                + """' AS DATE ) And date(dbo.EPISODE_ATS.episode_end_date)>=(CAST('"""
                + end_date
                + """' AS DATE )+1) then 2
            when date(dbo.EPISODE_ATS.episode_start_date)<CAST('"""
                + start_date
                + """' AS DATE ) And date(dbo.EPISODE_ATS.episode_end_date)>=CAST('"""
                + end_date
                + """' AS DATE ) then 3 
            else 4 end) AS WIP, '' as HLTH_ORG_OSP_OSP_ID, '' as MG_AUTH_OSP_OSP_ID, '' as SE_CBK_SK, '' as CL_ID_EUID, '' as CL_ID_IHI, '' as HLTH_ORG_OSP_TYP,'' as ICU1_Hours, '' as ICU2_Hours, '' as ICU_Hours, '' as CCU_Hours, '' as HDU_Hours, '' as NICU_Hours
            FROM dbo.EPISODE_ATS INNER JOIN dbo.FACILITY ON dbo.EPISODE_ATS.facility_identifier = dbo.FACILITY.facility_identifier WHERE (((dbo.EPISODE_ATS.facility_identifier)<>"D311" And (dbo.EPISODE_ATS.facility_identifier)<>"Q230") AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_ATS.snap_curr_indicator)="Y") AND ((dbo.FACILITY.snap_curr_indicator)="Y")) OR (((dbo.EPISODE_ATS.facility_identifier)<>"D311" And (dbo.EPISODE_ATS.facility_identifier)<>"Q230") AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_ATS.snap_curr_indicator)="Y") AND ((dbo.FACILITY.snap_curr_indicator)="Y")) OR (((dbo.EPISODE_ATS.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.EPISODE_ATS.snap_curr_indicator)="Y") AND ((dbo.FACILITY.snap_curr_indicator)="Y")) OR (((dbo.EPISODE_ATS.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.EPISODE_ATS.snap_curr_indicator)="Y") AND ((dbo.FACILITY.snap_curr_indicator)="Y"));"""
            )
        else:
            query_EpisodeAts = (
                """SELECT dbo.EPISODE_ATS.facility_identifier, dbo.EPISODE_ATS.stay_number, dbo.EPISODE_ATS.episode_sequence_number, dbo.EPISODE_ATS.person_identifier, dbo.EPISODE_ATS.episode_start_date, dbo.EPISODE_ATS.episode_end_date, dbo.EPISODE_ATS.mo_code2, dbo.EPISODE_ATS.episode_of_care_type, dbo.EPISODE_ATS.an_drg, dbo.EPISODE_ATS.major_diagnostic_category, dbo.EPISODE_ATS.mode_of_separation, dbo.EPISODE_ATS.source_of_referral, dbo.EPISODE_ATS.financial_program, dbo.EPISODE_ATS.episode_leave_days_total, dbo.EPISODE_ATS.episode_length_of_stay, dbo.EPISODE_ATS.first_psych_admission_flag, dbo.EPISODE_ATS.days_in_psych_unit, dbo.EPISODE_ATS.hours_in_psych_unit, dbo.EPISODE_ATS.hours_in_icu, dbo.EPISODE_ATS.place_of_occurrence, dbo.EPISODE_ATS.external_cause_code_1, dbo.EPISODE_ATS.external_cause_code_2, dbo.EPISODE_ATS.unplanned_theatre, dbo.EPISODE_ATS.palliative_care_status, dbo.EPISODE_ATS.unqual_baby_bed_days, dbo.EPISODE_ATS.unqualified_bed_days, dbo.EPISODE_ATS.unqualified_bed_time, dbo.EPISODE_ATS.qualified_bed_days, dbo.EPISODE_ATS.qualified_bed_time, dbo.EPISODE_ATS.legal_status_on_admit, dbo.EPISODE_ATS.pension_status, dbo.EPISODE_ATS.payment_status_on_sep, dbo.EPISODE_ATS.unit_type_on_admission, dbo.EPISODE_ATS.mrn, dbo.EPISODE_ATS.practice_identifier1, dbo.EPISODE_ATS.practice_identifier2, dbo.EPISODE_ATS.snap_upd_batch_run_no, dbo.EPISODE_ATS.clinical_codeset_1, dbo.EPISODE_ATS.clinical_codeset_2, dbo.EPISODE_ATS.clinical_codeset_3, dbo.EPISODE_ATS.an_drg_orig, dbo.EPISODE_ATS.an_drg_orig_version, dbo.EPISODE_ATS.mdc_orig, dbo.EPISODE_ATS.an_drg_orig_return_cd, dbo.EPISODE_ATS.an_drg_orig_pccl, dbo.EPISODE_ATS.external_cause_code_3, dbo.EPISODE_ATS.an_drg_version, dbo.EPISODE_ATS.episode_create_date, dbo.EPISODE_ATS.episode_update_date, dbo.EPISODE_ATS.involuntary_days_in_psych, dbo.EPISODE_ATS.episode_sequence_number_ats, dbo.EPISODE_ATS.episode_start_time, dbo.EPISODE_ATS.episode_end_time, dbo.EPISODE_ATS.financial_class, dbo.EPISODE_ATS.financial_class_local, dbo.EPISODE_ATS.source_system, dbo.EPISODE_ATS.upd_source_system, dbo.EPISODE_ATS.infant_start_weight, dbo.EPISODE_ATS.hours_on_mech_ventilation, dbo.EPISODE_ATS.hours_on_mech_vent_num, dbo.EPISODE_ATS.drg_mode_of_separation, dbo.EPISODE_ATS.drg_mhealth_legal_status, dbo.EPISODE_ATS.an_drg_current, dbo.EPISODE_ATS.an_drg_current_version, dbo.EPISODE_ATS.mdc_current, dbo.EPISODE_ATS.an_drg_current_return_cd, dbo.EPISODE_ATS.an_drg_current_pccl, dbo.EPISODE_ATS.financial_sub_program, dbo.EPISODE_ATS.episode_day_stay_los, dbo.EPISODE_ATS.clinical_coding_audit, dbo.EPISODE_ATS.clinical_coding_audit_date,
            dbo.FACILITY.area_identifier, '' AS area_code, dbo.FACILITY.facility_type, dbo.EPISODE_ATS.mo_code1, DATEFORMAT(now(), 'YYYY-MM-DD HH:NN:SS') AS getdate, 
            (case when dbo.EPISODE_ATS.episode_end_date Is Null And date(dbo.EPISODE_ATS.episode_start_date)<CAST('"""
                + start_date
                + """' AS DATE ) then 3
            when dbo.EPISODE_ATS.episode_end_date Is Null then 2
            when date(dbo.EPISODE_ATS.episode_start_date)<CAST('"""
                + start_date
                + """' AS DATE) And date(dbo.EPISODE_ATS.episode_end_date)<(CAST('"""
                + end_date
                + """' AS DATE )+1) then 1
            when date(dbo.EPISODE_ATS.episode_start_date)>=CAST('"""
                + start_date
                + """' AS DATE ) And date(dbo.EPISODE_ATS.episode_end_date)>=(CAST('"""
                + end_date
                + """' AS DATE )+1) then 2
            when date(dbo.EPISODE_ATS.episode_start_date)<CAST('"""
                + start_date
                + """' AS DATE ) And date(dbo.EPISODE_ATS.episode_end_date)>=CAST('"""
                + end_date
                + """' AS DATE ) then 3 
            else 4 end) AS WIP, '' as HLTH_ORG_OSP_OSP_ID, '' as MG_AUTH_OSP_OSP_ID, '' as SE_CBK_SK, '' as CL_ID_EUID, '' as CL_ID_IHI, '' as HLTH_ORG_OSP_TYP,'' as ICU1_Hours, '' as ICU2_Hours, '' as ICU_Hours, '' as CCU_Hours, '' as HDU_Hours, '' as NICU_Hours
            FROM dbo.EPISODE_ATS INNER JOIN dbo.FACILITY ON dbo.EPISODE_ATS.facility_identifier = dbo.FACILITY.facility_identifier WHERE ((((dbo.EPISODE_ATS.facility_identifier)<>"D311" And (dbo.EPISODE_ATS.facility_identifier)<>"Q230") AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_ATS.snap_curr_indicator)="Y") AND ((dbo.FACILITY.snap_curr_indicator)="Y")) OR (((dbo.EPISODE_ATS.facility_identifier)<>"D311" And (dbo.EPISODE_ATS.facility_identifier)<>"Q230") AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_ATS.snap_curr_indicator)="Y") AND ((dbo.FACILITY.snap_curr_indicator)="Y")) OR (((dbo.EPISODE_ATS.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.EPISODE_ATS.snap_curr_indicator)="Y") AND ((dbo.FACILITY.snap_curr_indicator)="Y")) OR (((dbo.EPISODE_ATS.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.EPISODE_ATS.snap_curr_indicator)="Y") AND ((dbo.FACILITY.snap_curr_indicator)="Y"))) AND dbo.FACILITY.facility_identifier NOT IN ("""
                + facilities_excluded
                + """);"""
            )
    elif source == "EDW":
        if len(facilities_included_list) > 0:
            query_EpisodeAts = (
                """SELECT DISTINCT k.facility_identifier,RIGHT(CONCAT('00000000', ISNULL(SUBSTRING(A.SRV_ENC_REC_ID,charindex('-',A.SRV_ENC_REC_ID)+1,8),'')), 8) as stay_number,a.SEQ_AP_SE_IN_ENC as episode_sequence_number,case when A.CL_ID_MASKED = 'Unknown/Invalid' then A.CL_ID_MASKED else RIGHT(CONCAT('0000000000', ISNULL(TRIM(A.CL_ID_MASKED),'')),10) end as person_identifier,CAST(a.SE_ST_DTTM as date) as episode_start_date,CAST(a.SE_END_DTTM as date) as episode_end_date,H.mo_code2 as mo_code2,a.SE_SRV_CATEGORY_CD as episode_of_care_type,'' as an_drg,'' as major_diagnostic_category, case when a.SE_SEP_MODE_NHDD_CD = '50' then a.SE_SEP_MODE_NHDD_CD else A.FRML_DISCH_MODE_CD end as mode_of_separation,a.SE_REQ_SRC_TYP_CD as source_of_referral,'' as financial_program,a.CT_TOT_SE_LEAVE_D_CT as episode_leave_days_total,a.CT_TOT_SE_BED_D_CT as episode_length_of_stay,'' as first_psych_admission_flag,a.CT_TOT_SE_PSYC_BED_D_CT as days_in_psych_unit,cast(ROUND(a.CT_TOT_SE_PSYC_BED_HRS,0) as int) as hours_in_psych_unit,cast(ROUND(a.CT_TOT_SE_ICU_HRS,0) as int) as hours_in_icu,'' as place_of_occurrence,'' as external_cause_code_1,'' as external_cause_code_2,G.SE_UNPLAN_RETURN_TH_FG as unplanned_theatre,'' as palliative_care_status,a.CT_TOT_SE_UNQUAL_D_CT as unqual_baby_bed_days,a.CT_TOT_SE_UNQUAL_D_CT as unqualified_bed_days,cast(round(a.CT_TOT_SE_UNQUAL_HRS *60,0) as int) as unqualified_bed_time,a.CT_TOT_SE_QUAL_D_CT as qualified_bed_days,cast(round(a.CT_TOT_SE_QUAL_HRS * 60,0) as int) as qualified_bed_time,a.FST_LGL_STAT_CD as legal_status_on_admit,'' as pension_status,L.LST_PAY_STAT_ON_SEP_CD as payment_status_on_sep,a.BED_TYP_CD as unit_type_on_admission,case when A.CL_ID in ('-1','Unknown/Invalid','') then A.CL_ID when len(A.CL_ID) > 10 then right(A.CL_ID,10) when len(A.CL_ID) < 10 then RIGHT(CONCAT('0000000000', ISNULL(TRIM(A.CL_ID),'')),10) else '' end as mrn,'' as practice_identifier1,'' as practice_identifier2,0 as snap_upd_batch_run_no,'' as clinical_codeset_1,'' as clinical_codeset_2,'' as clinical_codeset_3,'' as an_drg_orig,'' as an_drg_orig_version,'' as mdc_orig,''  as an_drg_orig_return_cd,'' as an_drg_orig_pccl,'' as external_cause_code_3,'' as an_drg_version,NULL as episode_create_date,NULL as episode_update_date,a.CT_TOT_SE_INVOL_MH_D_CT as involuntary_days_in_psych,a.SEQ_SE_IN_ENC as episode_sequence_number_ats,CAST(a.SE_ST_DTTM as time(0)) as episode_start_time,CAST(a.SE_END_DTTM as time(0)) as episode_end_time,a.LST_FIN_CLASS_CD as financial_class,'' as financial_class_local,a.SRC_SYSTEM_CD as source_system,'' as upd_source_system,REPLICATE('0', 4 - LEN(CAST(F.WGT_AT_SE_ST_GMS AS VARCHAR))) + CAST(F.WGT_AT_SE_ST_GMS AS VARCHAR) as infant_start_weight,REPLICATE('0', 4 - LEN(CAST(A.CT_TOT_SE_MECH_VENT_HRS AS VARCHAR))) + CAST(A.CT_TOT_SE_MECH_VENT_HRS AS VARCHAR) as hours_on_mech_ventilation,a.CT_TOT_SE_MECH_VENT_HRS as hours_on_mech_vent_num,case when a.SE_SEP_MODE_NHDD_CD = '-1' then a.SE_SEP_MODE_NHDD_CD else RIGHT(CONCAT('00',ISNULL(a.SE_SEP_MODE_NHDD_CD,'')),2) end as drg_mode_of_separation,a.SE_MH_LGL_STAT_NHDD_CD as drg_mhealth_legal_status,'' as an_drg_current,'' as an_drg_current_version,'' as mdc_current,'' as an_drg_current_return_cd,'' as an_drg_current_pccl,a.FST_HS_MH_SUB_PRGM_CD as financial_sub_program,a.CT_TOT_SE_DAYS as episode_day_stay_los,'' as clinical_coding_audit,NULL as clinical_coding_audit_date,K.MG_AUTH_OSP_HIE_FAC_ID as area_identifier, '' AS area_code,k.facility_type
			,H.mo_code1 as mo_code1,format(getdate(),'dd-MM-yyyy hh:mm:ss') as getdate,(CASE WHEN (a.DIM_DT_SE_END_SK Is Null or a.DIM_DT_SE_END_SK = '1111-01-01') AND (A.DIM_DT_SE_ST_SK < '"""
                + start_date
                + """' AND A.DIM_DT_SE_ST_SK !='1111-01-01') THEN 3
		    WHEN (a.DIM_DT_SE_END_SK Is Null or a.DIM_DT_SE_END_SK = '1111-01-01') THEN 2
		    WHEN (A.DIM_DT_SE_ST_SK < '"""
                + start_date
                + """' AND A.DIM_DT_SE_ST_SK !='1111-01-01') AND A.DIM_DT_SE_END_SK < dateadd(dd,1,'"""
                + end_date
                + """') THEN 1
		    WHEN (A.DIM_DT_SE_ST_SK >='"""
                + start_date
                + """' AND A.DIM_DT_SE_ST_SK !='1111-01-01') AND A.DIM_DT_SE_END_SK >=dateadd(dd,1,'"""
                + end_date
                + """') THEN 2
		    WHEN (A.DIM_DT_SE_ST_SK < '"""
                + start_date
                + """' AND A.DIM_DT_SE_ST_SK !='1111-01-01') AND A.DIM_DT_SE_END_SK >= '"""
                + end_date
                + """' THEN 3 
		    ELSE 4 end) AS WIP,K.OSP_ID as HLTH_ORG_OSP_OSP_ID,K.MG_AUTH_OSP_OSP_ID,A.SE_CBK_SK,A.CL_ID_EUID,A.CL_ID_IHI,K.HLTH_ORG_OSP_TYP_mod as HLTH_ORG_OSP_TYP,A.CT_TOT_SE_ICU1_HRS as ICU1_Hours, A.CT_TOT_SE_ICU2_HRS as ICU2_Hours, A.CT_TOT_SE_ICU_HRS as ICU_Hours,A.CT_TOT_SE_CCU_HRS as CCU_Hours, A.CT_TOT_SE_HDU_HRS as HDU_Hours, A.CT_TOT_SE_NICU_HRS as NICU_Hours,A.SRV_ENC_REC_ID,A.FRML_DISCH_MODE_CD,A.SE_SEP_MODE_NHDD_CD,M.facility_identifier as Responsible_Facility,A.SE_TYP_CD,A.SE_ADM_MODE_NHDD_CD FROM CRT.V_FACT_AP_SE_FLAT AS a LEFT JOIN (SELECT SE_CBK_SK,max(case when seq = 1 then mo_clinician else '' end)  as mo_code1,max(case when seq = 2 then mo_clinician else '' end)  as mo_code2 FROM (select  c.SE_CBK_SK,mo_clinician,DIM_OSP_CREATED_SK,ROW_NUMBER() OVER (PARTITION BY SE_CBK_SK ORDER BY SE_CBK_SK) as seq from CRT.V_FACT_AP_SE AS c LEFT JOIN (SELECT DIM_RSP_ISP_SK,case when ISP_MED_AHPRA_ID != '-1' then ISP_MED_AHPRA_ID when ISP_DENT_AHPRA_ID != '-1' then ISP_DENT_AHPRA_ID else '-1' end as mo_clinician	FROM CRT.v_DIM_RSP_ISP) as b on (C.DIM_LST_RSP_ISP_SK = B.DIM_RSP_ISP_SK) or (C.DIM_FST_RSP_ISP_SK = B.DIM_RSP_ISP_SK) LEFT JOIN (SELECT DIM_RSP_OSP_SK,OSP_ID FROM CRT.v_DIM_RSP_OSP) AS g on C.DIM_LST_RSP_OSP_SK = G.DIM_RSP_OSP_SK INNER JOIN (SELECT DIM_OSP_SK, HLTH_ORG_OSP_OSP_ID, MG_AUTH_OSP_OSP_ID, OSP_HIE_FAC_ID, MG_AUTH_OSP_HIE_FAC_ID,MG_AUTH_OSP_HLTH_SECTOR_CD,HLTH_ORG_OSP_HLTH_SECTOR_CD, OSP_TYP_CD,HLTH_ORG_OSP_HIE_FAC_ID,case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_HIE_FAC_ID else HLTH_ORG_OSP_HIE_FAC_ID end as facility_identifier, OSP_ID FROM CRT.v_DIM_OSP WHERE (MG_AUTH_OSP_HLTH_SECTOR_CD in('1','3')) and (HLTH_ORG_OSP_HLTH_SECTOR_CD in ('1','3')) AND HLTH_ORG_OSP_HIE_FAC_ID != '-1' AND HLTH_ORG_OSP_HIE_FAC_ID != '') AS K ON C.DIM_OSP_CREATED_SK = K.DIM_OSP_SK	WHERE (C.DIM_DT_SE_ST_SK<='"""
                + end_date
                + """' AND C.DIM_DT_SE_ST_SK !='1111-01-01') AND (C.DIM_DT_SE_END_SK >='"""
                + start_date
                + """' or C.DIM_DT_SE_END_SK is NULL or C.DIM_DT_SE_END_SK = '1111-01-01') and (K.MG_AUTH_OSP_HIE_FAC_ID='"""
                + lhd
                + """' or K.facility_identifier ='"""
                + lhd
                + """')) as z GROUP by SE_CBK_SK) as H on a.SE_CBK_SK = h.SE_CBK_SK LEFT JOIN (SELECT DISTINCT SE_CBK_SK,DIM_AP_SE_PRF_SK,WGT_AT_SE_ST_GMS , DIM_LST_FIN_CLASS_SK FROM CRT.V_FACT_AP_SE) as f on a.SE_CBK_SK = f.SE_CBK_SK LEFT JOIN (SELECT DISTINCT DIM_AP_SE_PRF_SK, SE_UNPLAN_RETURN_TH_FG FROM CRT.v_DIM_AP_SE_PRF) as g on f.DIM_AP_SE_PRF_SK = g.DIM_AP_SE_PRF_SK INNER JOIN (SELECT DISTINCT DIM_OSP_SK, OSP_HIE_FAC_ID,HLTH_ORG_OSP_OSP_ID, MG_AUTH_OSP_HLTH_SECTOR_CD, HLTH_ORG_OSP_HLTH_SECTOR_CD, OSP_TYP_CD,HLTH_ORG_OSP_HIE_FAC_ID, MG_AUTH_OSP_HIE_FAC_ID, MG_AUTH_OSP_OSP_ID, HLTH_ORG_OSP_TYP_CD, HLTH_ORG_OSP_TYP,OSP_TYP,case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_ID else HLTH_ORG_OSP_OSP_ID end as OSP_ID,case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_HIE_FAC_ID else HLTH_ORG_OSP_HIE_FAC_ID end as facility_identifier,case when OSP_TYP_CD In ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10', '2.08', '10.02', '10.03', '10.07', '10.08') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_TYP_CD else HLTH_ORG_OSP_TYP_CD end as facility_type,case when OSP_TYP_CD In ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10', '2.08', '10.02', '10.03', '10.07', '10.08') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_TYP else HLTH_ORG_OSP_TYP End as HLTH_ORG_OSP_TYP_mod FROM CRT.v_DIM_OSP where ((MG_AUTH_OSP_HLTH_SECTOR_CD IN ('1','3')) and (HLTH_ORG_OSP_HLTH_SECTOR_CD IN ('1','3'))) AND HLTH_ORG_OSP_HIE_FAC_ID != '-1' AND HLTH_ORG_OSP_HIE_FAC_ID != '') AS K ON A.DIM_OSP_CREATED_SK = K.DIM_OSP_SK LEFT JOIN CRT.v_DIM_LST_FIN_CLASS as L on F.DIM_LST_FIN_CLASS_SK = L.DIM_LST_FIN_CLASS_SK LEFT JOIN (SELECT DISTINCT case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_ID else HLTH_ORG_OSP_OSP_ID end as OSP_ID,case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_HIE_FAC_ID else HLTH_ORG_OSP_HIE_FAC_ID end as facility_identifier FROM CRT.v_DIM_OSP where ((MG_AUTH_OSP_HLTH_SECTOR_CD IN ('1','3')) and (HLTH_ORG_OSP_HLTH_SECTOR_CD IN ('1','3'))) AND HLTH_ORG_OSP_HIE_FAC_ID != '-1' AND HLTH_ORG_OSP_HIE_FAC_ID != '') AS M ON a.LST_OSP_ID = M.OSP_ID WHERE ((A.DIM_DT_SE_ST_SK <= '"""
                + end_date
                + """' AND A.DIM_DT_SE_ST_SK !='1111-01-01') AND (A.DIM_DT_SE_END_SK >= '"""
                + start_date
                + """' or A.DIM_DT_SE_END_SK is NULL or a.DIM_DT_SE_END_SK = '1111-01-01') AND (K.MG_AUTH_OSP_HIE_FAC_ID = '"""
                + lhd
                + """' or (k.facility_identifier)='"""
                + lhd
                + """')) AND k.facility_identifier in ("""
                + facilities_included
                + """);"""
            )
    retry_flag = True
    retry_count = 0
    while retry_flag and retry_count < 5:
        try:
            logging.info(query_EpisodeAts)
            tbl_dbo_episode_ats = pd.read_sql(query_EpisodeAts, cnxn)
            retry_flag = False
        except Exception as e:
            retry_count = retry_count + 1
            time.sleep(5)
            if retry_count == 5:
                logging.exception("Exception occurred")
                label_3_status = 0
                messagebox.showerror(
                    "SQL Error", "Error extracting EpisodeAts details\n" + str(e)
                )
                label_3_sub.configure(text="Failed (EpisodeAts)...", fg="red")
                main_screen.update()
                tbl_dbo_episode_ats = pd.DataFrame(
                    columns=[
                        "facility_identifier",
                        "stay_number",
                        "episode_sequence_number",
                        "person_identifier",
                        "episode_start_date",
                        "episode_end_date",
                        "mo_code2",
                        "episode_of_care_type",
                        "an_drg",
                        "major_diagnostic_category",
                        "mode_of_separation",
                        "source_of_referral",
                        "financial_program",
                        "episode_leave_days_total",
                        "episode_length_of_stay",
                        "first_psych_admission_flag",
                        "days_in_psych_unit",
                        "hours_in_psych_unit",
                        "hours_in_icu",
                        "place_of_occurrence",
                        "external_cause_code_1",
                        "external_cause_code_2",
                        "unplanned_theatre",
                        "palliative_care_status",
                        "unqual_baby_bed_days",
                        "unqualified_bed_days",
                        "unqualified_bed_time",
                        "qualified_bed_days",
                        "qualified_bed_time",
                        "legal_status_on_admit",
                        "pension_status",
                        "payment_status_on_sep",
                        "unit_type_on_admission",
                        "mrn",
                        "practice_identifier1",
                        "practice_identifier2",
                        "snap_upd_batch_run_no",
                        "clinical_codeset_1",
                        "clinical_codeset_2",
                        "clinical_codeset_3",
                        "an_drg_orig",
                        "an_drg_orig_version",
                        "mdc_orig",
                        "an_drg_orig_return_cd",
                        "an_drg_orig_pccl",
                        "external_cause_code_3",
                        "an_drg_version",
                        "episode_create_date",
                        "episode_update_date",
                        "involuntary_days_in_psych",
                        "episode_sequence_number_ats",
                        "episode_start_time",
                        "episode_end_time",
                        "financial_class",
                        "financial_class_local",
                        "source_system",
                        "upd_source_system",
                        "infant_start_weight",
                        "hours_on_mech_ventilation",
                        "hours_on_mech_vent_num",
                        "drg_mode_of_separation",
                        "drg_mhealth_legal_status",
                        "an_drg_current",
                        "an_drg_current_version",
                        "mdc_current",
                        "an_drg_current_return_cd",
                        "an_drg_current_pccl",
                        "financial_sub_program",
                        "episode_day_stay_los",
                        "clinical_coding_audit",
                        "clinical_coding_audit_date",
                        "area_identifier",
                        "area_code",
                        "facility_type",
                        "mo_code1",
                        "getdate",
                        "WIP",
                        "HLTH_ORG_OSP_OSP_ID",
                        "MG_AUTH_OSP_OSP_ID",
                        "SE_CBK_SK",
                        "CL_ID_EUID",
                        "CL_ID_IHI",
                        "HLTH_ORG_OSP_TYP",
                        "ICU1_Hours",
                        "ICU2_Hours",
                        "ICU_Hours",
                        "CCU_Hours",
                        "HDU_Hours",
                        "NICU_Hours",
                        "SRV_ENC_REC_ID",
                        "FRML_DISCH_MODE_CD",
                        "SE_SEP_MODE_NHDD_CD",
                        "Responsible_Facility",
                        "SE_TYP_CD",
                        "SE_ADM_MODE_NHDD_CD",
                    ]
                )
                return  # stop extraction
        else:
            tbl_dbo_episode_ats = tbl_dbo_episode_ats.fillna("")
            tbl_dbo_episode_ats = tbl_dbo_episode_ats[
                [
                    "facility_identifier",
                    "stay_number",
                    "episode_sequence_number",
                    "person_identifier",
                    "episode_start_date",
                    "episode_end_date",
                    "mo_code2",
                    "episode_of_care_type",
                    "an_drg",
                    "major_diagnostic_category",
                    "mode_of_separation",
                    "source_of_referral",
                    "financial_program",
                    "episode_leave_days_total",
                    "episode_length_of_stay",
                    "first_psych_admission_flag",
                    "days_in_psych_unit",
                    "hours_in_psych_unit",
                    "hours_in_icu",
                    "place_of_occurrence",
                    "external_cause_code_1",
                    "external_cause_code_2",
                    "unplanned_theatre",
                    "palliative_care_status",
                    "unqual_baby_bed_days",
                    "unqualified_bed_days",
                    "unqualified_bed_time",
                    "qualified_bed_days",
                    "qualified_bed_time",
                    "legal_status_on_admit",
                    "pension_status",
                    "payment_status_on_sep",
                    "unit_type_on_admission",
                    "mrn",
                    "practice_identifier1",
                    "practice_identifier2",
                    "snap_upd_batch_run_no",
                    "clinical_codeset_1",
                    "clinical_codeset_2",
                    "clinical_codeset_3",
                    "an_drg_orig",
                    "an_drg_orig_version",
                    "mdc_orig",
                    "an_drg_orig_return_cd",
                    "an_drg_orig_pccl",
                    "external_cause_code_3",
                    "an_drg_version",
                    "episode_create_date",
                    "episode_update_date",
                    "involuntary_days_in_psych",
                    "episode_sequence_number_ats",
                    "episode_start_time",
                    "episode_end_time",
                    "financial_class",
                    "financial_class_local",
                    "source_system",
                    "upd_source_system",
                    "infant_start_weight",
                    "hours_on_mech_ventilation",
                    "hours_on_mech_vent_num",
                    "drg_mode_of_separation",
                    "drg_mhealth_legal_status",
                    "an_drg_current",
                    "an_drg_current_version",
                    "mdc_current",
                    "an_drg_current_return_cd",
                    "an_drg_current_pccl",
                    "financial_sub_program",
                    "episode_day_stay_los",
                    "clinical_coding_audit",
                    "clinical_coding_audit_date",
                    "area_identifier",
                    "area_code",
                    "facility_type",
                    "mo_code1",
                    "getdate",
                    "WIP",
                    "HLTH_ORG_OSP_OSP_ID",
                    "MG_AUTH_OSP_OSP_ID",
                    "SE_CBK_SK",
                    "CL_ID_EUID",
                    "CL_ID_IHI",
                    "HLTH_ORG_OSP_TYP",
                    "ICU1_Hours",
                    "ICU2_Hours",
                    "ICU_Hours",
                    "CCU_Hours",
                    "HDU_Hours",
                    "NICU_Hours",
                    "SRV_ENC_REC_ID",
                    "FRML_DISCH_MODE_CD",
                    "SE_SEP_MODE_NHDD_CD",
                    "Responsible_Facility",
                    "SE_TYP_CD",
                    "SE_ADM_MODE_NHDD_CD",
                ]
            ]
            tbl_dbo_episode_ats = tbl_dbo_episode_ats[
                tbl_dbo_episode_ats["area_identifier"] == lhd_global
            ]
            tbl_dbo_episode_ats = tbl_dbo_episode_ats[
                tbl_dbo_episode_ats["facility_identifier"].isin(
                    facilities_included_list_global
                )
            ]
            tbl_dbo_episode_ats["WIP"] = tbl_dbo_episode_ats["WIP"].astype(str)
            tbl_dbo_episode_ats = tbl_dbo_episode_ats.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_dbo_episode_ats = tbl_dbo_episode_ats.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_dbo_episode_ats = tbl_dbo_episode_ats.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_episode_ats = tbl_dbo_episode_ats.apply(
                lambda x: x.replace(regex=r"NULL", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_episode_ats = tbl_dbo_episode_ats.apply(
                lambda x: x.replace(regex=r"Null", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_episode_ats = tbl_dbo_episode_ats.apply(
                lambda x: x.replace(regex=r"null", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_episode_ats["stay_number"] = (
                tbl_dbo_episode_ats["stay_number"]
                .astype(str)
                .str.pad(8, side="left", fillchar="0")
            )
            tbl_dbo_episode_ats["episode_sequence_number"] = (
                tbl_dbo_episode_ats["episode_sequence_number"]
                .astype(str)
                .str.pad(3, side="left", fillchar="0")
            )
            # dropping duplicate values
            tbl_dbo_episode_ats.drop_duplicates(keep="last", inplace=True)
            tbl_dbo_episode_ats.to_csv(
                "./ExtractorDB/OutputEpisodeAts.csv",
                index=False,
                na_rep="",
                float_format=str,
                decimal=str,
                date_format=str,
            )
            logging.info("tbl_dbo_episode_ats=%s", len(tbl_dbo_episode_ats))
            df_Excluded_EpisodeAts_invalid_caretype = tbl_dbo_episode_ats[
                (tbl_dbo_episode_ats["episode_of_care_type"] == "0")
                | (tbl_dbo_episode_ats["episode_of_care_type"] == "")
                | (tbl_dbo_episode_ats["episode_of_care_type"].isnull())
            ]
            df_Excluded_EpisodeAts_invalid_caretype = (
                df_Excluded_EpisodeAts_invalid_caretype[
                    [
                        "facility_identifier",
                        "stay_number",
                        "episode_sequence_number",
                        "HLTH_ORG_OSP_OSP_ID",
                        "MG_AUTH_OSP_OSP_ID",
                        "SE_CBK_SK",
                        "CL_ID_EUID",
                        "CL_ID_IHI",
                        "HLTH_ORG_OSP_TYP",
                    ]
                ]
            )
            df_Excluded_EpisodeAts_invalid_caretype["stay_number"] = (
                df_Excluded_EpisodeAts_invalid_caretype["stay_number"]
                .astype(str)
                .str.pad(8, side="left", fillchar="0")
            )
            df_Excluded_EpisodeAts_invalid_caretype["episode_sequence_number"] = (
                df_Excluded_EpisodeAts_invalid_caretype["episode_sequence_number"]
                .astype(str)
                .str.pad(3, side="left", fillchar="0")
            )
            df_Excluded_EpisodeAts_invalid_caretype["ed_identifier"] = "XXXXXXXXXX"
            df_Excluded_EpisodeAts_invalid_caretype["SNAP_encounter"] = "XXXX_XXXXXXXX"
            df_Excluded_EpisodeAts_invalid_caretype["ReasonForExclusion"] = (
                "Invalid Episode of Care Type"
            )
            df_Excluded_EpisodeAts_invalid_caretype["EncounterNumber"] = (
                df_Excluded_EpisodeAts_invalid_caretype["facility_identifier"]
                + "-I-"
                + df_Excluded_EpisodeAts_invalid_caretype["stay_number"]
                + "-"
                + df_Excluded_EpisodeAts_invalid_caretype["episode_sequence_number"]
            )
            df_Excluded_EpisodeAts_invalid_caretype = (
                df_Excluded_EpisodeAts_invalid_caretype[
                    [
                        "facility_identifier",
                        "stay_number",
                        "episode_sequence_number",
                        "ed_identifier",
                        "SNAP_encounter",
                        "ReasonForExclusion",
                        "EncounterNumber",
                        "HLTH_ORG_OSP_OSP_ID",
                        "MG_AUTH_OSP_OSP_ID",
                        "SE_CBK_SK",
                        "CL_ID_EUID",
                        "CL_ID_IHI",
                        "HLTH_ORG_OSP_TYP",
                    ]
                ]
            )
            df_Excluded_EpisodeAts_invalid_caretype = (
                df_Excluded_EpisodeAts_invalid_caretype.applymap(str)
            )
            df_Excluded_EpisodeAts_invalid_caretype = (
                df_Excluded_EpisodeAts_invalid_caretype.applymap(
                    lambda x: x.strip() if isinstance(x, str) else x
                )
            )
            df_Excluded_EpisodeAts_invalid_caretype = (
                df_Excluded_EpisodeAts_invalid_caretype.apply(
                    lambda x: x.replace(regex=r"^NaT$", value="")
                    if x.dtype == "object"
                    else x
                )
            )
            # dropping duplicate values
            df_Excluded_EpisodeAts_invalid_caretype.drop_duplicates(
                keep="last", inplace=True
            )
            df_Excluded_EpisodeAts_invalid_caretype.to_csv(
                "./ExtractorDB/OutputExcluded_EpisodeAts_invalid_caretype.csv",
                index=False,
                na_rep="",
                float_format=str,
                decimal=str,
                date_format=str,
            )  # Concatenate later with ED Excluded Encounters
            logging.info(
                "df_Excluded_EpisodeAts_invalid_caretype=%s",
                len(df_Excluded_EpisodeAts_invalid_caretype),
            )
    # OutputWardEpisode
    # columns = facility_identifier,stay_number,episode_sequence_number,ward_identifier,dbo_WARD_EPISODE_unit_type,area_identifier,dbo_WARD_EPISODE_ward_sequence_number,dbo_WARD_EPISODE_1_ward_sequence_number,dbo_WARD_EPISODE_1_unit_type,dbo_FACILITY_snap_curr_indicator,dbo_WARD_EPISODE_snap_curr_indicator,dbo_EPISODE_ATS_snap_curr_indicator,dbo_WARD_EPISODE_1_snap_curr_indicator
    # Access query = Make_tbl_dbo_Ward_Episode
    # INSERT INTO tbl_dbo_Ward_Episode ( facility_identifier, stay_number, episode_sequence_number, ward_identifier, dbo_WARD_EPISODE_unit_type, area_identifier, dbo_WARD_EPISODE_ward_sequence_number, dbo_WARD_EPISODE_1_ward_sequence_number, dbo_WARD_EPISODE_1_unit_type )
    # SELECT dbo_WARD_EPISODE.facility_identifier, dbo_WARD_EPISODE.stay_number, dbo_WARD_EPISODE.episode_sequence_number, dbo_WARD_EPISODE.ward_identifier, dbo_WARD_EPISODE.unit_type, dbo_FACILITY.area_identifier, dbo_WARD_EPISODE.ward_sequence_number, dbo_WARD_EPISODE_1.ward_sequence_number, dbo_WARD_EPISODE_1.unit_type
    # FROM ((dbo_WARD_EPISODE INNER JOIN dbo_FACILITY ON dbo_WARD_EPISODE.facility_identifier = dbo_FACILITY.facility_identifier) INNER JOIN dbo_WARD_EPISODE AS dbo_WARD_EPISODE_1 ON (dbo_WARD_EPISODE.facility_identifier = dbo_WARD_EPISODE_1.facility_identifier) AND (dbo_WARD_EPISODE.stay_number = dbo_WARD_EPISODE_1.stay_number) AND (dbo_WARD_EPISODE.episode_sequence_number = dbo_WARD_EPISODE_1.episode_sequence_number)) INNER JOIN dbo_EPISODE_ATS ON (dbo_WARD_EPISODE.facility_identifier = dbo_EPISODE_ATS.facility_identifier) AND (dbo_WARD_EPISODE.stay_number = dbo_EPISODE_ATS.stay_number) AND (dbo_WARD_EPISODE.episode_sequence_number = dbo_EPISODE_ATS.episode_sequence_number)
    # WHERE (((dbo_FACILITY.area_identifier)=[Forms]![Frm:1-ExtractSetUp]![AHS]) AND ((dbo_WARD_EPISODE.ward_sequence_number)=1 Or (dbo_WARD_EPISODE.ward_sequence_number)=2) AND ((dbo_WARD_EPISODE_1.ward_sequence_number)=1) AND ((dbo_WARD_EPISODE_1.unit_type)="17" Or (dbo_WARD_EPISODE_1.unit_type)="58") AND ((dbo_FACILITY.snap_curr_indicator)="Y") AND ((dbo_WARD_EPISODE.snap_curr_indicator)="Y") AND ((dbo_EPISODE_ATS.snap_curr_indicator)="Y") AND ((dbo_WARD_EPISODE_1.snap_curr_indicator)="Y") AND ((dbo_EPISODE_ATS.episode_start_date)<=[Forms]![Frm:1-ExtractSetUp]![End_Date]) AND ((dbo_EPISODE_ATS.episode_end_date)>=[Forms]![Frm:1-ExtractSetUp]![Start_Date])) OR (((dbo_FACILITY.area_identifier)=[Forms]![Frm:1-ExtractSetUp]![AHS]) AND ((dbo_WARD_EPISODE.ward_sequence_number)=1 Or (dbo_WARD_EPISODE.ward_sequence_number)=2) AND ((dbo_WARD_EPISODE_1.ward_sequence_number)=1) AND ((dbo_WARD_EPISODE_1.unit_type)="17" Or (dbo_WARD_EPISODE_1.unit_type)="58") AND ((dbo_FACILITY.snap_curr_indicator)="Y") AND ((dbo_WARD_EPISODE.snap_curr_indicator)="Y") AND ((dbo_EPISODE_ATS.snap_curr_indicator)="Y") AND ((dbo_WARD_EPISODE_1.snap_curr_indicator)="Y") AND ((dbo_EPISODE_ATS.episode_start_date)<=[Forms]![Frm:1-ExtractSetUp]![End_Date]) AND ((dbo_EPISODE_ATS.episode_end_date) Is Null));
    label_3_sub.configure(text="In Progress (WardEpisode)...", fg="blue")
    main_screen.update()
    if source == "HIE":
        if len(facilities_excluded_list) == 0:
            query_WardEpisode = (
                """SELECT dbo.WARD_EPISODE.facility_identifier, dbo.WARD_EPISODE.stay_number, dbo.WARD_EPISODE.episode_sequence_number, dbo.WARD_EPISODE.ward_identifier, dbo.WARD_EPISODE.unit_type AS dbo_WARD_EPISODE_unit_type, dbo.FACILITY.area_identifier, dbo.WARD_EPISODE.ward_sequence_number AS dbo_WARD_EPISODE_ward_sequence_number, WARD_EPISODE_1.ward_sequence_number AS dbo_WARD_EPISODE_1_ward_sequence_number, WARD_EPISODE_1.unit_type AS dbo_WARD_EPISODE_1_unit_type,
            dbo.FACILITY.snap_curr_indicator AS dbo_FACILITY_snap_curr_indicator, dbo.WARD_EPISODE.snap_curr_indicator AS dbo_WARD_EPISODE_snap_curr_indicator, dbo.EPISODE_ATS.snap_curr_indicator AS dbo_EPISODE_ATS_snap_curr_indicator, WARD_EPISODE_1.snap_curr_indicator AS dbo_WARD_EPISODE_1_snap_curr_indicator, '' as HLTH_ORG_OSP_OSP_ID, '' as MG_AUTH_OSP_OSP_ID, '' as SE_CBK_SK      
            FROM ((dbo.WARD_EPISODE INNER JOIN dbo.FACILITY ON dbo.WARD_EPISODE.facility_identifier = dbo.FACILITY.facility_identifier) INNER JOIN dbo.WARD_EPISODE AS WARD_EPISODE_1 ON (dbo.WARD_EPISODE.episode_sequence_number = WARD_EPISODE_1.episode_sequence_number) AND (dbo.WARD_EPISODE.stay_number = WARD_EPISODE_1.stay_number) AND (dbo.WARD_EPISODE.facility_identifier = WARD_EPISODE_1.facility_identifier)) INNER JOIN dbo.EPISODE_ATS ON (dbo.WARD_EPISODE.episode_sequence_number = dbo.EPISODE_ATS.episode_sequence_number) AND (dbo.WARD_EPISODE.stay_number = dbo.EPISODE_ATS.stay_number) AND (dbo.WARD_EPISODE.facility_identifier = dbo.EPISODE_ATS.facility_identifier) WHERE ((((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.WARD_EPISODE.ward_sequence_number)=1 Or (dbo.WARD_EPISODE.ward_sequence_number)=2) AND ((WARD_EPISODE_1.ward_sequence_number)=1) AND ((WARD_EPISODE_1.unit_type)='17' Or (WARD_EPISODE_1.unit_type)='58') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.WARD_EPISODE.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((WARD_EPISODE_1.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""
                + start_date
                + """')) OR (((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.WARD_EPISODE.ward_sequence_number)=1 Or (dbo.WARD_EPISODE.ward_sequence_number)=2) AND ((WARD_EPISODE_1.ward_sequence_number)=1) AND ((WARD_EPISODE_1.unit_type)='17' Or (WARD_EPISODE_1.unit_type)='58') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.WARD_EPISODE.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((WARD_EPISODE_1.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null)));"""
            )
        else:
            query_WardEpisode = (
                """SELECT dbo.WARD_EPISODE.facility_identifier, dbo.WARD_EPISODE.stay_number, dbo.WARD_EPISODE.episode_sequence_number, dbo.WARD_EPISODE.ward_identifier, dbo.WARD_EPISODE.unit_type AS dbo_WARD_EPISODE_unit_type, dbo.FACILITY.area_identifier, dbo.WARD_EPISODE.ward_sequence_number AS dbo_WARD_EPISODE_ward_sequence_number, WARD_EPISODE_1.ward_sequence_number AS dbo_WARD_EPISODE_1_ward_sequence_number, WARD_EPISODE_1.unit_type AS dbo_WARD_EPISODE_1_unit_type,
            dbo.FACILITY.snap_curr_indicator AS dbo_FACILITY_snap_curr_indicator, dbo.WARD_EPISODE.snap_curr_indicator AS dbo_WARD_EPISODE_snap_curr_indicator, dbo.EPISODE_ATS.snap_curr_indicator AS dbo_EPISODE_ATS_snap_curr_indicator, WARD_EPISODE_1.snap_curr_indicator AS dbo_WARD_EPISODE_1_snap_curr_indicator, '' as HLTH_ORG_OSP_OSP_ID, '' as MG_AUTH_OSP_OSP_ID, '' as SE_CBK_SK
            FROM ((dbo.WARD_EPISODE INNER JOIN dbo.FACILITY ON dbo.WARD_EPISODE.facility_identifier = dbo.FACILITY.facility_identifier) INNER JOIN dbo.WARD_EPISODE AS WARD_EPISODE_1 ON (dbo.WARD_EPISODE.episode_sequence_number = WARD_EPISODE_1.episode_sequence_number) AND (dbo.WARD_EPISODE.stay_number = WARD_EPISODE_1.stay_number) AND (dbo.WARD_EPISODE.facility_identifier = WARD_EPISODE_1.facility_identifier)) INNER JOIN dbo.EPISODE_ATS ON (dbo.WARD_EPISODE.episode_sequence_number = dbo.EPISODE_ATS.episode_sequence_number) AND (dbo.WARD_EPISODE.stay_number = dbo.EPISODE_ATS.stay_number) AND (dbo.WARD_EPISODE.facility_identifier = dbo.EPISODE_ATS.facility_identifier) WHERE ((((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.WARD_EPISODE.ward_sequence_number)=1 Or (dbo.WARD_EPISODE.ward_sequence_number)=2) AND ((WARD_EPISODE_1.ward_sequence_number)=1) AND ((WARD_EPISODE_1.unit_type)='17' Or (WARD_EPISODE_1.unit_type)='58') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.WARD_EPISODE.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((WARD_EPISODE_1.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""
                + start_date
                + """')) OR (((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.WARD_EPISODE.ward_sequence_number)=1 Or (dbo.WARD_EPISODE.ward_sequence_number)=2) AND ((WARD_EPISODE_1.ward_sequence_number)=1) AND ((WARD_EPISODE_1.unit_type)='17' Or (WARD_EPISODE_1.unit_type)='58') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.WARD_EPISODE.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((WARD_EPISODE_1.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null))) AND dbo.FACILITY.facility_identifier NOT IN ("""
                + facilities_excluded
                + """);"""
            )
    elif source == "EDW":
        if len(facilities_included_list) > 0:
            query_WardEpisode = (
                """SELECT DISTINCT k.facility_identifier, a.stay_number, a.episode_sequence_number, a.ward_identifier, a.dbo_WARD_EPISODE_unit_type, k.MG_AUTH_OSP_HIE_FAC_ID AS area_identifier, a.dbo_WARD_EPISODE_ward_sequence_number, b.dbo_WARD_EPISODE_1_ward_sequence_number, b.dbo_WARD_EPISODE_1_unit_type, '' AS dbo_FACILITY_snap_curr_indicator, '' AS dbo_WARD_EPISODE_snap_curr_indicator, '' AS dbo_EPISODE_ATS_snap_curr_indicator, '' AS dbo_WARD_EPISODE_1_snap_curr_indicator, K.OSP_ID as HLTH_ORG_OSP_OSP_ID, K.MG_AUTH_OSP_OSP_ID, A.SE_CBK_SK, a.ward_desc FROM (SELECT RIGHT(CONCAT('00000000', ISNULL(SUBSTRING(A.SRV_ENC_REC_ID,charindex('-',A.SRV_ENC_REC_ID)+1,8),'')), 8) AS stay_number, A.SEQ_AP_SE_IN_ENC AS episode_sequence_number
			, Z.dbo_WARD_EPISODE_ward_sequence_number, U.BED_TYP_CD AS dbo_WARD_EPISODE_unit_type, V.WARD_LOC_ID as ward_identifier, V.WARD_NM AS ward_desc, A.SE_SEG_ST_DTTM AS start_date, A.SE_SEG_END_DTTM AS end_date, Z.DIM_OSP_CREATED_SK, A.SE_CBK_SK FROM (SELECT  SE_SEG_CBK,SE_CBK_SK,SRV_ENC_REC_ID,SEQ_AP_SE_IN_ENC,SE_SEG_ST_DTTM,SE_SEG_END_DTTM,SE_ST_DTTM,SE_END_DTTM,DIM_HS_BED_WARD_SK
			,DIM_HS_BED_TYP_SK FROM CRT.v_FACT_AP_SE_SEG) AS A LEFT JOIN (SELECT DISTINCT ROW_NUMBER() OVER (PARTITION BY W.SRV_ENC_REC_ID, W.SEQ_AP_SE_IN_ENC ORDER BY Min(W.SE_SEG_CBK)) AS dbo_WARD_EPISODE_ward_sequence_number, W.SRV_ENC_REC_ID, W.SEQ_AP_SE_IN_ENC, MIN(W.SE_SEG_CBK) AS SE_SEG_CBK, W.HS_WARD_LOC_ID, W.DIM_OSP_CREATED_SK FROM (SELECT C.SE_CBK_SK,C.SRV_ENC_REC_ID,C.SEQ_AP_SE_IN_ENC,C.SE_SEG_CBK,D.HS_WARD_LOC_ID,C.DIM_RSP_OSP_SK,C.DIM_HS_BED_WARD_SK,C.DIM_OSP_CREATED_SK FROM CRT.v_FACT_AP_SE_SEG AS C LEFT JOIN (SELECT DIM_HS_BED_WARD_SK, BED_LOC_ID , WARD_LOC_ID as HS_WARD_LOC_ID FROM CRT.v_DIM_HS_BED_WARD) as D on C.DIM_HS_BED_WARD_SK = D.DIM_HS_BED_WARD_SK) AS W GROUP BY W.SRV_ENC_REC_ID, W.SEQ_AP_SE_IN_ENC, W.HS_WARD_LOC_ID, W.DIM_OSP_CREATED_SK) as Z ON A.SE_SEG_CBK = Z.SE_SEG_CBK LEFT JOIN (SELECT DIM_HS_BED_WARD_SK, WARD_NM, WARD_LOC_ID FROM CRT.v_DIM_HS_BED_WARD) as V on a.DIM_HS_BED_WARD_SK = V.DIM_HS_BED_WARD_SK LEFT JOIN (SELECT DIM_BED_TYP_SK, BED_TYP_CD FROM CRT.v_DIM_HS_BED_TYP) as U on A.DIM_HS_BED_TYP_SK = U.DIM_BED_TYP_SK WHERE Z.dbo_WARD_EPISODE_ward_sequence_number in (1,2) AND (CAST(a.SE_ST_DTTM AS DATE) <= '"""
                + end_date
                + """') AND ((CAST(a.SE_END_DTTM AS DATE) >= '"""
                + start_date
                + """') OR (a.SE_END_DTTM IS NULL))) AS a LEFT JOIN (SELECT DISTINCT RIGHT(CONCAT('00000000', ISNULL(SUBSTRING(A.SRV_ENC_REC_ID,charindex('-',A.SRV_ENC_REC_ID)+1,8),'')), 8) AS stay_number, A.SEQ_AP_SE_IN_ENC AS episode_sequence_number, A.SEQ_SE_LOC AS dbo_WARD_EPISODE_1_ward_sequence_number, c.BED_TYP_CD AS dbo_WARD_EPISODE_1_unit_type, MIN(A.SE_SEG_ST_DTTM) AS start_date, MAX(A.SE_SEG_END_DTTM) AS end_date, A.SE_CBK_SK FROM (SELECT SE_CBK_SK,SRV_ENC_REC_ID,SEQ_AP_SE_IN_ENC,SEQ_SE_LOC,SE_SEG_ST_DTTM 			,SE_SEG_END_DTTM,SE_ST_DTTM,SE_END_DTTM,DIM_HS_BED_WARD_SK,DIM_HS_BED_TYP_SK FROM CRT.v_FACT_AP_SE_SEG) AS a LEFT JOIN (SELECT DIM_BED_TYP_SK, BED_TYP_CD FROM CRT.v_DIM_HS_BED_TYP) as c on A.DIM_HS_BED_TYP_SK = c.DIM_BED_TYP_SK WHERE A.SEQ_SE_LOC IN (1) AND (CAST(a.SE_ST_DTTM AS DATE) <= '"""
                + end_date
                + """') AND ((CAST(a.SE_END_DTTM AS DATE) >= '"""
                + start_date
                + """') OR (a.SE_END_DTTM IS NULL)) GROUP BY A.SRV_ENC_REC_ID,A.SEQ_AP_SE_IN_ENC, A.SEQ_SE_LOC, c.BED_TYP_CD, A.SE_CBK_SK) AS B ON A.SE_CBK_SK = B.SE_CBK_SK INNER JOIN (SELECT DIM_OSP_SK, HLTH_ORG_OSP_OSP_ID, MG_AUTH_OSP_HIE_FAC_ID , MG_AUTH_OSP_HLTH_SECTOR_CD, HLTH_ORG_OSP_HLTH_SECTOR_CD ,OSP_HIE_FAC_ID, MG_AUTH_OSP_OSP_ID,HLTH_ORG_OSP_HIE_FAC_ID,OSP_TYP_CD, case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_ID else HLTH_ORG_OSP_OSP_ID end as OSP_ID,case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_HIE_FAC_ID else HLTH_ORG_OSP_HIE_FAC_ID end AS facility_identifier FROM CRT.v_DIM_OSP WHERE (MG_AUTH_OSP_HLTH_SECTOR_CD IN ('1','3')) and (HLTH_ORG_OSP_HLTH_SECTOR_CD IN ('1','3')) AND HLTH_ORG_OSP_HIE_FAC_ID != '-1' AND HLTH_ORG_OSP_HIE_FAC_ID != '') AS K ON a.DIM_OSP_CREATED_SK = K.DIM_OSP_SK WHERE (b.dbo_WARD_EPISODE_1_unit_type = '17' OR b.dbo_WARD_EPISODE_1_unit_type = '58') AND (k.facility_identifier) IN ("""
                + facilities_included
                + """) AND 
			K.MG_AUTH_OSP_HIE_FAC_ID = '"""
                + lhd
                + """' ORDER BY a.stay_number, a.dbo_WARD_EPISODE_ward_sequence_number;"""
            )
    retry_flag = True
    retry_count = 0
    while retry_flag and retry_count < 5:
        try:
            logging.info(query_WardEpisode)
            tbl_dbo_Ward_Episode = pd.read_sql(query_WardEpisode, cnxn)
            retry_flag = False
        except Exception as e:
            retry_count = retry_count + 1
            time.sleep(5)
            if retry_count == 5:
                logging.exception("Exception occurred")
                label_3_status = 0
                messagebox.showerror(
                    "SQL Error", "Error extracting WardEpisode details\n" + str(e)
                )
                label_3_sub.configure(text="Failed (WardEpisode)...", fg="red")
                main_screen.update()
                tbl_dbo_Ward_Episode = pd.DataFrame(
                    "facility_identifier",
                    "stay_number",
                    "episode_sequence_number",
                    "ward_identifier",
                    "dbo_WARD_EPISODE_unit_type",
                    "area_identifier",
                    "dbo_WARD_EPISODE_ward_sequence_number",
                    "dbo_WARD_EPISODE_1_ward_sequence_number",
                    "dbo_WARD_EPISODE_1_unit_type",
                    "dbo_FACILITY_snap_curr_indicator",
                    "dbo_WARD_EPISODE_snap_curr_indicator",
                    "dbo_EPISODE_ATS_snap_curr_indicator",
                    "dbo_WARD_EPISODE_1_snap_curr_indicator",
                    "HLTH_ORG_OSP_OSP_ID",
                    "MG_AUTH_OSP_OSP_ID",
                    "SE_CBK_SK",
                )
                return  # stop extraction
        else:
            tbl_dbo_Ward_Episode = tbl_dbo_Ward_Episode.fillna("")
            tbl_dbo_Ward_Episode = tbl_dbo_Ward_Episode[
                [
                    "facility_identifier",
                    "stay_number",
                    "episode_sequence_number",
                    "ward_identifier",
                    "dbo_WARD_EPISODE_unit_type",
                    "area_identifier",
                    "dbo_WARD_EPISODE_ward_sequence_number",
                    "dbo_WARD_EPISODE_1_ward_sequence_number",
                    "dbo_WARD_EPISODE_1_unit_type",
                    "dbo_FACILITY_snap_curr_indicator",
                    "dbo_WARD_EPISODE_snap_curr_indicator",
                    "dbo_EPISODE_ATS_snap_curr_indicator",
                    "dbo_WARD_EPISODE_1_snap_curr_indicator",
                    "HLTH_ORG_OSP_OSP_ID",
                    "MG_AUTH_OSP_OSP_ID",
                    "SE_CBK_SK",
                ]
            ]
            tbl_dbo_Ward_Episode = tbl_dbo_Ward_Episode[
                tbl_dbo_Ward_Episode["area_identifier"] == lhd_global
            ]
            tbl_dbo_Ward_Episode = tbl_dbo_Ward_Episode[
                tbl_dbo_Ward_Episode["facility_identifier"].isin(
                    facilities_included_list_global
                )
            ]
            tbl_dbo_Ward_Episode = tbl_dbo_Ward_Episode.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_dbo_Ward_Episode = tbl_dbo_Ward_Episode.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_dbo_Ward_Episode = tbl_dbo_Ward_Episode.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_Ward_Episode = tbl_dbo_Ward_Episode.apply(
                lambda x: x.replace(regex=r"NULL", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_Ward_Episode = tbl_dbo_Ward_Episode.apply(
                lambda x: x.replace(regex=r"null", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_Ward_Episode = tbl_dbo_Ward_Episode.apply(
                lambda x: x.replace(regex=r"Null", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_Ward_Episode["stay_number"] = (
                tbl_dbo_Ward_Episode["stay_number"]
                .astype(str)
                .str.pad(8, side="left", fillchar="0")
            )
            tbl_dbo_Ward_Episode["episode_sequence_number"] = (
                tbl_dbo_Ward_Episode["episode_sequence_number"]
                .astype(str)
                .str.pad(3, side="left", fillchar="0")
            )
            # dropping duplicate values
            tbl_dbo_Ward_Episode.drop_duplicates(keep="last", inplace=True)
            tbl_dbo_Ward_Episode.to_csv(
                "./ExtractorDB/OutputWardEpisode.csv",
                index=False,
                na_rep="",
                float_format=str,
                decimal=str,
                date_format=str,
            )
            logging.info("tbl_dbo_Ward_Episode=%s", len(tbl_dbo_Ward_Episode))
    # OutputEpisode
    # columns = facility_identifier,stay_number,episode_sequence_number,length_of_stay,drg_mode_of_separation,drg_mhealth_legal_status,mdc_current,infant_start_weight,an_drg_current,an_drg_current_version,hours_on_mech_ventilation,hours_on_mech_vent_num,enddate,endtime
    # Access query = qry_dbo_episode
    # SELECT dbo_EPISODE_ATS.facility_identifier, dbo_EPISODE_ATS.stay_number, dbo_EPISODE_ATS.episode_sequence_number, dbo_EPISODE.hours_on_mech_vent_num, dbo_EPISODE.hours_on_mech_ventilation, dbo_EPISODE.infant_start_weight, dbo_EPISODE.episode_end_date, dbo_EPISODE.episode_end_time, dbo_EPISODE.episode_of_care_type, dbo_EPISODE.episode_leave_days_total, dbo_EPISODE.episode_length_of_stay, dbo_EPISODE.episode_start_date, dbo_EPISODE.episode_start_time
    label_3_sub.configure(text="In Progress (Episode)...", fg="blue")
    main_screen.update()
    if source == "HIE":
        if len(facilities_excluded_list) == 0:
            query_Episode = (
                """SELECT dbo.EPISODE_ATS.facility_identifier, dbo.EPISODE_ATS.stay_number, dbo.EPISODE_ATS.episode_sequence_number, dbo.EPISODE.episode_length_of_stay AS episode_length_of_stay, dbo.EPISODE.drg_mode_of_separation, dbo.EPISODE.drg_mhealth_legal_status, dbo.EPISODE.mdc_current, dbo.EPISODE.infant_start_weight, dbo.EPISODE.an_drg_current, dbo.EPISODE.an_drg_current_version, dbo.EPISODE.hours_on_mech_ventilation, dbo.EPISODE.hours_on_mech_vent_num, dbo.EPISODE.episode_end_date AS enddate, dbo.EPISODE.episode_end_time AS endtime,  dbo.EPISODE.episode_of_care_type, dbo.EPISODE.episode_leave_days_total, dbo.EPISODE.episode_start_date AS startdate, dbo.EPISODE.episode_start_time AS starttime, '' as HLTH_ORG_OSP_OSP_ID, '' as MG_AUTH_OSP_OSP_ID, '' as SE_CBK_SK FROM (dbo.EPISODE_ATS INNER JOIN dbo.FACILITY ON dbo.EPISODE_ATS.facility_identifier = dbo.FACILITY.facility_identifier) INNER JOIN dbo.EPISODE ON (dbo.EPISODE_ATS.episode_sequence_number = dbo.EPISODE.episode_sequence_number) AND (dbo.EPISODE_ATS.stay_number = dbo.EPISODE.stay_number) AND (dbo.EPISODE_ATS.facility_identifier = dbo.EPISODE.facility_identifier) WHERE (((dbo.EPISODE_ATS.facility_identifier)<>"D311" And (dbo.EPISODE_ATS.facility_identifier)<>"Q230") AND ((dbo.EPISODE.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_ATS.snap_curr_indicator)="Y") AND ((dbo.FACILITY.snap_curr_indicator)="Y") AND ((dbo.EPISODE.snap_curr_indicator)="Y")) OR (((dbo.EPISODE_ATS.facility_identifier)<>"D311" And (dbo.EPISODE_ATS.facility_identifier)<>"Q230") AND ((dbo.EPISODE.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_ATS.snap_curr_indicator)="Y") AND ((dbo.FACILITY.snap_curr_indicator)="Y") AND ((dbo.EPISODE.snap_curr_indicator)="Y")) OR (((dbo.EPISODE_ATS.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.EPISODE_ATS.snap_curr_indicator)="Y") AND ((dbo.FACILITY.snap_curr_indicator)="Y") AND ((dbo.EPISODE.snap_curr_indicator)="Y")) OR (((dbo.EPISODE_ATS.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.EPISODE_ATS.snap_curr_indicator)="Y") AND ((dbo.FACILITY.snap_curr_indicator)="Y") AND ((dbo.EPISODE.snap_curr_indicator)="Y"));"""
            )
        else:
            query_Episode = (
                """SELECT dbo.EPISODE_ATS.facility_identifier, dbo.EPISODE_ATS.stay_number, dbo.EPISODE_ATS.episode_sequence_number, dbo.EPISODE.episode_length_of_stay AS episode_length_of_stay, dbo.EPISODE.drg_mode_of_separation, dbo.EPISODE.drg_mhealth_legal_status, dbo.EPISODE.mdc_current, dbo.EPISODE.infant_start_weight, dbo.EPISODE.an_drg_current, dbo.EPISODE.an_drg_current_version, dbo.EPISODE.hours_on_mech_ventilation, dbo.EPISODE.hours_on_mech_vent_num, dbo.EPISODE.episode_end_date AS enddate, dbo.EPISODE.episode_end_time AS endtime,  dbo.EPISODE.episode_of_care_type, dbo.EPISODE.episode_leave_days_total, dbo.EPISODE.episode_start_date AS startdate, dbo.EPISODE.episode_start_time AS starttime, '' as HLTH_ORG_OSP_OSP_ID, '' as MG_AUTH_OSP_OSP_ID, '' as SE_CBK_SK FROM (dbo.EPISODE_ATS INNER JOIN dbo.FACILITY ON dbo.EPISODE_ATS.facility_identifier = dbo.FACILITY.facility_identifier) INNER JOIN dbo.EPISODE ON (dbo.EPISODE_ATS.episode_sequence_number = dbo.EPISODE.episode_sequence_number) AND (dbo.EPISODE_ATS.stay_number = dbo.EPISODE.stay_number) AND (dbo.EPISODE_ATS.facility_identifier = dbo.EPISODE.facility_identifier) WHERE ((((dbo.EPISODE_ATS.facility_identifier)<>"D311" And (dbo.EPISODE_ATS.facility_identifier)<>"Q230") AND ((dbo.EPISODE.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_ATS.snap_curr_indicator)="Y") AND ((dbo.FACILITY.snap_curr_indicator)="Y") AND ((dbo.EPISODE.snap_curr_indicator)="Y")) OR (((dbo.EPISODE_ATS.facility_identifier)<>"D311" And (dbo.EPISODE_ATS.facility_identifier)<>"Q230") AND ((dbo.EPISODE.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_ATS.snap_curr_indicator)="Y") AND ((dbo.FACILITY.snap_curr_indicator)="Y") AND ((dbo.EPISODE.snap_curr_indicator)="Y")) OR (((dbo.EPISODE_ATS.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.EPISODE_ATS.snap_curr_indicator)="Y") AND ((dbo.FACILITY.snap_curr_indicator)="Y") AND ((dbo.EPISODE.snap_curr_indicator)="Y")) OR (((dbo.EPISODE_ATS.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.EPISODE_ATS.snap_curr_indicator)="Y") AND ((dbo.FACILITY.snap_curr_indicator)="Y") AND ((dbo.EPISODE.snap_curr_indicator)="Y"))) AND dbo.FACILITY.facility_identifier NOT IN ("""
                + facilities_excluded
                + """);"""
            )
    elif source == "EDW":
        if len(facilities_included_list) > 0:
            # Extra columns in HIE not in Badari's query:
            # WRONG (initial columns Ranjit populated): a.CT_TOT_SE_BED_D_CT as episode_length_of_stay, a.SE_SRV_CATEGORY_CD as episode_of_care_type, a.CT_TOT_SE_LEAVE_HRS as episode_leave_days_total, CAST(a.SE_ST_DTTM as date) as startdate,CAST(a.SE_ST_DTTM as time(0)) as starttime
            # CORRECT (final columns Ranjit populated): ,a.CT_TOT_SE_DAYS as episode_length_of_stay,a.SE_SRV_CATEGORY_CD as episode_of_care_type, a.CT_TOT_SE_LEAVE_D_CT as episode_leave_days_total
            # FROM CRT.V_FACT_AP_SE_FLAT AS a
            query_Episode = (
                """SELECT DISTINCT K.facility_identifier, RIGHT(CONCAT('00000000', ISNULL(SUBSTRING(A.SRV_ENC_REC_ID,charindex('-',A.SRV_ENC_REC_ID)+1,8),'')), 8) as stay_number,a.SEQ_AP_SE_IN_ENC as episode_sequence_number,a.CT_TOT_SE_BED_D_CT as episode_length_of_stay,case when a.SE_SEP_MODE_NHDD_CD = '-1' then a.SE_SEP_MODE_NHDD_CD else RIGHT(CONCAT('00',ISNULL(a.SE_SEP_MODE_NHDD_CD,'')),2) end as drg_mode_of_separation,a.SE_MH_LGL_STAT_NHDD_CD as drg_mhealth_legal_status,'' as mdc_current,REPLICATE('0', 4 - LEN(CAST(C.WGT_AT_SE_ST_GMS AS VARCHAR))) + CAST(C.WGT_AT_SE_ST_GMS AS VARCHAR) as infant_start_weight,'' as an_drg_current,'' as an_drg_current_version,REPLICATE('0', 4 - LEN(CAST(A.CT_TOT_SE_MECH_VENT_HRS AS VARCHAR))) + CAST(A.CT_TOT_SE_MECH_VENT_HRS AS VARCHAR) as hours_on_mech_ventilation,a.CT_TOT_SE_MECH_VENT_HRS as hours_on_mech_vent_num,CAST(a.SE_END_DTTM as date) as enddate,CAST(a.SE_END_DTTM as time(0)) as 
			endtime,a.SE_SRV_CATEGORY_CD as episode_of_care_type,a.CT_TOT_SE_LEAVE_D_CT as episode_leave_days_total,CAST(a.SE_ST_DTTM as date) as startdate,CAST(a.SE_ST_DTTM as time(0)) as starttime,K.OSP_ID as HLTH_ORG_OSP_OSP_ID,K.MG_AUTH_OSP_OSP_ID,A.SE_CBK_SK FROM CRT.V_FACT_AP_SE_FLAT as a LEFT JOIN (SELECT DISTINCT SE_CBK_SK, WGT_AT_SE_ST_GMS FROM CRT.v_FACT_AP_SE) as c on a.SE_CBK_SK = C.SE_CBK_SK INNER JOIN (SELECT DISTINCT DIM_OSP_SK,OSP_HIE_FAC_ID,HLTH_ORG_OSP_OSP_ID, MG_AUTH_OSP_HLTH_SECTOR_CD, HLTH_ORG_OSP_HLTH_SECTOR_CD, OSP_TYP_CD,HLTH_ORG_OSP_HIE_FAC_ID, MG_AUTH_OSP_HIE_FAC_ID, MG_AUTH_OSP_OSP_ID,case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_ID else HLTH_ORG_OSP_OSP_ID end as OSP_ID,case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') 
			AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_HIE_FAC_ID else HLTH_ORG_OSP_HIE_FAC_ID end as facility_identifier FROM CRT.v_DIM_OSP WHERE ((MG_AUTH_OSP_HLTH_SECTOR_CD IN ('1','3')) and (HLTH_ORG_OSP_HLTH_SECTOR_CD IN ('1','3'))) AND HLTH_ORG_OSP_HIE_FAC_ID != '-1' AND HLTH_ORG_OSP_HIE_FAC_ID != '') AS K ON A.DIM_OSP_CREATED_SK = K.DIM_OSP_SK WHERE (CAST(a.SE_end_DTTM as date) >= '"""
                + start_date
                + """' or a.SE_end_DTTM IS NULL) AND CAST(a.SE_ST_DTTM as date) <= '"""
                + end_date
                + """' AND (K.MG_AUTH_OSP_HIE_FAC_ID = '"""
                + lhd
                + """') AND (K.facility_identifier) IN ("""
                + facilities_included
                + """);"""
            )
    retry_flag = True
    retry_count = 0
    while retry_flag and retry_count < 5:
        try:
            logging.info(query_Episode)
            tbl_dbo_episode = pd.read_sql(query_Episode, cnxn)
            retry_flag = False
        except Exception as e:
            retry_count = retry_count + 1
            time.sleep(5)
            if retry_count == 5:
                logging.exception("Exception occurred")
                label_3_status = 0
                messagebox.showerror(
                    "SQL Error", "Error extracting Episode details\n" + str(e)
                )
                label_3_sub.configure(text="Failed (Episode)...", fg="red")
                main_screen.update()
                tbl_dbo_episode = pd.DataFrame(
                    columns=[
                        "facility_identifier",
                        "stay_number",
                        "episode_sequence_number",
                        "episode_length_of_stay",
                        "drg_mode_of_separation",
                        "drg_mhealth_legal_status",
                        "mdc_current",
                        "infant_start_weight",
                        "an_drg_current",
                        "an_drg_current_version",
                        "hours_on_mech_ventilation",
                        "hours_on_mech_vent_num",
                        "enddate",
                        "endtime",
                        "episode_of_care_type",
                        "episode_leave_days_total",
                        "startdate",
                        "starttime",
                        "HLTH_ORG_OSP_OSP_ID",
                        "MG_AUTH_OSP_OSP_ID",
                        "SE_CBK_SK",
                    ]
                )
                return  # stop extraction
        else:
            tbl_dbo_episode = tbl_dbo_episode.fillna("")
            tbl_dbo_episode = tbl_dbo_episode[
                [
                    "facility_identifier",
                    "stay_number",
                    "episode_sequence_number",
                    "episode_length_of_stay",
                    "drg_mode_of_separation",
                    "drg_mhealth_legal_status",
                    "mdc_current",
                    "infant_start_weight",
                    "an_drg_current",
                    "an_drg_current_version",
                    "hours_on_mech_ventilation",
                    "hours_on_mech_vent_num",
                    "enddate",
                    "endtime",
                    "episode_of_care_type",
                    "episode_leave_days_total",
                    "startdate",
                    "starttime",
                    "HLTH_ORG_OSP_OSP_ID",
                    "MG_AUTH_OSP_OSP_ID",
                    "SE_CBK_SK",
                ]
            ]
            tbl_dbo_episode = tbl_dbo_episode[
                tbl_dbo_episode["facility_identifier"].isin(
                    facilities_included_list_global
                )
            ]
            tbl_dbo_episode = tbl_dbo_episode.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_dbo_episode = tbl_dbo_episode.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_dbo_episode = tbl_dbo_episode.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_episode = tbl_dbo_episode.apply(
                lambda x: x.replace(regex=r"NULL", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_episode = tbl_dbo_episode.apply(
                lambda x: x.replace(regex=r"null", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_episode = tbl_dbo_episode.apply(
                lambda x: x.replace(regex=r"Null", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_episode["stay_number"] = (
                tbl_dbo_episode["stay_number"]
                .astype(str)
                .str.pad(8, side="left", fillchar="0")
            )
            tbl_dbo_episode["episode_sequence_number"] = (
                tbl_dbo_episode["episode_sequence_number"]
                .astype(str)
                .str.pad(3, side="left", fillchar="0")
            )
            # dropping duplicate values
            tbl_dbo_episode.drop_duplicates(keep="last", inplace=True)
            tbl_dbo_episode.to_csv(
                "./ExtractorDB/OutputEpisode.csv",
                index=False,
                na_rep="",
                float_format=str,
                decimal=str,
                date_format=str,
            )
            logging.info("tbl_dbo_episode=%s", len(tbl_dbo_episode))
    # OutputEpisodeSrg
    # columns = facility_identifier,stay_number,episode_sequence_number,episode_start_date,episode_end_date,episode_of_care_type,mode_of_separation,source_of_referral,episode_length_of_stay,hours_in_icu,payment_status_on_sep,snap_upd_batch_run_no,source_system,upd_source_system,an_drg_current,an_drg_current_version,an_drg_current_pccl,ed_status,icu_status,days_in_psych,unqualified_baby_flag,admission_status,rsi_admission_status,rsi_age_grouping,rsi_hccc_flag,rsi_facility_peer_group,rsi_elos,rsi_elos_difference,srg,esrg,cost_weight_a,cost_weight_b,cost_weight_c,cost_weight_d,cost_weight_e,cost_weight_f,trim_point,outlier_days_1,outlier_days_2,hccc_flag,surgery_indicator,casemix_policy_class,episode_funding_type,srg_version_number,episode_funded,srg_specialty_code,srg_current,esrg_current,cost_weight_a_current,cost_weight_b_current,cost_weight_c_current,cost_weight_d_current,cost_weight_e_current,cost_weight_f_current,trim_point_current,outlier_days_1_current,outlier_days_2_current,hccc_flag_current,surgery_indicator_current,casemix_policy_class_curr,episode_funding_type_curr,srg_version_number_curr,episode_funded_curr,srg_specialty_code_curr
    # Access query = qry_dbo_episode_srg
    # SELECT dbo_EPISODE_SRG.facility_identifier, dbo_EPISODE_SRG.stay_number, dbo_EPISODE_SRG.episode_sequence_number, dbo_EPISODE_SRG.srg_version, dbo_EPISODE_SRG.srg, dbo_EPISODE_SRG.esrg, dbo_EPISODE_SRG.ed_status, dbo_EPISODE_SRG.trim_point, dbo_EPISODE_SRG.outlier_days_1, dbo_EPISODE_SRG.outlier_days_2, dbo_EPISODE_SRG.cost_weight_a AS Expr1, dbo_EPISODE_SRG.cost_weight_b, dbo_EPISODE_SRG.cost_weight_c, dbo_EPISODE_SRG.cost_weight_d, dbo_EPISODE_SRG.cost_weight_e, dbo_EPISODE_SRG.cost_weight_f, dbo_EPISODE_SRG.surgery_indicator, dbo_EPISODE_SRG.icu_status
    # Inform8 query = """SELECT dbo.EPISODE_SRG.facility_identifier, dbo.EPISODE_SRG.stay_number, dbo.EPISODE_SRG.episode_sequence_number, dbo.EPISODE_SRG.srg_version AS srg_version_number, dbo.EPISODE_SRG.srg, dbo.EPISODE_SRG.esrg, dbo.EPISODE_SRG.ed_status, dbo.EPISODE_SRG.trim_point, dbo.EPISODE_SRG.outlier_days_1, dbo.EPISODE_SRG.outlier_days_2, dbo.EPISODE_SRG.cost_weight_a, dbo.EPISODE_SRG.cost_weight_b, dbo.EPISODE_SRG.cost_weight_c, dbo.EPISODE_SRG.cost_weight_d, dbo.EPISODE_SRG.cost_weight_e, dbo.EPISODE_SRG.cost_weight_f, dbo.EPISODE_SRG.surgery_indicator, dbo.EPISODE_SRG.icu_status FROM dbo.EPISODE_SRG INNER JOIN dbo.FACILITY ON dbo.EPISODE_SRG.facility_identifier = dbo.FACILITY.facility_identifier WHERE ((((dbo.EPISODE_SRG.episode_start_date)<='"""+end_date+"""') AND ((dbo.EPISODE_SRG.episode_end_date)>='"""+start_date+"""') AND ((dbo.EPISODE_SRG.an_drg_version)='"""+srg_drg_v+"""') AND ((dbo.EPISODE_SRG.snap_curr_indicator)='Y') AND ((dbo.FACILITY.area_identifier)='"""+lhd+"""') AND ((dbo.EPISODE_SRG.cost_weight_version)='"""+cost_weight_v+"""') AND ((dbo.FACILITY.snap_curr_indicator)='Y')) OR (((dbo.EPISODE_SRG.episode_start_date)<='"""+end_date+"""') AND ((dbo.EPISODE_SRG.episode_end_date) Is Null) AND ((dbo.EPISODE_SRG.an_drg_version)='"""+srg_drg_v+"""') AND ((dbo.EPISODE_SRG.snap_curr_indicator)='Y') AND ((dbo.FACILITY.area_identifier)='"""+lhd+"""') AND ((dbo.EPISODE_SRG.cost_weight_version)='"""+cost_weight_v+"""') AND ((dbo.FACILITY.snap_curr_indicator)='Y')) OR (((dbo.EPISODE_SRG.facility_identifier)='"""+lhd+"""') AND ((dbo.EPISODE_SRG.episode_start_date)<='"""+end_date+"""') AND ((dbo.EPISODE_SRG.episode_end_date)>='"""+start_date+"""') AND ((dbo.EPISODE_SRG.an_drg_version)='"""+srg_drg_v+"""') AND ((dbo.EPISODE_SRG.snap_curr_indicator)='Y') AND ((dbo.EPISODE_SRG.cost_weight_version)='"""+cost_weight_v+"""') AND ((dbo.FACILITY.snap_curr_indicator)='Y')) OR (((dbo.EPISODE_SRG.facility_identifier)='"""+lhd+"""') AND ((dbo.EPISODE_SRG.episode_start_date)<='"""+end_date+"""') AND ((dbo.EPISODE_SRG.episode_end_date) Is Null) AND ((dbo.EPISODE_SRG.an_drg_version)='"""+srg_drg_v+"""') AND ((dbo.EPISODE_SRG.snap_curr_indicator)='Y') AND ((dbo.EPISODE_SRG.cost_weight_version)='"""+cost_weight_v+"""') AND ((dbo.FACILITY.snap_curr_indicator)='Y'))) AND dbo.FACILITY.facility_identifier NOT IN ("""+facilities_excluded+""");"""
    label_3_sub.configure(text="In Progress (EpisodeSrg)...", fg="blue")
    main_screen.update()
    if source == "HIE":
        if len(facilities_excluded_list) == 0:
            query_EpisodeSrg = (
                """ SELECT dbo.EPISODE_SRG.facility_identifier, dbo.EPISODE_SRG.stay_number, dbo.EPISODE_SRG.episode_sequence_number, dbo.EPISODE_SRG.episode_start_date, dbo.EPISODE_SRG.episode_end_date, dbo.EPISODE_SRG.episode_of_care_type, '' AS mode_of_separation, '' AS source_of_referral, dbo.EPISODE_SRG.episode_length_of_stay, '0' AS hours_in_icu, '' AS payment_status_on_sep, dbo.EPISODE_SRG.snap_upd_batch_run_no, dbo.EPISODE_SRG.source_system, dbo.EPISODE_SRG.upd_source_system, '' AS an_drg_current, '' AS an_drg_current_version, '' AS an_drg_current_pccl, dbo.EPISODE_SRG.ed_status, dbo.EPISODE_SRG.icu_status, '' AS days_in_psych, '' AS unqualified_baby_flag, '' AS admission_status, '' AS rsi_admission_status, '' AS rsi_age_grouping, '' AS rsi_hccc_flag, '' AS rsi_facility_peer_group, '0' AS rsi_elos, '0' AS rsi_elos_difference, dbo.EPISODE_SRG.srg, dbo.EPISODE_SRG.esrg, dbo.EPISODE_SRG.cost_weight_a, dbo.EPISODE_SRG.cost_weight_b, dbo.EPISODE_SRG.cost_weight_c, dbo.EPISODE_SRG.cost_weight_d, dbo.EPISODE_SRG.cost_weight_e, dbo.EPISODE_SRG.cost_weight_f, dbo.EPISODE_SRG.trim_point, dbo.EPISODE_SRG.outlier_days_1, dbo.EPISODE_SRG.outlier_days_2, dbo.EPISODE_SRG.hccc_flag, dbo.EPISODE_SRG.surgery_indicator, dbo.EPISODE_SRG.casemix_policy_class, dbo.EPISODE_SRG.episode_funding_type, dbo.EPISODE_SRG.srg_version AS srg_version_number, '' AS episode_funded, '' AS srg_specialty_code, dbo.EPISODE_SRG.srg AS srg_current, dbo.EPISODE_SRG.esrg AS esrg_current, dbo.EPISODE_SRG.cost_weight_a AS cost_weight_a_current, dbo.EPISODE_SRG.cost_weight_b AS cost_weight_b_current, dbo.EPISODE_SRG.cost_weight_c AS cost_weight_c_current, dbo.EPISODE_SRG.cost_weight_d AS cost_weight_d_current, dbo.EPISODE_SRG.cost_weight_e AS cost_weight_e_current, dbo.EPISODE_SRG.cost_weight_f AS cost_weight_f_current, '0' AS trim_point_current, '0' AS outlier_days_1_current, '0' AS outlier_days_2_current, '' AS hccc_flag_current, '' AS surgery_indicator_current, '' AS casemix_policy_class_curr, '' AS episode_funding_type_curr, '' AS srg_version_number_curr, '' AS episode_funded_curr, '' AS srg_specialty_code_curr, '' as HLTH_ORG_OSP_OSP_ID, '' as MG_AUTH_OSP_OSP_ID, '' as SE_CBK_SK   
            FROM dbo.EPISODE_SRG INNER JOIN dbo.FACILITY ON dbo.EPISODE_SRG.facility_identifier = dbo.FACILITY.facility_identifier WHERE (((dbo.EPISODE_SRG.facility_identifier)<>"D311" And (dbo.EPISODE_SRG.facility_identifier)<>"Q230") AND ((dbo.EPISODE_SRG.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_SRG.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.EPISODE_SRG.an_drg_version)='"""
                + srg_drg_v
                + """') AND ((dbo.EPISODE_SRG.snap_curr_indicator)="Y") AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_SRG.cost_weight_version)='"""
                + cost_weight_v
                + """') AND ((dbo.FACILITY.snap_curr_indicator)="Y")) OR (((dbo.EPISODE_SRG.facility_identifier)<>"D311" And (dbo.EPISODE_SRG.facility_identifier)<>"Q230") AND ((dbo.EPISODE_SRG.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_SRG.episode_end_date) Is Null) AND ((dbo.EPISODE_SRG.an_drg_version)='"""
                + srg_drg_v
                + """') AND ((dbo.EPISODE_SRG.snap_curr_indicator)="Y") AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_SRG.cost_weight_version)='"""
                + cost_weight_v
                + """') AND ((dbo.FACILITY.snap_curr_indicator)="Y")) OR (((dbo.EPISODE_SRG.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_SRG.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_SRG.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.EPISODE_SRG.an_drg_version)='"""
                + srg_drg_v
                + """') AND ((dbo.EPISODE_SRG.snap_curr_indicator)="Y") AND ((dbo.EPISODE_SRG.cost_weight_version)='"""
                + cost_weight_v
                + """') AND ((dbo.FACILITY.snap_curr_indicator)="Y")) OR (((dbo.EPISODE_SRG.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_SRG.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_SRG.episode_end_date) Is Null) AND ((dbo.EPISODE_SRG.an_drg_version)='"""
                + srg_drg_v
                + """') AND ((dbo.EPISODE_SRG.snap_curr_indicator)="Y") AND ((dbo.EPISODE_SRG.cost_weight_version)='"""
                + cost_weight_v
                + """') AND ((dbo.FACILITY.snap_curr_indicator)="Y"));"""
            )
        else:
            query_EpisodeSrg = (
                """SELECT dbo.EPISODE_SRG.facility_identifier, dbo.EPISODE_SRG.stay_number, dbo.EPISODE_SRG.episode_sequence_number, dbo.EPISODE_SRG.episode_start_date, dbo.EPISODE_SRG.episode_end_date, dbo.EPISODE_SRG.episode_of_care_type, '' AS mode_of_separation, '' AS source_of_referral, dbo.EPISODE_SRG.episode_length_of_stay, '0' AS hours_in_icu, '' AS payment_status_on_sep, dbo.EPISODE_SRG.snap_upd_batch_run_no, dbo.EPISODE_SRG.source_system, dbo.EPISODE_SRG.upd_source_system, '' AS an_drg_current, '' AS an_drg_current_version, '' AS an_drg_current_pccl, dbo.EPISODE_SRG.ed_status, dbo.EPISODE_SRG.icu_status, '' AS days_in_psych, '' AS unqualified_baby_flag, '' AS admission_status, '' AS rsi_admission_status, '' AS rsi_age_grouping, '' AS rsi_hccc_flag, '' AS rsi_facility_peer_group, '0' AS rsi_elos, '0' AS rsi_elos_difference, dbo.EPISODE_SRG.srg, dbo.EPISODE_SRG.esrg, dbo.EPISODE_SRG.cost_weight_a, dbo.EPISODE_SRG.cost_weight_b, dbo.EPISODE_SRG.cost_weight_c, dbo.EPISODE_SRG.cost_weight_d, dbo.EPISODE_SRG.cost_weight_e, dbo.EPISODE_SRG.cost_weight_f, dbo.EPISODE_SRG.trim_point, dbo.EPISODE_SRG.outlier_days_1, dbo.EPISODE_SRG.outlier_days_2, dbo.EPISODE_SRG.hccc_flag, dbo.EPISODE_SRG.surgery_indicator, dbo.EPISODE_SRG.casemix_policy_class, dbo.EPISODE_SRG.episode_funding_type, dbo.EPISODE_SRG.srg_version AS srg_version_number, '' AS episode_funded, '' AS srg_specialty_code, dbo.EPISODE_SRG.srg AS srg_current, dbo.EPISODE_SRG.esrg AS esrg_current, dbo.EPISODE_SRG.cost_weight_a AS cost_weight_a_current, dbo.EPISODE_SRG.cost_weight_b AS cost_weight_b_current, dbo.EPISODE_SRG.cost_weight_c AS cost_weight_c_current, dbo.EPISODE_SRG.cost_weight_d AS cost_weight_d_current, dbo.EPISODE_SRG.cost_weight_e AS cost_weight_e_current, dbo.EPISODE_SRG.cost_weight_f AS cost_weight_f_current, '0' AS trim_point_current, '0' AS outlier_days_1_current, '0' AS outlier_days_2_current, '' AS hccc_flag_current, '' AS surgery_indicator_current, '' AS casemix_policy_class_curr, '' AS episode_funding_type_curr, '' AS srg_version_number_curr, '' AS episode_funded_curr, '' AS srg_specialty_code_curr, '' as HLTH_ORG_OSP_OSP_ID, '' as MG_AUTH_OSP_OSP_ID, '' as SE_CBK_SK
            FROM dbo.EPISODE_SRG INNER JOIN dbo.FACILITY ON dbo.EPISODE_SRG.facility_identifier = dbo.FACILITY.facility_identifier WHERE ((((dbo.EPISODE_SRG.facility_identifier)<>"D311" And (dbo.EPISODE_SRG.facility_identifier)<>"Q230") AND ((dbo.EPISODE_SRG.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_SRG.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.EPISODE_SRG.an_drg_version)='"""
                + srg_drg_v
                + """') AND ((dbo.EPISODE_SRG.snap_curr_indicator)="Y") AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_SRG.cost_weight_version)='"""
                + cost_weight_v
                + """') AND ((dbo.FACILITY.snap_curr_indicator)="Y")) OR (((dbo.EPISODE_SRG.facility_identifier)<>"D311" And (dbo.EPISODE_SRG.facility_identifier)<>"Q230") AND ((dbo.EPISODE_SRG.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_SRG.episode_end_date) Is Null) AND ((dbo.EPISODE_SRG.an_drg_version)='"""
                + srg_drg_v
                + """') AND ((dbo.EPISODE_SRG.snap_curr_indicator)="Y") AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_SRG.cost_weight_version)='"""
                + cost_weight_v
                + """') AND ((dbo.FACILITY.snap_curr_indicator)="Y")) OR (((dbo.EPISODE_SRG.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_SRG.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_SRG.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.EPISODE_SRG.an_drg_version)='"""
                + srg_drg_v
                + """') AND ((dbo.EPISODE_SRG.snap_curr_indicator)="Y") AND ((dbo.EPISODE_SRG.cost_weight_version)='"""
                + cost_weight_v
                + """') AND ((dbo.FACILITY.snap_curr_indicator)="Y")) OR (((dbo.EPISODE_SRG.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_SRG.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_SRG.episode_end_date) Is Null) AND ((dbo.EPISODE_SRG.an_drg_version)='"""
                + srg_drg_v
                + """') AND ((dbo.EPISODE_SRG.snap_curr_indicator)="Y") AND ((dbo.EPISODE_SRG.cost_weight_version)='"""
                + cost_weight_v
                + """') AND ((dbo.FACILITY.snap_curr_indicator)="Y"))) AND dbo.FACILITY.facility_identifier NOT IN ("""
                + facilities_excluded
                + """);"""
            )
    elif source == "EDW":
        if len(facilities_included_list) > 0:
            query_EpisodeSrg = (
                """SELECT DISTINCT K.facility_identifier,RIGHT(CONCAT('00000000', ISNULL(SUBSTRING(A.SRV_ENC_REC_ID,charindex('-',A.SRV_ENC_REC_ID)+1,8),'')), 8) as stay_number,a.SEQ_AP_SE_IN_ENC as episode_sequence_number,CAST(a.SE_ST_DTTM as date) as episode_start_date,CAST(a.SE_END_DTTM as date) as episode_end_date,a.SE_SRV_CATEGORY_CD as episode_of_care_type,'' as mode_of_separation,'' as source_of_referral,a.CT_TOT_SE_BED_D_CT as episode_length_of_stay,'0' as hours_in_icu,'' as payment_status_on_sep,0  as snap_upd_batch_run_no,''  as source_system,''  as upd_source_system,'' as an_drg_current,'' as an_drg_current_version,'' as an_drg_current_pccl,a.SE_ED_VISIT_IND_CD as ed_status,CASE WHEN b.SE_ICU_BED_USED_IND_CD = '-1' THEN '' WHEN b.SE_ICU_BED_USED_IND_CD = '{space}' THEN '' ELSE b.SE_ICU_BED_USED_IND_CD END as icu_status,'' as days_in_psych,'' as unqualified_baby_flag,'' as admission_status,'' as rsi_admission_status
			,'' as rsi_age_grouping,'' as rsi_hccc_flag,'' as rsi_facility_peer_group,'0' as rsi_elos,'0' as rsi_elos_difference,A.SRG_V4_CD as srg,A.ESRG_V4_CD as esrg,'' as cost_weight_a,'' as cost_weight_b,''	as cost_weight_c,'' as cost_weight_d,'' as cost_weight_e,'' as cost_weight_f,'0' as trim_point,'0' as outlier_days_1,'0' as outlier_days_2,'' as hccc_flag,CASE WHEN g.AR_DRG_TYP_CD = 'S' THEN 1 WHEN g.AR_DRG_TYP_CD = 'M' THEN 2 WHEN g.AR_DRG_TYP_CD = 'O' THEN 3 ELSE '' END as surgery_indicator,'' as casemix_policy_class,'' as episode_funding_type,'4.0' as srg_version_number,'' as episode_funded,'' as srg_specialty_code,A.SRG_V4_CD as srg_current,A.ESRG_V4_CD as esrg_current,'' as cost_weight_a_current,'' as cost_weight_b_current,'' as cost_weight_c_current,'' as cost_weight_d_current,'' as cost_weight_e_current,'' as cost_weight_f_current,'0' as trim_point_current,'0' as outlier_days_1_current,'0' as outlier_days_2_current,'' as hccc_flag_current,'' as 
			surgery_indicator_current,'' as casemix_policy_class_curr,'' as episode_funding_type_curr,'' as srg_version_number_curr,'' as episode_funded_curr,'' as srg_specialty_code_curr,K.OSP_ID as HLTH_ORG_OSP_OSP_ID ,K.MG_AUTH_OSP_OSP_ID,A.SE_CBK_SK FROM CRT.V_FACT_AP_SE_FLAT as a LEFT JOIN (SELECT DISTINCT SE_CBK_SK, DIM_AP_SE_DERIV_PRF_SK, DIMSET_AR_DRG_SK FROM CRT.V_FACT_AP_SE) as d on a.SE_CBK_SK = d.SE_CBK_SK LEFT JOIN (SELECT DISTINCT DIM_AP_SE_DERIV_PRF_SK, SE_ICU_BED_USED_IND_CD FROM CRT.v_DIM_AP_SE_DERIV_PRF) AS B ON d.DIM_AP_SE_DERIV_PRF_SK = b.DIM_AP_SE_DERIV_PRF_SK LEFT JOIN (SELECT DISTINCT DIMSET_AR_DRG_SK, DIM_AR_DRG_SK FROM CRT.v_DIMBRIDGE_AR_DRG) as f on D.DIMSET_AR_DRG_SK  = f.DIMSET_AR_DRG_SK LEFT JOIN (SELECT DISTINCT DIM_AR_DRG_SK, AR_DRG_TYP_CD, AR_DRG_DOM_VER FROM CRT.v_DIM_AR_DRG) as g on f.DIM_AR_DRG_SK = g.DIM_AR_DRG_SK INNER JOIN (SELECT DISTINCT DIM_OSP_SK, OSP_HIE_FAC_ID, HLTH_ORG_OSP_OSP_ID, MG_AUTH_OSP_HIE_FAC_ID, MG_AUTH_OSP_OSP_ID,MG_AUTH_OSP_HLTH_SECTOR_CD, HLTH_ORG_OSP_HLTH_SECTOR_CD, OSP_TYP_CD, HLTH_ORG_OSP_HIE_FAC_ID,case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_ID else HLTH_ORG_OSP_OSP_ID end as OSP_ID, case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_HIE_FAC_ID else HLTH_ORG_OSP_HIE_FAC_ID end as facility_identifier FROM CRT.v_DIM_OSP WHERE HLTH_ORG_OSP_HIE_FAC_ID != '-1' AND HLTH_ORG_OSP_HIE_FAC_ID != '' and ((MG_AUTH_OSP_HLTH_SECTOR_CD IN ('1','3')) and (HLTH_ORG_OSP_HLTH_SECTOR_CD IN 
			('1','3')))) AS K ON A.DIM_OSP_CREATED_SK = K.DIM_OSP_SK WHERE (CAST(a.SE_ST_DTTM as date) <= '"""
                + end_date
                + """' and (a.SE_end_DTTM  is NULL OR CAST(a.SE_end_DTTM as date) >= '"""
                + start_date
                + """') and G.AR_DRG_DOM_VER = '"""
                + srg_drg_v
                + """' and (K.MG_AUTH_OSP_HIE_FAC_ID = '"""
                + lhd
                + """' or (k.facility_identifier) = '"""
                + lhd
                + """')) AND (K.facility_identifier) IN ("""
                + facilities_included
                + """);"""
            )
    retry_flag = True
    retry_count = 0
    while retry_flag and retry_count < 5:
        try:
            logging.info(query_EpisodeSrg)
            tbl_dbo_episode_srg = pd.read_sql(query_EpisodeSrg, cnxn)
            retry_flag = False
        except Exception as e:
            retry_count = retry_count + 1
            time.sleep(5)
            if retry_count == 5:
                logging.exception("Exception occurred")
                label_3_status = 0
                messagebox.showerror(
                    "SQL Error", "Error extracting EpisodeSrg details\n" + str(e)
                )
                label_3_sub.configure(text="Failed (EpisodeSrg)...", fg="red")
                main_screen.update()
                tbl_dbo_episode_srg = pd.DataFrame(
                    columns=[
                        "facility_identifier",
                        "stay_number",
                        "episode_sequence_number",
                        "episode_start_date",
                        "episode_end_date",
                        "episode_of_care_type",
                        "mode_of_separation",
                        "source_of_referral",
                        "episode_length_of_stay",
                        "hours_in_icu",
                        "payment_status_on_sep",
                        "snap_upd_batch_run_no",
                        "source_system",
                        "upd_source_system",
                        "an_drg_current",
                        "an_drg_current_version",
                        "an_drg_current_pccl",
                        "ed_status",
                        "icu_status",
                        "days_in_psych",
                        "unqualified_baby_flag",
                        "admission_status",
                        "rsi_admission_status",
                        "rsi_age_grouping",
                        "rsi_hccc_flag",
                        "rsi_facility_peer_group",
                        "rsi_elos",
                        "rsi_elos_difference",
                        "srg",
                        "esrg",
                        "cost_weight_a",
                        "cost_weight_b",
                        "cost_weight_c",
                        "cost_weight_d",
                        "cost_weight_e",
                        "cost_weight_f",
                        "trim_point",
                        "outlier_days_1",
                        "outlier_days_2",
                        "hccc_flag",
                        "surgery_indicator",
                        "casemix_policy_class",
                        "episode_funding_type",
                        "srg_version_number",
                        "episode_funded",
                        "srg_specialty_code",
                        "srg_current",
                        "esrg_current",
                        "cost_weight_a_current",
                        "cost_weight_b_current",
                        "cost_weight_c_current",
                        "cost_weight_d_current",
                        "cost_weight_e_current",
                        "cost_weight_f_current",
                        "trim_point_current",
                        "outlier_days_1_current",
                        "outlier_days_2_current",
                        "hccc_flag_current",
                        "surgery_indicator_current",
                        "casemix_policy_class_curr",
                        "episode_funding_type_curr",
                        "srg_version_number_curr",
                        "episode_funded_curr",
                        "srg_specialty_code_curr",
                        "HLTH_ORG_OSP_OSP_ID",
                        "MG_AUTH_OSP_OSP_ID",
                        "SE_CBK_SK",
                    ]
                )
                return  # stop extraction
        else:
            tbl_dbo_episode_srg = tbl_dbo_episode_srg.fillna("")
            tbl_dbo_episode_srg = tbl_dbo_episode_srg[
                [
                    "facility_identifier",
                    "stay_number",
                    "episode_sequence_number",
                    "episode_start_date",
                    "episode_end_date",
                    "episode_of_care_type",
                    "mode_of_separation",
                    "source_of_referral",
                    "episode_length_of_stay",
                    "hours_in_icu",
                    "payment_status_on_sep",
                    "snap_upd_batch_run_no",
                    "source_system",
                    "upd_source_system",
                    "an_drg_current",
                    "an_drg_current_version",
                    "an_drg_current_pccl",
                    "ed_status",
                    "icu_status",
                    "days_in_psych",
                    "unqualified_baby_flag",
                    "admission_status",
                    "rsi_admission_status",
                    "rsi_age_grouping",
                    "rsi_hccc_flag",
                    "rsi_facility_peer_group",
                    "rsi_elos",
                    "rsi_elos_difference",
                    "srg",
                    "esrg",
                    "cost_weight_a",
                    "cost_weight_b",
                    "cost_weight_c",
                    "cost_weight_d",
                    "cost_weight_e",
                    "cost_weight_f",
                    "trim_point",
                    "outlier_days_1",
                    "outlier_days_2",
                    "hccc_flag",
                    "surgery_indicator",
                    "casemix_policy_class",
                    "episode_funding_type",
                    "srg_version_number",
                    "episode_funded",
                    "srg_specialty_code",
                    "srg_current",
                    "esrg_current",
                    "cost_weight_a_current",
                    "cost_weight_b_current",
                    "cost_weight_c_current",
                    "cost_weight_d_current",
                    "cost_weight_e_current",
                    "cost_weight_f_current",
                    "trim_point_current",
                    "outlier_days_1_current",
                    "outlier_days_2_current",
                    "hccc_flag_current",
                    "surgery_indicator_current",
                    "casemix_policy_class_curr",
                    "episode_funding_type_curr",
                    "srg_version_number_curr",
                    "episode_funded_curr",
                    "srg_specialty_code_curr",
                    "HLTH_ORG_OSP_OSP_ID",
                    "MG_AUTH_OSP_OSP_ID",
                    "SE_CBK_SK",
                ]
            ]
            tbl_dbo_episode_srg = tbl_dbo_episode_srg[
                tbl_dbo_episode_srg["facility_identifier"].isin(
                    facilities_included_list_global
                )
            ]
            tbl_dbo_episode_srg = tbl_dbo_episode_srg.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_dbo_episode_srg = tbl_dbo_episode_srg.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_dbo_episode_srg = tbl_dbo_episode_srg.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_episode_srg = tbl_dbo_episode_srg.apply(
                lambda x: x.replace(regex=r"NULL", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_episode_srg = tbl_dbo_episode_srg.apply(
                lambda x: x.replace(regex=r"null", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_episode_srg = tbl_dbo_episode_srg.apply(
                lambda x: x.replace(regex=r"Null", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_episode_srg["stay_number"] = (
                tbl_dbo_episode_srg["stay_number"]
                .astype(str)
                .str.pad(8, side="left", fillchar="0")
            )
            tbl_dbo_episode_srg["episode_sequence_number"] = (
                tbl_dbo_episode_srg["episode_sequence_number"]
                .astype(str)
                .str.pad(3, side="left", fillchar="0")
            )
            # dropping duplicate values
            tbl_dbo_episode_srg.drop_duplicates(keep="last", inplace=True)
            tbl_dbo_episode_srg.to_csv(
                "./ExtractorDB/OutputEpisodeSrg.csv",
                index=False,
                na_rep="",
                float_format=str,
                decimal=str,
                date_format=str,
            )
            logging.info("tbl_dbo_episode_srg=%s", len(tbl_dbo_episode_srg))
    # Access query = qry_transit_episode_DRG4
    # SELECT dbo.EPISODE_DRG.facility_identifier, dbo.EPISODE_DRG.stay_number, dbo.EPISODE_DRG.episode_sequence_number, dbo.EPISODE_DRG.an_drg_version AS 4_an_drg_version, dbo.EPISODE_DRG.an_drg AS 4_an_drg FROM dbo.EPISODE_DRG INNER JOIN dbo.FACILITY ON dbo.EPISODE_DRG.facility_identifier = dbo.FACILITY.facility_identifier WHERE (((dbo.EPISODE_DRG.facility_identifier)<>"D311" And (dbo.EPISODE_DRG.facility_identifier)<>"Q230") AND ((dbo.EPISODE_DRG.an_drg_version)='"""+drg4_v+"""') AND ((dbo.EPISODE_DRG.episode_start_date)<='"""+end_date+"""') AND ((dbo.EPISODE_DRG.episode_end_date)>='"""+start_date+"""') AND ((dbo.EPISODE_DRG.snap_curr_indicator)="Y") AND ((dbo.FACILITY.area_identifier)='"""+lhd+"""') AND ((dbo.FACILITY.snap_curr_indicator)="Y")) OR (((dbo.EPISODE_DRG.facility_identifier)<>"D311" And (dbo.EPISODE_DRG.facility_identifier)<>"Q230") AND ((dbo.EPISODE_DRG.an_drg_version)='"""+drg4_v+"""') AND ((dbo.EPISODE_DRG.episode_start_date)<='"""+end_date+"""') AND ((dbo.EPISODE_DRG.episode_end_date) Is Null) AND ((dbo.EPISODE_DRG.snap_curr_indicator)="Y") AND ((dbo.FACILITY.area_identifier)='"""+lhd+"""') AND ((dbo.FACILITY.snap_curr_indicator)="Y")) OR (((dbo.EPISODE_DRG.facility_identifier)='"""+lhd+"""') AND ((dbo.EPISODE_DRG.an_drg_version)='"""+drg4_v+"""') AND ((dbo.EPISODE_DRG.episode_start_date)<='"""+end_date+"""') AND ((dbo.EPISODE_DRG.episode_end_date)>='"""+start_date+"""') AND ((dbo.EPISODE_DRG.snap_curr_indicator)="Y") AND ((dbo.FACILITY.snap_curr_indicator)="Y"))  OR (((dbo.EPISODE_DRG.facility_identifier)='"""+lhd+"""') AND ((dbo.EPISODE_DRG.an_drg_version)='"""+drg4_v+"""') AND ((dbo.EPISODE_DRG.episode_start_date)<='"""+end_date+"""') AND ((dbo.EPISODE_DRG.episode_end_date) Is Null) AND ((dbo.EPISODE_DRG.snap_curr_indicator)="Y") AND ((dbo.FACILITY.snap_curr_indicator)="Y"));
    label_3_sub.configure(text="In Progress (transit_episode_DRG4)...", fg="blue")
    main_screen.update()
    # OutputEpisodeDrg
    # columns = facility_identifier,stay_number,episode_sequence_number,an_drg_version,episode_start_date,episode_end_date,an_drg,mdc,an_drg_return_cd,an_drg_pccl,an_drg_version_2,an_drg_2,an_drg_version_4,an_drg_4,mdc_2
    # Access query = qry_dbo_episode_DRG
    # dbo_EPISODE_DRG.facility_identifier, dbo_EPISODE_DRG.stay_number, dbo_EPISODE_DRG.episode_sequence_number, dbo_EPISODE_DRG.an_drg_version, dbo_EPISODE_DRG.an_drg, dbo_EPISODE_DRG_1.an_drg_version, dbo_EPISODE_DRG_1.an_drg, dbo_EPISODE_DRG.mdc, dbo_EPISODE_DRG_1.an_drg_pccl, dbo_EPISODE_DRG_1.mdc
    label_3_sub.configure(text="In Progress (EpisodeDrg)...", fg="blue")
    main_screen.update()
    if source == "HIE":
        if len(facilities_excluded_list) == 0:
            query_EpisodeDrg = (
                """SELECT dbo.EPISODE_DRG.facility_identifier, dbo.EPISODE_DRG.stay_number, dbo.EPISODE_DRG.episode_sequence_number, dbo.EPISODE_DRG.an_drg_version, dbo.EPISODE_DRG.episode_start_date, dbo.EPISODE_DRG.episode_end_date, dbo.EPISODE_DRG.an_drg, dbo.EPISODE_DRG.mdc, dbo.EPISODE_DRG.an_drg_return_cd, EPISODE_DRG_1.an_drg_pccl, EPISODE_DRG_1.an_drg_version as an_drg_version_2, EPISODE_DRG_1.an_drg as an_drg_2, EPISODE_DRG_4.an_drg_version as an_drg_version_4, EPISODE_DRG_4.an_drg as an_drg_4, EPISODE_DRG_1.mdc as mdc_2, '' as HLTH_ORG_OSP_OSP_ID, '' as MG_AUTH_OSP_OSP_ID, '' as SE_CBK_SK FROM ((dbo.EPISODE_DRG INNER JOIN dbo.FACILITY ON dbo.EPISODE_DRG.facility_identifier = dbo.FACILITY.facility_identifier) LEFT JOIN dbo.EPISODE_DRG AS EPISODE_DRG_1 ON (dbo.EPISODE_DRG.facility_identifier = EPISODE_DRG_1.facility_identifier) AND (dbo.EPISODE_DRG.stay_number = EPISODE_DRG_1.stay_number) AND (dbo.EPISODE_DRG.episode_sequence_number = EPISODE_DRG_1.episode_sequence_number)) LEFT JOIN dbo.EPISODE_DRG AS EPISODE_DRG_4 ON (dbo.EPISODE_DRG.facility_identifier = EPISODE_DRG_4.facility_identifier) AND (dbo.EPISODE_DRG.stay_number = EPISODE_DRG_4.stay_number) AND (dbo.EPISODE_DRG.episode_sequence_number = EPISODE_DRG_4.episode_sequence_number) WHERE ((((dbo.EPISODE_DRG.facility_identifier)<>"D311" And (dbo.EPISODE_DRG.facility_identifier)<>"Q230") AND ((dbo.EPISODE_DRG.an_drg_version)='"""
                + drg1_v
                + """') AND ((EPISODE_DRG_1.an_drg_version)='"""
                + drg2_v
                + """' Or (EPISODE_DRG_1.an_drg_version) Is Null) AND ((EPISODE_DRG_4.an_drg_version)='"""
                + drg4_v
                + """' Or (EPISODE_DRG_4.an_drg_version) Is Null) AND ((dbo.EPISODE_DRG.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_DRG.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.EPISODE_DRG.snap_curr_indicator)='Y') AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((EPISODE_DRG_1.snap_curr_indicator)='Y') AND ((EPISODE_DRG_4.snap_curr_indicator)='Y')) OR (((dbo.EPISODE_DRG.facility_identifier)<>"D311" And (dbo.EPISODE_DRG.facility_identifier)<>"Q230") AND ((dbo.EPISODE_DRG.an_drg_version)='"""
                + drg1_v
                + """') AND ((EPISODE_DRG_1.an_drg_version)='"""
                + drg2_v
                + """' Or (EPISODE_DRG_1.an_drg_version) Is Null) AND ((EPISODE_DRG_4.an_drg_version)='"""
                + drg4_v
                + """' Or (EPISODE_DRG_4.an_drg_version) Is Null) AND ((dbo.EPISODE_DRG.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_DRG.episode_end_date) Is Null) AND ((dbo.EPISODE_DRG.snap_curr_indicator)='Y') AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((EPISODE_DRG_1.snap_curr_indicator)='Y') AND ((EPISODE_DRG_4.snap_curr_indicator)='Y')) OR (((dbo.EPISODE_DRG.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_DRG.an_drg_version)='"""
                + drg1_v
                + """') AND ((EPISODE_DRG_1.an_drg_version)='"""
                + drg2_v
                + """' Or (EPISODE_DRG_1.an_drg_version) Is Null) AND ((EPISODE_DRG_4.an_drg_version)='"""
                + drg4_v
                + """' Or (EPISODE_DRG_4.an_drg_version) Is Null) AND ((dbo.EPISODE_DRG.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_DRG.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.EPISODE_DRG.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((EPISODE_DRG_1.snap_curr_indicator)='Y') AND ((EPISODE_DRG_4.snap_curr_indicator)='Y')) OR (((dbo.EPISODE_DRG.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_DRG.an_drg_version)='"""
                + drg1_v
                + """') AND ((EPISODE_DRG_1.an_drg_version)='"""
                + drg2_v
                + """' Or (EPISODE_DRG_1.an_drg_version) Is Null) AND ((EPISODE_DRG_4.an_drg_version)='"""
                + drg4_v
                + """' Or (EPISODE_DRG_4.an_drg_version) Is Null) AND ((dbo.EPISODE_DRG.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_DRG.episode_end_date) Is Null) AND ((dbo.EPISODE_DRG.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((EPISODE_DRG_1.snap_curr_indicator)='Y') AND ((EPISODE_DRG_4.snap_curr_indicator)='Y')));"""
            )
        else:
            query_EpisodeDrg = (
                """SELECT dbo.EPISODE_DRG.facility_identifier, dbo.EPISODE_DRG.stay_number, dbo.EPISODE_DRG.episode_sequence_number, dbo.EPISODE_DRG.an_drg_version, dbo.EPISODE_DRG.episode_start_date, dbo.EPISODE_DRG.episode_end_date, dbo.EPISODE_DRG.an_drg, dbo.EPISODE_DRG.mdc, dbo.EPISODE_DRG.an_drg_return_cd, EPISODE_DRG_1.an_drg_pccl, EPISODE_DRG_1.an_drg_version as an_drg_version_2, EPISODE_DRG_1.an_drg as an_drg_2, EPISODE_DRG_4.an_drg_version as an_drg_version_4, EPISODE_DRG_4.an_drg as an_drg_4, EPISODE_DRG_1.mdc as mdc_2, '' as HLTH_ORG_OSP_OSP_ID, '' as MG_AUTH_OSP_OSP_ID, '' as SE_CBK_SK FROM ((dbo.EPISODE_DRG INNER JOIN dbo.FACILITY ON dbo.EPISODE_DRG.facility_identifier = dbo.FACILITY.facility_identifier) LEFT JOIN dbo.EPISODE_DRG AS EPISODE_DRG_1 ON (dbo.EPISODE_DRG.facility_identifier = EPISODE_DRG_1.facility_identifier) AND (dbo.EPISODE_DRG.stay_number = EPISODE_DRG_1.stay_number) AND (dbo.EPISODE_DRG.episode_sequence_number = EPISODE_DRG_1.episode_sequence_number)) LEFT JOIN dbo.EPISODE_DRG AS EPISODE_DRG_4 ON (dbo.EPISODE_DRG.facility_identifier = EPISODE_DRG_4.facility_identifier) AND (dbo.EPISODE_DRG.stay_number = EPISODE_DRG_4.stay_number) AND (dbo.EPISODE_DRG.episode_sequence_number = EPISODE_DRG_4.episode_sequence_number) WHERE ((((dbo.EPISODE_DRG.facility_identifier)<>"D311" And (dbo.EPISODE_DRG.facility_identifier)<>"Q230") AND ((dbo.EPISODE_DRG.an_drg_version)='"""
                + drg1_v
                + """') AND ((EPISODE_DRG_1.an_drg_version)='"""
                + drg2_v
                + """' Or (EPISODE_DRG_1.an_drg_version) Is Null) AND ((EPISODE_DRG_4.an_drg_version)='"""
                + drg4_v
                + """' Or (EPISODE_DRG_4.an_drg_version) Is Null) AND ((dbo.EPISODE_DRG.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_DRG.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.EPISODE_DRG.snap_curr_indicator)='Y') AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((EPISODE_DRG_1.snap_curr_indicator)='Y') AND ((EPISODE_DRG_4.snap_curr_indicator)='Y')) OR (((dbo.EPISODE_DRG.facility_identifier)<>"D311" And (dbo.EPISODE_DRG.facility_identifier)<>"Q230") AND ((dbo.EPISODE_DRG.an_drg_version)='"""
                + drg1_v
                + """') AND ((EPISODE_DRG_1.an_drg_version)='"""
                + drg2_v
                + """' Or (EPISODE_DRG_1.an_drg_version) Is Null) AND ((EPISODE_DRG_4.an_drg_version)='"""
                + drg4_v
                + """' Or (EPISODE_DRG_4.an_drg_version) Is Null) AND ((dbo.EPISODE_DRG.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_DRG.episode_end_date) Is Null) AND ((dbo.EPISODE_DRG.snap_curr_indicator)='Y') AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((EPISODE_DRG_1.snap_curr_indicator)='Y') AND ((EPISODE_DRG_4.snap_curr_indicator)='Y')) OR (((dbo.EPISODE_DRG.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_DRG.an_drg_version)='"""
                + drg1_v
                + """') AND ((EPISODE_DRG_1.an_drg_version)='"""
                + drg2_v
                + """' Or (EPISODE_DRG_1.an_drg_version) Is Null) AND ((EPISODE_DRG_4.an_drg_version)='"""
                + drg4_v
                + """' Or (EPISODE_DRG_4.an_drg_version) Is Null) AND ((dbo.EPISODE_DRG.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_DRG.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.EPISODE_DRG.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((EPISODE_DRG_1.snap_curr_indicator)='Y') AND ((EPISODE_DRG_4.snap_curr_indicator)='Y')) OR (((dbo.EPISODE_DRG.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_DRG.an_drg_version)='"""
                + drg1_v
                + """') AND ((EPISODE_DRG_1.an_drg_version)='"""
                + drg2_v
                + """' Or (EPISODE_DRG_1.an_drg_version) Is Null) AND ((EPISODE_DRG_4.an_drg_version)='"""
                + drg4_v
                + """' Or (EPISODE_DRG_4.an_drg_version) Is Null) AND ((dbo.EPISODE_DRG.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_DRG.episode_end_date) Is Null) AND ((dbo.EPISODE_DRG.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((EPISODE_DRG_1.snap_curr_indicator)='Y') AND ((EPISODE_DRG_4.snap_curr_indicator)='Y'))) AND dbo.FACILITY.facility_identifier NOT IN ("""
                + facilities_excluded
                + """);"""
            )
    elif source == "EDW":
        if len(facilities_included_list) > 0:
            query_EpisodeDrg = (
                """SELECT DISTINCT D.facility_identifier,RIGHT(CONCAT('00000000', ISNULL(SUBSTRING(a.SRV_ENC_REC_ID,charindex('-',a.SRV_ENC_REC_ID)+1,8),'')), 8) as stay_number,a.SEQ_AP_SE_IN_ENC as episode_sequence_number
			,CASE WHEN '"""
                + drg1_v
                + """' = '11.0' THEN '11.0'
				  WHEN '"""
                + drg1_v
                + """' = '10.0' THEN '10.0'
				  WHEN '"""
                + drg1_v
                + """' = '9.0' THEN '9.0'
				  WHEN '"""
                + drg1_v
                + """' = '8.0' THEN '8.0'
				  WHEN '"""
                + drg1_v
                + """' = '7.0' THEN '7.0'
				  WHEN '"""
                + drg1_v
                + """' = '6.0' THEN '6.0' end as an_drg_version,CAST(a.SE_ST_DTTM as date) as episode_start_date,CAST(a.SE_END_DTTM as date) as episode_end_date,CASE WHEN '"""
                + drg1_v
                + """' = '11.0' THEN COALESCE(NULLIF(a.AR_DRG_V11_CD,''), '960Z')
				  WHEN '"""
                + drg1_v
                + """' = '10.0' THEN COALESCE(NULLIF(a.AR_DRG_V10_CD,''), '960Z')
				  WHEN '"""
                + drg1_v
                + """' = '9.0' THEN COALESCE(NULLIF(a.AR_DRG_V9_CD,''), '960Z')
				  WHEN '"""
                + drg1_v
                + """' = '8.0' THEN COALESCE(NULLIF(a.AR_DRG_V8_CD,''), '960Z')
				  WHEN '"""
                + drg1_v
                + """' = '7.0' THEN COALESCE(NULLIF(a.AR_DRG_V7_CD,''), '960Z')
				  WHEN '"""
                + drg1_v
                + """' = '6.0' THEN COALESCE(NULLIF(a.AR_DRG_V6_CD,''), '960Z') end as an_drg,CASE WHEN '"""
                + drg1_v
                + """' = '11.0' THEN A.MDC_v11_CD
				  WHEN '"""
                + drg1_v
                + """' = '10.0' THEN A.MDC_v10_CD
				  WHEN '"""
                + drg1_v
                + """' = '9.0' THEN A.MDC_v9_CD
				  WHEN '"""
                + drg1_v
                + """' = '8.0' THEN A.MDC_v8_CD
				  WHEN '"""
                + drg1_v
                + """' = '7.0' THEN A.MDC_v7_CD
				  WHEN '"""
                + drg1_v
                + """' = '6.0' THEN A.MDC_v6_CD end as mdc,'' as an_drg_return_cd,'' as an_drg_pccl,CASE WHEN '"""
                + drg2_v
                + """' = '11.0' THEN '11.0'
				  WHEN '"""
                + drg2_v
                + """' = '10.0' THEN '10.0'
				  WHEN '"""
                + drg2_v
                + """' = '9.0' THEN '9.0'
				  WHEN '"""
                + drg2_v
                + """' = '8.0' THEN '8.0'
				  WHEN '"""
                + drg2_v
                + """' = '7.0' THEN '7.0'
				  WHEN '"""
                + drg2_v
                + """' = '6.0' THEN '6.0' end as an_drg_version_2,CASE WHEN '"""
                + drg2_v
                + """' = '11.0' THEN COALESCE(NULLIF(a.AR_DRG_V11_CD,''), '960Z')
				  WHEN '"""
                + drg2_v
                + """' = '10.0' THEN COALESCE(NULLIF(a.AR_DRG_V10_CD,''), '960Z')
				  WHEN '"""
                + drg2_v
                + """' = '9.0' THEN COALESCE(NULLIF(a.AR_DRG_V9_CD,''), '960Z')
				  WHEN '"""
                + drg2_v
                + """' = '8.0' THEN COALESCE(NULLIF(a.AR_DRG_V8_CD,''), '960Z')
				  WHEN '"""
                + drg2_v
                + """' = '7.0' THEN COALESCE(NULLIF(a.AR_DRG_V7_CD,''), '960Z')
				  WHEN '"""
                + drg2_v
                + """' = '6.0' THEN COALESCE(NULLIF(a.AR_DRG_V6_CD,''), '960Z') end as an_drg_2,CASE WHEN '"""
                + drg4_v
                + """' = '11.0' THEN '11.0'
				  WHEN '"""
                + drg4_v
                + """' = '10.0' THEN '10.0'
				  WHEN '"""
                + drg4_v
                + """' = '9.0' THEN '9.0'
				  WHEN '"""
                + drg4_v
                + """' = '8.0' THEN '8.0'
				  WHEN '"""
                + drg4_v
                + """' = '7.0' THEN '7.0'
				  WHEN '"""
                + drg4_v
                + """' = '6.0' THEN '6.0' end as an_drg_version_4,CASE WHEN '"""
                + drg4_v
                + """' = '11.0' THEN COALESCE(NULLIF(a.AR_DRG_V11_CD,''), '960Z')
				  WHEN '"""
                + drg4_v
                + """' = '10.0' THEN COALESCE(NULLIF(a.AR_DRG_V10_CD,''), '960Z')
				  WHEN '"""
                + drg4_v
                + """' = '9.0' THEN COALESCE(NULLIF(a.AR_DRG_V9_CD,''), '960Z')
				  WHEN '"""
                + drg4_v
                + """' = '8.0' THEN COALESCE(NULLIF(a.AR_DRG_V8_CD,''), '960Z')
				  WHEN '"""
                + drg4_v
                + """' = '7.0' THEN COALESCE(NULLIF(a.AR_DRG_V7_CD,''), '960Z')
				  WHEN '"""
                + drg4_v
                + """' = '6.0' THEN COALESCE(NULLIF(a.AR_DRG_V6_CD,''), '960Z') end as an_drg_4,CASE WHEN '"""
                + drg2_v
                + """' = '11.0' THEN A.MDC_v11_CD
				  WHEN '"""
                + drg2_v
                + """' = '10.0' THEN A.MDC_v10_CD
				  WHEN '"""
                + drg2_v
                + """' = '9.0' THEN A.MDC_v9_CD
				  WHEN '"""
                + drg2_v
                + """' = '8.0' THEN A.MDC_v8_CD
				  WHEN '"""
                + drg2_v
                + """' = '7.0' THEN A.MDC_v7_CD
				  WHEN '"""
                + drg2_v
                + """' = '6.0' THEN A.MDC_v6_CD end as mdc_2,D.OSP_ID as HLTH_ORG_OSP_OSP_ID,D.MG_AUTH_OSP_OSP_ID,A.SE_CBK_SK,C.AR_DRG_ECCS_RAW
			FROM CRT.V_FACT_AP_SE_FLAT AS A	INNER JOIN (SELECT DISTINCT DIM_OSP_SK, OSP_HIE_FAC_ID,HLTH_ORG_OSP_OSP_ID, MG_AUTH_OSP_HLTH_SECTOR_CD, HLTH_ORG_OSP_HLTH_SECTOR_CD, OSP_TYP_CD,HLTH_ORG_OSP_HIE_FAC_ID, MG_AUTH_OSP_HIE_FAC_ID, MG_AUTH_OSP_OSP_ID,case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_HIE_FAC_ID else HLTH_ORG_OSP_HIE_FAC_ID end as facility_identifier, case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_ID else HLTH_ORG_OSP_OSP_ID end as OSP_ID FROM CRT.v_DIM_OSP WHERE OSP_HIE_FAC_ID != '-1' and ((MG_AUTH_OSP_HLTH_SECTOR_CD IN ('1','3')) and (HLTH_ORG_OSP_HLTH_SECTOR_CD IN ('1','3'))) AND HLTH_ORG_OSP_HIE_FAC_ID != '-1' AND HLTH_ORG_OSP_HIE_FAC_ID != '') AS D ON A.DIM_OSP_CREATED_SK = D.DIM_OSP_SK LEFT JOIN CRT.V_FACT_AP_SE_DRG AS C ON A.SE_CBK_SK = C.SE_CBK_SK AND C.AR_DRG_DOM_ID in (SELECT DISTINCT AR_DRG_DOM_ID FROM CRT.v_DIM_AR_DRG WHERE AR_DRG_DOM_VER = '11.0') WHERE d.MG_AUTH_OSP_HIE_FAC_ID = '"""
                + lhd
                + """' AND (CAST(a.SE_ST_DTTM as date) <= '"""
                + end_date
                + """') AND ((CAST(a.SE_end_DTTM as date) >= '"""
                + start_date
                + """') or (a.SE_END_DTTM Is Null)) AND (D.facility_identifier) IN ("""
                + facilities_included
                + """);"""
            )
    retry_flag = True
    retry_count = 0
    while retry_flag and retry_count < 5:
        try:
            logging.info(query_EpisodeDrg)
            tbl_dbo_episode_DRG = pd.read_sql(query_EpisodeDrg, cnxn)
            retry_flag = False
        except Exception as e:
            retry_count = retry_count + 1
            time.sleep(5)
            if retry_count == 5:
                logging.exception("Exception occurred")
                label_3_status = 0
                messagebox.showerror(
                    "SQL Error", "Error extracting EpisodeDrg details\n" + str(e)
                )
                label_3_sub.configure(text="Failed (EpisodeDrg)...", fg="red")
                main_screen.update()
                tbl_dbo_episode_DRG = pd.DataFrame(
                    columns=[
                        "facility_identifier",
                        "stay_number",
                        "episode_sequence_number",
                        "an_drg_version",
                        "episode_start_date",
                        "episode_end_date",
                        "an_drg",
                        "mdc",
                        "an_drg_return_cd",
                        "an_drg_pccl",
                        "an_drg_version_2",
                        "an_drg_2",
                        "an_drg_version_4",
                        "an_drg_4",
                        "mdc_2",
                        "HLTH_ORG_OSP_OSP_ID",
                        "MG_AUTH_OSP_OSP_ID",
                        "SE_CBK_SK",
                        "AR_DRG_ECCS_RAW",
                    ]
                )
                return  # stop extraction
        else:
            tbl_dbo_episode_DRG = tbl_dbo_episode_DRG.fillna("")
            tbl_dbo_episode_DRG = tbl_dbo_episode_DRG[
                [
                    "facility_identifier",
                    "stay_number",
                    "episode_sequence_number",
                    "an_drg_version",
                    "episode_start_date",
                    "episode_end_date",
                    "an_drg",
                    "mdc",
                    "an_drg_return_cd",
                    "an_drg_pccl",
                    "an_drg_version_2",
                    "an_drg_2",
                    "an_drg_version_4",
                    "an_drg_4",
                    "mdc_2",
                    "HLTH_ORG_OSP_OSP_ID",
                    "MG_AUTH_OSP_OSP_ID",
                    "SE_CBK_SK",
                    "AR_DRG_ECCS_RAW",
                ]
            ]
            tbl_dbo_episode_DRG = tbl_dbo_episode_DRG[
                tbl_dbo_episode_DRG["facility_identifier"].isin(
                    facilities_included_list_global
                )
            ]
            tbl_dbo_episode_DRG = tbl_dbo_episode_DRG.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_dbo_episode_DRG = tbl_dbo_episode_DRG.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_dbo_episode_DRG = tbl_dbo_episode_DRG.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_episode_DRG = tbl_dbo_episode_DRG.apply(
                lambda x: x.replace(regex=r"NULL", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_episode_DRG = tbl_dbo_episode_DRG.apply(
                lambda x: x.replace(regex=r"null", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_episode_DRG = tbl_dbo_episode_DRG.apply(
                lambda x: x.replace(regex=r"Null", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_episode_DRG["stay_number"] = (
                tbl_dbo_episode_DRG["stay_number"]
                .astype(str)
                .str.pad(8, side="left", fillchar="0")
            )
            tbl_dbo_episode_DRG["episode_sequence_number"] = (
                tbl_dbo_episode_DRG["episode_sequence_number"]
                .astype(str)
                .str.pad(3, side="left", fillchar="0")
            )
            tbl_dbo_episode_DRG.rename(
                columns={
                    "an_drg_version_2": "2_an_drg_version",
                    "an_drg_2": "2_an_drg",
                    "mdc_2": "2_mdc",
                },
                inplace=True,
            )
            # 15 August 2024
            tbl_dbo_episode_DRG["4_an_drg_version"] = tbl_dbo_episode_DRG[
                "an_drg_version_4"
            ]
            tbl_dbo_episode_DRG["4_an_drg"] = tbl_dbo_episode_DRG["an_drg_4"]
    # Access query: qry_update_episode_DRG4
    # UPDATE tbl_dbo_episode_DRG INNER JOIN tbl_transit_episode_DRG4 ON (tbl_dbo_episode_DRG.episode_sequence_number = tbl_transit_episode_DRG4.episode_sequence_number) AND (tbl_dbo_episode_DRG.stay_number = tbl_transit_episode_DRG4.stay_number) AND (tbl_dbo_episode_DRG.facility_identifier = tbl_transit_episode_DRG4.facility_identifier) SET tbl_dbo_episode_DRG.[4_an_drg_version] = [tbl_transit_episode_DRG4].[4_an_drg_version], tbl_dbo_episode_DRG.[4_an_drg] = [tbl_transit_episode_DRG4].[4_an_drg];
    # dropping duplicate values
    tbl_dbo_episode_DRG.drop_duplicates(keep="last", inplace=True)
    tbl_dbo_episode_DRG.to_csv(
        "./ExtractorDB/OutputEpisodeDrg.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    logging.info("tbl_dbo_episode_DRG=%s", len(tbl_dbo_episode_DRG))
    # 15 August 2024
    tbl_transit_episode_DRG4 = tbl_dbo_episode_DRG.copy()
    tbl_transit_episode_DRG4["stay_number"] = (
        tbl_transit_episode_DRG4["stay_number"].astype(str).str.strip()
    )
    tbl_transit_episode_DRG4["episode_sequence_number"] = (
        tbl_transit_episode_DRG4["episode_sequence_number"].astype(str).str.strip()
    )
    tbl_transit_episode_DRG4["stay_number"] = (
        tbl_transit_episode_DRG4["stay_number"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0")
    )
    tbl_transit_episode_DRG4["episode_sequence_number"] = (
        tbl_transit_episode_DRG4["episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    tbl_transit_episode_DRG4 = tbl_transit_episode_DRG4[
        [
            "facility_identifier",
            "stay_number",
            "episode_sequence_number",
            "4_an_drg_version",
            "4_an_drg",
            "HLTH_ORG_OSP_OSP_ID",
            "MG_AUTH_OSP_OSP_ID",
            "SE_CBK_SK",
        ]
    ]
    tbl_transit_episode_DRG4.drop_duplicates(keep="last", inplace=True)
    tbl_transit_episode_DRG4.to_csv(
        "./ExtractorDB/tbl_transit_episode_DRG4.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    logging.info("tbl_transit_episode_DRG4 =%s", len(tbl_transit_episode_DRG4))
    # qry_DRGS_960Z_Not_in_10
    # Access query: qry_DRGS_960Z_Not_in_10
    # INSERT INTO DRGS_960Z_Not_in_10 ( DRG8, DRG10, Hospital, STN, ESN, EncounterNumber )
    # SELECT Max(IIf([dbo_EPISODE_DRG]![an_drg_version]="8.0",[dbo_EPISODE_DRG]![an_drg])) AS Expr1, Max(IIf([dbo_EPISODE_DRG]![an_drg_version]="10.0",[dbo_EPISODE_DRG]![an_drg])) AS Expr2, dbo_EPISODE_DRG.facility_identifier, "SN" & Trim([stay_number]) AS Expr4, dbo_EPISODE_DRG.episode_sequence_number, [dbo_EPISODE_DRG]![facility_identifier] & "-I-" & Format([dbo_EPISODE_DRG]![stay_number],"00000000") & "-" & Format([dbo_EPISODE_DRG]![episode_sequence_number],"000") AS Expr3
    # FROM dbo_EPISODE_DRG
    # WHERE (((dbo_EPISODE_DRG.an_drg_version) In ("10.0","8.0")))
    # GROUP BY dbo_EPISODE_DRG.facility_identifier, "SN" & Trim([stay_number]), dbo_EPISODE_DRG.episode_sequence_number, [dbo_EPISODE_DRG]![facility_identifier] & "-I-" & Format([dbo_EPISODE_DRG]![stay_number],"00000000") & "-" & Format([dbo_EPISODE_DRG]![episode_sequence_number],"000"), dbo_EPISODE_DRG.episode_end_date
    # HAVING (((Max(IIf([dbo_EPISODE_DRG]![an_drg_version]="8.0",[dbo_EPISODE_DRG]![an_drg])))="960Z") AND ((Max(IIf([dbo_EPISODE_DRG]![an_drg_version]="10.0",[dbo_EPISODE_DRG]![an_drg])))<>"960Z") AND ((dbo_EPISODE_DRG.episode_end_date)>=#7/1/2022#));
    # if str(roundid) in aecc_round_id_list_OLD:
    if str(roundid) in aecc_round_id_list:
        label_3_sub.configure(
            text="In Progress (qry_DRGS_960Z_Not_in_10)...", fg="blue"
        )
        main_screen.update()
        drgs_960Z_Not_in_10 = tbl_dbo_episode_DRG.copy()
        drgs_960Z_Not_in_10["stay_number"] = (
            drgs_960Z_Not_in_10["stay_number"].astype(str).str.strip()
        )
        drgs_960Z_Not_in_10["episode_sequence_number"] = (
            drgs_960Z_Not_in_10["episode_sequence_number"].astype(str).str.strip()
        )
        drgs_960Z_Not_in_10["stay_number"] = (
            drgs_960Z_Not_in_10["stay_number"]
            .astype(str)
            .str.pad(8, side="left", fillchar="0")
        )
        drgs_960Z_Not_in_10["episode_sequence_number"] = (
            drgs_960Z_Not_in_10["episode_sequence_number"]
            .astype(str)
            .str.pad(3, side="left", fillchar="0")
        )
        drgs_960Z_Not_in_10["DRG8"] = "960Z"
        drgs_960Z_Not_in_10["DRG10"] = drgs_960Z_Not_in_10["an_drg"]
        drgs_960Z_Not_in_10["Hospital"] = drgs_960Z_Not_in_10["facility_identifier"]
        drgs_960Z_Not_in_10["EncounterNumber"] = (
            drgs_960Z_Not_in_10["facility_identifier"].astype(str).str.strip()
            + "-I-"
            + drgs_960Z_Not_in_10["stay_number"].astype(str).str.strip()
            + "-"
            + drgs_960Z_Not_in_10["episode_sequence_number"].astype(str).str.strip()
        )
        drgs_960Z_Not_in_10["STN"] = "SN" + drgs_960Z_Not_in_10["stay_number"]
        drgs_960Z_Not_in_10["ESN"] = drgs_960Z_Not_in_10["episode_sequence_number"]
        drgs_960Z_Not_in_10 = drgs_960Z_Not_in_10[
            ["DRG8", "DRG10", "Hospital", "STN", "ESN", "EncounterNumber"]
        ]
    else:
        drgs_960Z_Not_in_10 = pd.DataFrame(
            columns=["DRG8", "DRG10", "Hospital", "STN", "ESN", "EncounterNumber"]
        )
    # dropping duplicate values
    drgs_960Z_Not_in_10.drop_duplicates(keep="last", inplace=True)
    drgs_960Z_Not_in_10.to_csv(
        "./ExtractorDB/drgs_960Z_Not_in_10.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    logging.info("drgs_960Z_Not_in_10=%s", len(drgs_960Z_Not_in_10))
    # OutputWlExit
    # columns = facility_identifier,person_identifier,listing_date,indicated_proc_code,clinical_urg_final_crnt,reason_for_removal,removal_date,waiting_list_category,booking_identifier,admission_identifier,stay_number
    # Access query: qry_dbo_wl_exit
    # SELECT dbo_WL_EXIT.facility_identifier, dbo_WL_EXIT.listing_date, dbo_WL_EXIT.indicated_proc_code, dbo_WL_EXIT.clinical_urg_final_crnt, dbo_WL_EXIT.reason_for_removal, dbo_WL_EXIT.waiting_list_category, dbo_WL_EXIT.booking_identifier, dbo_WL_EXIT.admission_identifier, dbo_WL_EXIT.person_identifier, dbo_WL_EXIT.removal_date
    # is it dbo.EPISODE_ATS.stay_number
    label_3_sub.configure(text="In Progress (WlExit)...", fg="blue")
    main_screen.update()
    if source == "HIE":
        if len(facilities_excluded_list) == 0:
            query_WlExit = (
                """SELECT dbo.WL_EXIT.facility_identifier, dbo.WL_EXIT.person_identifier, dbo.WL_EXIT.listing_date, dbo.WL_EXIT.indicated_proc_code, dbo.WL_EXIT.clinical_urg_final_crnt, dbo.WL_EXIT.reason_for_removal, dbo.WL_EXIT.removal_date, dbo.WL_EXIT.waiting_list_category, dbo.WL_EXIT.booking_identifier, dbo.WL_EXIT.admission_identifier, '' AS stay_number , '' as HLTH_ORG_OSP_OSP_ID, '' as MG_AUTH_OSP_OSP_ID,  '' as SE_CBK_SK, '' AS CL_ID_EUID , '' AS CL_ID_IHI
            FROM ((dbo.WL_EXIT INNER JOIN dbo.FACILITY ON dbo.WL_EXIT.facility_identifier = dbo.FACILITY.facility_identifier) INNER JOIN dbo.STAY ON (dbo.WL_EXIT.removal_date = dbo.STAY.admission_date) AND (dbo.WL_EXIT.facility_identifier = dbo.STAY.facility_identifier) AND (dbo.WL_EXIT.person_identifier = dbo.STAY.person_identifier)) INNER JOIN dbo.EPISODE_ATS ON (dbo.STAY.stay_number = dbo.EPISODE_ATS.stay_number) AND (dbo.STAY.facility_identifier = dbo.EPISODE_ATS.facility_identifier) 
            GROUP BY dbo.WL_EXIT.facility_identifier, dbo.WL_EXIT.listing_date, dbo.WL_EXIT.indicated_proc_code, dbo.WL_EXIT.clinical_urg_final_crnt, dbo.WL_EXIT.reason_for_removal, dbo.WL_EXIT.waiting_list_category, dbo.WL_EXIT.booking_identifier, dbo.WL_EXIT.admission_identifier, dbo.WL_EXIT.person_identifier, dbo.WL_EXIT.removal_date, dbo.WL_EXIT.snap_curr_indicator, dbo.FACILITY.area_identifier, dbo.EPISODE_ATS.snap_curr_indicator, dbo.FACILITY.snap_curr_indicator, dbo.STAY.snap_curr_indicator, dbo.EPISODE_ATS.episode_start_date, dbo.EPISODE_ATS.episode_end_date, dbo.EPISODE_ATS.episode_sequence_number, '' 
            HAVING (((dbo.WL_EXIT.facility_identifier)<>"D311") AND ((dbo.WL_EXIT.reason_for_removal)="1" Or (dbo.WL_EXIT.reason_for_removal)="2") AND ((dbo.WL_EXIT.admission_identifier)<>"") AND ((dbo.WL_EXIT.snap_curr_indicator)="Y") AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.STAY.snap_curr_indicator)="Y") AND ((dbo.EPISODE_ATS.snap_curr_indicator)="Y") AND ((dbo.FACILITY.snap_curr_indicator)="Y") AND ((dbo.EPISODE_ATS.episode_start_date)<=('"""
                + end_date
                + """')) AND ((dbo.EPISODE_ATS.episode_end_date)>=('"""
                + start_date
                + """')) AND ((dbo.EPISODE_ATS.episode_sequence_number)=1)) OR (((dbo.WL_EXIT.facility_identifier)<>"D311") AND ((dbo.WL_EXIT.reason_for_removal)="1" Or (dbo.WL_EXIT.reason_for_removal)="2") AND ((dbo.WL_EXIT.admission_identifier)<>"") AND ((dbo.WL_EXIT.snap_curr_indicator)="Y") AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.STAY.snap_curr_indicator)="Y") AND ((dbo.EPISODE_ATS.snap_curr_indicator)="Y") AND ((dbo.FACILITY.snap_curr_indicator)="Y") AND ((dbo.EPISODE_ATS.episode_start_date)<=('"""
                + end_date
                + """')) AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.EPISODE_ATS.episode_sequence_number)=1)) OR (((dbo.WL_EXIT.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.WL_EXIT.reason_for_removal)="1" Or (dbo.WL_EXIT.reason_for_removal)="2") AND ((dbo.WL_EXIT.admission_identifier)<>"") AND ((dbo.WL_EXIT.snap_curr_indicator)="Y") AND ((dbo.STAY.snap_curr_indicator)="Y") AND ((dbo.EPISODE_ATS.snap_curr_indicator)="Y") AND ((dbo.FACILITY.snap_curr_indicator)="Y") AND ((dbo.EPISODE_ATS.episode_start_date)<=('"""
                + end_date
                + """')) AND ((dbo.EPISODE_ATS.episode_end_date)>=('"""
                + start_date
                + """')) AND ((dbo.EPISODE_ATS.episode_sequence_number)=1)) OR (((dbo.WL_EXIT.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.WL_EXIT.reason_for_removal)="1" Or (dbo.WL_EXIT.reason_for_removal)="2") AND ((dbo.WL_EXIT.admission_identifier)<>"") AND ((dbo.WL_EXIT.snap_curr_indicator)="Y") AND ((dbo.STAY.snap_curr_indicator)="Y") AND ((dbo.EPISODE_ATS.snap_curr_indicator)="Y") AND ((dbo.FACILITY.snap_curr_indicator)="Y") AND ((dbo.EPISODE_ATS.episode_start_date)<=('"""
                + end_date
                + """')) AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.EPISODE_ATS.episode_sequence_number)=1));"""
            )
        else:
            query_WlExit = (
                """SELECT dbo.WL_EXIT.facility_identifier, dbo.WL_EXIT.person_identifier, dbo.WL_EXIT.listing_date, dbo.WL_EXIT.indicated_proc_code, dbo.WL_EXIT.clinical_urg_final_crnt, dbo.WL_EXIT.reason_for_removal, dbo.WL_EXIT.removal_date, dbo.WL_EXIT.waiting_list_category, dbo.WL_EXIT.booking_identifier, dbo.WL_EXIT.admission_identifier, '' AS stay_number, '' as HLTH_ORG_OSP_OSP_ID, '' as MG_AUTH_OSP_OSP_ID, '' as SE_CBK_SK, '' AS CL_ID_EUID , '' AS CL_ID_IHI
            FROM ((dbo.WL_EXIT INNER JOIN dbo.FACILITY ON dbo.WL_EXIT.facility_identifier = dbo.FACILITY.facility_identifier) INNER JOIN dbo.STAY ON (dbo.WL_EXIT.removal_date = dbo.STAY.admission_date) AND (dbo.WL_EXIT.facility_identifier = dbo.STAY.facility_identifier) AND (dbo.WL_EXIT.person_identifier = dbo.STAY.person_identifier)) INNER JOIN dbo.EPISODE_ATS ON (dbo.STAY.stay_number = dbo.EPISODE_ATS.stay_number) AND (dbo.STAY.facility_identifier = dbo.EPISODE_ATS.facility_identifier) WHERE dbo.FACILITY.facility_identifier NOT IN ("""
                + facilities_excluded
                + """) 
            GROUP BY dbo.WL_EXIT.facility_identifier, dbo.WL_EXIT.listing_date, dbo.WL_EXIT.indicated_proc_code, dbo.WL_EXIT.clinical_urg_final_crnt, dbo.WL_EXIT.reason_for_removal, dbo.WL_EXIT.waiting_list_category, dbo.WL_EXIT.booking_identifier, dbo.WL_EXIT.admission_identifier, dbo.WL_EXIT.person_identifier, dbo.WL_EXIT.removal_date, dbo.WL_EXIT.snap_curr_indicator, dbo.FACILITY.area_identifier, dbo.EPISODE_ATS.snap_curr_indicator, dbo.FACILITY.snap_curr_indicator, dbo.STAY.snap_curr_indicator, dbo.EPISODE_ATS.episode_start_date, dbo.EPISODE_ATS.episode_end_date, dbo.EPISODE_ATS.episode_sequence_number, ''
            HAVING (((dbo.WL_EXIT.facility_identifier)<>"D311") AND ((dbo.WL_EXIT.reason_for_removal)="1" Or (dbo.WL_EXIT.reason_for_removal)="2") AND ((dbo.WL_EXIT.admission_identifier)<>"") AND ((dbo.WL_EXIT.snap_curr_indicator)="Y") AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.STAY.snap_curr_indicator)="Y") AND ((dbo.EPISODE_ATS.snap_curr_indicator)="Y") AND ((dbo.FACILITY.snap_curr_indicator)="Y") AND ((dbo.EPISODE_ATS.episode_start_date)<=('"""
                + end_date
                + """')) AND ((dbo.EPISODE_ATS.episode_end_date)>=('"""
                + start_date
                + """')) AND ((dbo.EPISODE_ATS.episode_sequence_number)=1)) OR (((dbo.WL_EXIT.facility_identifier)<>"D311") AND ((dbo.WL_EXIT.reason_for_removal)="1" Or (dbo.WL_EXIT.reason_for_removal)="2") AND ((dbo.WL_EXIT.admission_identifier)<>"") AND ((dbo.WL_EXIT.snap_curr_indicator)="Y") AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.STAY.snap_curr_indicator)="Y") AND ((dbo.EPISODE_ATS.snap_curr_indicator)="Y") AND ((dbo.FACILITY.snap_curr_indicator)="Y") AND ((dbo.EPISODE_ATS.episode_start_date)<=('"""
                + end_date
                + """')) AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.EPISODE_ATS.episode_sequence_number)=1)) OR (((dbo.WL_EXIT.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.WL_EXIT.reason_for_removal)="1" Or (dbo.WL_EXIT.reason_for_removal)="2") AND ((dbo.WL_EXIT.admission_identifier)<>"") AND ((dbo.WL_EXIT.snap_curr_indicator)="Y") AND ((dbo.STAY.snap_curr_indicator)="Y") AND ((dbo.EPISODE_ATS.snap_curr_indicator)="Y") AND ((dbo.FACILITY.snap_curr_indicator)="Y") AND ((dbo.EPISODE_ATS.episode_start_date)<=('"""
                + end_date
                + """')) AND ((dbo.EPISODE_ATS.episode_end_date)>=('"""
                + start_date
                + """')) AND ((dbo.EPISODE_ATS.episode_sequence_number)=1)) OR (((dbo.WL_EXIT.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.WL_EXIT.reason_for_removal)="1" Or (dbo.WL_EXIT.reason_for_removal)="2") AND ((dbo.WL_EXIT.admission_identifier)<>"") AND ((dbo.WL_EXIT.snap_curr_indicator)="Y") AND ((dbo.STAY.snap_curr_indicator)="Y") AND ((dbo.EPISODE_ATS.snap_curr_indicator)="Y") AND ((dbo.FACILITY.snap_curr_indicator)="Y") AND ((dbo.EPISODE_ATS.episode_start_date)<=('"""
                + end_date
                + """')) AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.EPISODE_ATS.episode_sequence_number)=1));"""
            )
    elif source == "EDW":
        if len(facilities_included_list) > 0:
            query_WlExit = (
                """SELECT DISTINCT K.facility_identifier,D.CL_ID_AUID as person_identifier,a.WL_LISTING_DT as listing_date,a.PLN_SRV_INTVN_IPC_PRIM_CD as indicated_proc_code,a.WL_BKG_LST_RFC_PRTY_CLN_PRTY_CD as clinical_urg_final_crnt,a.WL_REMOVAL_REASON_CD as reason_for_removal,CAST(a.WL_REMOVAL_DTTM as date) as removal_date,a.WL_BKG_PRTY_CLN_PRTY_CD as waiting_list_category,a.WL_BKG_REC_ID as booking_identifier,RIGHT(CONCAT('00000000', ISNULL(SUBSTRING(C.SRV_ENC_REC_ID,charindex('-',C.SRV_ENC_REC_ID)+1,8),'')), 8) as admission_identifier,'' as stay_number,K.OSP_ID as HLTH_ORG_OSP_OSP_ID
			,K.MG_AUTH_OSP_OSP_ID,D.SE_CBK_SK,D.CL_ID_EUID,D.CL_ID_IHI FROM CRT.v_FACT_WL_BKG as a LEFT JOIN CRT.v_FACT_AP_SE as c ON c.RLTD_WL_BKG_CBK_SK  = a.WL_BKG_CBK_SK AND CAST(a.WL_REMOVAL_DTTM as date) = CAST(c.FRML_ADM_DTTM as DATE) LEFT JOIN CRT.V_FACT_AP_SE_FLAT as d on C.SE_CBK_SK = d.SE_CBK_SK 
			INNER JOIN (SELECT DISTINCT DIM_OSP_SK, OSP_HIE_FAC_ID,HLTH_ORG_OSP_OSP_ID, MG_AUTH_OSP_HLTH_SECTOR_CD, HLTH_ORG_OSP_HLTH_SECTOR_CD, OSP_TYP_CD,HLTH_ORG_OSP_HIE_FAC_ID, MG_AUTH_OSP_HIE_FAC_ID, MG_AUTH_OSP_OSP_ID,case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_ID else HLTH_ORG_OSP_OSP_ID end as OSP_ID,case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_HIE_FAC_ID else HLTH_ORG_OSP_HIE_FAC_ID end as facility_identifier FROM CRT.v_DIM_OSP WHERE ((MG_AUTH_OSP_HLTH_SECTOR_CD IN ('1','3')) and (HLTH_ORG_OSP_HLTH_SECTOR_CD IN ('1','3'))) AND HLTH_ORG_OSP_HIE_FAC_ID != '-1' AND HLTH_ORG_OSP_HIE_FAC_ID != '') AS K ON D.DIM_OSP_CREATED_SK = K.DIM_OSP_SK WHERE (((a.WL_REMOVAL_REASON_CD)='01' Or (a.WL_REMOVAL_REASON_CD)='02') AND ((C.SRV_ENC_REC_ID) != '') AND ((K.MG_AUTH_OSP_HIE_FAC_ID) ='"""
                + lhd
                + """') AND ((CAST(c.SE_ST_DTTM as date))<=('"""
                + end_date
                + """')) AND ((CAST(c.SE_end_DTTM as date) >= '"""
                + start_date
                + """') or (c.SE_end_DTTM IS NULL)) AND ((c.SEQ_AP_SE_IN_ENC)=1)) AND (K.facility_identifier) IN ("""
                + facilities_included
                + """);"""
            )
    """ 
    # WL_BKG access has been revoked.
    retry_flag = True
    retry_count = 0  
    while retry_flag and retry_count < 5:
        try:
            logging.info(query_WlExit)
            tbl_dbo_wl_exit = pd.read_sql(query_WlExit, cnxn)
            retry_flag = False
        except Exception as e:
            retry_count = retry_count + 1
            time.sleep(5)
            if retry_count==5:
                logging.exception("Exception occurred")
                label_3_status = 0
                messagebox.showerror("SQL Error","Error extracting WlExit details\n"+str(e))
                label_3_sub.configure(text="Failed (WlExit)...",fg='red')
                main_screen.update()
                tbl_dbo_wl_exit = pd.DataFrame(columns=['facility_identifier', 'person_identifier', 'listing_date', 'indicated_proc_code', 'clinical_urg_final_crnt', 'reason_for_removal', 'removal_date', 'waiting_list_category', 'booking_identifier', 'admission_identifier', 'stay_number', 'HLTH_ORG_OSP_OSP_ID', 'MG_AUTH_OSP_OSP_ID', 'SE_CBK_SK', 'CL_ID_EUID', 'CL_ID_IHI'])
                return # stop extraction
        else:
            tbl_dbo_wl_exit= tbl_dbo_wl_exit.fillna("")
            tbl_dbo_wl_exit = tbl_dbo_wl_exit[['facility_identifier', 'person_identifier', 'listing_date', 'indicated_proc_code', 'clinical_urg_final_crnt', 'reason_for_removal', 'removal_date', 'waiting_list_category', 'booking_identifier', 'admission_identifier', 'stay_number', 'HLTH_ORG_OSP_OSP_ID', 'MG_AUTH_OSP_OSP_ID', 'SE_CBK_SK', 'CL_ID_EUID', 'CL_ID_IHI']]
            tbl_dbo_wl_exit = tbl_dbo_wl_exit[tbl_dbo_wl_exit['facility_identifier'].isin(facilities_included_list_global)]
            tbl_dbo_wl_exit = tbl_dbo_wl_exit.applymap(str)#.apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_dbo_wl_exit = tbl_dbo_wl_exit.applymap(lambda x: x.strip() if isinstance(x, str) else x)
            tbl_dbo_wl_exit = tbl_dbo_wl_exit.apply(lambda x: x.replace(regex=r'^NaT$', value='') if x.dtype == 'object' else x)
            tbl_dbo_wl_exit = tbl_dbo_wl_exit.apply(lambda x: x.replace(regex=r'NULL', value='') if x.dtype == 'object' else x)
            tbl_dbo_wl_exit = tbl_dbo_wl_exit.apply(lambda x: x.replace(regex=r'null', value='') if x.dtype == 'object' else x)
            tbl_dbo_wl_exit = tbl_dbo_wl_exit.apply(lambda x: x.replace(regex=r'Null', value='') if x.dtype == 'object' else x)
            # dropping duplicate values 
            tbl_dbo_wl_exit.drop_duplicates(keep='last', inplace=True) 
            tbl_dbo_wl_exit.to_csv('./ExtractorDB/OutputWlExit.csv', index=False, na_rep='', float_format=str, decimal=str, date_format=str)
            logging.info("tbl_dbo_wl_exit=%s",len(tbl_dbo_wl_exit))
    """
    # Because WL_BKG access was revoked before v1.16.1 (R29), create a dummy WL_BKG file
    tbl_dbo_wl_exit = pd.DataFrame(
        columns=[
            "facility_identifier",
            "person_identifier",
            "listing_date",
            "indicated_proc_code",
            "clinical_urg_final_crnt",
            "reason_for_removal",
            "removal_date",
            "waiting_list_category",
            "booking_identifier",
            "admission_identifier",
            "stay_number",
            "HLTH_ORG_OSP_OSP_ID",
            "MG_AUTH_OSP_OSP_ID",
            "SE_CBK_SK",
            "CL_ID_EUID",
            "CL_ID_IHI",
        ]
    )
    tbl_dbo_wl_exit.to_csv(
        "./ExtractorDB/OutputWlExit.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    logging.info("tbl_dbo_wl_exit=%s", len(tbl_dbo_wl_exit))

    # Update Sub task 1 status
    if label_3_status == 0:
        label_3_sub.configure(text="Failed", fg="red")
        main_screen.update()
    else:
        label_3_sub.configure(text="Completed", fg="green")
        main_screen.update()
    # label_3_res.configure(text="EpisodeAts:"+str(len(tbl_dbo_episode_ats))+", WardEpisode:"+str(len(tbl_dbo_Ward_Episode))+",  Episode:"+str(len(tbl_dbo_episode))+"\nEpisodeSrg:"+str(len(tbl_dbo_episode_srg))+",  EpisodeDrg:"+str(len(tbl_dbo_episode_DRG))+",  WlExit:"+str(len(tbl_dbo_wl_exit))+", drgs_960Z_Not_in_10:"+str(len(drgs_960Z_Not_in_10)))
    main_screen.update()
    ################################# ADDITIONAL
    """ Makes table from data in tbl_dbo_episode, tbl_dbo_episode_ats and tbl_dbo_episode_DRG into Episode ATS end date update.
    Where enddate is null in tbl_dbo_episode_ats And enddate is not null in tbl_dbo_episode_ats And an_drg <> 960Z in tbl_dbo_episode_DRG
    This table is created because an issue in HIE Updates from source systems where the enddate and endtime in the Episode_ATS table is null while in the episode table is populated. To ensure that the episode has ended the coding of the data is also taken into account and only coded DRGs are loaded into the table this prevents the issue where the Episode ATS table was right 
    and the populated Episode table should have had a null date and time."""
    # Access query: mt Episode ATS end date update -
    # SELECT tbl_dbo_episode_ats.episode_end_date, tbl_dbo_episode.facility_identifier, tbl_dbo_episode.stay_number, tbl_dbo_episode.episode_sequence_number, tbl_dbo_episode.enddate, tbl_dbo_episode.endtime, tbl_dbo_episode_DRG.an_drg, tbl_dbo_Facility.area_identifier INTO [Episode ATS end date update] FROM ((tbl_dbo_episode INNER JOIN tbl_dbo_episode_ats ON (tbl_dbo_episode.episode_sequence_number = tbl_dbo_episode_ats.episode_sequence_number) AND (tbl_dbo_episode.stay_number = tbl_dbo_episode_ats.stay_number) AND (tbl_dbo_episode.facility_identifier = tbl_dbo_episode_ats.facility_identifier)) LEFT JOIN tbl_dbo_episode_DRG ON (tbl_dbo_episode_ats.episode_sequence_number = tbl_dbo_episode_DRG.episode_sequence_number) AND (tbl_dbo_episode_ats.stay_number = tbl_dbo_episode_DRG.stay_number) AND (tbl_dbo_episode_ats.facility_identifier = tbl_dbo_episode_DRG.facility_identifier)) INNER JOIN tbl_dbo_Facility ON tbl_dbo_episode_ats.facility_identifier = tbl_dbo_Facility.facility_identifier WHERE (((tbl_dbo_episode_ats.episode_end_date) Is Null) AND ((tbl_dbo_episode.enddate) Is Not Null) AND ((tbl_dbo_episode_DRG.an_drg)<>"960Z")) OR (((tbl_dbo_episode_ats.episode_end_date) Is Null) AND ((tbl_dbo_episode.enddate) Is Not Null) AND ((tbl_dbo_Facility.area_identifier) In ("X630","X700","X710","X760","X810","X820")));
    if (
        len(tbl_dbo_episode) > 0
        and len(tbl_dbo_episode_ats) > 0
        and len(tbl_dbo_Facility) > 0
    ):  # and len(tbl_dbo_episode_DRG) > 0 (excluded this as it is a left join)
        tbl_Episode_ATS_end_date_update = (
            pd.merge(
                tbl_dbo_episode[
                    [
                        "episode_sequence_number",
                        "stay_number",
                        "facility_identifier",
                        "enddate",
                        "endtime",
                    ]
                ],
                tbl_dbo_episode_ats[
                    [
                        "episode_sequence_number",
                        "stay_number",
                        "facility_identifier",
                        "episode_end_date",
                    ]
                ],
                how="inner",
                on=["episode_sequence_number", "stay_number", "facility_identifier"],
                suffixes=("", "_drop"),
            )
            .merge(
                tbl_dbo_episode_DRG[
                    [
                        "episode_sequence_number",
                        "stay_number",
                        "facility_identifier",
                        "an_drg",
                    ]
                ],
                how="left",
                on=["episode_sequence_number", "stay_number", "facility_identifier"],
                suffixes=("", "_drop"),
            )
            .merge(
                tbl_dbo_Facility[["facility_identifier", "area_identifier"]],
                how="inner",
                on="facility_identifier",
                suffixes=("", "_drop"),
            )
        )
        tbl_Episode_ATS_end_date_update = tbl_Episode_ATS_end_date_update.apply(
            lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
        )
        tbl_Episode_ATS_end_date_update = tbl_Episode_ATS_end_date_update[
            [
                "episode_end_date",
                "facility_identifier",
                "stay_number",
                "episode_sequence_number",
                "enddate",
                "endtime",
                "an_drg",
                "area_identifier",
            ]
        ]
        tbl_Episode_ATS_end_date_update = tbl_Episode_ATS_end_date_update[
            (
                (
                    (pd.isna(tbl_Episode_ATS_end_date_update["episode_end_date"]))
                    | (tbl_Episode_ATS_end_date_update["episode_end_date"].isnull())
                    | (tbl_Episode_ATS_end_date_update["episode_end_date"] == "")
                )
                & (pd.notna(tbl_Episode_ATS_end_date_update["enddate"]))
                & (tbl_Episode_ATS_end_date_update["enddate"] != "")
                & (tbl_Episode_ATS_end_date_update["an_drg"] != "960Z")
            )
            | (
                (
                    (pd.isna(tbl_Episode_ATS_end_date_update["episode_end_date"]))
                    | (tbl_Episode_ATS_end_date_update["episode_end_date"].isnull())
                    | (tbl_Episode_ATS_end_date_update["episode_end_date"] == "")
                )
                & (pd.notna(tbl_Episode_ATS_end_date_update["enddate"]))
                & (tbl_Episode_ATS_end_date_update["enddate"] != "")
                & (
                    tbl_Episode_ATS_end_date_update["area_identifier"].isin(
                        ["X630", "X700", "X710", "X760", "X810", "X820"]
                    )
                )
            )
        ]
    else:
        tbl_Episode_ATS_end_date_update = pd.DataFrame(
            columns=[
                "episode_end_date",
                "facility_identifier",
                "stay_number",
                "episode_sequence_number",
                "enddate",
                "endtime",
                "an_drg",
                "area_identifier",
            ]
        )
    tbl_Episode_ATS_end_date_update = tbl_Episode_ATS_end_date_update.fillna("")
    tbl_Episode_ATS_end_date_update = tbl_Episode_ATS_end_date_update[
        tbl_Episode_ATS_end_date_update["area_identifier"] == lhd
    ]
    tbl_Episode_ATS_end_date_update = tbl_Episode_ATS_end_date_update[
        tbl_Episode_ATS_end_date_update["facility_identifier"].isin(
            facilities_included_list_global
        )
    ]
    tbl_Episode_ATS_end_date_update = tbl_Episode_ATS_end_date_update.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    tbl_Episode_ATS_end_date_update = tbl_Episode_ATS_end_date_update.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    tbl_Episode_ATS_end_date_update = tbl_Episode_ATS_end_date_update.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    tbl_Episode_ATS_end_date_update = tbl_Episode_ATS_end_date_update.apply(
        lambda x: x.replace(regex=r"NULL", value="") if x.dtype == "object" else x
    )
    tbl_Episode_ATS_end_date_update = tbl_Episode_ATS_end_date_update.apply(
        lambda x: x.replace(regex=r"null", value="") if x.dtype == "object" else x
    )
    tbl_Episode_ATS_end_date_update = tbl_Episode_ATS_end_date_update.apply(
        lambda x: x.replace(regex=r"Null", value="") if x.dtype == "object" else x
    )
    tbl_Episode_ATS_end_date_update["stay_number"] = (
        tbl_Episode_ATS_end_date_update["stay_number"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0")
    )
    tbl_Episode_ATS_end_date_update["episode_sequence_number"] = (
        tbl_Episode_ATS_end_date_update["episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    # dropping duplicate values
    tbl_Episode_ATS_end_date_update.drop_duplicates(keep="last", inplace=True)
    tbl_Episode_ATS_end_date_update.to_csv(
        "./ExtractorDB/tbl_Episode_ATS_end_date_update.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    logging.info(
        "Query: mt Episode ATS end date update completed.tbl_Episode_ATS_end_date_update=%s",
        len(tbl_Episode_ATS_end_date_update),
    )
    # there is a comment below this access query that we need to include LOS updates
    """Updates the tbl_dbo_episode_ats enddate and endtime from the fields of the same name in the Episode ATS end date update table """
    # Access query: update tbl_dbo_episode_ats -
    # UPDATE [Episode ATS end date update] INNER JOIN tbl_dbo_episode_ats ON ([Episode ATS end date update].episode_sequence_number = tbl_dbo_episode_ats.episode_sequence_number) AND ([Episode ATS end date update].stay_number = tbl_dbo_episode_ats.stay_number) AND ([Episode ATS end date update].facility_identifier = tbl_dbo_episode_ats.facility_identifier) SET tbl_dbo_episode_ats.episode_end_date = [enddate], tbl_dbo_episode_ats.episode_end_time = [endtime];
    if len(tbl_Episode_ATS_end_date_update) > 0 and len(tbl_dbo_episode_ats) > 0:
        tbl_dbo_episode_ats = tbl_dbo_episode_ats.merge(
            tbl_Episode_ATS_end_date_update[
                [
                    "facility_identifier",
                    "stay_number",
                    "episode_sequence_number",
                    "enddate",
                    "endtime",
                ]
            ],
            on=["facility_identifier", "stay_number", "episode_sequence_number"],
            how="left",
            suffixes=("", "_drop"),
            indicator=True,
        )
        tbl_dbo_episode_ats["episode_end_date"] = np.where(
            tbl_dbo_episode_ats["_merge"] == "both",
            tbl_dbo_episode_ats["enddate"],
            tbl_dbo_episode_ats["episode_end_date"],
        )
        tbl_dbo_episode_ats["episode_end_time"] = np.where(
            tbl_dbo_episode_ats["_merge"] == "both",
            tbl_dbo_episode_ats["endtime"],
            tbl_dbo_episode_ats["episode_end_time"],
        )
        # drop enddate, endtime columns from tbl_dbo_episode_ats
        tbl_dbo_episode_ats.drop(["enddate", "endtime", "_merge"], inplace=True, axis=1)
        tbl_dbo_episode_ats = tbl_dbo_episode_ats.fillna("")
        tbl_dbo_episode_ats = tbl_dbo_episode_ats[
            tbl_dbo_episode_ats["area_identifier"] == lhd
        ]
        tbl_dbo_episode_ats = tbl_dbo_episode_ats[
            tbl_dbo_episode_ats["facility_identifier"].isin(
                facilities_included_list_global
            )
        ]
        tbl_dbo_episode_ats = tbl_dbo_episode_ats.applymap(
            str
        )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
        tbl_dbo_episode_ats = tbl_dbo_episode_ats.applymap(
            lambda x: x.strip() if isinstance(x, str) else x
        )
        tbl_dbo_episode_ats = tbl_dbo_episode_ats.apply(
            lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
        )
        tbl_dbo_episode_ats = tbl_dbo_episode_ats.apply(
            lambda x: x.replace(regex=r"NULL", value="") if x.dtype == "object" else x
        )
        tbl_dbo_episode_ats = tbl_dbo_episode_ats.apply(
            lambda x: x.replace(regex=r"null", value="") if x.dtype == "object" else x
        )
        tbl_dbo_episode_ats = tbl_dbo_episode_ats.apply(
            lambda x: x.replace(regex=r"Null", value="") if x.dtype == "object" else x
        )
        # dropping duplicate values
        tbl_dbo_episode_ats.drop_duplicates(keep="last", inplace=True)
        tbl_dbo_episode_ats.to_csv(
            "./ExtractorDB/OutputEpisodeAts.csv",
            index=False,
            na_rep="",
            float_format=str,
            decimal=str,
            date_format=str,
        )
        logging.info(
            "Query: tbl_dbo_episode_ats completed.tbl_dbo_episode_ats created with %s records and saved to ./ExtractorDB/OutputEpisodeAts.csv.",
            len(tbl_dbo_episode_ats),
        )
    # Access query:  Update WIP 0
    # UPDATE tbl_dbo_episode_ats SET tbl_dbo_episode_ats.WIP = "0" WHERE (((tbl_dbo_episode_ats.WIP) Is Null) AND ((tbl_dbo_episode_ats.episode_start_date)<[Forms]![Frm:1-ExtractSetUp]![Start_Date]) AND ((tbl_dbo_episode_ats.episode_end_date)<[Forms]![Frm:1-ExtractSetUp]![End_Date])) OR (((tbl_dbo_episode_ats.WIP) Is Null) AND ((tbl_dbo_episode_ats.episode_start_date)>[Forms]![Frm:1-ExtractSetUp]![End_Date]));
    tbl_dbo_episode_ats["episode_start_date"] = pd.to_datetime(
        tbl_dbo_episode_ats["episode_start_date"].astype(str).str[:10],
        errors="coerce",
        format="%Y-%m-%d",
    )
    tbl_dbo_episode_ats["episode_end_date"] = pd.to_datetime(
        tbl_dbo_episode_ats["episode_end_date"].astype(str).str[:10],
        errors="coerce",
        format="%Y-%m-%d",
    )
    start_date_dt = pd.to_datetime(start_date, format="%Y-%m-%d %H:%M:%S")
    end_date_dt = pd.to_datetime(end_date, format="%Y-%m-%d %H:%M:%S")
    tbl_dbo_episode_ats["WIP"] = np.where(
        (
            (
                (
                    (tbl_dbo_episode_ats["WIP"].isnull())
                    | (tbl_dbo_episode_ats["WIP"] == "")
                )
                & (tbl_dbo_episode_ats["episode_start_date"] < start_date_dt)
                & (tbl_dbo_episode_ats["episode_end_date"] < end_date_dt)
            )
            | (
                (
                    (tbl_dbo_episode_ats["WIP"].isnull())
                    | (tbl_dbo_episode_ats["WIP"] == "")
                )
                & (tbl_dbo_episode_ats["episode_start_date"] > end_date_dt)
            )
        ),
        "0",
        tbl_dbo_episode_ats["WIP"],
    )
    # Access query:  Update WIP 1
    # UPDATE tbl_dbo_episode_ats SET tbl_dbo_episode_ats.WIP = "1" WHERE (((tbl_dbo_episode_ats.WIP) Is Null) AND ((tbl_dbo_episode_ats.episode_start_date)<[Forms]![Frm:1-ExtractSetUp]![Start_Date]) AND ((tbl_dbo_episode_ats.episode_end_date) Between [Forms]![Frm:1-ExtractSetUp]![Start_Date] And [Forms]![Frm:1-ExtractSetUp]![End_Date]));
    tbl_dbo_episode_ats["WIP"] = np.where(
        (
            ((tbl_dbo_episode_ats["WIP"].isnull()) | (tbl_dbo_episode_ats["WIP"] == ""))
            & (tbl_dbo_episode_ats["episode_start_date"] < start_date_dt)
            & (tbl_dbo_episode_ats["episode_end_date"] >= start_date_dt)
            & (tbl_dbo_episode_ats["episode_end_date"] <= end_date_dt)
        ),
        "1",
        tbl_dbo_episode_ats["WIP"],
    )
    # Access query:  Update WIP 2
    # UPDATE tbl_dbo_episode_ats SET tbl_dbo_episode_ats.WIP = "2" WHERE (((tbl_dbo_episode_ats.episode_start_date) Between [Forms]![Frm:1-ExtractSetUp]![Start_Date] And [Forms]![Frm:1-ExtractSetUp]![End_Date]) AND ((tbl_dbo_episode_ats.episode_end_date)>[Forms]![Frm:1-ExtractSetUp]![End_Date] Or (tbl_dbo_episode_ats.episode_end_date) Is Null));
    tbl_dbo_episode_ats["WIP"] = np.where(
        (
            (tbl_dbo_episode_ats["episode_start_date"] >= start_date_dt)
            & (tbl_dbo_episode_ats["episode_start_date"] <= end_date_dt)
        )
        & (
            (tbl_dbo_episode_ats["episode_end_date"] > end_date_dt)
            | (
                (tbl_dbo_episode_ats["episode_end_date"].isnull())
                | (tbl_dbo_episode_ats["episode_end_date"] == "")
            )
        ),
        "2",
        tbl_dbo_episode_ats["WIP"],
    )
    # Access query:  Update WIP 3
    # UPDATE tbl_dbo_episode_ats SET tbl_dbo_episode_ats.WIP = "3" WHERE (((tbl_dbo_episode_ats.WIP) Is Null) AND ((tbl_dbo_episode_ats.episode_start_date)<[Forms]![Frm:1-ExtractSetUp]![Start_Date]) AND ((tbl_dbo_episode_ats.episode_end_date)>[Forms]![Frm:1-ExtractSetUp]![End_Date] Or (tbl_dbo_episode_ats.episode_end_date) Is Null));
    tbl_dbo_episode_ats["WIP"] = np.where(
        ((tbl_dbo_episode_ats["WIP"].isnull()) | (tbl_dbo_episode_ats["WIP"] == ""))
        & (tbl_dbo_episode_ats["episode_start_date"] < start_date_dt)
        & (
            (tbl_dbo_episode_ats["episode_end_date"] > end_date_dt)
            | (
                (tbl_dbo_episode_ats["episode_end_date"].isnull())
                | (tbl_dbo_episode_ats["episode_end_date"] == "")
            )
        ),
        "3",
        tbl_dbo_episode_ats["WIP"],
    )
    # Access query:  Update WIP 4
    # UPDATE tbl_dbo_episode_ats SET tbl_dbo_episode_ats.WIP = "4" WHERE (((tbl_dbo_episode_ats.episode_start_date) Between [Forms]![Frm:1-ExtractSetUp]![Start_Date] And [Forms]![Frm:1-ExtractSetUp]![End_Date]) AND ((tbl_dbo_episode_ats.episode_end_date) Between [Forms]![Frm:1-ExtractSetUp]![Start_Date] And [Forms]![Frm:1-ExtractSetUp]![End_Date]));
    tbl_dbo_episode_ats["WIP"] = np.where(
        (tbl_dbo_episode_ats["episode_start_date"] >= start_date_dt)
        & (tbl_dbo_episode_ats["episode_start_date"] <= end_date_dt)
        & (tbl_dbo_episode_ats["episode_end_date"] >= start_date_dt)
        & (tbl_dbo_episode_ats["episode_end_date"] <= end_date_dt),
        "4",
        tbl_dbo_episode_ats["WIP"],
    )
    tbl_dbo_episode_ats = tbl_dbo_episode_ats.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    tbl_dbo_episode_ats = tbl_dbo_episode_ats.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    tbl_dbo_episode_ats = tbl_dbo_episode_ats.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    # dropping duplicate values
    tbl_dbo_episode_ats.drop_duplicates(keep="last", inplace=True)
    tbl_dbo_episode_ats.to_csv(
        "./ExtractorDB/OutputEpisodeAts.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    logging.info(
        "Query: Update WIP 1,2,3, and 4 completed.tbl_dbo_episode_ats created with %s records and saved to ./ExtractorDB/OutputEpisodeAts.csv.",
        len(tbl_dbo_episode_ats),
    )
    """If any of the episodes in Episode ATS end date update table enddate is less than the startdate in the main form then these episodes are added to the tbl_ExcludedEncounters. This is used for reconciliation purposes. """
    # Access query: append excluded tables episode end date -
    # INSERT INTO tbl_ExcludedEncounters ( facility_identifier, stay_number, episode_sequence_number, [Reason For Exclusion] )SELECT [Episode ATS end date update].facility_identifier, [Episode ATS end date update].stay_number, [Episode ATS end date update].episode_sequence_number, "Episode end in ATS blank but in Episode Table its not blank and before the start of the costing period" AS Expr1 FROM [Episode ATS end date update] WHERE ((([Episode ATS end date update].enddate)<[Forms]![Frm:1-ExtractSetUp]![Start_Date]));
    df_Excluded_EpisodeAts_enddate_le_startdate = tbl_Episode_ATS_end_date_update[
        pd.to_datetime(
            tbl_Episode_ATS_end_date_update["enddate"],
            errors="coerce",
            format="%Y-%m-%d %H:%M:%S",
        )
        < pd.to_datetime(start_date, format="%Y-%m-%d %H:%M:%S")
    ]
    if len(df_Excluded_EpisodeAts_enddate_le_startdate) > 0:
        df_Excluded_EpisodeAts_enddate_le_startdate["ReasonForExclusion"] = (
            "Episode end in ATS blank but in Episode Table its not blank and before the start of the costing period"
        )
        df_Excluded_EpisodeAts_enddate_le_startdate["ed_identifier"] = "XXXXXXXXXX"
        df_Excluded_EpisodeAts_enddate_le_startdate["SNAP_encounter"] = "XXXX_XXXXXXXX"
        df_Excluded_EpisodeAts_enddate_le_startdate["EncounterNumber"] = (
            df_Excluded_EpisodeAts_enddate_le_startdate["facility_identifier"]
            .astype(str)
            .str.strip()
            + "-I-"
            + df_Excluded_EpisodeAts_enddate_le_startdate["stay_number"]
            .astype(str)
            .str.strip()
            + "-"
            + df_Excluded_EpisodeAts_enddate_le_startdate["episode_sequence_number"]
            .astype(str)
            .str.strip()
        )
        df_Excluded_EpisodeAts_enddate_le_startdate = (
            df_Excluded_EpisodeAts_enddate_le_startdate[
                [
                    "facility_identifier",
                    "stay_number",
                    "episode_sequence_number",
                    "ed_identifier",
                    "SNAP_encounter",
                    "ReasonForExclusion",
                    "EncounterNumber",
                ]
            ]
        )
        df_Excluded_EpisodeAts_enddate_le_startdate = (
            df_Excluded_EpisodeAts_enddate_le_startdate.fillna("")
        )
    else:
        df_Excluded_EpisodeAts_enddate_le_startdate = pd.DataFrame(
            columns=[
                "facility_identifier",
                "stay_number",
                "episode_sequence_number",
                "ed_identifier",
                "SNAP_encounter",
                "ReasonForExclusion",
                "EncounterNumber",
            ]
        )
    df_Excluded_EpisodeAts_enddate_le_startdate = (
        df_Excluded_EpisodeAts_enddate_le_startdate[
            df_Excluded_EpisodeAts_enddate_le_startdate["facility_identifier"].isin(
                facilities_included_list_global
            )
        ]
    )
    df_Excluded_EpisodeAts_enddate_le_startdate = (
        df_Excluded_EpisodeAts_enddate_le_startdate.applymap(str)
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    df_Excluded_EpisodeAts_enddate_le_startdate = (
        df_Excluded_EpisodeAts_enddate_le_startdate.applymap(
            lambda x: x.strip() if isinstance(x, str) else x
        )
    )
    df_Excluded_EpisodeAts_enddate_le_startdate = (
        df_Excluded_EpisodeAts_enddate_le_startdate.apply(
            lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
        )
    )
    df_Excluded_EpisodeAts_enddate_le_startdate["stay_number"] = (
        df_Excluded_EpisodeAts_enddate_le_startdate["stay_number"]
        .astype(str)
        .str.pad(8, side="left", fillchar="0")
    )
    df_Excluded_EpisodeAts_enddate_le_startdate["episode_sequence_number"] = (
        df_Excluded_EpisodeAts_enddate_le_startdate["episode_sequence_number"]
        .astype(str)
        .str.pad(3, side="left", fillchar="0")
    )
    # dropping duplicate values
    df_Excluded_EpisodeAts_enddate_le_startdate.drop_duplicates(
        keep="last", inplace=True
    )
    df_Excluded_EpisodeAts_enddate_le_startdate.to_csv(
        "./ExtractorDB/Excluded_EpisodeAts_enddate_less_startdate.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    logging.info(
        "Query: append excluded tables episode end date completed. df_Excluded_EpisodeAts_enddate_le_startdate created with %s records and saved to ./ExtractorDB/Excluded_EpisodeAts_enddate_less_startdate.csv.",
        len(df_Excluded_EpisodeAts_enddate_le_startdate),
    )
    ######################################### EXTRACT DATA - SUB TASK 4 #######################################REVIEW QUERIES
    # Set default value of sub-task status to 1
    label_4_status = 1
    # OutputDaysEpisode
    # Inform8 columns = facility_identifier,stay_number,episode_sequence_number,specialty_unit_code,start_date,start_time,end_date,end_time,local_bed_identifier,ward_identifier,unit_type,trans_type,mo_code,dbo_DAYS_EPISODE_snap_curr_indicator,dbo_EPISODE_ATS_snap_curr_indicator,leave_type,clinician_name,dbo_PRACTICE_snap_curr_indicator,dbo_FACILITY_snap_curr_indicator
    # Access query = Append_to_tbl_dbo_days_episode
    label_4_sub.configure(text="In Progress (DaysEpisode)...", fg="blue")
    main_screen.update()
    # In query_DaysEpisode, change dbo.DAYS_EPISODE.start_date (& end_date) to select cast(dbo.DAYS_EPISODE.start_date as date) AS start_date;
    if source == "HIE":
        if len(facilities_excluded_list) == 0:
            # dbo.DAYS_EPISODE.specialty_unit_code, cast(dbo.DAYS_EPISODE.start_date as date) AS start_date, dbo.DAYS_EPISODE.start_time, cast(dbo.DAYS_EPISODE.end_date as date) AS end_date,
            query_DaysEpisode = (
                """SELECT dbo.DAYS_EPISODE.facility_identifier, dbo.DAYS_EPISODE.stay_number, dbo.DAYS_EPISODE.episode_sequence_number, dbo.DAYS_EPISODE.specialty_unit_code, ''  as specialty_unit_code_desc, dbo.DAYS_EPISODE.start_date, dbo.DAYS_EPISODE.start_time, dbo.DAYS_EPISODE.end_date, dbo.DAYS_EPISODE.end_time, dbo.DAYS_EPISODE.local_bed_identifier, dbo.DAYS_EPISODE.ward_identifier, '' as Ward_Desc, '' as Bed_Desc, dbo.DAYS_EPISODE.unit_type, dbo.DAYS_EPISODE.trans_type, dbo.DAYS_EPISODE.mo_code, dbo.DAYS_EPISODE.snap_curr_indicator AS dbo_DAYS_EPISODE_snap_curr_indicator, dbo.EPISODE_ATS.snap_curr_indicator AS dbo_EPISODE_ATS_snap_curr_indicator, dbo.DAYS_EPISODE.leave_type, dbo.PRACTICE.clinician_name, dbo.PRACTICE.snap_curr_indicator AS dbo_PRACTICE_snap_curr_indicator, dbo.FACILITY.snap_curr_indicator AS dbo_FACILITY_snap_curr_indicator, '' as HLTH_ORG_OSP_OSP_ID, '' as MG_AUTH_OSP_OSP_ID, '' as SE_CBK_SK,'' as SINGLE_ROOM_IND_CD
            FROM dbo.PRACTICE RIGHT JOIN ((dbo.DAYS_EPISODE INNER JOIN dbo.FACILITY ON dbo.DAYS_EPISODE.facility_identifier = dbo.FACILITY.facility_identifier) INNER JOIN dbo.EPISODE_ATS ON (dbo.DAYS_EPISODE.episode_sequence_number = dbo.EPISODE_ATS.episode_sequence_number) AND (dbo.DAYS_EPISODE.stay_number = dbo.EPISODE_ATS.stay_number) AND (dbo.DAYS_EPISODE.facility_identifier = dbo.EPISODE_ATS.facility_identifier)) ON (dbo.PRACTICE.facility_identifier = dbo.DAYS_EPISODE.facility_identifier) AND (dbo.PRACTICE.mo_code = dbo.DAYS_EPISODE.mo_code) 
            GROUP BY dbo.DAYS_EPISODE.facility_identifier, dbo.DAYS_EPISODE.stay_number, dbo.DAYS_EPISODE.episode_sequence_number, dbo.DAYS_EPISODE.specialty_unit_code, dbo.DAYS_EPISODE.start_date, dbo.DAYS_EPISODE.start_time, dbo.DAYS_EPISODE.end_date, dbo.DAYS_EPISODE.end_time, dbo.DAYS_EPISODE.local_bed_identifier, dbo.DAYS_EPISODE.ward_identifier, dbo.DAYS_EPISODE.unit_type, dbo.DAYS_EPISODE.trans_type, dbo.DAYS_EPISODE.mo_code, dbo.PRACTICE.clinician_name, dbo.DAYS_EPISODE.leave_type, dbo.DAYS_EPISODE.snap_curr_indicator, dbo.EPISODE_ATS.snap_curr_indicator, dbo.PRACTICE.snap_curr_indicator, dbo.FACILITY.snap_curr_indicator, dbo.EPISODE_ATS.episode_start_date, dbo.EPISODE_ATS.episode_end_date, dbo.FACILITY.area_identifier, dbo.PRACTICE.snap_curr_indicator, dbo.EPISODE_ATS.episode_of_care_type 
            HAVING (((dbo.DAYS_EPISODE.facility_identifier)<>"D311" And (dbo.DAYS_EPISODE.facility_identifier)<>"Q230") AND ((dbo.DAYS_EPISODE.snap_curr_indicator)='Y' And (dbo.DAYS_EPISODE.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.PRACTICE.snap_curr_indicator)='Y' Or (dbo.PRACTICE.snap_curr_indicator) Is Null)) OR (((dbo.DAYS_EPISODE.facility_identifier)<>"D311" And (dbo.DAYS_EPISODE.facility_identifier)<>"Q230") AND ((dbo.DAYS_EPISODE.snap_curr_indicator)='Y' And (dbo.DAYS_EPISODE.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.PRACTICE.snap_curr_indicator)='Y' Or (dbo.PRACTICE.snap_curr_indicator) Is Null)) OR (((dbo.DAYS_EPISODE.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.DAYS_EPISODE.snap_curr_indicator)='Y' And (dbo.DAYS_EPISODE.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.PRACTICE.snap_curr_indicator)='Y' Or (dbo.PRACTICE.snap_curr_indicator) Is Null)) OR (((dbo.DAYS_EPISODE.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.DAYS_EPISODE.snap_curr_indicator)='Y' And (dbo.DAYS_EPISODE.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.PRACTICE.snap_curr_indicator)='Y' Or (dbo.PRACTICE.snap_curr_indicator) Is Null));"""
            )
        else:
            query_DaysEpisode = (
                """SELECT dbo.DAYS_EPISODE.facility_identifier, dbo.DAYS_EPISODE.stay_number, dbo.DAYS_EPISODE.episode_sequence_number, dbo.DAYS_EPISODE.specialty_unit_code, ''  as specialty_unit_code_desc, dbo.DAYS_EPISODE.start_date, dbo.DAYS_EPISODE.start_time, dbo.DAYS_EPISODE.end_date, dbo.DAYS_EPISODE.end_time, dbo.DAYS_EPISODE.local_bed_identifier, dbo.DAYS_EPISODE.ward_identifier, '' as Ward_Desc, '' as Bed_Desc, dbo.DAYS_EPISODE.unit_type, dbo.DAYS_EPISODE.trans_type, dbo.DAYS_EPISODE.mo_code, dbo.DAYS_EPISODE.snap_curr_indicator AS dbo_DAYS_EPISODE_snap_curr_indicator, dbo.EPISODE_ATS.snap_curr_indicator AS dbo_EPISODE_ATS_snap_curr_indicator, dbo.DAYS_EPISODE.leave_type, dbo.PRACTICE.clinician_name, dbo.PRACTICE.snap_curr_indicator AS dbo_PRACTICE_snap_curr_indicator, dbo.FACILITY.snap_curr_indicator AS dbo_FACILITY_snap_curr_indicator, '' as HLTH_ORG_OSP_OSP_ID, '' as MG_AUTH_OSP_OSP_ID, '' as SE_CBK_SK, '' as SINGLE_ROOM_IND_CD
            FROM dbo.PRACTICE RIGHT JOIN ((dbo.DAYS_EPISODE INNER JOIN dbo.FACILITY ON dbo.DAYS_EPISODE.facility_identifier = dbo.FACILITY.facility_identifier) INNER JOIN dbo.EPISODE_ATS ON (dbo.DAYS_EPISODE.episode_sequence_number = dbo.EPISODE_ATS.episode_sequence_number) AND (dbo.DAYS_EPISODE.stay_number = dbo.EPISODE_ATS.stay_number) AND (dbo.DAYS_EPISODE.facility_identifier = dbo.EPISODE_ATS.facility_identifier)) ON (dbo.PRACTICE.facility_identifier = dbo.DAYS_EPISODE.facility_identifier) AND (dbo.PRACTICE.mo_code = dbo.DAYS_EPISODE.mo_code) 
            WHERE dbo.FACILITY.facility_identifier NOT IN ("""
                + facilities_excluded
                + """) 
            GROUP BY dbo.DAYS_EPISODE.facility_identifier, dbo.DAYS_EPISODE.stay_number, dbo.DAYS_EPISODE.episode_sequence_number, dbo.DAYS_EPISODE.specialty_unit_code, dbo.DAYS_EPISODE.start_date, dbo.DAYS_EPISODE.start_time, dbo.DAYS_EPISODE.end_date, dbo.DAYS_EPISODE.end_time, dbo.DAYS_EPISODE.local_bed_identifier, dbo.DAYS_EPISODE.ward_identifier, dbo.DAYS_EPISODE.unit_type, dbo.DAYS_EPISODE.trans_type, dbo.DAYS_EPISODE.mo_code, dbo.PRACTICE.clinician_name, dbo.DAYS_EPISODE.leave_type, dbo.DAYS_EPISODE.snap_curr_indicator, dbo.EPISODE_ATS.snap_curr_indicator, dbo.PRACTICE.snap_curr_indicator, dbo.FACILITY.snap_curr_indicator, dbo.EPISODE_ATS.episode_start_date, dbo.EPISODE_ATS.episode_end_date, dbo.FACILITY.area_identifier, dbo.PRACTICE.snap_curr_indicator, dbo.EPISODE_ATS.episode_of_care_type 
            HAVING (((dbo.DAYS_EPISODE.facility_identifier)<>"D311" And (dbo.DAYS_EPISODE.facility_identifier)<>"Q230") AND ((dbo.DAYS_EPISODE.snap_curr_indicator)='Y' And (dbo.DAYS_EPISODE.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.PRACTICE.snap_curr_indicator)='Y' Or (dbo.PRACTICE.snap_curr_indicator) Is Null)) OR (((dbo.DAYS_EPISODE.facility_identifier)<>"D311" And (dbo.DAYS_EPISODE.facility_identifier)<>"Q230") AND ((dbo.DAYS_EPISODE.snap_curr_indicator)='Y' And (dbo.DAYS_EPISODE.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.PRACTICE.snap_curr_indicator)='Y' Or (dbo.PRACTICE.snap_curr_indicator) Is Null)) OR (((dbo.DAYS_EPISODE.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.DAYS_EPISODE.snap_curr_indicator)='Y' And (dbo.DAYS_EPISODE.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.PRACTICE.snap_curr_indicator)='Y' Or (dbo.PRACTICE.snap_curr_indicator) Is Null)) OR (((dbo.DAYS_EPISODE.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.DAYS_EPISODE.snap_curr_indicator)='Y' And (dbo.DAYS_EPISODE.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.PRACTICE.snap_curr_indicator)='Y' Or (dbo.PRACTICE.snap_curr_indicator) Is Null)) ;"""
            )
    elif source == "EDW":
        if len(facilities_included_list) > 0:
            query_DaysEpisode = (
                """SELECT DISTINCT k.facility_identifier,RIGHT(CONCAT('00000000', ISNULL(SUBSTRING(A.SRV_ENC_REC_ID,charindex('-',A.SRV_ENC_REC_ID)+1,8),'')), 8) as stay_number,A.SEQ_AP_SE_IN_ENC as episode_sequence_number,C.RSP_ISP_DISC_SPEC_CD as specialty_unit_code,C.RSP_ISP_DISC_SPEC_CD_DESC as specialty_unit_code_desc,cast(A.SE_SEG_ST_DTTM as date) as start_date,cast(A.SE_SEG_ST_DTTM as time(0)) as start_time,cast(A.SE_SEG_END_DTTM as date) as end_date,cast(A.SE_SEG_END_DTTM as time(0)) as end_time,F.BED_LOC_ID as local_bed_identifier,F.WARD_LOC_ID as ward_identifier,F.WARD_NM,F.BED_DESC,D.BED_TYP_CD as unit_type,case when A.DIM_SE_LEAVE_PRF_SK <> -1 and SUBSTRING(a.SE_LEAVE_PRF_CBK,charindex('|',a.SE_LEAVE_PRF_CBK)+1,1) in ('C', 'L') then 'LEA' else '' end as trans_type,case when B.mo_clinician is NULL then '' else B.mo_clinician end as mo_code,'' AS dbo_DAYS_EPISODE_snap_curr_indicator,'' AS dbo_EPISODE_ATS_snap_curr_indicator,case when A.DIM_SE_LEAVE_PRF_SK <> -1 then replace(SUBSTRING(a.SE_LEAVE_PRF_CBK,charindex('|',a.SE_LEAVE_PRF_CBK)+1,2),'~','') else '' end as leave_type,concat(B.ISP_LEGAL_GIVEN_NM,' ',B.ISP_LEGAL_FAMILY_NM) as clinician_name,'' AS dbo_PRACTICE_snap_curr_indicator,'' AS dbo_FACILITY_snap_curr_indicator,K.OSP_ID as HLTH_ORG_OSP_OSP_ID,K.MG_AUTH_OSP_OSP_ID,A.SE_CBK_SK,F.WARD_NM as ward_desc,N.SINGLE_ROOM_IND_CD ,A.DIM_RSP_ISP_SK,o.facility_identifier as Responsible_Facility FROM (SELECT SE_CBK_SK,SE_SEG_CBK, SEQ_SEG_IN_SE,SEQ_AP_SE_IN_ENC, SRV_ENC_REC_ID,SE_SEG_ST_DTTM,SE_SEG_END_DTTM,DIM_HS_BED_WARD_SK,DIM_HS_BED_TYP_SK,DIM_SE_LEAVE_PRF_SK,SEQ_SE_LEAVE,DIM_DT_SE_ST_SK,DIM_DT_SE_END_SK,RSP_ISP_ID,RSP_ISP_DISC_SPEC_CD, DIM_RSP_ISP_SK, DIM_RSP_ISP_DISC_SPEC_SK, DIMSET_ISP_SK, DIM_RSP_OSP_SK, DIM_AP_SE_PRF2_SK, DIM_HS_BED_ATTR_PRF_SK, DIM_OSP_CREATED_SK,SE_LEAVE_PRF_CBK FROM CRT.v_FACT_AP_SE_SEG) as a LEFT JOIN (SELECT DIM_RSP_ISP_SK,ISP_ID, ISP_MED_AHPRA_ID, ISP_LEGAL_FAMILY_NM, ISP_LEGAL_GIVEN_NM,case when ISP_MED_AHPRA_ID != '-1' then ISP_MED_AHPRA_ID when ISP_DENT_AHPRA_ID != '-1' then ISP_DENT_AHPRA_ID else '-1' end as mo_clinician FROM CRT.v_DIM_RSP_ISP) as b on A.DIM_RSP_ISP_SK = B.DIM_RSP_ISP_SK LEFT JOIN (SELECT DIM_RSP_ISP_DISC_SPEC_SK,RSP_ISP_DISC_SPEC_CD,RSP_ISP_DISC_SPEC_CD_DESC FROM CRT.v_DIM_RSP_ISP_DISC_SPEC) as c on C.DIM_RSP_ISP_DISC_SPEC_SK = A.DIM_RSP_ISP_DISC_SPEC_SK LEFT JOIN (SELECT DIM_BED_TYP_SK,BED_TYP_CD FROM CRT.v_DIM_HS_BED_TYP) as D on d.DIM_BED_TYP_SK = a.DIM_HS_BED_TYP_SK LEFT JOIN (SELECT DIM_HS_BED_WARD_SK, BED_LOC_ID, WARD_LOC_ID,WARD_NM,BED_DESC FROM CRT.v_DIM_HS_BED_WARD) as F on a.DIM_HS_BED_WARD_SK = f.DIM_HS_BED_WARD_SK INNER JOIN (SELECT DISTINCT DIM_OSP_SK, HLTH_ORG_OSP_OSP_ID, MG_AUTH_OSP_OSP_ID, OSP_HIE_FAC_ID, MG_AUTH_OSP_HIE_FAC_ID,MG_AUTH_OSP_HLTH_SECTOR_CD,HLTH_ORG_OSP_HLTH_SECTOR_CD, OSP_TYP_CD,HLTH_ORG_OSP_HIE_FAC_ID,case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_HIE_FAC_ID else HLTH_ORG_OSP_HIE_FAC_ID end as facility_identifier,case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_ID else HLTH_ORG_OSP_OSP_ID end as OSP_ID FROM CRT.v_DIM_OSP WHERE (MG_AUTH_OSP_HLTH_SECTOR_CD in('1','3')) and (HLTH_ORG_OSP_HLTH_SECTOR_CD in ('1','3')) AND HLTH_ORG_OSP_HIE_FAC_ID != '-1' AND HLTH_ORG_OSP_HIE_FAC_ID != '') AS K ON A.DIM_OSP_CREATED_SK = K.DIM_OSP_SK LEFT JOIN (select DIM_BED_ATTR_PRF_SK, SINGLE_ROOM_IND_CD  from CRT.v_DIM_HS_BED_ATTR_PRF) as N on a.DIM_HS_BED_ATTR_PRF_SK  = N.DIM_BED_ATTR_PRF_SK LEFT JOIN (SELECT DISTINCT SE_CBK_SK, LST_OSP_ID FROM CRT.V_FACT_AP_SE_FLAT WHERE ((cast(SE_ST_DTTM as date) <= '"""
                + end_date
                + """') AND (cast(SE_END_DTTM as date) >= '"""
                + start_date
                + """' or SE_END_DTTM Is Null))) AS P ON A.SE_CBK_SK = P.SE_CBK_SK LEFT JOIN (SELECT DISTINCT case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_ID else HLTH_ORG_OSP_OSP_ID end as OSP_ID,case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_HIE_FAC_ID else HLTH_ORG_OSP_HIE_FAC_ID end as facility_identifier FROM CRT.v_DIM_OSP where ((MG_AUTH_OSP_HLTH_SECTOR_CD IN ('1','3')) and (HLTH_ORG_OSP_HLTH_SECTOR_CD IN ('1','3'))) AND HLTH_ORG_OSP_HIE_FAC_ID != '-1' AND HLTH_ORG_OSP_HIE_FAC_ID != '') AS o ON p.LST_OSP_ID = o.OSP_ID WHERE ((cast(a.SE_SEG_ST_DTTM as date) <= '"""
                + end_date
                + """') AND (cast(a.SE_SEG_END_DTTM as date) >= '"""
                + start_date
                + """' or a.SE_SEG_END_DTTM Is Null)) AND (K.MG_AUTH_OSP_HIE_FAC_ID='"""
                + lhd
                + """' or K.facility_identifier ='"""
                + lhd
                + """') AND K.facility_identifier IN ("""
                + facilities_included
                + """);"""
            )
    retry_flag = True
    retry_count = 0
    while retry_flag and retry_count < 5:
        try:
            logging.info(query_DaysEpisode)
            tbl_dbo_days_episode = pd.read_sql(query_DaysEpisode, cnxn)
            retry_flag = False
        except Exception as e:
            retry_count = retry_count + 1
            time.sleep(5)
            if retry_count == 5:
                logging.exception("Exception occurred")
                label_4_status = 0
                messagebox.showerror(
                    "SQL Error", "Error extracting DaysEpisode details\n" + str(e)
                )
                label_4_sub.configure(text="Failed (DaysEpisode)...", fg="red")
                main_screen.update()
                tbl_dbo_days_episode = pd.DataFrame(
                    columns=[
                        "facility_identifier",
                        "stay_number",
                        "episode_sequence_number",
                        "specialty_unit_code",
                        "start_date",
                        "start_time",
                        "end_date",
                        "end_time",
                        "local_bed_identifier",
                        "ward_identifier",
                        "unit_type",
                        "trans_type",
                        "mo_code",
                        "dbo_DAYS_EPISODE_snap_curr_indicator",
                        "dbo_EPISODE_ATS_snap_curr_indicator",
                        "leave_type",
                        "clinician_name",
                        "dbo_PRACTICE_snap_curr_indicator",
                        "dbo_FACILITY_snap_curr_indicator",
                        "HLTH_ORG_OSP_OSP_ID",
                        "MG_AUTH_OSP_OSP_ID",
                        "SE_CBK_SK",
                        "WARD_NM",
                        "BED_DESC",
                        "specialty_unit_code_desc",
                        "SINGLE_ROOM_IND_CD",
                        "DIM_RSP_ISP_SK",
                        "Responsible_Facility",
                    ]
                )
                return  # stop extraction
        else:
            tbl_dbo_days_episode = tbl_dbo_days_episode.fillna("")
            tbl_dbo_days_episode = tbl_dbo_days_episode[
                [
                    "facility_identifier",
                    "stay_number",
                    "episode_sequence_number",
                    "specialty_unit_code",
                    "start_date",
                    "start_time",
                    "end_date",
                    "end_time",
                    "local_bed_identifier",
                    "ward_identifier",
                    "unit_type",
                    "trans_type",
                    "mo_code",
                    "dbo_DAYS_EPISODE_snap_curr_indicator",
                    "dbo_EPISODE_ATS_snap_curr_indicator",
                    "leave_type",
                    "clinician_name",
                    "dbo_PRACTICE_snap_curr_indicator",
                    "dbo_FACILITY_snap_curr_indicator",
                    "HLTH_ORG_OSP_OSP_ID",
                    "MG_AUTH_OSP_OSP_ID",
                    "SE_CBK_SK",
                    "WARD_NM",
                    "BED_DESC",
                    "specialty_unit_code_desc",
                    "SINGLE_ROOM_IND_CD",
                    "DIM_RSP_ISP_SK",
                    "Responsible_Facility",
                ]
            ]
            tbl_dbo_days_episode = tbl_dbo_days_episode[
                tbl_dbo_days_episode["facility_identifier"].isin(
                    facilities_included_list_global
                )
            ]
            tbl_dbo_days_episode = tbl_dbo_days_episode.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_dbo_days_episode = tbl_dbo_days_episode.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_dbo_days_episode = tbl_dbo_days_episode.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_days_episode = tbl_dbo_days_episode.apply(
                lambda x: x.replace(regex=r"NULL", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_days_episode = tbl_dbo_days_episode.apply(
                lambda x: x.replace(regex=r"null", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_days_episode = tbl_dbo_days_episode.apply(
                lambda x: x.replace(regex=r"Null", value="")
                if x.dtype == "object"
                else x
            )
            tbl_dbo_days_episode["stay_number"] = (
                tbl_dbo_days_episode["stay_number"]
                .astype(str)
                .str.pad(8, side="left", fillchar="0")
            )
            tbl_dbo_days_episode["episode_sequence_number"] = (
                tbl_dbo_days_episode["episode_sequence_number"]
                .astype(str)
                .str.pad(3, side="left", fillchar="0")
            )
            # dropping duplicate values
            tbl_dbo_days_episode.drop_duplicates(keep="last", inplace=True)
            tbl_dbo_days_episode.to_csv(
                "./ExtractorDB/OutputDaysEpisode.csv",
                index=False,
                na_rep="",
                float_format=str,
                decimal=str,
                date_format=str,
            )
            logging.info("tbl_dbo_days_episode=%s", len(tbl_dbo_days_episode))
    # PpmTransferAmo
    # columns = facility_identifier', 'mo_code', 'Code', 'clinician_name', 'Consultant_Status', 'LHD'
    # Access query = Append_to_tbl_PPM_transfer_AMO
    label_4_sub.configure(text="In Progress (PPM_transfer_AMO)...", fg="blue")
    main_screen.update()
    if source == "HIE":
        if len(facilities_excluded_list) == 0:
            # clinician_name is not in dbo.DAYS_EPISODE
            query_PpmTransferAmo = (
                """SELECT DISTINCT dbo.DAYS_EPISODE.facility_identifier as facility_identifier, TRIM(STRING(dbo.DAYS_EPISODE.mo_code)) as mo_code, (TRIM(STRING(dbo.DAYS_EPISODE.facility_identifier)) + "-" + TRIM(STRING(dbo.DAYS_EPISODE.mo_code))) AS Code, dbo.PRACTICE.clinician_name as clinician_name, '' AS Consultant_Status, dbo.FACILITY.area_identifier AS LHD, '' as HLTH_ORG_OSP_OSP_ID, '' as MG_AUTH_OSP_OSP_ID, '' as SE_CBK_SK
            FROM dbo.PRACTICE RIGHT JOIN ((dbo.DAYS_EPISODE INNER JOIN dbo.FACILITY ON dbo.DAYS_EPISODE.facility_identifier = dbo.FACILITY.facility_identifier) INNER JOIN dbo.EPISODE_ATS ON (dbo.DAYS_EPISODE.episode_sequence_number = dbo.EPISODE_ATS.episode_sequence_number) AND (dbo.DAYS_EPISODE.stay_number = dbo.EPISODE_ATS.stay_number) AND (dbo.DAYS_EPISODE.facility_identifier = dbo.EPISODE_ATS.facility_identifier)) ON (dbo.PRACTICE.facility_identifier = dbo.DAYS_EPISODE.facility_identifier) AND (dbo.PRACTICE.mo_code = dbo.DAYS_EPISODE.mo_code) 
            GROUP BY dbo.DAYS_EPISODE.facility_identifier, dbo.DAYS_EPISODE.stay_number, dbo.DAYS_EPISODE.episode_sequence_number, dbo.DAYS_EPISODE.specialty_unit_code, dbo.DAYS_EPISODE.start_date, dbo.DAYS_EPISODE.start_time, dbo.DAYS_EPISODE.end_date, dbo.DAYS_EPISODE.end_time, dbo.DAYS_EPISODE.local_bed_identifier, dbo.DAYS_EPISODE.ward_identifier, dbo.DAYS_EPISODE.unit_type, dbo.DAYS_EPISODE.trans_type, dbo.DAYS_EPISODE.mo_code, dbo.PRACTICE.clinician_name, '', dbo.FACILITY.area_identifier,  dbo.DAYS_EPISODE.snap_curr_indicator, dbo.EPISODE_ATS.snap_curr_indicator, dbo.PRACTICE.snap_curr_indicator, dbo.FACILITY.snap_curr_indicator, dbo.EPISODE_ATS.episode_start_date, dbo.EPISODE_ATS.episode_end_date, dbo.FACILITY.area_identifier, dbo.PRACTICE.snap_curr_indicator, dbo.EPISODE_ATS.episode_of_care_type 
            HAVING (((dbo.DAYS_EPISODE.facility_identifier)<>"D311" And (dbo.DAYS_EPISODE.facility_identifier)<>"Q230") AND ((dbo.DAYS_EPISODE.snap_curr_indicator)='Y' And (dbo.DAYS_EPISODE.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND 
            ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.PRACTICE.snap_curr_indicator)='Y' Or (dbo.PRACTICE.snap_curr_indicator) Is Null)) OR (((dbo.DAYS_EPISODE.facility_identifier)<>"D311" And (dbo.DAYS_EPISODE.facility_identifier)<>"Q230") AND ((dbo.DAYS_EPISODE.snap_curr_indicator)='Y' And (dbo.DAYS_EPISODE.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.PRACTICE.snap_curr_indicator)='Y' Or (dbo.PRACTICE.snap_curr_indicator) Is Null)) OR (((dbo.DAYS_EPISODE.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.DAYS_EPISODE.snap_curr_indicator)='Y' And (dbo.DAYS_EPISODE.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.PRACTICE.snap_curr_indicator)='Y' Or (dbo.PRACTICE.snap_curr_indicator) Is Null)) OR (((dbo.DAYS_EPISODE.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.DAYS_EPISODE.snap_curr_indicator)='Y' And (dbo.DAYS_EPISODE.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.PRACTICE.snap_curr_indicator)='Y' Or (dbo.PRACTICE.snap_curr_indicator) Is Null)) ;"""
            )
        else:
            query_PpmTransferAmo = (
                """SELECT DISTINCT dbo.DAYS_EPISODE.facility_identifier as facility_identifier, TRIM(STRING(dbo.DAYS_EPISODE.mo_code)) as mo_code, (TRIM(STRING(dbo.DAYS_EPISODE.facility_identifier)) + "-" + TRIM(STRING(dbo.DAYS_EPISODE.mo_code))) AS Code, dbo.PRACTICE.clinician_name as clinician_name, '' AS Consultant_Status, dbo.FACILITY.area_identifier AS LHD, '' as HLTH_ORG_OSP_OSP_ID, '' as MG_AUTH_OSP_OSP_ID, '' as SE_CBK_SK
            FROM dbo.PRACTICE RIGHT JOIN ((dbo.DAYS_EPISODE INNER JOIN dbo.FACILITY ON dbo.DAYS_EPISODE.facility_identifier = dbo.FACILITY.facility_identifier) INNER JOIN dbo.EPISODE_ATS ON (dbo.DAYS_EPISODE.episode_sequence_number = dbo.EPISODE_ATS.episode_sequence_number) AND (dbo.DAYS_EPISODE.stay_number = dbo.EPISODE_ATS.stay_number) AND (dbo.DAYS_EPISODE.facility_identifier = dbo.EPISODE_ATS.facility_identifier)) ON (dbo.PRACTICE.facility_identifier = dbo.DAYS_EPISODE.facility_identifier) AND (dbo.PRACTICE.mo_code = dbo.DAYS_EPISODE.mo_code) WHERE dbo.FACILITY.facility_identifier NOT IN ("""
                + facilities_excluded
                + """) GROUP BY dbo.DAYS_EPISODE.facility_identifier, dbo.DAYS_EPISODE.stay_number, dbo.DAYS_EPISODE.episode_sequence_number, dbo.DAYS_EPISODE.specialty_unit_code, dbo.DAYS_EPISODE.start_date, dbo.DAYS_EPISODE.start_time, dbo.DAYS_EPISODE.end_date, dbo.DAYS_EPISODE.end_time, dbo.DAYS_EPISODE.local_bed_identifier, dbo.DAYS_EPISODE.ward_identifier, dbo.DAYS_EPISODE.unit_type, dbo.DAYS_EPISODE.trans_type, dbo.DAYS_EPISODE.mo_code, dbo.PRACTICE.clinician_name, '', dbo.FACILITY.area_identifier,  dbo.DAYS_EPISODE.snap_curr_indicator, dbo.EPISODE_ATS.snap_curr_indicator, dbo.PRACTICE.snap_curr_indicator, dbo.FACILITY.snap_curr_indicator, dbo.EPISODE_ATS.episode_start_date, dbo.EPISODE_ATS.episode_end_date, dbo.FACILITY.area_identifier, dbo.PRACTICE.snap_curr_indicator, dbo.EPISODE_ATS.episode_of_care_type 
            HAVING (((dbo.DAYS_EPISODE.facility_identifier)<>"D311" And (dbo.DAYS_EPISODE.facility_identifier)<>"Q230") AND ((dbo.DAYS_EPISODE.snap_curr_indicator)='Y' And (dbo.DAYS_EPISODE.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND 
            ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.PRACTICE.snap_curr_indicator)='Y' Or (dbo.PRACTICE.snap_curr_indicator) Is Null)) OR (((dbo.DAYS_EPISODE.facility_identifier)<>"D311" And (dbo.DAYS_EPISODE.facility_identifier)<>"Q230") AND ((dbo.DAYS_EPISODE.snap_curr_indicator)='Y' And (dbo.DAYS_EPISODE.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.PRACTICE.snap_curr_indicator)='Y' Or (dbo.PRACTICE.snap_curr_indicator) Is Null)) OR (((dbo.DAYS_EPISODE.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.DAYS_EPISODE.snap_curr_indicator)='Y' And (dbo.DAYS_EPISODE.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.PRACTICE.snap_curr_indicator)='Y' Or (dbo.PRACTICE.snap_curr_indicator) Is Null)) OR (((dbo.DAYS_EPISODE.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.DAYS_EPISODE.snap_curr_indicator)='Y' And (dbo.DAYS_EPISODE.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.PRACTICE.snap_curr_indicator)='Y' Or (dbo.PRACTICE.snap_curr_indicator) Is Null)) ;"""
            )
    elif source == "EDW":
        if len(facilities_included_list) > 0:
            # Kylie: mo_code with -1 or '' has to be included. LHDs are having issues with their PAS not having rego details entered. this i a pas issue and will take years to fix likely. remove  AND c.mo_clinician != ''  from WHERE clause from v1.14
            query_PpmTransferAmo = (
                """SELECT DISTINCT d.facility_identifier,c.mo_clinician as mo_code,trim(d.facility_identifier) + '-' + trim(c.mo_clinician) as Code,c.clinician_name,'' as Consultant_Status,d.MG_AUTH_OSP_HIE_FAC_ID as LHD,d.OSP_ID as HLTH_ORG_OSP_OSP_ID,d.MG_AUTH_OSP_OSP_ID,A.SE_CBK_SK,A.DIM_RSP_ISP_SK FROM CRT.V_FACT_AP_SE_SEG as a LEFT JOIN (SELECT DIM_RSP_ISP_SK,case when ISP_MED_AHPRA_ID != '-1' then ISP_MED_AHPRA_ID when ISP_DENT_AHPRA_ID != '-1' then ISP_DENT_AHPRA_ID 
			else '-1' end as mo_clinician,(concat(ISP_LEGAL_GIVEN_NM,' ',ISP_LEGAL_FAMILY_NM)) as clinician_name	FROM CRT.v_DIM_RSP_ISP) as c on A.DIM_RSP_ISP_SK = c.DIM_RSP_ISP_SK INNER JOIN (SELECT DISTINCT DIM_OSP_SK, OSP_HIE_FAC_ID,HLTH_ORG_OSP_OSP_ID, MG_AUTH_OSP_HLTH_SECTOR_CD, HLTH_ORG_OSP_HLTH_SECTOR_CD, OSP_TYP_CD,HLTH_ORG_OSP_HIE_FAC_ID, MG_AUTH_OSP_HIE_FAC_ID, MG_AUTH_OSP_OSP_ID, case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_ID else HLTH_ORG_OSP_OSP_ID end as OSP_ID,case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_HIE_FAC_ID else HLTH_ORG_OSP_HIE_FAC_ID end as facility_identifier FROM CRT.v_DIM_OSP where ((MG_AUTH_OSP_HLTH_SECTOR_CD IN ('1','3')) and (HLTH_ORG_OSP_HLTH_SECTOR_CD IN ('1','3'))) AND HLTH_ORG_OSP_HIE_FAC_ID != '-1' AND HLTH_ORG_OSP_HIE_FAC_ID != '') AS D ON A.DIM_OSP_CREATED_SK = D.DIM_OSP_SK WHERE d.facility_identifier IN ("""
                + facilities_included
                + """) GROUP BY d.facility_identifier,a.SRV_ENC_REC_ID,a.SEQ_AP_SE_IN_ENC,CAST(a.SE_SEG_ST_DTTM as date),CAST(a.SE_SEG_ST_DTTM as time(0)),CAST(a.SE_SEG_END_DTTM as date),CAST(a.SE_SEG_END_DTTM as time(0)),concat(trim(substring(c.mo_clinician,4,10)),substring(c.mo_clinician,1,3)),trim(d.facility_identifier) + '-' + trim(substring(c.mo_clinician,4,10)) +  substring(c.mo_clinician,1,3),c.clinician_name,d.MG_AUTH_OSP_HIE_FAC_ID,CAST(a.SE_ST_DTTM as date),CAST(a.SE_end_DTTM as date),a.SE_end_DTTM,d.MG_AUTH_OSP_HLTH_SECTOR_CD,d.HLTH_ORG_OSP_HLTH_SECTOR_CD,d.HLTH_ORG_OSP_OSP_ID,d.MG_AUTH_OSP_OSP_ID,A.SE_CBK_SK,d.OSP_TYP_CD,d.HLTH_ORG_OSP_HIE_FAC_ID,c.mo_clinician,d.OSP_ID,A.DIM_RSP_ISP_SK HAVING (((CAST(a.SE_ST_DTTM as date))<='"""
                + end_date
                + """') AND ((CAST(a.SE_END_DTTM as date)) >= '"""
                + start_date
                + """' OR a.SE_END_DTTM IS NULL) AND (d.MG_AUTH_OSP_HIE_FAC_ID='"""
                + lhd
                + """' or (d.facility_identifier)='"""
                + lhd
                + """'));"""
            )
    retry_flag = True
    retry_count = 0
    while retry_flag and retry_count < 5:
        try:
            logging.info(query_PpmTransferAmo)
            df_PpmTransferAmo = pd.read_sql(query_PpmTransferAmo, cnxn)
            retry_flag = False
        except Exception as e:
            retry_count = retry_count + 1
            time.sleep(5)
            if retry_count == 5:
                logging.exception("Exception occurred")
                label_4_status = 0
                messagebox.showerror(
                    "SQL Error", "Error extracting PPM_transfer_AMO details\n" + str(e)
                )
                label_4_sub.configure(text="Failed (PPM_transfer_AMO)...", fg="red")
                main_screen.update()
                df_PpmTransferAmo = pd.DataFrame(
                    columns=[
                        "facility_identifier",
                        "mo_code",
                        "Code",
                        "clinician_name",
                        "Consultant_Status",
                        "LHD",
                        "HLTH_ORG_OSP_OSP_ID",
                        "MG_AUTH_OSP_OSP_ID",
                        "SE_CBK_SK",
                        "DIM_RSP_ISP_SK",
                    ]
                )
                return  # stop extraction
        else:
            df_PpmTransferAmo = df_PpmTransferAmo.fillna("")
            df_PpmTransferAmo = df_PpmTransferAmo[
                [
                    "facility_identifier",
                    "mo_code",
                    "Code",
                    "clinician_name",
                    "Consultant_Status",
                    "LHD",
                    "HLTH_ORG_OSP_OSP_ID",
                    "MG_AUTH_OSP_OSP_ID",
                    "SE_CBK_SK",
                    "DIM_RSP_ISP_SK",
                ]
            ]
            df_PpmTransferAmo = df_PpmTransferAmo[
                df_PpmTransferAmo["LHD"] == lhd_global
            ]
            df_PpmTransferAmo = df_PpmTransferAmo[
                df_PpmTransferAmo["facility_identifier"].isin(
                    facilities_included_list_global
                )
            ]
            df_PpmTransferAmo = df_PpmTransferAmo.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            df_PpmTransferAmo = df_PpmTransferAmo.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            df_PpmTransferAmo = df_PpmTransferAmo.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            df_PpmTransferAmo = df_PpmTransferAmo.apply(
                lambda x: x.replace(regex=r"NULL", value="")
                if x.dtype == "object"
                else x
            )
            df_PpmTransferAmo = df_PpmTransferAmo.apply(
                lambda x: x.replace(regex=r"null", value="")
                if x.dtype == "object"
                else x
            )
            df_PpmTransferAmo = df_PpmTransferAmo.apply(
                lambda x: x.replace(regex=r"Null", value="")
                if x.dtype == "object"
                else x
            )
            # dropping duplicate values
            df_PpmTransferAmo.drop_duplicates(keep="last", inplace=True)
            df_PpmTransferAmo.to_csv(
                "./temp_transform/query_Tbl_PPM_transfer_AMO.csv",
                index=False,
                na_rep="",
                float_format=str,
                decimal=str,
                date_format=str,
            )
            logging.info(
                "df_PpmTransferAmo created with %s records and saved to ./temp_transform/query_Tbl_PPM_transfer_AMO.csv",
                len(df_PpmTransferAmo),
            )
    # PpmTransferLeave00
    # columns = 'facility_identifier', 'stay_number', 'episode_sequence_number', 'start_date', 'start_time', 'end_date', 'end_time', 'trans_type', 'LeaveDays'
    # Access query = tbl_PPM_transfer_Leave
    label_4_sub.configure(text="In Progress (PPM_transfer_Leave00)...", fg="blue")
    main_screen.update()
    if source == "HIE":
        if len(facilities_excluded_list) == 0:
            query_PpmTransferLeave00 = (
                """SELECT DISTINCT dbo.DAYS_EPISODE.facility_identifier, dbo.DAYS_EPISODE.stay_number, dbo.DAYS_EPISODE.episode_sequence_number, dbo.DAYS_EPISODE.start_date, dbo.DAYS_EPISODE.start_time, dbo.DAYS_EPISODE.end_date, dbo.DAYS_EPISODE.end_time, dbo.DAYS_EPISODE.trans_type,
            cast(sum(datediff(day,
            (case when CAST( dbo.DAYS_EPISODE.start_date AS DATE )>=CAST('"""
                + start_date
                + """' AS DATE )  AND CAST( dbo.DAYS_EPISODE.start_date AS DATE ) <= CAST('"""
                + end_date
                + """' AS DATE ) then CAST( dbo.DAYS_EPISODE.start_date AS DATE ) end),
            (case when CAST( dbo.DAYS_EPISODE.end_date AS DATE )>=CAST('"""
                + start_date
                + """' AS DATE )  AND CAST( dbo.DAYS_EPISODE.end_date AS DATE ) <= CAST('"""
                + end_date
                + """' AS DATE ) then CAST( dbo.DAYS_EPISODE.end_date AS DATE ) end)
            )) as int) AS LeaveDays, '' as HLTH_ORG_OSP_OSP_ID, '' as MG_AUTH_OSP_OSP_ID, '' as SE_CBK_SK
            FROM dbo.PRACTICE RIGHT JOIN ((dbo.DAYS_EPISODE INNER JOIN dbo.FACILITY ON dbo.DAYS_EPISODE.facility_identifier = dbo.FACILITY.facility_identifier) INNER JOIN dbo.EPISODE_ATS ON (dbo.DAYS_EPISODE.episode_sequence_number = dbo.EPISODE_ATS.episode_sequence_number) AND (dbo.DAYS_EPISODE.stay_number = dbo.EPISODE_ATS.stay_number) AND (dbo.DAYS_EPISODE.facility_identifier = dbo.EPISODE_ATS.facility_identifier)) ON (dbo.PRACTICE.facility_identifier = dbo.DAYS_EPISODE.facility_identifier) AND (dbo.PRACTICE.mo_code = dbo.DAYS_EPISODE.mo_code) WHERE (((dbo.DAYS_EPISODE.trans_type)='LEA')) 
            GROUP BY dbo.DAYS_EPISODE.facility_identifier, dbo.DAYS_EPISODE.stay_number, dbo.DAYS_EPISODE.episode_sequence_number, dbo.DAYS_EPISODE.start_date, dbo.DAYS_EPISODE.start_time, dbo.DAYS_EPISODE.end_date, dbo.DAYS_EPISODE.end_time, dbo.DAYS_EPISODE.trans_type, dbo.DAYS_EPISODE.snap_curr_indicator, dbo.EPISODE_ATS.snap_curr_indicator, dbo.PRACTICE.snap_curr_indicator, dbo.FACILITY.snap_curr_indicator, dbo.EPISODE_ATS.episode_start_date, dbo.EPISODE_ATS.episode_end_date, dbo.FACILITY.area_identifier, dbo.PRACTICE.snap_curr_indicator, dbo.EPISODE_ATS.episode_of_care_type 
            HAVING (((dbo.DAYS_EPISODE.facility_identifier)<>"D311" And (dbo.DAYS_EPISODE.facility_identifier)<>"Q230") AND ((dbo.DAYS_EPISODE.snap_curr_indicator)='Y' And (dbo.DAYS_EPISODE.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND 
            ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.PRACTICE.snap_curr_indicator)='Y' Or (dbo.PRACTICE.snap_curr_indicator) Is Null)) OR (((dbo.DAYS_EPISODE.facility_identifier)<>"D311" And (dbo.DAYS_EPISODE.facility_identifier)<>"Q230") AND ((dbo.DAYS_EPISODE.snap_curr_indicator)='Y' And (dbo.DAYS_EPISODE.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.PRACTICE.snap_curr_indicator)='Y' Or (dbo.PRACTICE.snap_curr_indicator) Is Null)) OR (((dbo.DAYS_EPISODE.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.DAYS_EPISODE.snap_curr_indicator)='Y' And (dbo.DAYS_EPISODE.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.PRACTICE.snap_curr_indicator)='Y' Or (dbo.PRACTICE.snap_curr_indicator) Is Null)) OR (((dbo.DAYS_EPISODE.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.DAYS_EPISODE.snap_curr_indicator)='Y' And (dbo.DAYS_EPISODE.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.PRACTICE.snap_curr_indicator)='Y' Or (dbo.PRACTICE.snap_curr_indicator) Is Null)) ;"""
            )
        else:
            query_PpmTransferLeave00 = (
                """SELECT DISTINCT dbo.DAYS_EPISODE.facility_identifier, dbo.DAYS_EPISODE.stay_number, dbo.DAYS_EPISODE.episode_sequence_number, dbo.DAYS_EPISODE.start_date, dbo.DAYS_EPISODE.start_time, dbo.DAYS_EPISODE.end_date, dbo.DAYS_EPISODE.end_time, dbo.DAYS_EPISODE.trans_type,
            cast(sum(datediff(day,
            (case when CAST( dbo.DAYS_EPISODE.start_date AS DATE )>=CAST('"""
                + start_date
                + """' AS DATE )  AND CAST( dbo.DAYS_EPISODE.start_date AS DATE ) <= CAST('"""
                + end_date
                + """' AS DATE ) then CAST( dbo.DAYS_EPISODE.start_date AS DATE ) end),
            (case when CAST( dbo.DAYS_EPISODE.end_date AS DATE )>=CAST('"""
                + start_date
                + """' AS DATE )  AND CAST( dbo.DAYS_EPISODE.end_date AS DATE ) <= CAST('"""
                + end_date
                + """' AS DATE ) then CAST( dbo.DAYS_EPISODE.end_date AS DATE ) end)
            )) as int) AS LeaveDays, '' as HLTH_ORG_OSP_OSP_ID, '' as MG_AUTH_OSP_OSP_ID, '' as SE_CBK_SK
            FROM dbo.PRACTICE RIGHT JOIN ((dbo.DAYS_EPISODE INNER JOIN dbo.FACILITY ON dbo.DAYS_EPISODE.facility_identifier = dbo.FACILITY.facility_identifier) INNER JOIN dbo.EPISODE_ATS ON (dbo.DAYS_EPISODE.episode_sequence_number = dbo.EPISODE_ATS.episode_sequence_number) AND (dbo.DAYS_EPISODE.stay_number = dbo.EPISODE_ATS.stay_number) AND (dbo.DAYS_EPISODE.facility_identifier = dbo.EPISODE_ATS.facility_identifier)) ON (dbo.PRACTICE.facility_identifier = dbo.DAYS_EPISODE.facility_identifier) AND (dbo.PRACTICE.mo_code = dbo.DAYS_EPISODE.mo_code) 
            WHERE dbo.FACILITY.facility_identifier NOT IN ("""
                + facilities_excluded
                + """) AND (((dbo.DAYS_EPISODE.trans_type)='LEA')) 
            GROUP BY dbo.DAYS_EPISODE.facility_identifier, dbo.DAYS_EPISODE.stay_number, dbo.DAYS_EPISODE.episode_sequence_number, dbo.DAYS_EPISODE.start_date, dbo.DAYS_EPISODE.start_time, dbo.DAYS_EPISODE.end_date, dbo.DAYS_EPISODE.end_time, dbo.DAYS_EPISODE.trans_type, dbo.DAYS_EPISODE.snap_curr_indicator, dbo.EPISODE_ATS.snap_curr_indicator, dbo.PRACTICE.snap_curr_indicator, dbo.FACILITY.snap_curr_indicator, dbo.EPISODE_ATS.episode_start_date, dbo.EPISODE_ATS.episode_end_date, dbo.FACILITY.area_identifier, dbo.PRACTICE.snap_curr_indicator, dbo.EPISODE_ATS.episode_of_care_type 
            HAVING (((dbo.DAYS_EPISODE.facility_identifier)<>"D311" And (dbo.DAYS_EPISODE.facility_identifier)<>"Q230") AND ((dbo.DAYS_EPISODE.snap_curr_indicator)='Y' And (dbo.DAYS_EPISODE.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND 
            ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.PRACTICE.snap_curr_indicator)='Y' Or (dbo.PRACTICE.snap_curr_indicator) Is Null)) OR (((dbo.DAYS_EPISODE.facility_identifier)<>"D311" And (dbo.DAYS_EPISODE.facility_identifier)<>"Q230") AND ((dbo.DAYS_EPISODE.snap_curr_indicator)='Y' And (dbo.DAYS_EPISODE.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.PRACTICE.snap_curr_indicator)='Y' Or (dbo.PRACTICE.snap_curr_indicator) Is Null)) OR (((dbo.DAYS_EPISODE.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.DAYS_EPISODE.snap_curr_indicator)='Y' And (dbo.DAYS_EPISODE.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.PRACTICE.snap_curr_indicator)='Y' Or (dbo.PRACTICE.snap_curr_indicator) Is Null)) OR (((dbo.DAYS_EPISODE.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.DAYS_EPISODE.snap_curr_indicator)='Y' And (dbo.DAYS_EPISODE.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.PRACTICE.snap_curr_indicator)='Y' Or (dbo.PRACTICE.snap_curr_indicator) Is Null)) ;"""
            )
    elif source == "EDW":
        if len(facilities_included_list) > 0:
            query_PpmTransferLeave00 = (
                """SELECT * FROM (SELECT DISTINCT K.facility_identifier,RIGHT(CONCAT('00000000', ISNULL(SUBSTRING(C.SRV_ENC_REC_ID,charindex('-',C.SRV_ENC_REC_ID)+1,8),'')), 8) as stay_number,C.SEQ_AP_SE_IN_ENC as episode_sequence_number,CAST(C.SE_SEG_ST_DTTM as date) as start_date,CAST(C.SE_SEG_ST_DTTM as time(0)) as start_time,CAST(C.SE_SEG_END_DTTM as date) as end_date,CAST(C.SE_SEG_END_DTTM as time(0)) as end_time, case when c.DIM_SE_LEAVE_PRF_SK <> -1 and SUBSTRING(c.SE_LEAVE_PRF_CBK,charindex('|',c.SE_LEAVE_PRF_CBK)+1,1) in ('C', 'L') then 'LEA' else '' end as trans_type,case when (C.SE_SEG_ST_DTTM is not null and cast(C.SE_SEG_ST_DTTM as date) !='9999-12-31' and C.SE_SEG_END_DTTM is not null and cast(C.SE_SEG_END_DTTM as date) != '9999-12-31') then datediff(day,CAST(C.SE_SEG_ST_DTTM as date), CAST(C.SE_SEG_END_DTTM as date)) else 0 end as LeaveDays, K.OSP_ID as HLTH_ORG_OSP_OSP_ID,K.MG_AUTH_OSP_OSP_ID,C.SE_CBK_SK FROM CRT.V_FACT_AP_SE_SEG as C INNER JOIN (SELECT DISTINCT DIM_OSP_SK, OSP_HIE_FAC_ID,HLTH_ORG_OSP_OSP_ID, MG_AUTH_OSP_HLTH_SECTOR_CD, HLTH_ORG_OSP_HLTH_SECTOR_CD, OSP_TYP_CD,HLTH_ORG_OSP_HIE_FAC_ID, MG_AUTH_OSP_HIE_FAC_ID, MG_AUTH_OSP_OSP_ID,case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_ID else HLTH_ORG_OSP_OSP_ID end as OSP_ID, case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_HIE_FAC_ID else HLTH_ORG_OSP_HIE_FAC_ID end as facility_identifier FROM CRT.v_DIM_OSP WHERE HLTH_ORG_OSP_HIE_FAC_ID != '-1' AND HLTH_ORG_OSP_HIE_FAC_ID != '' and ((MG_AUTH_OSP_HLTH_SECTOR_CD IN ('1','3')) and (HLTH_ORG_OSP_HLTH_SECTOR_CD IN ('1','3')))) AS K ON C.DIM_OSP_CREATED_SK = K.DIM_OSP_SK WHERE K.facility_identifier IN ("""
                + facilities_included
                + """) GROUP BY K.facility_identifier,C.SRV_ENC_REC_ID,C.SEQ_AP_SE_IN_ENC,C.SE_SEG_ST_DTTM , C.SE_SEG_END_DTTM, c.SEQ_AP_SE_IN_ENC,c.SEQ_SEG_IN_SE,C.DIM_SE_LEAVE_PRF_SK,C.SE_LEAVE_PRF_CBK,K.MG_AUTH_OSP_HIE_FAC_ID, CAST(C.SE_ST_DTTM as date), CAST(C.SE_END_DTTM as date),C.SE_END_DTTM,K.MG_AUTH_OSP_HLTH_SECTOR_CD,K.HLTH_ORG_OSP_HLTH_SECTOR_CD,K.OSP_ID, K.HLTH_ORG_OSP_OSP_ID,K.MG_AUTH_OSP_OSP_ID,C.SE_CBK_SK, K.OSP_TYP_CD, K.HLTH_ORG_OSP_HIE_FAC_ID HAVING (((CAST(C.SE_SEG_ST_DTTM as date))<='"""
                + end_date
                + """') AND ((CAST(C.SE_SEG_END_DTTM as date))>='"""
                + start_date
                + """' OR (C.SE_SEG_END_DTTM) Is Null) AND ((K.MG_AUTH_OSP_HIE_FAC_ID)='"""
                + lhd
                + """' OR (K.facility_identifier)='"""
                + lhd
                + """'))) as A WHERE trans_type = 'LEA'  ;"""
            )
    retry_flag = True
    retry_count = 0
    while retry_flag and retry_count < 5:
        try:
            logging.info(query_PpmTransferLeave00)
            tbl_PPM_transfer_Leave_00 = pd.read_sql(query_PpmTransferLeave00, cnxn)
            retry_flag = False
        except Exception as e:
            retry_count = retry_count + 1
            time.sleep(5)
            if retry_count == 5:
                logging.exception("Exception occurred")
                label_4_status = 0
                messagebox.showerror(
                    "SQL Error",
                    "Error extracting PPM_transfer_Leave00 details\n" + str(e),
                )
                label_4_sub.configure(text="Failed (PPM_transfer_Leave00)...", fg="red")
                main_screen.update()
                tbl_PPM_transfer_Leave_00 = pd.DataFrame(
                    columns=[
                        "facility_identifier",
                        "stay_number",
                        "episode_sequence_number",
                        "start_date",
                        "start_time",
                        "end_date",
                        "end_time",
                        "trans_type",
                        "LeaveDays",
                        "HLTH_ORG_OSP_OSP_ID",
                        "MG_AUTH_OSP_OSP_ID",
                        "SE_CBK_SK",
                    ]
                )
                return  # stop extraction
        else:
            tbl_PPM_transfer_Leave_00 = tbl_PPM_transfer_Leave_00.fillna("")
            tbl_PPM_transfer_Leave_00 = tbl_PPM_transfer_Leave_00[
                [
                    "facility_identifier",
                    "stay_number",
                    "episode_sequence_number",
                    "start_date",
                    "start_time",
                    "end_date",
                    "end_time",
                    "trans_type",
                    "LeaveDays",
                    "HLTH_ORG_OSP_OSP_ID",
                    "MG_AUTH_OSP_OSP_ID",
                    "SE_CBK_SK",
                ]
            ]
            tbl_PPM_transfer_Leave_00 = tbl_PPM_transfer_Leave_00[
                tbl_PPM_transfer_Leave_00["facility_identifier"].isin(
                    facilities_included_list_global
                )
            ]
            tbl_PPM_transfer_Leave_00 = tbl_PPM_transfer_Leave_00.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_PPM_transfer_Leave_00 = tbl_PPM_transfer_Leave_00.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_PPM_transfer_Leave_00 = tbl_PPM_transfer_Leave_00.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_PPM_transfer_Leave_00 = tbl_PPM_transfer_Leave_00.apply(
                lambda x: x.replace(regex=r"NULL", value="")
                if x.dtype == "object"
                else x
            )
            tbl_PPM_transfer_Leave_00 = tbl_PPM_transfer_Leave_00.apply(
                lambda x: x.replace(regex=r"null", value="")
                if x.dtype == "object"
                else x
            )
            tbl_PPM_transfer_Leave_00 = tbl_PPM_transfer_Leave_00.apply(
                lambda x: x.replace(regex=r"Null", value="")
                if x.dtype == "object"
                else x
            )
            tbl_PPM_transfer_Leave_00["stay_number"] = (
                tbl_PPM_transfer_Leave_00["stay_number"]
                .astype(str)
                .str.pad(8, side="left", fillchar="0")
            )
            tbl_PPM_transfer_Leave_00["episode_sequence_number"] = (
                tbl_PPM_transfer_Leave_00["episode_sequence_number"]
                .astype(str)
                .str.pad(3, side="left", fillchar="0")
            )
            # dropping duplicate values
            tbl_PPM_transfer_Leave_00.drop_duplicates(keep="last", inplace=True)
            tbl_PPM_transfer_Leave_00.to_csv(
                "./ExtractorDB/tbl_PPM_transfer_Leave00.csv",
                index=False,
                na_rep="",
                float_format=str,
                decimal=str,
                date_format=str,
            )
            logging.info("tbl_PPM_transfer_Leave_00=%s", len(tbl_PPM_transfer_Leave_00))
    # PpmTransferLeave02
    # columns =
    # Access query = tbl_PPM_transfer_Leave 01
    label_4_sub.configure(text="In Progress (PPM_transfer_Leave02)...", fg="blue")
    main_screen.update()
    if source == "HIE":
        if len(facilities_excluded_list) == 0:
            query_PpmTransferLeave02 = (
                """SELECT tbl_PPM_transfer_Leave.facility_identifier, tbl_PPM_transfer_Leave.stay_number, tbl_PPM_transfer_Leave.episode_sequence_number, tbl_PPM_transfer_Leave.trans_type, 
            cast(sum(datediff(day,
            (case when CAST( tbl_PPM_transfer_Leave.start_date AS DATE )<CAST('"""
                + start_date
                + """' AS DATE ) then CAST('"""
                + start_date
                + """' AS DATE )
                  else case when CAST( tbl_PPM_transfer_Leave.start_date AS DATE )>CAST('"""
                + end_date
                + """' AS DATE ) then CAST('"""
                + start_date
                + """' AS DATE )
                            else CAST( tbl_PPM_transfer_Leave.start_date AS DATE ) 
                            end 
                  end),
            (case when CAST( tbl_PPM_transfer_Leave.end_date AS DATE ) Is Null then CAST('"""
                + end_date
                + """' AS DATE )
                  else case when CAST( tbl_PPM_transfer_Leave.end_date AS DATE )>CAST('"""
                + end_date
                + """' AS DATE ) then CAST('"""
                + end_date
                + """' AS DATE )
                            else CAST( tbl_PPM_transfer_Leave.end_date AS DATE ) 
                            end
                  end)
            )) as int) AS LeaveDays, '' as HLTH_ORG_OSP_OSP_ID, '' as MG_AUTH_OSP_OSP_ID, '' as SE_CBK_SK
            FROM (SELECT DISTINCT dbo.DAYS_EPISODE.facility_identifier, dbo.DAYS_EPISODE.stay_number, dbo.DAYS_EPISODE.episode_sequence_number, dbo.DAYS_EPISODE.start_date, dbo.DAYS_EPISODE.start_time, dbo.DAYS_EPISODE.end_date, dbo.DAYS_EPISODE.end_time, dbo.DAYS_EPISODE.trans_type FROM dbo.PRACTICE RIGHT JOIN ((dbo.DAYS_EPISODE INNER JOIN dbo.FACILITY ON dbo.DAYS_EPISODE.facility_identifier = dbo.FACILITY.facility_identifier) INNER JOIN dbo.EPISODE_ATS ON (dbo.DAYS_EPISODE.episode_sequence_number = dbo.EPISODE_ATS.episode_sequence_number) AND (dbo.DAYS_EPISODE.stay_number = dbo.EPISODE_ATS.stay_number) AND (dbo.DAYS_EPISODE.facility_identifier = dbo.EPISODE_ATS.facility_identifier)) ON (dbo.PRACTICE.facility_identifier = dbo.DAYS_EPISODE.facility_identifier) AND (dbo.PRACTICE.mo_code = dbo.DAYS_EPISODE.mo_code) WHERE (((dbo.DAYS_EPISODE.trans_type)='LEA')) 
            GROUP BY dbo.DAYS_EPISODE.facility_identifier, dbo.DAYS_EPISODE.stay_number, dbo.DAYS_EPISODE.episode_sequence_number, dbo.DAYS_EPISODE.start_date, dbo.DAYS_EPISODE.start_time, dbo.DAYS_EPISODE.end_date, dbo.DAYS_EPISODE.end_time, dbo.DAYS_EPISODE.trans_type, dbo.DAYS_EPISODE.snap_curr_indicator, dbo.EPISODE_ATS.snap_curr_indicator, dbo.PRACTICE.snap_curr_indicator, dbo.FACILITY.snap_curr_indicator, dbo.EPISODE_ATS.episode_start_date, dbo.EPISODE_ATS.episode_end_date, dbo.FACILITY.area_identifier, dbo.PRACTICE.snap_curr_indicator, dbo.EPISODE_ATS.episode_of_care_type 
            HAVING (((dbo.DAYS_EPISODE.facility_identifier)<>"D311" And (dbo.DAYS_EPISODE.facility_identifier)<>"Q230") AND ((dbo.DAYS_EPISODE.snap_curr_indicator)='Y' And (dbo.DAYS_EPISODE.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND 
            ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.PRACTICE.snap_curr_indicator)='Y' Or (dbo.PRACTICE.snap_curr_indicator) Is Null)) OR (((dbo.DAYS_EPISODE.facility_identifier)<>"D311" And (dbo.DAYS_EPISODE.facility_identifier)<>"Q230") AND ((dbo.DAYS_EPISODE.snap_curr_indicator)='Y' And (dbo.DAYS_EPISODE.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.PRACTICE.snap_curr_indicator)='Y' Or (dbo.PRACTICE.snap_curr_indicator) Is Null)) OR (((dbo.DAYS_EPISODE.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.DAYS_EPISODE.snap_curr_indicator)='Y' And (dbo.DAYS_EPISODE.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.PRACTICE.snap_curr_indicator)='Y' Or (dbo.PRACTICE.snap_curr_indicator) Is Null)) OR (((dbo.DAYS_EPISODE.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.DAYS_EPISODE.snap_curr_indicator)='Y' And (dbo.DAYS_EPISODE.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.PRACTICE.snap_curr_indicator)='Y' Or (dbo.PRACTICE.snap_curr_indicator) Is Null))) AS tbl_PPM_transfer_Leave
            WHERE (((tbl_PPM_transfer_Leave.start_date) Between '"""
                + start_date
                + """' And '"""
                + end_date
                + """')) OR (((tbl_PPM_transfer_Leave.end_date) Between '"""
                + start_date
                + """' And '"""
                + end_date
                + """')) OR (((tbl_PPM_transfer_Leave.start_date) < '"""
                + start_date
                + """') AND ((tbl_PPM_transfer_Leave.end_date) > '"""
                + end_date
                + """' Or (tbl_PPM_transfer_Leave.end_date) Is Null))
            GROUP BY tbl_PPM_transfer_Leave.facility_identifier, tbl_PPM_transfer_Leave.stay_number, tbl_PPM_transfer_Leave.episode_sequence_number, tbl_PPM_transfer_Leave.trans_type;"""
            )
        else:
            query_PpmTransferLeave02 = (
                """SELECT tbl_PPM_transfer_Leave.facility_identifier, tbl_PPM_transfer_Leave.stay_number, tbl_PPM_transfer_Leave.episode_sequence_number, tbl_PPM_transfer_Leave.trans_type, 
            cast(sum(datediff(day,
            (case when CAST( tbl_PPM_transfer_Leave.start_date AS DATE )<CAST('"""
                + start_date
                + """' AS DATE ) then CAST('"""
                + start_date
                + """' AS DATE )
                  else case when CAST( tbl_PPM_transfer_Leave.start_date AS DATE )>CAST('"""
                + end_date
                + """' AS DATE ) then CAST('"""
                + start_date
                + """' AS DATE )
                            else CAST( tbl_PPM_transfer_Leave.start_date AS DATE ) 
                            end 
                  end),
            (case when CAST( tbl_PPM_transfer_Leave.end_date AS DATE ) Is Null then CAST('"""
                + end_date
                + """' AS DATE )
                  else case when CAST( tbl_PPM_transfer_Leave.end_date AS DATE )>CAST('"""
                + end_date
                + """' AS DATE ) then CAST('"""
                + end_date
                + """' AS DATE )
                            else CAST( tbl_PPM_transfer_Leave.end_date AS DATE ) 
                            end
                  end)
            )) as int) AS LeaveDays, '' as HLTH_ORG_OSP_OSP_ID, '' as MG_AUTH_OSP_OSP_ID, '' as SE_CBK_SK
            FROM (SELECT DISTINCT dbo.DAYS_EPISODE.facility_identifier, dbo.DAYS_EPISODE.stay_number, dbo.DAYS_EPISODE.episode_sequence_number, dbo.DAYS_EPISODE.start_date, dbo.DAYS_EPISODE.start_time, dbo.DAYS_EPISODE.end_date, dbo.DAYS_EPISODE.end_time, dbo.DAYS_EPISODE.trans_type FROM dbo.PRACTICE RIGHT JOIN ((dbo.DAYS_EPISODE INNER JOIN dbo.FACILITY ON dbo.DAYS_EPISODE.facility_identifier = dbo.FACILITY.facility_identifier) INNER JOIN dbo.EPISODE_ATS ON (dbo.DAYS_EPISODE.episode_sequence_number = dbo.EPISODE_ATS.episode_sequence_number) AND (dbo.DAYS_EPISODE.stay_number = dbo.EPISODE_ATS.stay_number) AND (dbo.DAYS_EPISODE.facility_identifier = dbo.EPISODE_ATS.facility_identifier)) ON (dbo.PRACTICE.facility_identifier = dbo.DAYS_EPISODE.facility_identifier) AND (dbo.PRACTICE.mo_code = dbo.DAYS_EPISODE.mo_code) WHERE dbo.FACILITY.facility_identifier NOT IN ("""
                + facilities_excluded
                + """) AND (((dbo.DAYS_EPISODE.trans_type)='LEA')) 
            GROUP BY dbo.DAYS_EPISODE.facility_identifier, dbo.DAYS_EPISODE.stay_number, dbo.DAYS_EPISODE.episode_sequence_number, dbo.DAYS_EPISODE.start_date, dbo.DAYS_EPISODE.start_time, dbo.DAYS_EPISODE.end_date, dbo.DAYS_EPISODE.end_time, dbo.DAYS_EPISODE.trans_type, dbo.DAYS_EPISODE.snap_curr_indicator, dbo.EPISODE_ATS.snap_curr_indicator, dbo.PRACTICE.snap_curr_indicator, dbo.FACILITY.snap_curr_indicator, dbo.EPISODE_ATS.episode_start_date, dbo.EPISODE_ATS.episode_end_date, dbo.FACILITY.area_identifier, dbo.PRACTICE.snap_curr_indicator, dbo.EPISODE_ATS.episode_of_care_type 
            HAVING (((dbo.DAYS_EPISODE.facility_identifier)<>"D311" And (dbo.DAYS_EPISODE.facility_identifier)<>"Q230") AND ((dbo.DAYS_EPISODE.snap_curr_indicator)='Y' And (dbo.DAYS_EPISODE.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND 
            ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.PRACTICE.snap_curr_indicator)='Y' Or (dbo.PRACTICE.snap_curr_indicator) Is Null)) OR (((dbo.DAYS_EPISODE.facility_identifier)<>"D311" And (dbo.DAYS_EPISODE.facility_identifier)<>"Q230") AND ((dbo.DAYS_EPISODE.snap_curr_indicator)='Y' And (dbo.DAYS_EPISODE.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.PRACTICE.snap_curr_indicator)='Y' Or (dbo.PRACTICE.snap_curr_indicator) Is Null)) OR (((dbo.DAYS_EPISODE.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.DAYS_EPISODE.snap_curr_indicator)='Y' And (dbo.DAYS_EPISODE.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.PRACTICE.snap_curr_indicator)='Y' Or (dbo.PRACTICE.snap_curr_indicator) Is Null)) OR (((dbo.DAYS_EPISODE.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.DAYS_EPISODE.snap_curr_indicator)='Y' And (dbo.DAYS_EPISODE.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.PRACTICE.snap_curr_indicator)='Y' Or (dbo.PRACTICE.snap_curr_indicator) Is Null))) AS tbl_PPM_transfer_Leave
            WHERE (((tbl_PPM_transfer_Leave.start_date) Between '"""
                + start_date
                + """' And '"""
                + end_date
                + """')) OR (((tbl_PPM_transfer_Leave.end_date) Between '"""
                + start_date
                + """' And '"""
                + end_date
                + """')) OR (((tbl_PPM_transfer_Leave.start_date) < '"""
                + start_date
                + """') AND ((tbl_PPM_transfer_Leave.end_date) > '"""
                + end_date
                + """' Or (tbl_PPM_transfer_Leave.end_date) Is Null))
            GROUP BY tbl_PPM_transfer_Leave.facility_identifier, tbl_PPM_transfer_Leave.stay_number, tbl_PPM_transfer_Leave.episode_sequence_number, tbl_PPM_transfer_Leave.trans_type;"""
            )
    elif source == "EDW":
        if len(facilities_included_list) > 0:
            query_PpmTransferLeave02 = (
                """SELECT DISTINCT tbl_PPM_transfer_Leave.facility_identifier, tbl_PPM_transfer_Leave.stay_number, tbl_PPM_transfer_Leave.episode_sequence_number, tbl_PPM_transfer_Leave.trans_type,sum(Daysdiff) as LeaveDays,HLTH_ORG_OSP_OSP_ID,MG_AUTH_OSP_OSP_ID,SE_CBK_SK FROM (SELECT DISTINCT k.facility_identifier,RIGHT(CONCAT('00000000', ISNULL(SUBSTRING(C.SRV_ENC_REC_ID,charindex('-',C.SRV_ENC_REC_ID)+1,8),'')),8) as stay_number	,C.SEQ_AP_SE_IN_ENC as episode_sequence_number,cast(C.SE_SEG_ST_DTTM as date) as start_date,cast(C.SE_SEG_ST_DTTM as time(0)) as start_time,cast(C.SE_SEG_END_DTTM as date) as end_date,cast(C.SE_SEG_END_DTTM as time(0)) as end_time,case when c.DIM_SE_LEAVE_PRF_SK <> -1 and SUBSTRING(c.SE_LEAVE_PRF_CBK,charindex('|',c.SE_LEAVE_PRF_CBK)+1,1) in ('C', 'L') then 'LEA' else '' end as trans_type,K.OSP_ID as HLTH_ORG_OSP_OSP_ID,K.MG_AUTH_OSP_OSP_ID,C.SE_CBK_SK,case when (C.SE_SEG_ST_DTTM is not null and cast(C.SE_SEG_ST_DTTM as date) !='9999-12-31' and C.SE_SEG_END_DTTM is not null and cast(C.SE_SEG_END_DTTM as date) != '9999-12-31') then datediff(day,CAST(C.SE_SEG_ST_DTTM as date), CAST(C.SE_SEG_END_DTTM as date)) else 0 end as Daysdiff	FROM CRT.v_FACT_AP_SE_SEG as C INNER JOIN (SELECT DISTINCT DIM_OSP_SK, OSP_HIE_FAC_ID,HLTH_ORG_OSP_OSP_ID, MG_AUTH_OSP_HLTH_SECTOR_CD, HLTH_ORG_OSP_HLTH_SECTOR_CD, OSP_TYP_CD,HLTH_ORG_OSP_HIE_FAC_ID, MG_AUTH_OSP_HIE_FAC_ID, MG_AUTH_OSP_OSP_ID,case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_ID else HLTH_ORG_OSP_OSP_ID end as OSP_ID,case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_HIE_FAC_ID else HLTH_ORG_OSP_HIE_FAC_ID end as facility_identifier FROM CRT.v_DIM_OSP WHERE ((MG_AUTH_OSP_HLTH_SECTOR_CD IN ('1','3')) and (HLTH_ORG_OSP_HLTH_SECTOR_CD IN ('1','3'))) AND HLTH_ORG_OSP_HIE_FAC_ID != '-1' AND HLTH_ORG_OSP_HIE_FAC_ID != '') AS K ON C.DIM_OSP_CREATED_SK = K.DIM_OSP_SK WHERE (K.facility_identifier) IN ("""
                + facilities_included
                + """) GROUP BY 	K.facility_identifier,C.SRV_ENC_REC_ID,C.SEQ_AP_SE_IN_ENC,C.SE_SEG_ST_DTTM,C.SE_SEG_ST_DTTM,C.SE_SEG_END_DTTM,C.SE_SEG_END_DTTM,c.SEQ_AP_SE_IN_ENC,c.SEQ_SEG_IN_SE,C.DIM_SE_LEAVE_PRF_SK,c.SE_LEAVE_PRF_CBK,CAST(C.SE_ST_DTTM as date),CAST(C.SE_end_DTTM as date),K.MG_AUTH_OSP_HIE_FAC_ID,K.MG_AUTH_OSP_HLTH_SECTOR_CD,K.HLTH_ORG_OSP_HLTH_SECTOR_CD,K.OSP_ID,K.HLTH_ORG_OSP_OSP_ID,K.MG_AUTH_OSP_OSP_ID,C.SE_CBK_SK,K.OSP_TYP_CD,K.HLTH_ORG_OSP_HIE_FAC_ID HAVING (((CAST(C.SE_SEG_ST_DTTM as date))<='"""
                + end_date
                + """') AND ((CAST(C.SE_SEG_END_DTTM as date))>='"""
                + start_date
                + """' OR (CAST(C.SE_SEG_END_DTTM as date)) Is Null) AND ((K.MG_AUTH_OSP_HIE_FAC_ID)='"""
                + lhd
                + """' OR (K.facility_identifier)='"""
                + lhd
                + """'))) as tbl_PPM_transfer_Leave WHERE tbl_PPM_transfer_Leave.trans_type = 'LEA' AND ((((tbl_PPM_transfer_Leave.start_date) Between '"""
                + start_date
                + """' AND '"""
                + end_date
                + """')) OR (((tbl_PPM_transfer_Leave.end_date) Between '"""
                + start_date
                + """' AND '"""
                + end_date
                + """')) OR (((tbl_PPM_transfer_Leave.start_date) < '"""
                + start_date
                + """') AND ((tbl_PPM_transfer_Leave.end_date) > '"""
                + end_date
                + """' Or (tbl_PPM_transfer_Leave.end_date) Is Null))) GROUP BY tbl_PPM_transfer_Leave.facility_identifier,tbl_PPM_transfer_Leave.stay_number,tbl_PPM_transfer_Leave.episode_sequence_number,tbl_PPM_transfer_Leave.trans_type,HLTH_ORG_OSP_OSP_ID,MG_AUTH_OSP_OSP_ID,SE_CBK_SK  ;"""
            )
    retry_flag = True
    retry_count = 0
    while retry_flag and retry_count < 5:
        try:
            logging.info(query_PpmTransferLeave02)
            tbl_PPM_transfer_Leave_02 = pd.read_sql(query_PpmTransferLeave02, cnxn)
            retry_flag = False
        except Exception as e:
            retry_count = retry_count + 1
            time.sleep(5)
            if retry_count == 5:
                logging.exception("Exception occurred")
                label_4_status = 0
                messagebox.showerror(
                    "SQL Error",
                    "Error extracting PPM_transfer_Leave02 details\n" + str(e),
                )
                label_4_sub.configure(text="Failed (PPM_transfer_Leave02)...", fg="red")
                main_screen.update()
                tbl_PPM_transfer_Leave_02 = pd.DataFrame(
                    columns=[
                        "facility_identifier",
                        "stay_number",
                        "episode_sequence_number",
                        "trans_type",
                        "LeaveDays",
                        "HLTH_ORG_OSP_OSP_ID",
                        "MG_AUTH_OSP_OSP_ID",
                        "SE_CBK_SK",
                    ]
                )
                return  # stop extraction
        else:
            tbl_PPM_transfer_Leave_02 = tbl_PPM_transfer_Leave_02.fillna("")
            tbl_PPM_transfer_Leave_02 = tbl_PPM_transfer_Leave_02[
                [
                    "facility_identifier",
                    "stay_number",
                    "episode_sequence_number",
                    "trans_type",
                    "LeaveDays",
                    "HLTH_ORG_OSP_OSP_ID",
                    "MG_AUTH_OSP_OSP_ID",
                    "SE_CBK_SK",
                ]
            ]
            tbl_PPM_transfer_Leave_02 = tbl_PPM_transfer_Leave_02[
                tbl_PPM_transfer_Leave_02["facility_identifier"].isin(
                    facilities_included_list_global
                )
            ]
            tbl_PPM_transfer_Leave_02 = tbl_PPM_transfer_Leave_02.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_PPM_transfer_Leave_02 = tbl_PPM_transfer_Leave_02.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_PPM_transfer_Leave_02 = tbl_PPM_transfer_Leave_02.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_PPM_transfer_Leave_02 = tbl_PPM_transfer_Leave_02.apply(
                lambda x: x.replace(regex=r"NULL", value="")
                if x.dtype == "object"
                else x
            )
            tbl_PPM_transfer_Leave_02 = tbl_PPM_transfer_Leave_02.apply(
                lambda x: x.replace(regex=r"null", value="")
                if x.dtype == "object"
                else x
            )
            tbl_PPM_transfer_Leave_02 = tbl_PPM_transfer_Leave_02.apply(
                lambda x: x.replace(regex=r"Null", value="")
                if x.dtype == "object"
                else x
            )
            tbl_PPM_transfer_Leave_02["stay_number"] = (
                tbl_PPM_transfer_Leave_02["stay_number"]
                .astype(str)
                .str.pad(8, side="left", fillchar="0")
            )
            tbl_PPM_transfer_Leave_02["episode_sequence_number"] = (
                tbl_PPM_transfer_Leave_02["episode_sequence_number"]
                .astype(str)
                .str.pad(3, side="left", fillchar="0")
            )
            # dropping duplicate values
            tbl_PPM_transfer_Leave_02.drop_duplicates(keep="last", inplace=True)
            tbl_PPM_transfer_Leave_02.to_csv(
                "./ExtractorDB/tbl_PPM_transfer_Leave02.csv",
                index=False,
                na_rep="",
                float_format=str,
                decimal=str,
                date_format=str,
            )
            logging.info("tbl_PPM_transfer_Leave_02=%s", len(tbl_PPM_transfer_Leave_02))
    # Update Sub task status
    if label_4_status == 0:
        label_4_sub.configure(text="Failed", fg="red")
        main_screen.update()
    else:
        label_4_sub.configure(text="Completed", fg="green")
        main_screen.update()
    # label_4_res.configure(text="DaysEpisode:"+str(len(tbl_dbo_days_episode))+",  df_PpmTransferAmo:"+str(len(df_PpmTransferAmo))+",\ntbl_PPM_transfer_Leave00:"+str(len(tbl_PPM_transfer_Leave_00))+",   tbl_PPM_transfer_Leave02:"+str(len(tbl_PPM_transfer_Leave_02)))
    main_screen.update()
    ######################################### EXTRACT DATA - SUB TASK 5 #######################################
    # Set default value of sub-task status to 1
    label_5_status = 1
    # PpmIcdDiagnoses
    # columns = EncounterNumber,DiagnosisCode,DiagnosisVersion,Sequence,ConditionOnset
    """ Appends data from the dbo_diagnosis table where the lhd and date range entered in the form is for episodes in ATS table"""
    # Access query = Append_to_tbl_PPM_ICD_diagnoses
    #   Note: Acces code uses diagnosis_code_curr and clinical_codeset_curr instead of diagnosis_code and clinical_codeset used in Inform8
    #   Access SELECT query: INSERT INTO tbl_PPM_ICD_diagnoses ( EncounterNumber, DiagnosisCode, DiagnosisVersion, Sequence, ConditionOnset ) SELECT [dbo_episode_ats]![facility_identifier] & "-" & "I" & "-" & Format$([dbo_episode_ats]![stay_number],"00000000") & "-" & IIf(Len([dbo_episode_ats]![episode_sequence_number])=3,[dbo_episode_ats]![episode_sequence_number],IIf(Len([dbo_episode_ats]![episode_sequence_number])=2,"0" & [dbo_episode_ats]![episode_sequence_number],"00" & [dbo_episode_ats]![episode_sequence_number])) AS Expr1, dbo_DIAGNOSIS.diagnosis_code_curr, dbo_DIAGNOSIS.clinical_codeset_curr, IIf(dbo_DIAGNOSIS.diagnosis_type="P",0,Val(dbo_DIAGNOSIS.diagnosis_type)) AS Expr2, dbo_DIAGNOSIS.condition_onset_flag
    # val(dbo.DIAGNOSIS.diagnosis_type) in sql = CASE WHEN Patindex('%[^0-9]%', dbo.DIAGNOSIS.diagnosis_type) > 0 THEN Cast(LEFT(dbo.DIAGNOSIS.diagnosis_type, Patindex('%[^0-9]%', dbo.DIAGNOSIS.diagnosis_type) - 1) AS INT) ELSE 0 END
    label_5_sub.configure(text="In Progress (Diagnoses)...", fg="blue")
    main_screen.update()
    if source == "HIE":
        if len(facilities_excluded_list) == 0:
            query_IcdDiagnoses = (
                """SELECT (TRIM(STRING(dbo.EPISODE_ATS.facility_identifier)) + "-I-" + RIGHT(TRIM(STRING('00000000', dbo.EPISODE_ATS.stay_number)),8) + "-" + RIGHT(TRIM(STRING('000', dbo.EPISODE_ATS.episode_sequence_number)),3)) AS EncounterNumber, dbo.DIAGNOSIS.diagnosis_code_curr as DiagnosisCode, dbo.DIAGNOSIS.clinical_codeset as DiagnosisVersion, (case when dbo.DIAGNOSIS.diagnosis_type='P' Then '0' else dbo.DIAGNOSIS.diagnosis_type end) as Sequence, dbo.DIAGNOSIS.condition_onset_flag AS ConditionOnset, '' as HLTH_ORG_OSP_OSP_ID, '' as MG_AUTH_OSP_OSP_ID, '' as SE_CBK_SK, '' as EDW_Enc_Number FROM (dbo.DIAGNOSIS INNER JOIN dbo.EPISODE_ATS ON (dbo.DIAGNOSIS.stay_number = dbo.EPISODE_ATS.stay_number) AND (dbo.DIAGNOSIS.facility_identifier = dbo.EPISODE_ATS.facility_identifier) AND (dbo.DIAGNOSIS.episode_sequence_number = dbo.EPISODE_ATS.episode_sequence_number)) INNER JOIN dbo.FACILITY ON dbo.EPISODE_ATS.facility_identifier = dbo.FACILITY.facility_identifier 
            WHERE ((((dbo.DIAGNOSIS.clinical_codeset)='"""
                + icd10_v
                + """') AND ((dbo.DIAGNOSIS.snap_curr_indicator)="Y") AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.FACILITY.snap_curr_indicator)='Y')  AND ((dbo.EPISODE_ATS.facility_identifier)<>"D311" And (dbo.EPISODE_ATS.facility_identifier)<>"Q230")) OR 
            (((dbo.DIAGNOSIS.clinical_codeset)='"""
                + icd10_v
                + """') AND ((dbo.DIAGNOSIS.snap_curr_indicator)="Y") AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.facility_identifier)<>"D311" And (dbo.EPISODE_ATS.facility_identifier)<>"Q230")) OR 
            (((dbo.DIAGNOSIS.clinical_codeset)='"""
                + icd10_v
                + """') AND ((dbo.DIAGNOSIS.snap_curr_indicator)="Y") AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.facility_identifier)='"""
                + lhd
                + """')) OR 
            (((dbo.DIAGNOSIS.clinical_codeset)='"""
                + icd10_v
                + """') AND ((dbo.DIAGNOSIS.snap_curr_indicator)="Y") AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.facility_identifier)='"""
                + lhd
                + """')));"""
            )
        else:
            query_IcdDiagnoses = (
                """SELECT (TRIM(STRING(dbo.EPISODE_ATS.facility_identifier)) + "-I-" + RIGHT(TRIM(STRING('00000000', dbo.EPISODE_ATS.stay_number)),8) + "-" +  RIGHT(TRIM(STRING('000', dbo.EPISODE_ATS.episode_sequence_number)),3)) AS EncounterNumber, dbo.DIAGNOSIS.diagnosis_code_curr as DiagnosisCode, dbo.DIAGNOSIS.clinical_codeset as DiagnosisVersion, (case when dbo.DIAGNOSIS.diagnosis_type='P' Then '0' else dbo.DIAGNOSIS.diagnosis_type end) as Sequence, dbo.DIAGNOSIS.condition_onset_flag AS ConditionOnset, '' as HLTH_ORG_OSP_OSP_ID, '' as MG_AUTH_OSP_OSP_ID, '' as SE_CBK_SK, '' as EDW_Enc_Number FROM (dbo.DIAGNOSIS INNER JOIN dbo.EPISODE_ATS ON (dbo.DIAGNOSIS.stay_number = dbo.EPISODE_ATS.stay_number) AND (dbo.DIAGNOSIS.facility_identifier = dbo.EPISODE_ATS.facility_identifier) AND (dbo.DIAGNOSIS.episode_sequence_number = dbo.EPISODE_ATS.episode_sequence_number)) INNER JOIN dbo.FACILITY ON dbo.EPISODE_ATS.facility_identifier = dbo.FACILITY.facility_identifier 
            WHERE ((((dbo.DIAGNOSIS.clinical_codeset)='"""
                + icd10_v
                + """') AND ((dbo.DIAGNOSIS.snap_curr_indicator)="Y") AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.FACILITY.snap_curr_indicator)='Y')  AND ((dbo.EPISODE_ATS.facility_identifier)<>"D311" And (dbo.EPISODE_ATS.facility_identifier)<>"Q230")) OR 
            (((dbo.DIAGNOSIS.clinical_codeset)='"""
                + icd10_v
                + """') AND ((dbo.DIAGNOSIS.snap_curr_indicator)="Y") AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.facility_identifier)<>"D311" And (dbo.EPISODE_ATS.facility_identifier)<>"Q230")) OR 
            (((dbo.DIAGNOSIS.clinical_codeset)='"""
                + icd10_v
                + """') AND ((dbo.DIAGNOSIS.snap_curr_indicator)="Y") AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.facility_identifier)='"""
                + lhd
                + """')) OR 
            (((dbo.DIAGNOSIS.clinical_codeset)='"""
                + icd10_v
                + """') AND ((dbo.DIAGNOSIS.snap_curr_indicator)="Y") AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.facility_identifier)='"""
                + lhd
                + """'))) AND dbo.FACILITY.facility_identifier NOT IN ("""
                + facilities_excluded
                + """);"""
            )
    elif source == "EDW":
        if len(facilities_included_list) > 0:
            query_IcdDiagnoses = (
                """with Diagrec as
            (select distinct SE_CBK_SK,SRV_ENC_REC_ID, SEQ_AP_SE_IN_ENC, DIM_OSP_CREATED_SK, CURR_DIAG_CD,DIAG_CD,case when CURR_DIAG_DOM_NM = 
            'International Statistical Classification of Diseases and Related Health Problems, Tenth Revision, Australian Modification (ICD10-AM) 13th Edition (EDW)' then 'ICD10V13'
                 when CURR_DIAG_DOM_NM = 
             'International Statistical Classification of Diseases and Related Health Problems, Tenth Revision, Australian Modification (ICD10-AM) 12th Edition (EDW)' then 'ICD10V12'
                 when CURR_DIAG_DOM_NM = 
             'International Statistical Classification of Diseases and Related Health Problems, Tenth Revision, Australian Modification (ICD10-AM) 11th Edition (EDW)' then 'ICD10V11' 
                 when CURR_DIAG_DOM_NM = 
             'International Statistical Classification of Diseases and Related Health Problems, Tenth Revision, Australian Modification (ICD10-AM) 10th Edition (EDW)' then 'ICD10V10' else '' end as Curr_DiagnosisVersion
            ,case when DIAG_DOM_NM = 
            'International Statistical Classification of Diseases and Related Health Problems, Tenth Revision, Australian Modification (ICD10-AM) 13th Edition (EDW)' then 'ICD10V13'
                 when DIAG_DOM_NM = 
             'International Statistical Classification of Diseases and Related Health Problems, Tenth Revision, Australian Modification (ICD10-AM) 12th Edition (EDW)' then 'ICD10V12'
                 when DIAG_DOM_NM = 
             'International Statistical Classification of Diseases and Related Health Problems, Tenth Revision, Australian Modification (ICD10-AM) 11th Edition (EDW)' then 'ICD10V11' 
                 when DIAG_DOM_NM = 
             'International Statistical Classification of Diseases and Related Health Problems, Tenth Revision, Australian Modification (ICD10-AM) 10th Edition (EDW)' then 'ICD10V10' else '' end as DiagnosisVersion
            ,DIAG_SEQ_NUM,COND_ONSET_TYP_CD from CRT.v_FACT_AP_SE_DIAGNOSIS_FLAT 
            where (DIM_DT_SE_ST_SK <= '"""
                + end_date
                + """' AND DIM_DT_SE_ST_SK != '1111-01-01') and (DIM_DT_SE_END_SK >= '"""
                + start_date
                + """' or DIM_DT_SE_END_SK is NULL OR DIM_DT_SE_END_SK = '1111-01-01')), OSPFiltered AS (SELECT DIM_OSP_SK, OSP_HIE_FAC_ID, MG_AUTH_OSP_HIE_FAC_ID, HLTH_ORG_OSP_OSP_ID,MG_AUTH_OSP_OSP_ID, HLTH_ORG_OSP_HIE_FAC_ID,case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_ID else HLTH_ORG_OSP_OSP_ID end as OSP_ID,case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09','35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_HIE_FAC_ID else HLTH_ORG_OSP_HIE_FAC_ID end as facility_identifier FROM CRT.v_DIM_OSP WHERE MG_AUTH_OSP_HLTH_SECTOR_CD IN ('1','3') AND HLTH_ORG_OSP_HLTH_SECTOR_CD IN ('1','3') AND HLTH_ORG_OSP_HIE_FAC_ID NOT IN ('-1', ''))
            select distinct (TRIM(K.facility_identifier) + '-I-' + RIGHT(CONCAT('00000000', ISNULL(SUBSTRING(a.SRV_ENC_REC_ID,charindex('-',a.SRV_ENC_REC_ID)+1,8),'')), 8) + '-' + RIGHT(CONCAT('000',ISNULL(a.SEQ_AP_SE_IN_ENC,'')),3)) as EncounterNumber ,case when a.Curr_DiagnosisVersion = '"""
                + icd10_v
                + """' then a.CURR_DIAG_CD else a.DIAG_CD end as DiagnosisCode,case when a.Curr_DiagnosisVersion = '"""
                + icd10_v
                + """' then a.Curr_DiagnosisVersion else a.DiagnosisVersion end as DiagnosisVersion,RIGHT(CONCAT('00',ISNULL(TRIM(CAST((case when a.DIAG_SEQ_NUM = 1 Then '0' else a.DIAG_SEQ_NUM - 1 end) AS VARCHAR)),'')),2) as Sequence,a.COND_ONSET_TYP_CD as ConditionOnset,K.OSP_ID as HLTH_ORG_OSP_OSP_ID,K.MG_AUTH_OSP_OSP_ID,A.SE_CBK_SK,(TRIM(K.HLTH_ORG_OSP_OSP_ID) + '-I-' + RIGHT(CONCAT('00000000', ISNULL(SUBSTRING(a.SRV_ENC_REC_ID,charindex('-',a.SRV_ENC_REC_ID)+1,8),'')), 8) + '-' + RIGHT(CONCAT('000',ISNULL(a.SEQ_AP_SE_IN_ENC,'')),3)) AS EDW_Enc_Number from Diagrec as a inner join OSPFiltered as k ON A.DIM_OSP_CREATED_SK = K.DIM_OSP_SK 
            WHERE (K.MG_AUTH_OSP_HIE_FAC_ID='"""
                + lhd
                + """' OR (K.facility_identifier)='"""
                + lhd
                + """') AND (K.facility_identifier) IN ("""
                + facilities_included
                + """);"""
            )
    retry_flag = True
    retry_count = 0
    while retry_flag and retry_count < 5:
        try:
            logging.info(query_IcdDiagnoses)
            tbl_PPM_ICD_diagnoses = pd.read_sql(query_IcdDiagnoses, cnxn)
            retry_flag = False
        except Exception as e:
            retry_count = retry_count + 1
            time.sleep(5)
            if retry_count == 5:
                logging.exception("Exception occurred")
                label_5_status = 0
                messagebox.showerror(
                    "SQL Error", "Error extracting Diagnoses details\n" + str(e)
                )
                label_5_sub.configure(text="Failed (Diagnoses)...", fg="red")
                main_screen.update()
                tbl_PPM_ICD_diagnoses = pd.DataFrame(
                    columns=[
                        "EncounterNumber",
                        "DiagnosisCode",
                        "DiagnosisVersion",
                        "Sequence",
                        "ConditionOnset",
                        "HLTH_ORG_OSP_OSP_ID",
                        "MG_AUTH_OSP_OSP_ID",
                        "SE_CBK_SK",
                        "EDW_Enc_Number",
                    ]
                )
                return  # stop extraction
        else:
            """If sequence is null then 1 if not then sequence +1 """
            # Access query = Diag_update_SeqNo
            # UPDATE tbl_PPM_ICD_diagnoses SET tbl_PPM_ICD_diagnoses.Sequence = IIf([Sequence] Is Null,1,[Sequence]+1);
            tbl_PPM_ICD_diagnoses = tbl_PPM_ICD_diagnoses.fillna("")
            tbl_PPM_ICD_diagnoses["Sequence"] = tbl_PPM_ICD_diagnoses[
                "Sequence"
            ].replace("<NA>", "")  # or 'Unknown', etc.
            tbl_PPM_ICD_diagnoses["Sequence"] = tbl_PPM_ICD_diagnoses[
                "Sequence"
            ].replace(r"<NA>", "", regex=True)
            # tbl_PPM_ICD_diagnoses['Sequence'] = np.where((pd.isna(tbl_PPM_ICD_diagnoses['Sequence'])) | (tbl_PPM_ICD_diagnoses['Sequence'].isnull()) | (tbl_PPM_ICD_diagnoses['Sequence']==''), 1, tbl_PPM_ICD_diagnoses['Sequence'].astype(int, errors='ignore')+1)
            # tbl_PPM_ICD_diagnoses['Sequence'] = tbl_PPM_ICD_diagnoses['Sequence'].apply(lambda x: '' if pd.isna(x) or x == '' or x=='<NA>' else pd.to_numeric(x, errors='coerce')).astype('Int64')
            tbl_PPM_ICD_diagnoses = tbl_PPM_ICD_diagnoses[
                [
                    "EncounterNumber",
                    "DiagnosisCode",
                    "DiagnosisVersion",
                    "Sequence",
                    "ConditionOnset",
                    "HLTH_ORG_OSP_OSP_ID",
                    "MG_AUTH_OSP_OSP_ID",
                    "SE_CBK_SK",
                    "EDW_Enc_Number",
                ]
            ]
            tbl_PPM_ICD_diagnoses = tbl_PPM_ICD_diagnoses.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_PPM_ICD_diagnoses = tbl_PPM_ICD_diagnoses.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_PPM_ICD_diagnoses = tbl_PPM_ICD_diagnoses.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_PPM_ICD_diagnoses = tbl_PPM_ICD_diagnoses.apply(
                lambda x: x.replace(regex=r"NULL", value="")
                if x.dtype == "object"
                else x
            )
            tbl_PPM_ICD_diagnoses = tbl_PPM_ICD_diagnoses.apply(
                lambda x: x.replace(regex=r"null", value="")
                if x.dtype == "object"
                else x
            )
            tbl_PPM_ICD_diagnoses = tbl_PPM_ICD_diagnoses.apply(
                lambda x: x.replace(regex=r"Null", value="")
                if x.dtype == "object"
                else x
            )
            # dropping duplicate values
            tbl_PPM_ICD_diagnoses.drop_duplicates(keep="last", inplace=True)
            tbl_PPM_ICD_diagnoses.to_csv(
                "./ExtractorDB/PpmIcdDiagnoses.csv",
                index=False,
                na_rep="",
                float_format=str,
                decimal=str,
                date_format=str,
            )
            logging.info("tbl_PPM_ICD_diagnoses=%s", len(tbl_PPM_ICD_diagnoses))
    # qry_Diagnosis_ICD10V12
    # Access query: qry_Diagnosis_ICD10V12
    # INSERT INTO diagnosis_ICD10V12 ( clinical_codeset_curr, diagnosis_type, episode_sequence_number, stay_number, facility_identifier, diagnosis_code_curr, condition_onset_flag, EncounterNumber )
    # SELECT dbo_DIAGNOSIS.clinical_codeset_curr, dbo_DIAGNOSIS.diagnosis_type, dbo_DIAGNOSIS.episode_sequence_number, "SN" & Trim([dbo_EPISODE_ATS]![stay_number]) AS Expr1, dbo_DIAGNOSIS.facility_identifier, dbo_DIAGNOSIS.diagnosis_code_curr, dbo_DIAGNOSIS.condition_onset_flag, [dbo_EPISODE_ATS]![facility_identifier] & "-I-" & Format([dbo_EPISODE_ATS]![stay_number],"00000000") & "-" & Format([dbo_EPISODE_ATS]![episode_sequence_number],"000") AS EncounterNumber
    # FROM dbo_EPISODE INNER JOIN (dbo_DIAGNOSIS INNER JOIN dbo_EPISODE_ATS ON (dbo_DIAGNOSIS.episode_sequence_number = dbo_EPISODE_ATS.episode_sequence_number) AND (dbo_DIAGNOSIS.stay_number = dbo_EPISODE_ATS.stay_number) AND (dbo_DIAGNOSIS.facility_identifier = dbo_EPISODE_ATS.facility_identifier)) ON (dbo_EPISODE.episode_sequence_number = dbo_DIAGNOSIS.episode_sequence_number) AND (dbo_EPISODE.stay_number = dbo_DIAGNOSIS.stay_number) AND (dbo_EPISODE.facility_identifier = dbo_DIAGNOSIS.facility_identifier)
    # WHERE (((dbo_EPISODE_ATS.episode_end_date)>=#7/1/2022#) AND ((dbo_EPISODE.episode_end_date)>=#7/1/2022#))
    # GROUP BY dbo_DIAGNOSIS.clinical_codeset_curr, dbo_DIAGNOSIS.diagnosis_type, dbo_DIAGNOSIS.episode_sequence_number, "SN" & Trim([dbo_EPISODE_ATS]![stay_number]), dbo_DIAGNOSIS.facility_identifier, dbo_DIAGNOSIS.diagnosis_code_curr, dbo_DIAGNOSIS.condition_onset_flag, [dbo_EPISODE_ATS]![facility_identifier] & "-I-" & Format([dbo_EPISODE_ATS]![stay_number],"00000000") & "-" & Format([dbo_EPISODE_ATS]![episode_sequence_number],"000"), dbo_EPISODE.snap_curr_indicator, dbo_DIAGNOSIS.snap_curr_indicator, dbo_EPISODE_ATS.snap_curr_indicator
    # HAVING (((dbo_DIAGNOSIS.clinical_codeset_curr)="ICD10V12") AND ((dbo_EPISODE.snap_curr_indicator)="Y") AND ((dbo_DIAGNOSIS.snap_curr_indicator)="Y") AND ((dbo_EPISODE_ATS.snap_curr_indicator)="Y"));
    # if str(roundid) in aecc_round_id_list_OLD:
    if str(roundid) in aecc_round_id_list:
        label_5_sub.configure(text="In Progress (qry_Diagnosis_ICD10V12)...", fg="blue")
        main_screen.update()
        # 15 Aug 2024
        diagnosis_ICD10V12 = tbl_PPM_ICD_diagnoses.copy()
        diagnosis_ICD10V12["clinical_codeset_curr"] = diagnosis_ICD10V12[
            "DiagnosisVersion"
        ]
        # diagnosis_ICD10V12['diagnosis_type'] = diagnosis_ICD10V12['Sequence'].astype(int, errors='ignore')-1
        diagnosis_ICD10V12["diagnosis_type"] = diagnosis_ICD10V12["Sequence"]
        # diagnosis_ICD10V12['diagnosis_type'] = diagnosis_ICD10V12['diagnosis_type'].astype(str).str.pad(2, side ='left', fillchar ='0')
        diagnosis_ICD10V12["diagnosis_type"] = diagnosis_ICD10V12[
            "diagnosis_type"
        ].where(
            (
                diagnosis_ICD10V12["diagnosis_type"].isnull()
                | (diagnosis_ICD10V12["diagnosis_type"] == "")
            ),
            diagnosis_ICD10V12["diagnosis_type"]
            .astype(str)
            .str.pad(2, side="left", fillchar="0"),
        )
        diagnosis_ICD10V12["EncounterNumber_dummy"] = diagnosis_ICD10V12[
            "EncounterNumber"
        ]
        diagnosis_ICD10V12["facility_identifier"] = (
            diagnosis_ICD10V12["EncounterNumber_dummy"].str.split("-").str[0]
        )
        diagnosis_ICD10V12["stay_number"] = (
            "SN" + diagnosis_ICD10V12["EncounterNumber_dummy"].str.split("-").str[2]
        )
        diagnosis_ICD10V12["episode_sequence_number"] = (
            diagnosis_ICD10V12["EncounterNumber_dummy"].str.split("-").str[3]
        )
        diagnosis_ICD10V12["diagnosis_code_curr"] = diagnosis_ICD10V12["DiagnosisCode"]
        diagnosis_ICD10V12["condition_onset_flag"] = diagnosis_ICD10V12[
            "ConditionOnset"
        ]
        diagnosis_ICD10V12 = diagnosis_ICD10V12[
            [
                "clinical_codeset_curr",
                "diagnosis_type",
                "episode_sequence_number",
                "stay_number",
                "facility_identifier",
                "diagnosis_code_curr",
                "condition_onset_flag",
                "EncounterNumber",
            ]
        ]
    else:
        diagnosis_ICD10V12 = pd.DataFrame(
            columns=[
                "clinical_codeset_curr",
                "diagnosis_type",
                "episode_sequence_number",
                "stay_number",
                "facility_identifier",
                "diagnosis_code_curr",
                "condition_onset_flag",
                "EncounterNumber",
            ]
        )
    # dropping duplicate values
    diagnosis_ICD10V12.drop_duplicates(keep="last", inplace=True)
    diagnosis_ICD10V12.to_csv(
        "./ExtractorDB/diagnosis_ICD10V12.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    logging.info("diagnosis_ICD10V12=%s", len(diagnosis_ICD10V12))
    # Update Sub task status
    if label_5_status == 0:
        label_5_sub.configure(text="Failed", fg="red")
        main_screen.update()
    else:
        label_5_sub.configure(text="Completed", fg="green")
        main_screen.update()
    # label_5_res.configure(text="IcdDiagnoses:"+str(len(tbl_PPM_ICD_diagnoses))+", diagnosis_ICD10V12:"+str(len(diagnosis_ICD10V12)))
    main_screen.update()
    ######################################### EXTRACT DATA - SUB TASK 6 #######################################
    # Set default value of sub-task status to 1
    label_6_status = 1
    # PpmIcdProcedures
    # columns = EncounterNumber,ProcedureCode,ProcedureDateTime,ProcedureVersion,Sequence
    """ Appends data from the dbo_medproc table where the lhd and date range entered in the form is for episodes in ATS table"""
    # Access query = Append_to_tble_PPM_ICD_procedures uses procedure_code_curr, clinical_codeset_curr
    # SELECT [dbo_EPISODE_ATS]![facility_identifier] & "-" & "I" & "-" & Format$([dbo_EPISODE_ATS]![stay_number],"00000000") & "-" & IIf(Len([dbo_EPISODE_ATS]![episode_sequence_number])=3,[dbo_EPISODE_ATS]![episode_sequence_number],IIf(Len([dbo_EPISODE_ATS]![episode_sequence_number])=2,"0" & [dbo_EPISODE_ATS]![episode_sequence_number],"00" & [dbo_EPISODE_ATS]![episode_sequence_number])) AS Expr1, dbo_MEDPROC.procedure_code_curr, dbo_MEDPROC.procedure_date, dbo_MEDPROC.clinical_codeset_curr, dbo_MEDPROC.procedure_type
    label_6_sub.configure(text="In Progress (Procedures)...", fg="blue")
    main_screen.update()
    if source == "HIE":
        if len(facilities_excluded_list) == 0:
            query_IcdProcedures = (
                """SELECT (TRIM(STRING(dbo.EPISODE_ATS.facility_identifier)) + "-I-" + RIGHT(TRIM(STRING('00000000', dbo.EPISODE_ATS.stay_number)),8) + "-" + RIGHT(TRIM(STRING('000', dbo.EPISODE_ATS.episode_sequence_number)),3)) AS EncounterNumber, dbo.MEDPROC.procedure_code_curr as ProcedureCode, dbo.MEDPROC.procedure_date as ProcedureDateTime, dbo.MEDPROC.clinical_codeset AS ProcedureVersion, (case when dbo.MEDPROC.procedure_type='P' Then '0' else dbo.MEDPROC.procedure_type end) AS Sequence, '' as HLTH_ORG_OSP_OSP_ID, '' as MG_AUTH_OSP_OSP_ID, '' as SE_CBK_SK, '' as EDW_Enc_Number 
            FROM (dbo.FACILITY INNER JOIN dbo.EPISODE_ATS ON dbo.FACILITY.facility_identifier = dbo.EPISODE_ATS.facility_identifier) INNER JOIN dbo.MEDPROC ON (dbo.EPISODE_ATS.episode_sequence_number = dbo.MEDPROC.episode_sequence_number) AND (dbo.EPISODE_ATS.stay_number = dbo.MEDPROC.stay_number) AND (dbo.EPISODE_ATS.facility_identifier = dbo.MEDPROC.facility_identifier) 
            WHERE ((((dbo.MEDPROC.clinical_codeset)='"""
                + icd10_v
                + """') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date)>=
            '"""
                + start_date
                + """') AND ((dbo.MEDPROC.snap_curr_indicator)="Y") AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_ATS.facility_identifier)<>"D311" And (dbo.EPISODE_ATS.facility_identifier)<>"Q230")) OR
            (((dbo.MEDPROC.clinical_codeset)='"""
                + icd10_v
                + """') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.MEDPROC.snap_curr_indicator)="Y") AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_ATS.facility_identifier)<>"D311" And (dbo.EPISODE_ATS.facility_identifier)<>"Q230")) 
            OR (((dbo.MEDPROC.clinical_codeset)='"""
                + icd10_v
                + """') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.MEDPROC.snap_curr_indicator)="Y") AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.facility_identifier)='"""
                + lhd
                + """')) 
            OR (((dbo.MEDPROC.clinical_codeset_curr)='"""
                + icd10_v
                + """') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.MEDPROC.snap_curr_indicator)="Y") AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.facility_identifier)='"""
                + lhd
                + """')));"""
            )
        else:
            query_IcdProcedures = (
                """SELECT (TRIM(STRING(dbo.EPISODE_ATS.facility_identifier)) + "-I-" + RIGHT(TRIM(STRING('00000000', dbo.EPISODE_ATS.stay_number)),8) + "-" + RIGHT(TRIM(STRING('000', dbo.EPISODE_ATS.episode_sequence_number)),3)) AS EncounterNumber, dbo.MEDPROC.procedure_code_curr as ProcedureCode, dbo.MEDPROC.procedure_date as ProcedureDateTime, dbo.MEDPROC.clinical_codeset AS ProcedureVersion, (case when dbo.MEDPROC.procedure_type='P' Then '0' else dbo.MEDPROC.procedure_type end) AS Sequence, '' as HLTH_ORG_OSP_OSP_ID, '' as MG_AUTH_OSP_OSP_ID, '' as SE_CBK_SK, '' as EDW_Enc_Number 
            FROM (dbo.FACILITY INNER JOIN dbo.EPISODE_ATS ON dbo.FACILITY.facility_identifier = dbo.EPISODE_ATS.facility_identifier) INNER JOIN dbo.MEDPROC ON (dbo.EPISODE_ATS.episode_sequence_number = dbo.MEDPROC.episode_sequence_number) AND (dbo.EPISODE_ATS.stay_number = dbo.MEDPROC.stay_number) AND (dbo.EPISODE_ATS.facility_identifier = dbo.MEDPROC.facility_identifier) 
            WHERE ((((dbo.MEDPROC.clinical_codeset)='"""
                + icd10_v
                + """') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date)>=
            '"""
                + start_date
                + """') AND ((dbo.MEDPROC.snap_curr_indicator)="Y") AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_ATS.facility_identifier)<>"D311" And (dbo.EPISODE_ATS.facility_identifier)<>"Q230")) OR
            (((dbo.MEDPROC.clinical_codeset)='"""
                + icd10_v
                + """') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.MEDPROC.snap_curr_indicator)="Y") AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.EPISODE_ATS.facility_identifier)<>"D311" And (dbo.EPISODE_ATS.facility_identifier)<>"Q230")) 
            OR (((dbo.MEDPROC.clinical_codeset)='"""
                + icd10_v
                + """') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date)>='"""
                + start_date
                + """') AND ((dbo.MEDPROC.snap_curr_indicator)="Y") AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.facility_identifier)='"""
                + lhd
                + """')) 
            OR (((dbo.MEDPROC.clinical_codeset_curr)='"""
                + icd10_v
                + """') AND ((dbo.EPISODE_ATS.episode_start_date)<='"""
                + end_date
                + """') AND ((dbo.EPISODE_ATS.episode_end_date) Is Null) AND ((dbo.MEDPROC.snap_curr_indicator)="Y") AND ((dbo.EPISODE_ATS.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.EPISODE_ATS.facility_identifier)='"""
                + lhd
                + """'))) AND dbo.FACILITY.facility_identifier NOT IN ("""
                + facilities_excluded
                + """);"""
            )
    elif source == "EDW":
        if len(facilities_included_list) > 0:
            query_IcdProcedures = (
                """SELECT DISTINCT (TRIM(K.facility_identifier) + '-I-' + RIGHT(CONCAT('00000000', ISNULL(SUBSTRING(C.SRV_ENC_REC_ID,charindex('-',C.SRV_ENC_REC_ID)+1,8),'')), 8) + '-'+ 
			RIGHT(CONCAT('000',cast(C.SEQ_AP_SE_IN_ENC as varchar)),3)) as EncounterNumber,c.INTVN_CD as ProcedureCode,case when c.SE_INTVN_SEQ_NUM != 1 and d.SRC_SYSTEM_CD like '%7448%' and cast(c.INTVN_ST_DTTM as date) = cast(d.SRC_CREATE_DTTM as date) then '' else ISNULL(CASE WHEN CONVERT(DATE, c.INTVN_ST_DTTM) = '1900-01-01' THEN '' ELSE CONVERT(CHAR(10), c.INTVN_ST_DTTM, 120) END, '') end as ProcedureDateTime,C.ProcedureVersion, /* Proc seq number original format retained */case when c.SE_INTVN_SEQ_NUM = '' then '' else RIGHT(CONCAT('00',ISNULL(TRIM(CAST((c.SE_INTVN_SEQ_NUM) AS VARCHAR)),'')),2) end as Sequence,K.OSP_ID as HLTH_ORG_OSP_OSP_ID,K.MG_AUTH_OSP_OSP_ID,C.SE_CBK_SK,(TRIM(K.HLTH_ORG_OSP_OSP_ID ) + '-I-' + RIGHT(CONCAT('00000000',ISNULL(SUBSTRING(C.SRV_ENC_REC_ID,charindex('-',C.SRV_ENC_REC_ID)+1,8),'')), 8) + '-' + RIGHT(CONCAT('000',cast(C.SEQ_AP_SE_IN_ENC as varchar)),3)) AS EDW_Enc_Number FROM (select distinct SE_CBK_SK,SRV_ENC_REC_ID, INTVN_CD,INTVN_ST_DTTM,SEQ_AP_SE_IN_ENC
			,case when INTVN_DOM_NM = 'Australian Classification of Health Interventions (ACHI) 13th edition (EDW)' then 'ICD10V13'
                 when INTVN_DOM_NM = 'Australian Classification of Health Interventions (ACHI) 12th edition (EDW)' then 'ICD10V12'
				 when INTVN_DOM_NM = 'Australian Medicare Benefits Schedule - Extended (MBS-E) associated with ICD10AM 1st edition (EDW)' then 'ICD10V01'
				 when INTVN_DOM_NM = 'Australian Classification of Health Interventions (ACHI) 7th edition (EDW)' then 'ICD10V07'
				 when INTVN_DOM_NM = 'Australian Classification of Health Interventions (ACHI) 3rd edition (EDW)' then 'ICD10V03'
				 when INTVN_DOM_NM = 'Australian Classification of Health Interventions (ACHI) 6th edition (EDW)' then 'ICD10V06'
				 when INTVN_DOM_NM = 'Australian Classification of Health Interventions (ACHI) 5th edition (EDW)' then 'ICD10V05'
				 when INTVN_DOM_NM = 'Australian Medicare Benefits Schedule - Extended (MBS-E) associated with ICD10AM 2nd edition (EDW)' then 'ICD10V02'
				 when INTVN_DOM_NM = 'Australian Classification of Health Interventions (ACHI) 10th edition (EDW)' then 'ICD10V10'
				 when INTVN_DOM_NM = 'Australian Classification of Health Interventions (ACHI) 9th edition (EDW)' then 'ICD10V09'
				 when INTVN_DOM_NM = 'Australian Classification of Health Interventions (ACHI) 8th edition (EDW)' then 'ICD10V08'
				 when INTVN_DOM_NM = 'Australian Classification of Health Interventions (ACHI) 11th edition (EDW)' then 'ICD10V11'
				 when INTVN_DOM_NM = 'Australian Classification of Health Interventions (ACHI) 4th edition (EDW)' then 'ICD10V04'
				 when INTVN_DOM_NM = 'Unknown/Invalid' then '' else '' end as ProcedureVersion				 
				 ,SE_INTVN_SEQ_NUM,LST_OSP_ID,DIM_OSP_CREATED_SK from CRT.v_FACT_AP_SE_INTVN_FLAT where (DIM_DT_SE_ST_SK <= '"""
                + end_date
                + """' AND DIM_DT_SE_ST_SK != '1111-01-01') and (DIM_DT_SE_END_SK >= '"""
                + start_date
                + """' or DIM_DT_SE_END_SK is NULL OR DIM_DT_SE_END_SK = '1111-01-01')) as c LEFT JOIN (SELECT SE_CBK_SK, SE_REC_ID, SRC_CREATE_DTTM, SRC_SYSTEM_CD FROM CRT.v_FACT_AP_SE_INTVN) as d ON c.SE_CBK_SK = d.SE_CBK_SK INNER JOIN (SELECT DISTINCT DIM_OSP_SK, OSP_HIE_FAC_ID,HLTH_ORG_OSP_OSP_ID, MG_AUTH_OSP_HLTH_SECTOR_CD, HLTH_ORG_OSP_HLTH_SECTOR_CD, OSP_TYP_CD,HLTH_ORG_OSP_HIE_FAC_ID, MG_AUTH_OSP_HIE_FAC_ID, MG_AUTH_OSP_OSP_ID,case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04','35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_HIE_FAC_ID else HLTH_ORG_OSP_HIE_FAC_ID end as facility_identifier,case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_ID else HLTH_ORG_OSP_OSP_ID end as OSP_ID FROM CRT.v_DIM_OSP where ((MG_AUTH_OSP_HLTH_SECTOR_CD IN ('1','3')) and (HLTH_ORG_OSP_HLTH_SECTOR_CD IN ('1','3'))) AND HLTH_ORG_OSP_HIE_FAC_ID != '-1' AND HLTH_ORG_OSP_HIE_FAC_ID != '') AS K ON C.DIM_OSP_CREATED_SK = K.DIM_OSP_SK WHERE ((((c.ProcedureVersion) = '"""
                + icd10_v
                + """') AND (K.MG_AUTH_OSP_HIE_FAC_ID='"""
                + lhd
                + """' OR (K.facility_identifier) = '"""
                + lhd
                + """'))) AND (k.facility_identifier IN ("""
                + facilities_included
                + """)) ;"""
            )
    retry_flag = True
    retry_count = 0
    while retry_flag and retry_count < 5:
        try:
            logging.info(query_IcdProcedures)
            tbl_PPM_ICD_procedures = pd.read_sql(query_IcdProcedures, cnxn)
            retry_flag = False
        except Exception as e:
            retry_count = retry_count + 1
            time.sleep(5)
            if retry_count == 5:
                logging.exception("Exception occurred")
                label_6_status = 0
                messagebox.showerror(
                    "SQL Error", "Error extracting Procedures details\n" + str(e)
                )
                label_6_sub.configure(text="Failed (Procedures)...", fg="red")
                main_screen.update()
                tbl_PPM_ICD_procedures = pd.DataFrame(
                    columns=[
                        "EncounterNumber",
                        "ProcedureCode",
                        "ProcedureDateTime",
                        "ProcedureVersion",
                        "Sequence",
                        "HLTH_ORG_OSP_OSP_ID",
                        "MG_AUTH_OSP_OSP_ID",
                        "SE_CBK_SK",
                        "EDW_Enc_Number",
                    ]
                )
                return  # stop extraction
        else:
            tbl_PPM_ICD_procedures = tbl_PPM_ICD_procedures.fillna("")
            tbl_PPM_ICD_procedures["Sequence"] = tbl_PPM_ICD_procedures[
                "Sequence"
            ].replace("<NA>", "")  # or 'Unknown', etc.
            tbl_PPM_ICD_procedures["Sequence"] = tbl_PPM_ICD_procedures[
                "Sequence"
            ].replace(r"<NA>", "", regex=True)
            """If sequence is null then 1 if not then sequence +1 """
            # Access query = Proc_update_SeqNo
            # UPDATE tbl_PPM_ICD_procedures SET tbl_PPM_ICD_procedures.Sequence = IIf([Sequence] Is Null,1,[Sequence]+1);
            # tbl_PPM_ICD_procedures['Sequence'] = np.where((pd.isna(tbl_PPM_ICD_procedures['Sequence']) | (tbl_PPM_ICD_procedures['Sequence'].isnull()) | (tbl_PPM_ICD_procedures['Sequence']=='')), 1, tbl_PPM_ICD_procedures['Sequence'].astype(int, errors='ignore')+1)
            # tbl_PPM_ICD_procedures['Sequence'] = tbl_PPM_ICD_procedures['Sequence'].apply(lambda x: '' if pd.isna(x) or x == '' or x=='<NA>' else pd.to_numeric(x, errors='coerce')).astype('Int64')
            tbl_PPM_ICD_procedures = tbl_PPM_ICD_procedures[
                [
                    "EncounterNumber",
                    "ProcedureCode",
                    "ProcedureDateTime",
                    "ProcedureVersion",
                    "Sequence",
                    "HLTH_ORG_OSP_OSP_ID",
                    "MG_AUTH_OSP_OSP_ID",
                    "SE_CBK_SK",
                    "EDW_Enc_Number",
                ]
            ]
            tbl_PPM_ICD_procedures = tbl_PPM_ICD_procedures.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_PPM_ICD_procedures = tbl_PPM_ICD_procedures.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_PPM_ICD_procedures = tbl_PPM_ICD_procedures.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_PPM_ICD_procedures = tbl_PPM_ICD_procedures.apply(
                lambda x: x.replace(regex=r"NULL", value="")
                if x.dtype == "object"
                else x
            )
            tbl_PPM_ICD_procedures = tbl_PPM_ICD_procedures.apply(
                lambda x: x.replace(regex=r"null", value="")
                if x.dtype == "object"
                else x
            )
            tbl_PPM_ICD_procedures = tbl_PPM_ICD_procedures.apply(
                lambda x: x.replace(regex=r"Null", value="")
                if x.dtype == "object"
                else x
            )
            # dropping duplicate values
            tbl_PPM_ICD_procedures.drop_duplicates(keep="last", inplace=True)
            tbl_PPM_ICD_procedures.to_csv(
                "./ExtractorDB/PpmIcdProcedures.csv",
                index=False,
                na_rep="",
                float_format=str,
                decimal=str,
                date_format=str,
            )
            logging.info("tbl_PPM_ICD_procedures=%s", len(tbl_PPM_ICD_procedures))
    # qry_Procedure_ICD10V12
    # Access query: qry_Procedure_ICD10V12
    # INSERT INTO Procedure_ICD10V12 ( clinical_codeset_curr, procedure_type, episode_sequence_number, stay_number, facility_identifier, procedure_code_curr, procedure_date, EncounterNumber )
    # SELECT dbo_MEDPROC.clinical_codeset_curr, dbo_MEDPROC.procedure_type, dbo_MEDPROC.episode_sequence_number, "SN" & Trim([dbo_EPISODE_ATS]![stay_number]) AS Expr1, dbo_MEDPROC.facility_identifier, dbo_MEDPROC.procedure_code_curr, dbo_MEDPROC.procedure_date, [dbo_EPISODE_ATS]![facility_identifier] & "-I-" & Format([dbo_EPISODE_ATS]![stay_number],"00000000") & "-" & Format([dbo_EPISODE_ATS]![episode_sequence_number],"000") AS EncounterNumber
    # FROM (dbo_MEDPROC INNER JOIN dbo_EPISODE_ATS ON (dbo_MEDPROC.episode_sequence_number = dbo_EPISODE_ATS.episode_sequence_number) AND (dbo_MEDPROC.stay_number = dbo_EPISODE_ATS.stay_number) AND (dbo_MEDPROC.facility_identifier = dbo_EPISODE_ATS.facility_identifier)) INNER JOIN dbo_EPISODE ON (dbo_MEDPROC.episode_sequence_number = dbo_EPISODE.episode_sequence_number) AND (dbo_MEDPROC.stay_number = dbo_EPISODE.stay_number) AND (dbo_MEDPROC.facility_identifier = dbo_EPISODE.facility_identifier)
    # WHERE (((dbo_EPISODE_ATS.episode_end_date)>=#7/1/2022#) AND ((dbo_EPISODE.episode_end_date)>=#7/1/2022#))
    # GROUP BY dbo_MEDPROC.clinical_codeset_curr, dbo_MEDPROC.procedure_type, dbo_MEDPROC.episode_sequence_number, "SN" & Trim([dbo_EPISODE_ATS]![stay_number]), dbo_MEDPROC.facility_identifier, dbo_MEDPROC.procedure_code_curr, dbo_MEDPROC.procedure_date, [dbo_EPISODE_ATS]![facility_identifier] & "-I-" & Format([dbo_EPISODE_ATS]![stay_number],"00000000") & "-" & Format([dbo_EPISODE_ATS]![episode_sequence_number],"000"), dbo_MEDPROC.snap_curr_indicator, dbo_EPISODE.snap_curr_indicator, dbo_EPISODE_ATS.snap_curr_indicator
    # HAVING (((dbo_MEDPROC.clinical_codeset_curr)="ICD10V12") AND ((dbo_MEDPROC.snap_curr_indicator)="Y") AND ((dbo_EPISODE.snap_curr_indicator)="Y") AND ((dbo_EPISODE_ATS.snap_curr_indicator)="Y"));
    # if str(roundid) in aecc_round_id_list_OLD:
    if str(roundid) in aecc_round_id_list:
        label_6_sub.configure(text="In Progress (qry_Procedure_ICD10V12)...", fg="blue")
        main_screen.update()
        procedure_ICD10V12 = tbl_PPM_ICD_procedures.copy()
        procedure_ICD10V12["clinical_codeset_curr"] = procedure_ICD10V12[
            "ProcedureVersion"
        ]
        # procedure_ICD10V12['procedure_type'] = procedure_ICD10V12['Sequence'].astype(int, errors='ignore')-1
        procedure_ICD10V12["procedure_type"] = procedure_ICD10V12["Sequence"]
        # procedure_ICD10V12['procedure_type'] = procedure_ICD10V12['procedure_type'].astype(str).str.pad(2, side ='left', fillchar ='0')
        procedure_ICD10V12["procedure_type"] = procedure_ICD10V12[
            "procedure_type"
        ].where(
            (
                procedure_ICD10V12["procedure_type"].isnull()
                | (procedure_ICD10V12["procedure_type"] == "")
            ),
            procedure_ICD10V12["procedure_type"]
            .astype(str)
            .str.pad(2, side="left", fillchar="0"),
        )
        procedure_ICD10V12["EncounterNumber_dummy"] = procedure_ICD10V12[
            "EncounterNumber"
        ]
        procedure_ICD10V12["facility_identifier"] = (
            procedure_ICD10V12["EncounterNumber_dummy"].str.split("-").str[0]
        )
        procedure_ICD10V12["stay_number"] = (
            "SN" + procedure_ICD10V12["EncounterNumber_dummy"].str.split("-").str[2]
        )
        procedure_ICD10V12["episode_sequence_number"] = (
            procedure_ICD10V12["EncounterNumber_dummy"].str.split("-").str[3]
        )
        procedure_ICD10V12["procedure_code_curr"] = procedure_ICD10V12["ProcedureCode"]
        procedure_ICD10V12["procedure_date"] = procedure_ICD10V12["ProcedureDateTime"]
    else:
        procedure_ICD10V12 = pd.DataFrame(
            columns=[
                "clinical_codeset_curr",
                "procedure_type",
                "episode_sequence_number",
                "stay_number",
                "facility_identifier",
                "procedure_code_curr",
                "procedure_date",
                "EncounterNumber",
            ]
        )
    # dropping duplicate values
    procedure_ICD10V12.drop_duplicates(keep="last", inplace=True)
    procedure_ICD10V12.to_csv(
        "./ExtractorDB/procedure_ICD10V12.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    logging.info("procedure_ICD10V12=%s", len(procedure_ICD10V12))
    # Update Sub task status
    if label_6_status == 0:
        label_6_sub.configure(text="Failed", fg="red")
        main_screen.update()
    else:
        label_6_sub.configure(text="Completed", fg="green")
        main_screen.update()
    # label_6_res.configure(text="IcdProcedures:"+str(len(tbl_PPM_ICD_procedures))+", procedure_ICD10V12:"+str(len(procedure_ICD10V12)))
    main_screen.update()
    ######################################### EXTRACT DATA - SUB TASK 7 #######################################
    # Set default value of sub-task status to 1
    label_7_status = 1
    # PpmEdPatient
    # columns = PatientNumber,Gender,EthnicOrigin,DateOfBirth,mrn_for_matching
    # Access query = Append to tbl_ppm_ED_Patient
    # SELECT Trim([dbo_ED_VISIT]![facility_identifier] & "-" & Format$([dbo_ED_VISIT]![mrn],"0000000000")) AS Expr1, Max(dbo_ED_VISIT.sex) AS MaxOfsex, Max(dbo_ED_VISIT.country_of_birth) AS MaxOfcountry_of_birth, Max(Format([dbo_ED_VISIT]![birth_date],"yyyy-mm-dd hh:nn:ss")) AS Expr3
    # mrn_for_matching from the query Append_to_tbl_PPM_Patient_AUID is: trim(dbo.stay.facility_identifier) + '-' + right(dbo.stay.mrn,10))
    label_7_sub.configure(text="In Progress (EdPatient)...", fg="blue")
    main_screen.update()
    if source == "HIE":
        if len(facilities_excluded_list) == 0:
            # GROUP BY dbo.ED_VISIT.facility_identifier, dbo.ED_VISIT.mrn;"""
            query_EdPatient = (
                """SELECT (TRIM(STRING(dbo.ED_VISIT.facility_identifier)) + "-" +  RIGHT(TRIM(STRING('0000000000',dbo.ED_VISIT.mrn)),10)) AS PatientNumber, Max(dbo.ED_VISIT.sex) AS Gender, Max(dbo.ED_VISIT.indigenous_status) AS indigenous_status, Max(dbo.ED_VISIT.country_of_birth) AS EthnicOrigin, Max(dbo.ED_VISIT.birth_date) AS DateOfBirth, '' AS mrn_for_matching, '' as HLTH_ORG_OSP_OSP_ID, '' as MG_AUTH_OSP_OSP_ID, '' as SE_CBK_SK, '' as EDW_Pat_Number, '' as AUID FROM dbo.ED_VISIT INNER JOIN dbo.FACILITY ON dbo.ED_VISIT.facility_identifier = dbo.FACILITY.facility_identifier WHERE 
            ((((dbo.ED_VISIT.snap_curr_indicator)='Y' Or (dbo.ED_VISIT.snap_curr_indicator)='Y' Or (dbo.ED_VISIT.snap_curr_indicator)='Y' Or (dbo.ED_VISIT.snap_curr_indicator)='Y') AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.ED_VISIT.arrival_date)<=('"""
                + end_date
                + """')) AND ((dbo.ED_VISIT.actual_departure_date)>=('"""
                + start_date
                + """')) AND ((dbo.ED_VISIT.facility_identifier)<>"D311" And (dbo.ED_VISIT.facility_identifier)<>"Q230")) OR 
            (((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.ED_VISIT.arrival_date)<=('"""
                + end_date
                + """')) AND ((dbo.ED_VISIT.actual_departure_date) Is Null) AND ((dbo.ED_VISIT.facility_identifier)<>"D311" And (dbo.ED_VISIT.facility_identifier)<>"Q230")) 
            OR (((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.ED_VISIT.arrival_date)<=('"""
                + end_date
                + """')) AND ((dbo.ED_VISIT.actual_departure_date)>=('"""
                + start_date
                + """')) AND ((dbo.ED_VISIT.facility_identifier)='"""
                + lhd
                + """')) 
            OR (((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.ED_VISIT.arrival_date)<=('"""
                + end_date
                + """')) AND ((dbo.ED_VISIT.actual_departure_date) Is Null) AND ((dbo.ED_VISIT.facility_identifier)='"""
                + lhd
                + """'))) GROUP BY dbo.ED_VISIT.facility_identifier ,dbo.ED_VISIT.mrn;"""
            )
            # GROUP BY (TRIM(STRING(dbo.ED_VISIT.facility_identifier)) + "-" +  RIGHT(TRIM(STRING('0000000000',dbo.ED_VISIT.mrn)),10)),  dbo.ED_VISIT.snap_curr_indicator, dbo.ED_VISIT.area_of_usual_residence HAVING (((dbo.ED_VISIT.snap_curr_indicator)="Y" Or (dbo.ED_VISIT.snap_curr_indicator)="Y" Or (dbo.ED_VISIT.snap_curr_indicator)="Y" Or (dbo.ED_VISIT.snap_curr_indicator)="Y"));"""
        else:
            # GROUP BY dbo.ED_VISIT.facility_identifier, dbo.ED_VISIT.mrn;"""
            query_EdPatient = (
                """SELECT (TRIM(STRING(dbo.ED_VISIT.facility_identifier)) + "-" +  RIGHT(TRIM(STRING('0000000000',dbo.ED_VISIT.mrn)),10)) AS PatientNumber, Max(dbo.ED_VISIT.sex) AS Gender, Max(dbo.ED_VISIT.indigenous_status) AS indigenous_status, Max(dbo.ED_VISIT.country_of_birth) AS EthnicOrigin, Max(dbo.ED_VISIT.birth_date) AS DateOfBirth, '' AS mrn_for_matching, '' as HLTH_ORG_OSP_OSP_ID, '' as MG_AUTH_OSP_OSP_ID, '' as SE_CBK_SK, '' as EDW_Pat_Number, '' as AUID FROM dbo.ED_VISIT INNER JOIN dbo.FACILITY ON dbo.ED_VISIT.facility_identifier = dbo.FACILITY.facility_identifier WHERE ((((dbo.ED_VISIT.snap_curr_indicator)='Y' Or (dbo.ED_VISIT.snap_curr_indicator)='Y' Or (dbo.ED_VISIT.snap_curr_indicator)='Y' Or (dbo.ED_VISIT.snap_curr_indicator)='Y') AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.ED_VISIT.arrival_date)<=('"""
                + end_date
                + """')) AND ((dbo.ED_VISIT.actual_departure_date)>=('"""
                + start_date
                + """')) AND ((dbo.ED_VISIT.facility_identifier)<>"D311" And (dbo.ED_VISIT.facility_identifier)<>"Q230")) OR 
            (((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.ED_VISIT.arrival_date)<=('"""
                + end_date
                + """')) AND ((dbo.ED_VISIT.actual_departure_date) Is Null) AND ((dbo.ED_VISIT.facility_identifier)<>"D311" And (dbo.ED_VISIT.facility_identifier)<>"Q230")) 
            OR (((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.ED_VISIT.arrival_date)<=('"""
                + end_date
                + """')) AND ((dbo.ED_VISIT.actual_departure_date)>=('"""
                + start_date
                + """')) AND ((dbo.ED_VISIT.facility_identifier)='"""
                + lhd
                + """')) 
            OR (((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.ED_VISIT.arrival_date)<=('"""
                + end_date
                + """')) AND ((dbo.ED_VISIT.actual_departure_date) Is Null) AND ((dbo.ED_VISIT.facility_identifier)='"""
                + lhd
                + """'))) AND dbo.FACILITY.facility_identifier NOT IN ("""
                + facilities_excluded
                + """) GROUP BY dbo.ED_VISIT.facility_identifier ,dbo.ED_VISIT.mrn;"""
            )
            # GROUP BY (TRIM(STRING(dbo.ED_VISIT.facility_identifier)) + "-" +  RIGHT(TRIM(STRING('0000000000',dbo.ED_VISIT.mrn)),10)), dbo.ED_VISIT.snap_curr_indicator, dbo.ED_VISIT.area_of_usual_residence HAVING (((dbo.ED_VISIT.snap_curr_indicator)="Y" Or (dbo.ED_VISIT.snap_curr_indicator)="Y" Or (dbo.ED_VISIT.snap_curr_indicator)="Y" Or (dbo.ED_VISIT.snap_curr_indicator)="Y"));"""
    elif source == "EDW":
        if len(facilities_included_list) > 0:
            query_EdPatient = (
                """SELECT case when (K.MG_AUTH_OSP_HIE_FAC_ID in ('X740','X830','X840','X850','X860') OR k.facility_identifier in ('X740','X830','X840','X850','X860'))
			AND A.CL_ID_AUID in ('-1','Unknown/Invalid','') then (TRIM(k.facility_identifier) + '-' + TRIM(A.CL_ID_AUID))
			when (K.MG_AUTH_OSP_HIE_FAC_ID in ('X740','X830','X840','X850','X860') OR k.facility_identifier in ('X740','X830','X840','X850','X860'))
			AND A.CL_ID_AUID not in ('-1','Unknown/Invalid','') then (TRIM(k.facility_identifier) + '-' +  Right(CONCAT('0000000000', ISNULL(TRIM(A.CL_ID_AUID),'')),10))
			when (K.MG_AUTH_OSP_HIE_FAC_ID not in ('X740','X830','X840','X850','X860') AND k.facility_identifier not in ('X740','X830','X840','X850','X860'))
			AND A.CL_ID in ('-1','Unknown/Invalid','') then (TRIM(k.facility_identifier) + '-' + TRIM(A.CL_ID)) 
			when (K.MG_AUTH_OSP_HIE_FAC_ID not in ('X740','X830','X840','X850','X860') AND k.facility_identifier not in ('X740','X830','X840','X850','X860'))
			AND A.CL_ID not in ('-1','Unknown/Invalid','') then (TRIM(k.facility_identifier) + '-' +  Right(CONCAT('0000000000', ISNULL(TRIM(A.CL_ID),'')),10)) end as PatientNumber, Max(A.CL_SEX_CD) as Gender, Max(A.CL_INDIGENOUS_STAT_CD) as indigenous_status, Max(A.CL_CTRY_OF_BIRTH_CD) as EthnicOrigin, Max(A.CL_DOB) as DateOfBirth, '' as mrn_for_matching,K.OSP_ID as HLTH_ORG_OSP_OSP_ID,K.MG_AUTH_OSP_OSP_ID,A.SE_CBK_SK,case when (K.MG_AUTH_OSP_HIE_FAC_ID in ('X740','X830','X840','X850','X860') OR k.facility_identifier in ('X740','X830','X840','X850','X860')) AND A.CL_ID_AUID in ('-1','Unknown/Invalid','') then (TRIM(k.OSP_ID) + '-' + TRIM(A.CL_ID_AUID)) when (K.MG_AUTH_OSP_HIE_FAC_ID in ('X740','X830','X840','X850','X860') OR k.facility_identifier in ('X740','X830','X840','X850','X860'))
			AND A.CL_ID_AUID not in ('-1','Unknown/Invalid','') then (TRIM(k.OSP_ID) + '-' +  Right(CONCAT('0000000000', ISNULL(TRIM(A.CL_ID_AUID),'')),10)) when (K.MG_AUTH_OSP_HIE_FAC_ID not in ('X740','X830','X840','X850','X860') AND k.facility_identifier not in ('X740','X830','X840','X850','X860'))
			AND A.CL_ID in ('-1','Unknown/Invalid','') then (TRIM(k.OSP_ID) + '-' + TRIM(A.CL_ID)) when (K.MG_AUTH_OSP_HIE_FAC_ID not in ('X740','X830','X840','X850','X860') AND k.facility_identifier not in ('X740','X830','X840','X850','X860')) AND A.CL_ID not in ('-1','Unknown/Invalid','') then (TRIM(k.OSP_ID) + '-' +  Right(CONCAT('0000000000', ISNULL(TRIM(A.CL_ID),'')),10)) end AS EDW_Pat_Number,(CASE WHEN A.CL_ID_AUID in ('-1','Unknown/Invalid','') then A.CL_ID_AUID WHEN len(A.CL_ID_AUID) <= 10 THEN right('0000000000'+A.CL_ID_AUID,10) WHEN len(A.CL_ID_AUID) > 10 THEN right('0000000000'+A.CL_ID_AUID,10) ELSE '-' end) as AUID FROM CRT.v_FACT_ED_SE_FLAT as a INNER JOIN (SELECT DISTINCT DIM_OSP_SK, OSP_HIE_FAC_ID,HLTH_ORG_OSP_OSP_ID, MG_AUTH_OSP_HLTH_SECTOR_CD, HLTH_ORG_OSP_HLTH_SECTOR_CD, OSP_TYP_CD,HLTH_ORG_OSP_HIE_FAC_ID, MG_AUTH_OSP_HIE_FAC_ID , MG_AUTH_OSP_OSP_ID,case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_ID else HLTH_ORG_OSP_OSP_ID end as OSP_ID,case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_HIE_FAC_ID else HLTH_ORG_OSP_HIE_FAC_ID end as facility_identifier FROM CRT.v_DIM_OSP WHERE ((MG_AUTH_OSP_HLTH_SECTOR_CD IN ('1','3')) and (HLTH_ORG_OSP_HLTH_SECTOR_CD IN ('1','3'))) AND HLTH_ORG_OSP_HIE_FAC_ID != '-1' AND HLTH_ORG_OSP_HIE_FAC_ID != '') AS K ON A.DIM_OSP_CREATED_SK = K.DIM_OSP_SK WHERE (k.facility_identifier) IN ("""
                + facilities_included
                + """) AND ((K.MG_AUTH_OSP_HIE_FAC_ID='"""
                + lhd
                + """' OR (k.facility_identifier)='"""
                + lhd
                + """') AND (CAST(A.CL_ARR_DTTM AS DATE)<=('"""
                + end_date
                + """')) AND (CAST(A.CL_DEP_DTTM AS DATE)>= '"""
                + start_date
                + """' OR A.CL_DEP_DTTM is NULL)) GROUP BY  k.facility_identifier,K.OSP_TYP_CD,K.OSP_HIE_FAC_ID,K.HLTH_ORG_OSP_HIE_FAC_ID, A.CL_ID,K.MG_AUTH_OSP_OSP_ID,K.OSP_ID,A.SE_CBK_SK,K.MG_AUTH_OSP_HIE_FAC_ID
			,A.CL_ID_AUID;"""
            )
    retry_flag = True
    retry_count = 0
    while retry_flag and retry_count < 5:
        try:
            logging.info(query_EdPatient)  # Ranjit
            tbl_ppm_ED_Patient = pd.read_sql(query_EdPatient, cnxn)
            retry_flag = False
        except Exception as e:
            retry_count = retry_count + 1
            time.sleep(5)
            if retry_count == 5:
                logging.exception("Exception occurred")
                label_7_status = 0
                messagebox.showerror(
                    "SQL Error", "Error extracting EdPatient details\n" + str(e)
                )
                label_7_sub.configure(text="Failed (EdPatient)...", fg="red")
                main_screen.update()
                tbl_ppm_ED_Patient = pd.DataFrame(
                    columns=[
                        "PatientNumber",
                        "Gender",
                        "indigenous_status",
                        "EthnicOrigin",
                        "DateOfBirth",
                        "mrn_for_matching",
                        "HLTH_ORG_OSP_OSP_ID",
                        "MG_AUTH_OSP_OSP_ID",
                        "SE_CBK_SK",
                        "EDW_Pat_Number",
                        "AUID",
                    ]
                )
                return  # stop extraction
        else:
            tbl_ppm_ED_Patient = tbl_ppm_ED_Patient.fillna("")
            tbl_ppm_ED_Patient.sort_values(
                by=[
                    "PatientNumber",
                    "Gender",
                    "indigenous_status",
                    "EthnicOrigin",
                    "DateOfBirth",
                    "mrn_for_matching",
                ],
                inplace=True,
            )
            tbl_ppm_ED_Patient = tbl_ppm_ED_Patient.drop_duplicates(
                subset=[
                    "PatientNumber",
                    "Gender",
                    "indigenous_status",
                    "EthnicOrigin",
                    "DateOfBirth",
                    "mrn_for_matching",
                ],
                keep="last",
            )
            tbl_ppm_ED_Patient = tbl_ppm_ED_Patient[
                [
                    "PatientNumber",
                    "Gender",
                    "indigenous_status",
                    "EthnicOrigin",
                    "DateOfBirth",
                    "mrn_for_matching",
                    "HLTH_ORG_OSP_OSP_ID",
                    "MG_AUTH_OSP_OSP_ID",
                    "SE_CBK_SK",
                    "EDW_Pat_Number",
                    "AUID",
                ]
            ]
            tbl_ppm_ED_Patient = tbl_ppm_ED_Patient.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_ppm_ED_Patient = tbl_ppm_ED_Patient.apply(
                lambda x: x.replace(regex=r"NULL", value="")
                if x.dtype == "object"
                else x
            )
            tbl_ppm_ED_Patient = tbl_ppm_ED_Patient.apply(
                lambda x: x.replace(regex=r"null", value="")
                if x.dtype == "object"
                else x
            )
            tbl_ppm_ED_Patient = tbl_ppm_ED_Patient.apply(
                lambda x: x.replace(regex=r"Null", value="")
                if x.dtype == "object"
                else x
            )
            logging.info("tbl_ppm_ED_Patient=%s", len(tbl_ppm_ED_Patient))
    tbl_ppm_ED_Patient = tbl_ppm_ED_Patient[
        [
            "PatientNumber",
            "Gender",
            "indigenous_status",
            "EthnicOrigin",
            "DateOfBirth",
            "mrn_for_matching",
            "HLTH_ORG_OSP_OSP_ID",
            "MG_AUTH_OSP_OSP_ID",
            "SE_CBK_SK",
            "EDW_Pat_Number",
            "AUID",
        ]
    ]
    tbl_ppm_ED_Patient = tbl_ppm_ED_Patient.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    tbl_ppm_ED_Patient = tbl_ppm_ED_Patient.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    tbl_ppm_ED_Patient = tbl_ppm_ED_Patient.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    tbl_ppm_ED_Patient = tbl_ppm_ED_Patient.apply(
        lambda x: x.replace(regex=r"NULL", value="") if x.dtype == "object" else x
    )
    tbl_ppm_ED_Patient = tbl_ppm_ED_Patient.apply(
        lambda x: x.replace(regex=r"null", value="") if x.dtype == "object" else x
    )
    tbl_ppm_ED_Patient = tbl_ppm_ED_Patient.apply(
        lambda x: x.replace(regex=r"Null", value="") if x.dtype == "object" else x
    )
    # dropping duplicate values
    tbl_ppm_ED_Patient.drop_duplicates(keep="last", inplace=True)
    tbl_ppm_ED_Patient.to_csv(
        "./ExtractorDB/PpmEdPatient.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    logging.info("tbl_ppm_ED_Patient=%s", len(tbl_ppm_ED_Patient))
    # Update Sub task status
    if label_7_status == 0:
        label_7_sub.configure(text="Failed", fg="red")
        main_screen.update()
    else:
        label_7_sub.configure(text="Completed", fg="green")
        main_screen.update()
    # label_7_res.configure(text="EdPatient:"+str(len(tbl_ppm_ED_Patient)))
    main_screen.update()
    ######################################### EXTRACT DATA - SUB TASK 8 #######################################
    # Set default value of sub-task status to 1
    label_8_status = 1
    # PpmEdEncounterPreclean
    # columns = Stu,EncounterNumber,PostCode,Suburb,EncounterType,PatientNumber,Hospital,LengthofStay,StartDateTime,EndDateTime,Age,WeightedSeparation,Extra_InpatientStayNumber,Extra:TriageCategory,Extra_ModeofArrival,Extra:EDVisitType,Extra_EDDiagnosis,Extra:ModeofSep,Extra_EDTriageDateTime,Extra_EDReferralSource,Extra_IndigenousStatus,Extra_MedicareNumber,person_area_uid,SnapFrom,Extra_UDG,Extra:URG,Extra_ClinStartDTTM,Extra_DepartureReadyDTTM,Extra_EDDiagnosisType,Extra_AdmWard,Extra_EdCompStatus,Extra_Version_Id,Extra_LHD_of_usual_residence,getdate
    # Access query = Append to tbl_ppm_ED_Encounter (SNOWMED)
    # INSERT INTO tbl_ppm_ED_Encounter_preclean ( Stu, EncounterNumber, PostCode, Suburb, PatientNumber, Hospital, LengthofStay, StartDateTime, EndDateTime, age, WeightedSeparation, [Extra:TriageCategory], [Extra:ModeofArrival], [Extra:EDVisitType], [Extra:ModeofSep], [Extra:EDTriageDateTime], [Extra:EDReferralSource], [Extra:IndigenousStatus], [Extra:MedicareNumber], person_area_uid, SnapFrom, [Extra:ClinStartDTTM], [Extra:DepartureReadyDTTM], [Extra:EdCompStatus], [Extra:UDG], [Extra:LHD_of_usual_residence], getdate )
    label_8_sub.configure(text="In Progress (EdEncounterPreclean)...", fg="blue")
    main_screen.update()
    if source == "HIE":
        """Appends data from ed_visit table to the tbl_ppm_EDEncounter_preclean table based on form selections. This table was created as there are duplicates in the ED Visit """
        # Access query: Append_to_tbl_PPM_ICD_procedures_SNAP. comments by Suellen:This a step that I believe is repeated later and could be deleted. Where it appends procedures matched by staynumber/seq to tbl_PPM_ICD_procedures if they match snapApp_CostingExtract
        if len(facilities_excluded_list) == 0:
            query_EdEncounterPreclean = (
                """SELECT dbo.ED_VISIT.ed_visit_identifier as Stu, 
            (case when len(TRIM(STRING(dbo.ED_VISIT.ed_visit_identifier))) >= 10 AND TRIM(STRING(dbo.ED_VISIT.facility_identifier)) = 'P202' THEN TRIM(STRING(dbo.ED_VISIT.facility_identifier)) + "-E-" +  TRIM(STRING(dbo.ED_VISIT.ed_visit_identifier))
            when len(TRIM(STRING(dbo.ED_VISIT.ed_visit_identifier))) >= 10 AND TRIM(STRING(dbo.ED_VISIT.facility_identifier)) != 'P202' THEN TRIM(STRING(dbo.ED_VISIT.facility_identifier)) + "-E-" + substring(TRIM(STRING(dbo.ED_VISIT.ed_visit_identifier)), 3, 8)
            else TRIM(STRING(dbo.ED_VISIT.facility_identifier)) + "-E-" +  RIGHT(TRIM(STRING('00000000',dbo.ED_VISIT.ed_visit_identifier)),8)
            end) AS EncounterNumber, 
            dbo.ED_VISIT.patient_postcode as PostCode, dbo.ED_VISIT.area_of_usual_residence as Suburb, '' AS EncounterType, (TRIM(STRING(dbo.ED_VISIT.facility_identifier)) + "-" +  RIGHT(TRIM(STRING('0000000000',dbo.ED_VISIT.mrn)),10)) AS PatientNumber, dbo.ED_VISIT.facility_identifier as Hospital, (case when dbo.ed_visit.actual_departure_time is null then datediff(minute, dbo.ed_visit.arrival_time, dbo.ed_visit.departure_ready_time) else datediff(minute, dbo.ed_visit.arrival_time, dbo.ed_visit.actual_departure_time) end)  AS LengthofStay, 
            dbo.ED_VISIT.arrival_time as StartDateTime, 
            (case when dbo.ed_visit.actual_departure_time is null then dbo.ed_visit.departure_ready_time else dbo.ed_visit.actual_departure_time end) as EndDateTime,
            dbo.ED_VISIT.age as Age, dbo.ED_VISIT.udg_weight as WeightedSeparation, '' AS Extra_InpatientStayNumber, dbo.ED_VISIT.triage_category as Extra_TriageCategory, dbo.ED_VISIT.mode_of_arrival as Extra_ModeofArrival, dbo.ED_VISIT.ed_visit_type as Extra_EDVisitType, '' AS Extra_EDDiagnosis, dbo.ED_VISIT.mode_of_separation as Extra_ModeofSep, dbo.ED_VISIT.triage_time as Extra_EDTriageDateTime, dbo.ED_VISIT.ed_source_of_referral as Extra_EDReferralSource, dbo.ED_VISIT.indigenous_status as Extra_IndigenousStatus, dbo.ED_VISIT.medicare_number as Extra_MedicareNumber, dbo.ED_VISIT.person_area_uid as person_area_uid, DATEFORMAT(dbo.ED_VISIT.snap_from_date, 'YYYY-MM-DD HH:NN:SS') as SnapFrom, 
            ((case when dbo.ED_VISIT.udg_urgency IS NULL then '0' else STRING(dbo.ED_VISIT.udg_urgency) end) + (case when dbo.ED_VISIT.udg_disposition IS NULL then '0' else STRING(dbo.ED_VISIT.udg_disposition) end)) as Extra_UDG, 
            '' AS Extra_URG, 
            (case when dbo.ED_VISIT.first_seen_clinician_time IS NULL AND dbo.ED_VISIT.first_seen_nurse_time IS NULL then NULL
            when dbo.ED_VISIT.first_seen_clinician_time IS NOT NULL AND dbo.ED_VISIT.first_seen_nurse_time IS NOT NULL AND dbo.ED_VISIT.first_seen_clinician_time < dbo.ED_VISIT.first_seen_nurse_time THEN dbo.ED_VISIT.first_seen_clinician_time
            when dbo.ED_VISIT.first_seen_clinician_time IS NOT NULL AND dbo.ED_VISIT.first_seen_nurse_time IS NOT NULL AND dbo.ED_VISIT.first_seen_clinician_time > dbo.ED_VISIT.first_seen_nurse_time THEN dbo.ED_VISIT.first_seen_nurse_time
            when dbo.ED_VISIT.first_seen_clinician_time IS NOT NULL AND dbo.ED_VISIT.first_seen_nurse_time IS NULL then dbo.ED_VISIT.first_seen_clinician_time
            ELSE dbo.ED_VISIT.first_seen_nurse_time
            end) as Extra_ClinStartDTTM, 
            dbo.ED_VISIT.departure_ready_time as Extra_DepartureReadyDTTM, '' AS Extra_EDDiagnosisType, '' AS Extra_AdmWard, dbo.ED_VISIT.compensable_status as Extra_EdCompStatus, '' AS Extra_Version_Id, dbo.SLA_AREA.area_identifier AS Extra_LHD_of_usual_residence, DATEFORMAT(now(), 'YYYY-MM-DD HH:NN:SS') AS getdate  , '' as HLTH_ORG_OSP_OSP_ID, '' as MG_AUTH_OSP_OSP_ID, '' as SE_CBK_SK, '' as CL_ID_EUID, '' AS CL_ID_IHI, '' AS FST_BILL_CATEGORY_CD, '' as EDW_Pat_Number, '' as EDW_Enc_Number
            FROM (dbo.ED_VISIT INNER JOIN dbo.FACILITY ON dbo.ED_VISIT.facility_identifier = dbo.FACILITY.facility_identifier) LEFT JOIN dbo.SLA_AREA ON dbo.ED_VISIT.area_of_usual_residence = dbo.SLA_AREA.sla_code 
            GROUP BY dbo.ED_VISIT.ed_visit_identifier, (case when len(TRIM(STRING(dbo.ED_VISIT.ed_visit_identifier))) >= 10 AND TRIM(STRING(dbo.ED_VISIT.facility_identifier)) = 'P202' THEN TRIM(STRING(dbo.ED_VISIT.facility_identifier)) + "-E-" +  TRIM(STRING(dbo.ED_VISIT.ed_visit_identifier))
            when len(TRIM(STRING(dbo.ED_VISIT.ed_visit_identifier))) >= 10 AND TRIM(STRING(dbo.ED_VISIT.facility_identifier)) != 'P202' THEN TRIM(STRING(dbo.ED_VISIT.facility_identifier)) + "-E-" + substring(TRIM(STRING(dbo.ED_VISIT.ed_visit_identifier)), 3, 8)
            else TRIM(STRING(dbo.ED_VISIT.facility_identifier)) + "-E-" +  RIGHT(TRIM(STRING('00000000',dbo.ED_VISIT.ed_visit_identifier)),8)
            end), dbo.ED_VISIT.patient_postcode, dbo.ED_VISIT.area_of_usual_residence, (TRIM(STRING(dbo.ED_VISIT.facility_identifier)) + "-" +  RIGHT(TRIM(STRING('0000000000',dbo.ED_VISIT.mrn)),10)), dbo.ED_VISIT.facility_identifier,
            (case when dbo.ed_visit.actual_departure_time is null then datediff(minute, dbo.ed_visit.arrival_time, dbo.ed_visit.departure_ready_time) else datediff(minute, dbo.ed_visit.arrival_time, dbo.ed_visit.actual_departure_time) end),         
            dbo.ED_VISIT.arrival_time, (case when dbo.ed_visit.actual_departure_time is null then dbo.ed_visit.departure_ready_time else dbo.ed_visit.actual_departure_time end),
            dbo.ED_VISIT.age, dbo.ED_VISIT.udg_weight, dbo.ED_VISIT.triage_category, dbo.ED_VISIT.mode_of_arrival, dbo.ED_VISIT.ed_visit_type, dbo.ED_VISIT.mode_of_separation, dbo.ED_VISIT.triage_time, dbo.ED_VISIT.ed_source_of_referral, dbo.ED_VISIT.indigenous_status, dbo.ED_VISIT.medicare_number, dbo.ED_VISIT.person_area_uid, dbo.ED_VISIT.snap_from_date, 
            ((case when dbo.ED_VISIT.udg_urgency IS NULL then '0' else STRING(dbo.ED_VISIT.udg_urgency) end) + (case when dbo.ED_VISIT.udg_disposition IS NULL then '0' else STRING(dbo.ED_VISIT.udg_disposition) end)),
            (case when dbo.ED_VISIT.first_seen_clinician_time IS NULL AND dbo.ED_VISIT.first_seen_nurse_time IS NULL then NULL
            when dbo.ED_VISIT.first_seen_clinician_time IS NOT NULL AND dbo.ED_VISIT.first_seen_nurse_time IS NOT NULL AND dbo.ED_VISIT.first_seen_clinician_time < dbo.ED_VISIT.first_seen_nurse_time THEN dbo.ED_VISIT.first_seen_clinician_time
            when dbo.ED_VISIT.first_seen_clinician_time IS NOT NULL AND dbo.ED_VISIT.first_seen_nurse_time IS NOT NULL AND dbo.ED_VISIT.first_seen_clinician_time > dbo.ED_VISIT.first_seen_nurse_time THEN dbo.ED_VISIT.first_seen_nurse_time
            when dbo.ED_VISIT.first_seen_clinician_time IS NOT NULL AND dbo.ED_VISIT.first_seen_nurse_time IS NULL then dbo.ED_VISIT.first_seen_clinician_time
            ELSE dbo.ED_VISIT.first_seen_nurse_time
            end), dbo.ED_VISIT.departure_ready_time, dbo.ED_VISIT.compensable_status, dbo.SLA_AREA.area_identifier, dbo.ED_VISIT.arrival_date, dbo.ED_VISIT.actual_departure_date, dbo.ED_VISIT.departure_ready_date, dbo.FACILITY.area_identifier, dbo.ED_VISIT.snap_curr_indicator, dbo.FACILITY.snap_curr_indicator, dbo.SLA_AREA.current_flag, dbo.SLA_AREA.snap_curr_indicator 
            HAVING ((((dbo.ED_VISIT.facility_identifier)<>"D311" And (dbo.ED_VISIT.facility_identifier)<>"Q230") AND ((dbo.ED_VISIT.mode_of_separation)<>'99' Or (dbo.ED_VISIT.mode_of_separation) Is Null) AND ((dbo.ED_VISIT.arrival_date)<=('"""
                + end_date
                + """')) AND ((dbo.ED_VISIT.actual_departure_date)>=('"""
                + start_date
                + """') And (dbo.ED_VISIT.actual_departure_date)<=('"""
                + end_date
                + """')) AND ((dbo.ED_VISIT.snap_curr_indicator)='Y') AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.SLA_AREA.current_flag)='Y' Or (dbo.SLA_AREA.current_flag) Is Null) AND ((dbo.SLA_AREA.snap_curr_indicator)='Y' Or (dbo.SLA_AREA.snap_curr_indicator) Is Null)) OR 
            (((dbo.ED_VISIT.facility_identifier)<>"D311" And (dbo.ED_VISIT.facility_identifier)<>"Q230") AND ((dbo.ED_VISIT.mode_of_separation)<>'99' Or (dbo.ED_VISIT.mode_of_separation) Is Null) AND ((dbo.ED_VISIT.arrival_date)>=('"""
                + start_date
                + """') And (dbo.ED_VISIT.arrival_date)<=('"""
                + end_date
                + """')) AND ((dbo.ED_VISIT.actual_departure_date) Is Null Or (dbo.ED_VISIT.actual_departure_date)>=('"""
                + start_date
                + """')) AND ((dbo.ED_VISIT.departure_ready_date)>='"""
                + start_date
                + """' or (dbo.ED_VISIT.departure_ready_date) Is Null) AND ((dbo.ED_VISIT.snap_curr_indicator)='Y') AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.SLA_AREA.current_flag)='Y' Or (dbo.SLA_AREA.current_flag) Is Null) AND ((dbo.SLA_AREA.snap_curr_indicator)='Y' Or (dbo.SLA_AREA.snap_curr_indicator) Is Null)) OR 
            (((dbo.ED_VISIT.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.ED_VISIT.mode_of_separation)<>'99' Or (dbo.ED_VISIT.mode_of_separation) Is Null) AND ((dbo.ED_VISIT.arrival_date)<=('"""
                + end_date
                + """')) AND ((dbo.ED_VISIT.actual_departure_date)>=('"""
                + start_date
                + """') And (dbo.ED_VISIT.actual_departure_date)<=('"""
                + end_date
                + """')) AND ((dbo.ED_VISIT.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.SLA_AREA.current_flag)='Y' Or (dbo.SLA_AREA.current_flag) Is Null) AND ((dbo.SLA_AREA.snap_curr_indicator)='Y' Or (dbo.SLA_AREA.snap_curr_indicator) Is Null)) OR    
            (((dbo.ED_VISIT.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.ED_VISIT.mode_of_separation)<>'99' Or (dbo.ED_VISIT.mode_of_separation) Is Null) AND ((dbo.ED_VISIT.arrival_date)>=('"""
                + start_date
                + """') And (dbo.ED_VISIT.arrival_date)<=('"""
                + end_date
                + """')) AND ((dbo.ED_VISIT.actual_departure_date) Is Null Or (dbo.ED_VISIT.actual_departure_date)>=('"""
                + start_date
                + """')) AND ((dbo.ED_VISIT.departure_ready_date)>='"""
                + start_date
                + """' or (dbo.ED_VISIT.departure_ready_date) Is Null) AND ((dbo.ED_VISIT.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.SLA_AREA.current_flag)='Y' Or (dbo.SLA_AREA.current_flag) Is Null) AND ((dbo.SLA_AREA.snap_curr_indicator)='Y' Or (dbo.SLA_AREA.snap_curr_indicator) Is Null)));"""
            )
        else:
            query_EdEncounterPreclean = (
                """SELECT dbo.ED_VISIT.ed_visit_identifier as Stu, 
            (case when len(TRIM(STRING(dbo.ED_VISIT.ed_visit_identifier))) >= 10 AND TRIM(STRING(dbo.ED_VISIT.facility_identifier)) = 'P202' THEN TRIM(STRING(dbo.ED_VISIT.facility_identifier)) + "-E-" +  TRIM(STRING(dbo.ED_VISIT.ed_visit_identifier))
            when len(TRIM(STRING(dbo.ED_VISIT.ed_visit_identifier))) >= 10 AND TRIM(STRING(dbo.ED_VISIT.facility_identifier)) != 'P202' THEN TRIM(STRING(dbo.ED_VISIT.facility_identifier)) + "-E-" + substring(TRIM(STRING(dbo.ED_VISIT.ed_visit_identifier)), 3, 8)
            else TRIM(STRING(dbo.ED_VISIT.facility_identifier)) + "-E-" +  RIGHT(TRIM(STRING('00000000',dbo.ED_VISIT.ed_visit_identifier)),8)
            end) AS EncounterNumber, 
            dbo.ED_VISIT.patient_postcode as PostCode, dbo.ED_VISIT.area_of_usual_residence as Suburb, '' AS EncounterType, (TRIM(STRING(dbo.ED_VISIT.facility_identifier)) + "-" +  RIGHT(TRIM(STRING('0000000000',dbo.ED_VISIT.mrn)),10)) AS PatientNumber, dbo.ED_VISIT.facility_identifier as Hospital, (case when dbo.ed_visit.actual_departure_time is null then datediff(minute, dbo.ed_visit.arrival_time, dbo.ed_visit.departure_ready_time) else datediff(minute, dbo.ed_visit.arrival_time, dbo.ed_visit.actual_departure_time) end)  AS LengthofStay, 
            dbo.ED_VISIT.arrival_time as StartDateTime, 
            (case when dbo.ed_visit.actual_departure_time is null then dbo.ed_visit.departure_ready_time else dbo.ed_visit.actual_departure_time end) as EndDateTime,
            dbo.ED_VISIT.age as Age, dbo.ED_VISIT.udg_weight as WeightedSeparation, '' AS Extra_InpatientStayNumber, dbo.ED_VISIT.triage_category as Extra_TriageCategory, dbo.ED_VISIT.mode_of_arrival as Extra_ModeofArrival, dbo.ED_VISIT.ed_visit_type as Extra_EDVisitType, '' AS Extra_EDDiagnosis, dbo.ED_VISIT.mode_of_separation as Extra_ModeofSep, dbo.ED_VISIT.triage_time as Extra_EDTriageDateTime, dbo.ED_VISIT.ed_source_of_referral as Extra_EDReferralSource, dbo.ED_VISIT.indigenous_status as Extra_IndigenousStatus, dbo.ED_VISIT.medicare_number as Extra_MedicareNumber, dbo.ED_VISIT.person_area_uid as person_area_uid, DATEFORMAT(dbo.ED_VISIT.snap_from_date, 'YYYY-MM-DD HH:NN:SS') as SnapFrom, 
            ((case when dbo.ED_VISIT.udg_urgency IS NULL then '0' else STRING(dbo.ED_VISIT.udg_urgency) end) + (case when dbo.ED_VISIT.udg_disposition IS NULL then '0' else STRING(dbo.ED_VISIT.udg_disposition) end)) as Extra_UDG, 
            '' AS Extra_URG, 
            (case when dbo.ED_VISIT.first_seen_clinician_time IS NULL AND dbo.ED_VISIT.first_seen_nurse_time IS NULL then NULL
            when dbo.ED_VISIT.first_seen_clinician_time IS NOT NULL AND dbo.ED_VISIT.first_seen_nurse_time IS NOT NULL AND dbo.ED_VISIT.first_seen_clinician_time < dbo.ED_VISIT.first_seen_nurse_time THEN dbo.ED_VISIT.first_seen_clinician_time
            when dbo.ED_VISIT.first_seen_clinician_time IS NOT NULL AND dbo.ED_VISIT.first_seen_nurse_time IS NOT NULL AND dbo.ED_VISIT.first_seen_clinician_time > dbo.ED_VISIT.first_seen_nurse_time THEN dbo.ED_VISIT.first_seen_nurse_time
            when dbo.ED_VISIT.first_seen_clinician_time IS NOT NULL AND dbo.ED_VISIT.first_seen_nurse_time IS NULL then dbo.ED_VISIT.first_seen_clinician_time
            ELSE dbo.ED_VISIT.first_seen_nurse_time
            end) as Extra_ClinStartDTTM, 
            dbo.ED_VISIT.departure_ready_time as Extra_DepartureReadyDTTM, '' AS Extra_EDDiagnosisType, '' AS Extra_AdmWard, dbo.ED_VISIT.compensable_status as Extra_EdCompStatus, '' AS Extra_Version_Id, dbo.SLA_AREA.area_identifier AS Extra_LHD_of_usual_residence, DATEFORMAT(now(), 'YYYY-MM-DD HH:NN:SS') AS getdate , '' as HLTH_ORG_OSP_OSP_ID, '' as MG_AUTH_OSP_OSP_ID, '' as SE_CBK_SK, '' as CL_ID_EUID, '' AS CL_ID_IHI, '' AS FST_BILL_CATEGORY_CD, '' as EDW_Pat_Number, '' as EDW_Enc_Number
            FROM (dbo.ED_VISIT INNER JOIN dbo.FACILITY ON dbo.ED_VISIT.facility_identifier = dbo.FACILITY.facility_identifier) LEFT JOIN dbo.SLA_AREA ON dbo.ED_VISIT.area_of_usual_residence = dbo.SLA_AREA.sla_code 
            GROUP BY dbo.ED_VISIT.ed_visit_identifier, (case when len(TRIM(STRING(dbo.ED_VISIT.ed_visit_identifier))) >= 10 AND TRIM(STRING(dbo.ED_VISIT.facility_identifier)) = 'P202' THEN TRIM(STRING(dbo.ED_VISIT.facility_identifier)) + "-E-" +  TRIM(STRING(dbo.ED_VISIT.ed_visit_identifier))
            when len(TRIM(STRING(dbo.ED_VISIT.ed_visit_identifier))) >= 10 AND TRIM(STRING(dbo.ED_VISIT.facility_identifier)) != 'P202' THEN TRIM(STRING(dbo.ED_VISIT.facility_identifier)) + "-E-" + substring(TRIM(STRING(dbo.ED_VISIT.ed_visit_identifier)), 3, 8)
            else TRIM(STRING(dbo.ED_VISIT.facility_identifier)) + "-E-" +  RIGHT(TRIM(STRING('00000000',dbo.ED_VISIT.ed_visit_identifier)),8)
            end), dbo.ED_VISIT.patient_postcode, dbo.ED_VISIT.area_of_usual_residence, (TRIM(STRING(dbo.ED_VISIT.facility_identifier)) + "-" +  RIGHT(TRIM(STRING('0000000000',dbo.ED_VISIT.mrn)),10)), dbo.ED_VISIT.facility_identifier,
            (case when dbo.ed_visit.actual_departure_time is null then datediff(minute, dbo.ed_visit.arrival_time, dbo.ed_visit.departure_ready_time) else datediff(minute, dbo.ed_visit.arrival_time, dbo.ed_visit.actual_departure_time) end),         
            dbo.ED_VISIT.arrival_time, (case when dbo.ed_visit.actual_departure_time is null then dbo.ed_visit.departure_ready_time else dbo.ed_visit.actual_departure_time end),
            dbo.ED_VISIT.age, dbo.ED_VISIT.udg_weight, dbo.ED_VISIT.triage_category, dbo.ED_VISIT.mode_of_arrival, dbo.ED_VISIT.ed_visit_type, dbo.ED_VISIT.mode_of_separation, dbo.ED_VISIT.triage_time, dbo.ED_VISIT.ed_source_of_referral, dbo.ED_VISIT.indigenous_status, dbo.ED_VISIT.medicare_number, dbo.ED_VISIT.person_area_uid, dbo.ED_VISIT.snap_from_date, 
            ((case when dbo.ED_VISIT.udg_urgency IS NULL then '0' else STRING(dbo.ED_VISIT.udg_urgency) end) + (case when dbo.ED_VISIT.udg_disposition IS NULL then '0' else STRING(dbo.ED_VISIT.udg_disposition) end)),
            (case when dbo.ED_VISIT.first_seen_clinician_time IS NULL AND dbo.ED_VISIT.first_seen_nurse_time IS NULL then NULL
            when dbo.ED_VISIT.first_seen_clinician_time IS NOT NULL AND dbo.ED_VISIT.first_seen_nurse_time IS NOT NULL AND dbo.ED_VISIT.first_seen_clinician_time < dbo.ED_VISIT.first_seen_nurse_time THEN dbo.ED_VISIT.first_seen_clinician_time
            when dbo.ED_VISIT.first_seen_clinician_time IS NOT NULL AND dbo.ED_VISIT.first_seen_nurse_time IS NOT NULL AND dbo.ED_VISIT.first_seen_clinician_time > dbo.ED_VISIT.first_seen_nurse_time THEN dbo.ED_VISIT.first_seen_nurse_time
            when dbo.ED_VISIT.first_seen_clinician_time IS NOT NULL AND dbo.ED_VISIT.first_seen_nurse_time IS NULL then dbo.ED_VISIT.first_seen_clinician_time
            ELSE dbo.ED_VISIT.first_seen_nurse_time
            end), dbo.ED_VISIT.departure_ready_time, dbo.ED_VISIT.compensable_status, dbo.SLA_AREA.area_identifier, dbo.ED_VISIT.arrival_date, dbo.ED_VISIT.actual_departure_date, dbo.ED_VISIT.departure_ready_date, dbo.FACILITY.area_identifier, dbo.ED_VISIT.snap_curr_indicator, dbo.FACILITY.snap_curr_indicator, dbo.SLA_AREA.current_flag, dbo.SLA_AREA.snap_curr_indicator, dbo.FACILITY.facility_identifier 
            HAVING ((((dbo.ED_VISIT.facility_identifier)<>"D311" And (dbo.ED_VISIT.facility_identifier)<>"Q230") AND ((dbo.ED_VISIT.mode_of_separation)<>'99' Or (dbo.ED_VISIT.mode_of_separation) Is Null) AND ((dbo.ED_VISIT.arrival_date)<=('"""
                + end_date
                + """')) AND ((dbo.ED_VISIT.actual_departure_date)>=('"""
                + start_date
                + """') And (dbo.ED_VISIT.actual_departure_date)<=('"""
                + end_date
                + """')) AND ((dbo.ED_VISIT.snap_curr_indicator)='Y') AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.SLA_AREA.current_flag)='Y' Or (dbo.SLA_AREA.current_flag) Is Null) AND ((dbo.SLA_AREA.snap_curr_indicator)='Y' Or (dbo.SLA_AREA.snap_curr_indicator) Is Null)) OR 
            (((dbo.ED_VISIT.facility_identifier)<>"D311" And (dbo.ED_VISIT.facility_identifier)<>"Q230") AND ((dbo.ED_VISIT.mode_of_separation)<>'99' Or (dbo.ED_VISIT.mode_of_separation) Is Null) AND ((dbo.ED_VISIT.arrival_date)>=('"""
                + start_date
                + """') And (dbo.ED_VISIT.arrival_date)<=('"""
                + end_date
                + """')) AND ((dbo.ED_VISIT.actual_departure_date) Is Null Or (dbo.ED_VISIT.actual_departure_date)>=('"""
                + start_date
                + """')) AND ((dbo.ED_VISIT.departure_ready_date)>='"""
                + start_date
                + """' or (dbo.ED_VISIT.departure_ready_date) Is Null) AND ((dbo.ED_VISIT.snap_curr_indicator)='Y') AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.SLA_AREA.current_flag)='Y' Or (dbo.SLA_AREA.current_flag) Is Null) AND ((dbo.SLA_AREA.snap_curr_indicator)='Y' Or (dbo.SLA_AREA.snap_curr_indicator) Is Null)) OR 
            (((dbo.ED_VISIT.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.ED_VISIT.mode_of_separation)<>'99' Or (dbo.ED_VISIT.mode_of_separation) Is Null) AND ((dbo.ED_VISIT.arrival_date)<=('"""
                + end_date
                + """')) AND ((dbo.ED_VISIT.actual_departure_date)>=('"""
                + start_date
                + """') And (dbo.ED_VISIT.actual_departure_date)<=('"""
                + end_date
                + """')) AND ((dbo.ED_VISIT.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.SLA_AREA.current_flag)='Y' Or (dbo.SLA_AREA.current_flag) Is Null) AND ((dbo.SLA_AREA.snap_curr_indicator)='Y' Or (dbo.SLA_AREA.snap_curr_indicator) Is Null)) OR    
            (((dbo.ED_VISIT.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.ED_VISIT.mode_of_separation)<>'99' Or (dbo.ED_VISIT.mode_of_separation) Is Null) AND ((dbo.ED_VISIT.arrival_date)>=('"""
                + start_date
                + """') And (dbo.ED_VISIT.arrival_date)<=('"""
                + end_date
                + """')) AND ((dbo.ED_VISIT.actual_departure_date) Is Null Or (dbo.ED_VISIT.actual_departure_date)>=('"""
                + start_date
                + """')) AND ((dbo.ED_VISIT.departure_ready_date)>='"""
                + start_date
                + """' or (dbo.ED_VISIT.departure_ready_date) Is Null) AND ((dbo.ED_VISIT.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.SLA_AREA.current_flag)='Y' Or (dbo.SLA_AREA.current_flag) Is Null) AND ((dbo.SLA_AREA.snap_curr_indicator)='Y' Or (dbo.SLA_AREA.snap_curr_indicator) Is Null))) AND dbo.FACILITY.facility_identifier NOT IN ("""
                + facilities_excluded
                + """);"""
            )
    elif source == "EDW":
        if len(facilities_included_list) > 0:
            # Clinician seen datetime: https://teams.moh.health.nsw.gov.au/SPP/HSIPR/EBI/Lists/LRS%20Discussion%20Board1/Flat.aspx?RootFolder=%2fSPP%2fHSIPR%2fEBI%2fLists%2fLRS%20Discussion%20Board1%2f%5bSSA104%5fCLINICAL%5fCARE%5fCOMMENCEMENT%5fDTTM%5fC1%5fC5%5d%20does%20not%20match%20%27First%20Seen%27%20data&FolderCTID=0x012002007D80F8DD32AEF54BAAD54ABD0A3C0CD6
            # select SRV_ENC_REC_ID,SB_E_FST_DOC_SEEN_DTTM,SB_E_FST_PHY_SN_DTTM, SB_E_FST_NRS_PRAC_SN_DTTM,  SB_E_FST_NRS_PROT_DTTM,  SB_E_FST_NRS_SN_DTTM,
            # DATEDIFF(second, SB_E_FST_NRS_PROT_DTTM, SB_E_FST_NRS_SN_DTTM) AS date_difference, least(SB_E_FST_DOC_SEEN_DTTM,SB_E_FST_PHY_SN_DTTM, SB_E_FST_NRS_PRAC_SN_DTTM, SB_E_FST_NRS_PROT_DTTM)
            # from CRT.v_FACT_ED_SE_FLAT where DATEDIFF(second, SB_E_FST_NRS_PROT_DTTM, SB_E_FST_NRS_SN_DTTM) > 0
            query_EdEncounterPreclean = (
                """SELECT ISNULL(SUBSTRING(A.SRV_ENC_REC_ID,charindex('-',A.SRV_ENC_REC_ID)+1,10),'') as Stu, (case when len(TRIM(A.SRV_ENC_REC_ID)) >= 10 AND TRIM(K.facility_identifier) = 'P202' THEN TRIM(K.facility_identifier) + '-E-' +  RIGHT(CONCAT('0000000000', ISNULL(SUBSTRING(A.SRV_ENC_REC_ID,charindex('-',A.SRV_ENC_REC_ID)+1,10),'')), 10) when len(TRIM(A.SRV_ENC_REC_ID)) >= 10 AND TRIM(K.facility_identifier) != 'P202' THEN TRIM(K.facility_identifier) + '-E-' + RIGHT(CONCAT('0000000000', ISNULL(SUBSTRING(A.SRV_ENC_REC_ID,charindex('-',A.SRV_ENC_REC_ID)+1,10),'')), 10) else TRIM(K.facility_identifier) + '-E-' +  RIGHT(CONCAT('0000000000', ISNULL(SUBSTRING(A.SRV_ENC_REC_ID,charindex('-',A.SRV_ENC_REC_ID)+1,10),'')), 10) end) as EncounterNumber,A.CLN_POSTCODE as  PostCode,concat(upper(substring(trim(A.CLN_SUBURB_LOCITY),1,1)),lower(substring(trim(A.CLN_SUBURB_LOCITY),2,len(trim(A.CLN_SUBURB_LOCITY))))) as Suburb,'' as EncounterType,case when (K.MG_AUTH_OSP_HIE_FAC_ID in ('X740','X830','X840','X850','X860') OR k.facility_identifier in ('X740','X830','X840','X850','X860'))
			AND A.CL_ID_AUID in ('-1','Unknown/Invalid','') then (TRIM(k.facility_identifier) + '-' + TRIM(A.CL_ID_AUID))
			 when (K.MG_AUTH_OSP_HIE_FAC_ID in ('X740','X830','X840','X850','X860') OR k.facility_identifier in ('X740','X830','X840','X850','X860'))
			AND A.CL_ID_AUID not in ('-1','Unknown/Invalid','') then (TRIM(k.facility_identifier) + '-' +  Right(CONCAT('0000000000', ISNULL(TRIM(A.CL_ID_AUID),'')),10))
			 when (K.MG_AUTH_OSP_HIE_FAC_ID not in ('X740','X830','X840','X850','X860') AND k.facility_identifier not in ('X740','X830','X840','X850','X860'))
			AND A.CL_ID in ('-1','Unknown/Invalid','') then (TRIM(k.facility_identifier) + '-' + TRIM(A.CL_ID)) 
			when (K.MG_AUTH_OSP_HIE_FAC_ID not in ('X740','X830','X840','X850','X860') AND k.facility_identifier not in ('X740','X830','X840','X850','X860'))
			AND A.CL_ID not in ('-1','Unknown/Invalid','') then (TRIM(k.facility_identifier) + '-' +  Right(CONCAT('0000000000', ISNULL(TRIM(A.CL_ID),'')),10)) end as PatientNumber, K.facility_identifier as Hospital,(CASE WHEN A.CL_DEP_DTTM IS NULL THEN datediff(minute, A.CL_ARR_DTTM, A.SB_E_FST_PT_DEP_RDY_DTTM) ELSE datediff(minute, A.CL_ARR_DTTM, A.CL_DEP_DTTM) END) as LengthofStay, A.CL_ARR_DTTM as StartDateTime,(CASE WHEN A.CL_DEP_DTTM IS NULL THEN (A.SB_E_FST_PT_DEP_RDY_DTTM) ELSE (A.CL_DEP_DTTM) END) as EndDateTime, A.AGE_AT_ST_YRS as Age, E.CT_LGCY_UDG_WGT as WeightedSeparation,'' as Extra_InpatientStayNumber, A.ED_TRIAGE_CD as Extra_TriageCategory,CAST(A.CL_MOA_CD AS int) as Extra_ModeofArrival, case when A.ED_VISIT_TYP_CD in ('-1','Unknown/Invalid','') then A.ED_VISIT_TYP_CD else RIGHT(CONCAT('00', ISNULL(TRIM(A.ED_VISIT_TYP_CD),'')),2) end as Extra_EDVisitType, '' as Extra_EDDiagnosis, A.ED_MOS_CD as Extra_ModeofSep,A.SB_E_FST_TRIAGE_DTTM as Extra_EDTriageDateTime,A.SE_REQ_SRC_TYP_CD as Extra_EDReferralSource, A.CL_INDIGENOUS_STAT_CD as Extra_IndigenousStatus, '' as Extra_MedicareNumber, A.CL_ID_AUID as person_area_uid, NULL as SnapFrom, ((CASE WHEN E.LGCY_UDG_UGCY_CD IS NULL THEN '0' ELSE E.LGCY_UDG_UGCY_CD END) + (CASE WHEN E.LGCY_UDG_DISP_CD IS NULL THEN '0' ELSE E.LGCY_UDG_DISP_CD END)) as Extra_UDG, '' as Extra_URG,least(A.SB_E_FST_DOC_SEEN_DTTM, A.SB_E_FST_PHY_SN_DTTM, A.SB_E_FST_NRS_PRAC_SN_DTTM, A.SB_E_FST_NRS_PROT_DTTM) as Extra_ClinStartDTTM,A.SB_E_FST_PT_DEP_RDY_DTTM as Extra_DepartureReadyDTTM,'' as Extra_EDDiagnosisType,'' as Extra_AdmWard,case when A.FST_BILL_CATEGORY_CD in ('10','14','15','16','17','18','19','20','21','22','23','24','28','29','30','31','32',	'36','38','39','40','41','42','43','44','45','46','47','48','49','50','96','97','98') then '1'
						when A.FST_BILL_CATEGORY_CD = '-1' then ''
					   when A.FST_BILL_CATEGORY_CD in ('02','03','25','33') then '2'
					   when A.FST_BILL_CATEGORY_CD in ('04','05','06','07','08','34') then '3'
					   when A.FST_BILL_CATEGORY_CD in ('12','13','26','27','35') then '6'
					   when A.FST_BILL_CATEGORY_CD = '01' then '7'	
					   when A.FST_BILL_CATEGORY_CD = '09' then '5'	
					   when A.FST_BILL_CATEGORY_CD = '11' then '9'	
			else '' end as Extra_EdCompStatus,'' as Extra_Version_Id,case when (G.MG_AUTH_OSP_HIE_FAC_ID = '' or G.MG_AUTH_OSP_HIE_FAC_ID IS NULL) then A.GNAF_LHD_HLTH_JURIS_ID else G.MG_AUTH_OSP_HIE_FAC_ID end as Extra_LHD_of_usual_residence, format(getdate(),'dd-MM-yyyy hh:mm:ss') as getdate,K.OSP_ID as HLTH_ORG_OSP_OSP_ID,K.MG_AUTH_OSP_OSP_ID,A.SE_CBK_SK,A.CL_ID_EUID,A.CL_ID_IHI,A.FST_BILL_CATEGORY_CD,case when (K.MG_AUTH_OSP_HIE_FAC_ID in ('X740','X830','X840','X850','X860') OR k.facility_identifier in ('X740','X830','X840','X850','X860')) AND A.CL_ID_AUID in ('-1','Unknown/Invalid','') then (TRIM(k.OSP_ID) + '-' + TRIM(A.CL_ID_AUID)) when (K.MG_AUTH_OSP_HIE_FAC_ID in ('X740','X830','X840','X850','X860') OR k.facility_identifier in ('X740','X830','X840','X850','X860')) AND A.CL_ID_AUID not in ('-1','Unknown/Invalid','') then (TRIM(k.OSP_ID) + '-' +  Right(CONCAT('0000000000', ISNULL(TRIM(A.CL_ID_AUID),'')),10)) when (K.MG_AUTH_OSP_HIE_FAC_ID not in ('X740','X830','X840','X850','X860') AND k.facility_identifier not in ('X740','X830','X840','X850','X860')) AND A.CL_ID in ('-1','Unknown/Invalid','') then (TRIM(k.OSP_ID) + '-' + TRIM(A.CL_ID)) 
			when (K.MG_AUTH_OSP_HIE_FAC_ID not in ('X740','X830','X840','X850','X860') AND k.facility_identifier not in ('X740','X830','X840','X850','X860'))
			AND A.CL_ID not in ('-1','Unknown/Invalid','') then (TRIM(k.OSP_ID) + '-' +  Right(CONCAT('0000000000', ISNULL(TRIM(A.CL_ID),'')),10)) end AS EDW_Pat_Number,(case when len(TRIM(A.SRV_ENC_REC_ID)) >= 10 AND TRIM(K.facility_identifier) = 'P202' THEN TRIM((K.HLTH_ORG_OSP_OSP_ID)) 
			+ '-E-' +  RIGHT(CONCAT('0000000000', ISNULL(SUBSTRING(A.SRV_ENC_REC_ID,charindex('-',A.SRV_ENC_REC_ID)+1,10),'')), 10) 
			   when len(TRIM(A.SRV_ENC_REC_ID)) >= 10 AND TRIM(K.facility_identifier) != 'P202' THEN TRIM((K.HLTH_ORG_OSP_OSP_ID)) + '-E-' + 
			RIGHT(CONCAT('0000000000', ISNULL(SUBSTRING(A.SRV_ENC_REC_ID,charindex('-',A.SRV_ENC_REC_ID)+1,10),'')), 10) 
			else TRIM((K.HLTH_ORG_OSP_OSP_ID)) + '-E-' + RIGHT(CONCAT('0000000000', ISNULL(SUBSTRING(A.SRV_ENC_REC_ID,charindex('-',A.SRV_ENC_REC_ID)+1,10),'')), 10) end) AS EDW_Enc_Number,E.LGCY_UDG_UGCY_CD,E.LGCY_UDG_DISP_CD,A.FST_FIN_CLASS_CD,A.SRV_ENC_REC_ID,coalesce(L.INTVN_CD,I.INTVN_CD) AS EDINTERVENTION_CD
			,coalesce(L.INTVN_DOM_NM, j.INTVN_DOM_NM) AS EDINTERVENTION_VER,A.ASGS_SA_L2_16_CD, A.CL_URES_ADDR_ASGS21_SA_L2_CD ,M.AP_SE_CBK_SK,N.SRV_ENC_REC_ID AS IP_SRV_ENC_REC_ID FROM CRT.v_FACT_ED_SE_FLAT AS A INNER JOIN (SELECT DISTINCT DIM_OSP_SK, OSP_HIE_FAC_ID,HLTH_ORG_OSP_OSP_ID, MG_AUTH_OSP_HLTH_SECTOR_CD, HLTH_ORG_OSP_HLTH_SECTOR_CD, OSP_TYP_CD,HLTH_ORG_OSP_HIE_FAC_ID, MG_AUTH_OSP_HIE_FAC_ID, MG_AUTH_OSP_OSP_ID,case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_ID else HLTH_ORG_OSP_OSP_ID end as OSP_ID, case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','NA2.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_HIE_FAC_ID else HLTH_ORG_OSP_HIE_FAC_ID end as Facility_identifier FROM CRT.v_DIM_OSP where (MG_AUTH_OSP_HLTH_SECTOR_CD IN ('1','3') and HLTH_ORG_OSP_HLTH_SECTOR_CD IN ('1','3')) AND HLTH_ORG_OSP_HIE_FAC_ID != '-1' AND HLTH_ORG_OSP_HIE_FAC_ID != '') AS K ON A.DIM_OSP_CREATED_SK  = K.DIM_OSP_SK LEFT JOIN CRT.v_FACT_ED_SE AS B ON A.SE_CBK_SK = B.SE_CBK_SK LEFT JOIN CRT.v_DIM_LGCY_UDG AS E ON B.DIM_LGCY_UDG_SK = E.DIM_LGCY_UDG_SK LEFT JOIN (SELECT DISTINCT MG_AUTH_OSP_OSP_ID, MG_AUTH_OSP_FULL_NM, MG_AUTH_OSP_HIE_FAC_ID FROM CRT.v_DIM_OSP ) AS G ON G.MG_AUTH_OSP_OSP_ID = STUFF(A.GNAF_LHD_HLTH_JURIS_ID,4,1,'0') LEFT JOIN CRT.v_FACT_ED_SE_WAU AS h on a.SE_CBK_SK = H.SE_CBK_SK LEFT JOIN (SELECT SE_INT.SE_CBK_SK, DIM_INT.INTVN_DOM_NM, DIM_INT.INTVN_CD,ROW_NUMBER() OVER (PARTITION BY SE_INT.SE_CBK_SK ORDER BY SE_INT.SE_INTVN_REC_ID DESC) AS RN FROM CRT.v_FACT_SE_INTVN SE_INT INNER JOIN crt.v_DIM_INTVN DIM_INT ON SE_INT.DIM_INTVN_SK = DIM_INT.DIM_INTVN_SK WHERE SE_INT.SE_INTVN_SEQ_NUM = '01' and DIM_INT.INTVN_CD not IN ('','-1') AND (SE_INT.DIM_DT_SE_ST_SK <= '"""
                + end_date
                + """' AND SE_INT.DIM_DT_SE_ST_SK != '1111-01-01') and (SE_INT.DIM_DT_SE_END_SK >= '"""
                + start_date
                + """' or SE_INT.DIM_DT_SE_END_SK is NULL OR SE_INT.DIM_DT_SE_END_SK = '1111-01-01') AND SE_INT.SE_TYP_CD = 1) AS L ON H.SE_CBK_SK = L.SE_CBK_SK LEFT JOIN (SELECT DISTINCT SE_CBK_SK,SE_INTVN_SEQ_NUM, INTVN_CD, DIM_INTVN_SK FROM CRT.v_FACT_ED_SE_INTVN where SE_INTVN_SEQ_NUM='01' and INTVN_CD not IN ('','-1') and (DIM_DT_SE_ST_SK <= '"""
                + end_date
                + """' AND DIM_DT_SE_ST_SK != '1111-01-01') and (DIM_DT_SE_END_SK >= '"""
                + start_date
                + """' or DIM_DT_SE_END_SK is NULL OR DIM_DT_SE_END_SK = '1111-01-01')) AS I on a.SE_CBK_SK = i.SE_CBK_SK LEFT JOIN (SELECT DISTINCT DIM_INTVN_SK, INTVN_DOM_NM FROM CRT.v_DIM_INTVN where (INTVN_EFFT_ST_DT <= '"""
                + end_date
                + """' AND INTVN_EFFT_ST_DT != '1111-01-01') and (INTVN_EFFT_END_DT >= '"""
                + start_date
                + """' or INTVN_EFFT_END_DT is NULL OR INTVN_EFFT_END_DT = '1111-01-01')) AS J on i.DIM_INTVN_SK = j.DIM_INTVN_SK LEFT JOIN CRT.v_FACT_AP_EDSSU AS m on A.SE_CBK_SK = M.ED_SE_CBK_SK LEFT JOIN CRT.V_FACT_AP_SE_FLAT as N on N.SE_CBK_SK = M.AP_SE_CBK_SK GROUP BY  k.HLTH_ORG_OSP_HIE_FAC_ID,ISNULL(SUBSTRING(A.SRV_ENC_REC_ID,charindex('-',A.SRV_ENC_REC_ID)+1,10),'') ,(case when len(TRIM(A.SRV_ENC_REC_ID)) >= 10 AND TRIM(K.facility_identifier) = 'P202' THEN TRIM(K.facility_identifier) + '-E-' +  RIGHT(CONCAT('0000000000', ISNULL(SUBSTRING(A.SRV_ENC_REC_ID,charindex('-',A.SRV_ENC_REC_ID)+1,10),'')), 10) when len(TRIM(A.SRV_ENC_REC_ID)) >= 10 AND TRIM(K.facility_identifier) != 'P202' THEN TRIM(K.facility_identifier) + '-E-' + RIGHT(CONCAT('0000000000', ISNULL(SUBSTRING(A.SRV_ENC_REC_ID,charindex('-',A.SRV_ENC_REC_ID)+1,10),'')),10) 
			   else TRIM(K.facility_identifier) + '-E-' +  RIGHT(CONCAT('0000000000', ISNULL(SUBSTRING(A.SRV_ENC_REC_ID,charindex('-',A.SRV_ENC_REC_ID)+1,10),'')), 10) end),A.CLN_POSTCODE,A.CLN_SUBURB_LOCITY,case when (K.MG_AUTH_OSP_HIE_FAC_ID in ('X740','X830','X840','X850','X860') OR k.facility_identifier in ('X740','X830','X840','X850','X860')) AND A.CL_ID_AUID in ('-1','Unknown/Invalid','') then (TRIM(k.facility_identifier) + '-' + TRIM(A.CL_ID_AUID))
			 when (K.MG_AUTH_OSP_HIE_FAC_ID in ('X740','X830','X840','X850','X860') OR k.facility_identifier in ('X740','X830','X840','X850','X860'))
			AND A.CL_ID_AUID not in ('-1','Unknown/Invalid','') then (TRIM(k.facility_identifier) + '-' +  Right(CONCAT('0000000000', ISNULL(TRIM(A.CL_ID_AUID),'')),10))
			 when (K.MG_AUTH_OSP_HIE_FAC_ID not in ('X740','X830','X840','X850','X860') AND k.facility_identifier not in ('X740','X830','X840','X850','X860'))
			AND A.CL_ID in ('-1','Unknown/Invalid','') then (TRIM(k.facility_identifier) + '-' + TRIM(A.CL_ID)) 
			when (K.MG_AUTH_OSP_HIE_FAC_ID not in ('X740','X830','X840','X850','X860') AND k.facility_identifier not in ('X740','X830','X840','X850','X860'))
			AND A.CL_ID not in ('-1','Unknown/Invalid','') then (TRIM(k.facility_identifier) + '-' +  Right(CONCAT('0000000000', ISNULL(TRIM(A.CL_ID),'')),10)) end, K.facility_identifier, (CASE WHEN (A.CL_DEP_DTTM) IS NULL THEN datediff(minute,(A.CL_ARR_DTTM),(A.SB_E_FST_PT_DEP_RDY_DTTM)) ELSE datediff(minute,(A.CL_ARR_DTTM),(A.CL_DEP_DTTM)) END),A.CL_ARR_DTTM,(CASE WHEN A.CL_DEP_DTTM IS NULL THEN A.SB_E_FST_PT_DEP_RDY_DTTM ELSE A.CL_DEP_DTTM END),A.AGE_AT_ST_YRS,A.ED_TRIAGE_CD,A.CL_MOA_CD,A.ED_VISIT_TYP_CD,A.ED_MOS_CD,A.SB_E_FST_TRIAGE_DTTM		,A.SE_REQ_SRC_TYP_CD,A.CL_INDIGENOUS_STAT_CD,A.CL_MC_CARD_NUM,A.CL_ID_AUID,A.CL_ID, ((CASE WHEN E.LGCY_UDG_UGCY_CD IS NULL THEN '0' ELSE E.LGCY_UDG_UGCY_CD END) + (CASE WHEN E.LGCY_UDG_DISP_CD IS NULL THEN '0' ELSE E.LGCY_UDG_DISP_CD END)),least(A.SB_E_FST_DOC_SEEN_DTTM, A.SB_E_FST_PHY_SN_DTTM, A.SB_E_FST_NRS_PRAC_SN_DTTM, A.SB_E_FST_NRS_PROT_DTTM),A.SB_E_FST_PT_DEP_RDY_DTTM, A.FST_FIN_CLASS_CD, K.MG_AUTH_OSP_HIE_FAC_ID, CAST(A.CL_ARR_DTTM as date), CAST(A.CL_DEP_DTTM as date), CAST(A.SB_E_FST_PT_DEP_RDY_DTTM as date),k.MG_AUTH_OSP_HLTH_SECTOR_CD,k.HLTH_ORG_OSP_HLTH_SECTOR_CD,K.OSP_ID,K.HLTH_ORG_OSP_OSP_ID,K.MG_AUTH_OSP_OSP_ID,A.SE_CBK_SK
			,A.CL_ID_EUID,A.CL_ID_IHI,A.FST_BILL_CATEGORY_CD,case when (K.MG_AUTH_OSP_HIE_FAC_ID in ('X740','X830','X840','X850','X860') OR k.facility_identifier in ('X740','X830','X840','X850','X860')) AND A.CL_ID_AUID in ('-1','Unknown/Invalid','') then (TRIM(k.OSP_ID) + '-' + TRIM(A.CL_ID_AUID))
			 when (K.MG_AUTH_OSP_HIE_FAC_ID in ('X740','X830','X840','X850','X860') OR k.facility_identifier in ('X740','X830','X840','X850','X860'))
			AND A.CL_ID_AUID not in ('-1','Unknown/Invalid','') then (TRIM(k.OSP_ID) + '-' +  Right(CONCAT('0000000000', ISNULL(TRIM(A.CL_ID_AUID),'')),10))
			 when (K.MG_AUTH_OSP_HIE_FAC_ID not in ('X740','X830','X840','X850','X860') AND k.facility_identifier not in ('X740','X830','X840','X850','X860'))
			AND A.CL_ID in ('-1','Unknown/Invalid','') then (TRIM(k.OSP_ID) + '-' + TRIM(A.CL_ID)) 
			when (K.MG_AUTH_OSP_HIE_FAC_ID not in ('X740','X830','X840','X850','X860') AND k.facility_identifier not in ('X740','X830','X840','X850','X860'))
			AND A.CL_ID not in ('-1','Unknown/Invalid','') then (TRIM(k.OSP_ID) + '-' +  Right(CONCAT('0000000000', ISNULL(TRIM(A.CL_ID),'')),10)) end,(case when len(TRIM(A.SRV_ENC_REC_ID)) >= 10 AND TRIM(K.facility_identifier) = 'P202' THEN TRIM((K.HLTH_ORG_OSP_OSP_ID)) + '-E-' +  RIGHT(CONCAT('0000000000', ISNULL(SUBSTRING(A.SRV_ENC_REC_ID,charindex('-',A.SRV_ENC_REC_ID)+1,10),'')), 10) when len(TRIM(A.SRV_ENC_REC_ID)) >= 10 AND TRIM(K.facility_identifier) != 'P202' THEN TRIM((K.HLTH_ORG_OSP_OSP_ID)) + '-E-' + RIGHT(CONCAT('0000000000', ISNULL(SUBSTRING(A.SRV_ENC_REC_ID,charindex('-',A.SRV_ENC_REC_ID)+1,10),'')), 10) 
			else TRIM((K.HLTH_ORG_OSP_OSP_ID)) + '-E-' +  RIGHT(CONCAT('0000000000', ISNULL(SUBSTRING(A.SRV_ENC_REC_ID,charindex('-',A.SRV_ENC_REC_ID)+1,10),'')), 10) end),E.LGCY_UDG_UGCY_CD,E.LGCY_UDG_DISP_CD,G.MG_AUTH_OSP_HIE_FAC_ID,E.CT_LGCY_UDG_WGT,A.GNAF_LHD_HLTH_JURIS_ID,A.SRV_ENC_REC_ID
			,I.INTVN_CD, j.INTVN_DOM_NM, L.INTVN_CD, L.INTVN_DOM_NM ,A.ASGS_SA_L2_16_CD, A.CL_URES_ADDR_ASGS21_SA_L2_CD ,M.AP_SE_CBK_SK,N.SRV_ENC_REC_ID HAVING (((A.ED_MOS_CD <>'98' Or A.ED_MOS_CD Is Null) AND ((CAST(A.CL_ARR_DTTM as date))<=('"""
                + end_date
                + """')) AND ((CAST(A.CL_DEP_DTTM as date))>=('"""
                + start_date
                + """') And (CAST(A.CL_DEP_DTTM as date))<=('"""
                + end_date
                + """')) AND ((K.MG_AUTH_OSP_HIE_FAC_ID)='"""
                + lhd
                + """' OR (K.facility_identifier)='"""
                + lhd
                + """')) OR ((A.ED_MOS_CD <>'98' Or A.ED_MOS_CD Is Null) AND ((CAST(A.CL_ARR_DTTM as date))>=('"""
                + start_date
                + """') And (CAST(A.CL_ARR_DTTM as date))<=('"""
                + end_date
                + """')) AND ((CAST(A.CL_DEP_DTTM as date)) Is Null Or (CAST(A.CL_DEP_DTTM as date))>=('"""
                + start_date
                + """')) AND ((CAST(A.SB_E_FST_PT_DEP_RDY_DTTM AS DATE))>='"""
                + start_date
                + """' or (CAST(A.SB_E_FST_PT_DEP_RDY_DTTM AS DATE)) Is Null) AND ((K.MG_AUTH_OSP_HIE_FAC_ID)='"""
                + lhd
                + """' OR (K.facility_identifier)='"""
                + lhd
                + """'))) AND K.facility_identifier IN ("""
                + facilities_included
                + """);"""
            )
    retry_flag = True
    retry_count = 0
    while retry_flag and retry_count < 5:
        try:
            logging.info(query_EdEncounterPreclean)
            tbl_ppm_ED_Encounter_preclean = pd.read_sql(query_EdEncounterPreclean, cnxn)
            retry_flag = False
        except Exception as e:
            retry_count = retry_count + 1
            time.sleep(5)
            if retry_count == 5:
                logging.exception("Exception occurred")
                label_8_status = 0
                messagebox.showerror(
                    "SQL Error",
                    "Error extracting PpmEdEncounterPreclean details\n" + str(e),
                )
                label_8_sub.configure(
                    text="Failed (PpmEdEncounterPreclean)...", fg="red"
                )
                main_screen.update()
                # tbl_ppm_ED_Encounter_preclean = pd.DataFrame(columns=['Stu', 'EncounterNumber', 'PostCode', 'Suburb', 'EncounterType', 'PatientNumber', 'Hospital', 'LengthofStay', 'StartDateTime', 'EndDateTime', 'Age', 'WeightedSeparation', 'Extra_InpatientStayNumber', 'Extra_TriageCategory', 'Extra_ModeofArrival', 'Extra_EDVisitType', 'Extra_EDDiagnosis', 'Extra_ModeofSep', 'Extra_EDTriageDateTime', 'Extra_EDReferralSource', 'Extra_IndigenousStatus', 'Extra_MedicareNumber', 'person_area_uid', 'SnapFrom', 'Extra_UDG', 'Extra_URG', 'Extra_ClinStartDTTM', 'Extra_DepartureReadyDTTM', 'Extra_EDDiagnosisType', 'Extra_AdmWard', 'Extra_EdCompStatus', 'Extra_Version_Id', 'Extra_LHD_of_usual_residence', 'getdate', 'HLTH_ORG_OSP_OSP_ID', 'MG_AUTH_OSP_OSP_ID', 'SE_CBK_SK', 'CL_ID_EUID', 'CL_ID_IHI', 'FST_BILL_CATEGORY_CD', 'EDW_Pat_Number', 'EDW_Enc_Number'])
                return  # stop extraction
        else:
            tbl_ppm_ED_Encounter_preclean = tbl_ppm_ED_Encounter_preclean.fillna("")
            tbl_ppm_ED_Encounter_preclean = tbl_ppm_ED_Encounter_preclean[
                [
                    "Stu",
                    "EncounterNumber",
                    "PostCode",
                    "Suburb",
                    "EncounterType",
                    "PatientNumber",
                    "Hospital",
                    "LengthofStay",
                    "StartDateTime",
                    "EndDateTime",
                    "Age",
                    "WeightedSeparation",
                    "Extra_InpatientStayNumber",
                    "Extra_TriageCategory",
                    "Extra_ModeofArrival",
                    "Extra_EDVisitType",
                    "Extra_EDDiagnosis",
                    "Extra_ModeofSep",
                    "Extra_EDTriageDateTime",
                    "Extra_EDReferralSource",
                    "Extra_IndigenousStatus",
                    "Extra_MedicareNumber",
                    "person_area_uid",
                    "SnapFrom",
                    "Extra_UDG",
                    "Extra_URG",
                    "Extra_ClinStartDTTM",
                    "Extra_DepartureReadyDTTM",
                    "Extra_EDDiagnosisType",
                    "Extra_AdmWard",
                    "Extra_EdCompStatus",
                    "Extra_Version_Id",
                    "Extra_LHD_of_usual_residence",
                    "getdate",
                    "HLTH_ORG_OSP_OSP_ID",
                    "MG_AUTH_OSP_OSP_ID",
                    "SE_CBK_SK",
                    "CL_ID_EUID",
                    "CL_ID_IHI",
                    "FST_BILL_CATEGORY_CD",
                    "FST_FIN_CLASS_CD",
                    "EDW_Pat_Number",
                    "EDW_Enc_Number",
                    "SRV_ENC_REC_ID",
                    "EDINTERVENTION_CD",
                    "EDINTERVENTION_VER",
                    "ASGS_SA_L2_16_CD",
                    "CL_URES_ADDR_ASGS21_SA_L2_CD",
                    "AP_SE_CBK_SK",
                    "IP_SRV_ENC_REC_ID",
                ]
            ]
            tbl_ppm_ED_Encounter_preclean.rename(
                columns={
                    "Extra_TriageCategory": "Extra:TriageCategory",
                    "Extra_URG": "Extra:URG",
                    "Extra_EDVisitType": "Extra:EDVisitType",
                    "Extra_ModeofSep": "Extra:ModeofSep",
                },
                inplace=True,
            )
            tbl_ppm_ED_Encounter_preclean["LengthofStay"] = (
                tbl_ppm_ED_Encounter_preclean["LengthofStay"]
                .replace("", "0")
                .apply(lambda x: int(float(x)))
            )  # .astype('Int64', errors='ignore') - cause ValueError: invalid literal for int() with base 10: ''
            # tbl_ppm_ED_Encounter_preclean['LengthofStay'] = tbl_ppm_ED_Encounter_preclean['LengthofStay'].fillna(0).astype(int, errors='ignore')
            tbl_ppm_ED_Encounter_preclean = tbl_ppm_ED_Encounter_preclean.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_ppm_ED_Encounter_preclean = tbl_ppm_ED_Encounter_preclean.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_ppm_ED_Encounter_preclean = tbl_ppm_ED_Encounter_preclean.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_ppm_ED_Encounter_preclean = tbl_ppm_ED_Encounter_preclean.apply(
                lambda x: x.replace(regex=r"^nan$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_ppm_ED_Encounter_preclean = tbl_ppm_ED_Encounter_preclean.apply(
                lambda x: x.replace(regex=r"NULL", value="")
                if x.dtype == "object"
                else x
            )
            tbl_ppm_ED_Encounter_preclean = tbl_ppm_ED_Encounter_preclean.apply(
                lambda x: x.replace(regex=r"null", value="")
                if x.dtype == "object"
                else x
            )
            tbl_ppm_ED_Encounter_preclean = tbl_ppm_ED_Encounter_preclean.apply(
                lambda x: x.replace(regex=r"Null", value="")
                if x.dtype == "object"
                else x
            )
            tbl_ppm_ED_Encounter_preclean = tbl_ppm_ED_Encounter_preclean.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            tbl_ppm_ED_Encounter_preclean = tbl_ppm_ED_Encounter_preclean.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            tbl_ppm_ED_Encounter_preclean = tbl_ppm_ED_Encounter_preclean.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            tbl_ppm_ED_Encounter_preclean = tbl_ppm_ED_Encounter_preclean.apply(
                lambda x: x.replace(regex=r"NULL", value="")
                if x.dtype == "object"
                else x
            )
            tbl_ppm_ED_Encounter_preclean = tbl_ppm_ED_Encounter_preclean.apply(
                lambda x: x.replace(regex=r"null", value="")
                if x.dtype == "object"
                else x
            )
            tbl_ppm_ED_Encounter_preclean = tbl_ppm_ED_Encounter_preclean.apply(
                lambda x: x.replace(regex=r"Null", value="")
                if x.dtype == "object"
                else x
            )
            # dropping duplicate values
            tbl_ppm_ED_Encounter_preclean.drop_duplicates(keep="last", inplace=True)
            tbl_ppm_ED_Encounter_preclean.to_csv(
                "./ExtractorDB/PpmEdEncounterPreclean.csv",
                index=False,
                na_rep="",
                float_format=str,
                decimal=str,
                date_format=str,
            )
            logging.info(
                "tbl_ppm_ED_Encounter_preclean=%s", len(tbl_ppm_ED_Encounter_preclean)
            )
    df_ED_Diag_Slice = pd.DataFrame()
    df_ED_Diag_Slice_1 = pd.DataFrame()
    df_ED_Diag_Slice_2 = pd.DataFrame()
    # ED_Diag_Slice using ED_DIAGNOSIS
    # columns = facility_identifier,ed_visit_identifier,ed_diagnosis_type,ed_diagnosis_code,area_identifier,clinical_codeset
    # Access query = ED_Diag_subquery
    # SELECT dbo_ED_DIAGNOSIS.facility_identifier, dbo_ED_DIAGNOSIS.ed_visit_identifier, dbo_ED_DIAGNOSIS.ed_diagnosis_type, dbo_ED_DIAGNOSIS.ed_diagnosis_code, dbo_FACILITY.area_identifier, dbo_ED_DIAGNOSIS.clinical_codeset
    label_8_sub.configure(text="In Progress (ED_DIAGNOSIS)...", fg="blue")
    main_screen.update()
    if source == "HIE":
        # Note: access query ED_Diag_subquery excludes: dbo_ED_DIAGNOSIS.facility_identifier)<>"Q230"
        if len(facilities_excluded_list) == 0:
            query_ED_Diag_Slice_1 = (
                """SELECT dbo.ED_DIAGNOSIS.facility_identifier, dbo.ED_DIAGNOSIS.ed_visit_identifier, dbo.ED_DIAGNOSIS.ed_diagnosis_type, dbo.ED_DIAGNOSIS.ed_diagnosis_code, dbo.FACILITY.area_identifier, dbo.ED_DIAGNOSIS.clinical_codeset, '' as ed_diagnosis_type2, '' as ed_diagnosis_code2, '' as ed_diagnosis_type3, '' as ed_diagnosis_code3, '' as HLTH_ORG_OSP_OSP_ID, '' as MG_AUTH_OSP_OSP_ID, '' as SE_CBK_SK FROM dbo.ED_DIAGNOSIS INNER JOIN dbo.FACILITY ON dbo.ED_DIAGNOSIS.facility_identifier = dbo.FACILITY.facility_identifier WHERE ((((dbo.ED_DIAGNOSIS.facility_identifier)<>"Q230") AND ((dbo.ED_DIAGNOSIS.ed_diagnosis_type)='P' OR (dbo.ED_DIAGNOSIS.ed_diagnosis_type)='p') AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.ED_DIAGNOSIS.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.ED_DIAGNOSIS.arrival_date) >= dateadd(day, -5, CAST('"""
                + start_date
                + """' AS DATE )) And (dbo.ED_DIAGNOSIS.arrival_date) <= dateadd(day, 5, CAST('"""
                + end_date
                + """' AS DATE )))) OR (((dbo.ED_DIAGNOSIS.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.ED_DIAGNOSIS.ed_diagnosis_type)='P' OR (dbo.ED_DIAGNOSIS.ed_diagnosis_type)='p') AND ((dbo.ED_DIAGNOSIS.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.ED_DIAGNOSIS.arrival_date) >= dateadd(day, -5, CAST('"""
                + start_date
                + """' AS DATE )) And (dbo.ED_DIAGNOSIS.arrival_date) <= dateadd(day, 5, CAST('"""
                + end_date
                + """' AS DATE )))));"""
            )
        else:
            query_ED_Diag_Slice_1 = (
                """SELECT dbo.ED_DIAGNOSIS.facility_identifier, dbo.ED_DIAGNOSIS.ed_visit_identifier, dbo.ED_DIAGNOSIS.ed_diagnosis_type, dbo.ED_DIAGNOSIS.ed_diagnosis_code, dbo.FACILITY.area_identifier, dbo.ED_DIAGNOSIS.clinical_codeset, '' as ed_diagnosis_type2, '' as ed_diagnosis_code2, '' as ed_diagnosis_type3, '' as ed_diagnosis_code3, '' as HLTH_ORG_OSP_OSP_ID, '' as MG_AUTH_OSP_OSP_ID, '' as SE_CBK_SK FROM dbo.ED_DIAGNOSIS INNER JOIN dbo.FACILITY ON dbo.ED_DIAGNOSIS.facility_identifier = dbo.FACILITY.facility_identifier WHERE ((((dbo.ED_DIAGNOSIS.facility_identifier)<>"Q230") AND ((dbo.ED_DIAGNOSIS.ed_diagnosis_type)='P' OR (dbo.ED_DIAGNOSIS.ed_diagnosis_type)='p') AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.ED_DIAGNOSIS.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.ED_DIAGNOSIS.arrival_date) >= dateadd(day, -5, CAST('"""
                + start_date
                + """' AS DATE )) And (dbo.ED_DIAGNOSIS.arrival_date) <= dateadd(day, 5, CAST('"""
                + end_date
                + """' AS DATE )))) OR (((dbo.ED_DIAGNOSIS.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.ED_DIAGNOSIS.ed_diagnosis_type)='P' OR (dbo.ED_DIAGNOSIS.ed_diagnosis_type)='p') AND ((dbo.ED_DIAGNOSIS.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.ED_DIAGNOSIS.arrival_date) >= dateadd(day, -5, CAST('"""
                + start_date
                + """' AS DATE )) And (dbo.ED_DIAGNOSIS.arrival_date) <= dateadd(day, 5, CAST('"""
                + end_date
                + """' AS DATE ))))) AND dbo.FACILITY.facility_identifier NOT IN ("""
                + facilities_excluded
                + """);"""
            )
    elif source == "EDW":
        if len(facilities_included_list) > 0:
            query_ED_Diag_Slice_1 = (
                """SELECT DISTINCT C.facility_identifier,ISNULL(SUBSTRING(A.SRV_ENC_REC_ID,charindex('-',A.SRV_ENC_REC_ID)+1,10),'') as ed_visit_identifier,max(case when a.DIAG_SEQ_NUM = 1 then A.DIAG_TYP_CD else '' end) as ed_diagnosis_type,max(case when a.DIAG_SEQ_NUM = 1 then A.DIAG_CD else '' end) as ed_diagnosis_code,max(case when a.DIAG_SEQ_NUM = 2 then A.DIAG_TYP_CD else '' end) as ed_diagnosis_type2,max(case when a.DIAG_SEQ_NUM = 2 then A.DIAG_CD else '' end) as ed_diagnosis_code2,max(case when a.DIAG_SEQ_NUM = 3 then A.DIAG_TYP_CD else '' end) as ed_diagnosis_type3,max(case when a.DIAG_SEQ_NUM = 3 then A.DIAG_CD else '' end) as ed_diagnosis_code3,C.MG_AUTH_OSP_HIE_FAC_ID as area_identifier,A.DIAG_DOM_NM as clinical_codeset,C.OSP_ID as HLTH_ORG_OSP_OSP_ID,C.MG_AUTH_OSP_OSP_ID,A.SE_CBK_SK,max(a.DIAG_DOM_NM) as EDDiag_ver FROM (SELECT DISTINCT A.SE_CBK_SK, A.SRV_ENC_REC_ID, B.DIAG_CD, A.DIAG_TYP_CD
            ,case when B.DIAG_DOM_NM = 
            'International Statistical Classification of Diseases and Related Health Problems, Tenth Revision, Australian Modification (ICD10-AM) 13th Edition (EDW)' then 'ICD10AM_V13'
                 when B.DIAG_DOM_NM = 
            'International Statistical Classification of Diseases and Related Health Problems, Tenth Revision, Australian Modification (ICD10-AM) 12th Edition (EDW)' then 'ICD10AM_V12' 
                  when B.DIAG_DOM_NM = 
            'International Statistical Classification of Diseases and Related Health Problems, Tenth Revision, Australian Modification (ICD10-AM) 11th Edition (EDW)' then 'ICD10AM_V11' 
                  when B.DIAG_DOM_NM = 
            'International Statistical Classification of Diseases and Related Health Problems, Tenth Revision, Australian Modification (ICD10-AM) 10th Edition (EDW)' then 'ICD10AM_V10' else DIAG_DOM_NM end as DIAG_DOM_NM,A.DIM_DT_SE_ST_SK,C.DIM_OSP_CREATED_SK,A.DIAG_SEQ_NUM FROM CRT.v_FACT_ED_SE_DIAG as a LEFT JOIN CRT.v_DIM_DIAG as b on a.DIM_DIAG_SK = b.DIM_DIAG_SK LEFT JOIN (SELECT DISTINCT SE_CBK_SK,DIM_OSP_CREATED_SK FROM CRT.v_FACT_ED_SE) AS C on a.SE_CBK_SK = C.SE_CBK_SK where B.DIAG_DOM_NM != 'Unknown/Invalid' AND (A.DIM_DT_SE_ST_SK >= dateadd(day, -5, CAST('"""
                + start_date
                + """' AS DATE))) And (A.DIM_DT_SE_ST_SK <= dateadd(day, 5, CAST('"""
                + end_date
                + """' AS DATE ))) AND A.DIM_DT_SE_ST_SK != '1111-01-01') AS a INNER JOIN (SELECT DISTINCT DIM_OSP_SK, OSP_HIE_FAC_ID, MG_AUTH_OSP_HIE_FAC_ID, MG_AUTH_OSP_OSP_ID,MG_AUTH_OSP_HLTH_SECTOR_CD,HLTH_ORG_OSP_HLTH_SECTOR_CD,OSP_TYP_CD,HLTH_ORG_OSP_HIE_FAC_ID,case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_HIE_FAC_ID else HLTH_ORG_OSP_HIE_FAC_ID end as facility_identifier,case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_ID else HLTH_ORG_OSP_OSP_ID end as OSP_ID FROM CRT.v_DIM_OSP WHERE ((MG_AUTH_OSP_HLTH_SECTOR_CD IN ('1','3')) and (HLTH_ORG_OSP_HLTH_SECTOR_CD IN ('1','3'))) AND HLTH_ORG_OSP_HIE_FAC_ID != '-1' AND HLTH_ORG_OSP_HIE_FAC_ID != '') AS C ON A.DIM_OSP_CREATED_SK = C.DIM_OSP_SK WHERE (c.facility_identifier) IN ("""
                + facilities_included
                + """) AND A.DIAG_DOM_NM != 'SNOMED CT Concept (EDW)' AND (A.DIAG_TYP_CD in ('DD','DE','DA','dd','de','da') AND (C.MG_AUTH_OSP_HIE_FAC_ID='"""
                + lhd
                + """' or (c.facility_identifier)='"""
                + lhd
                + """')) group by C.facility_identifier,ISNULL(SUBSTRING(A.SRV_ENC_REC_ID,charindex('-',A.SRV_ENC_REC_ID)+1,10),''),C.MG_AUTH_OSP_HIE_FAC_ID,A.DIAG_DOM_NM,C.OSP_ID,C.MG_AUTH_OSP_OSP_ID,A.SE_CBK_SK;"""
            )
    retry_flag = True
    retry_count = 0
    while retry_flag and retry_count < 5:
        try:
            logging.info(query_ED_Diag_Slice_1)
            df_ED_Diag_Slice_1 = pd.read_sql(query_ED_Diag_Slice_1, cnxn)
            retry_flag = False
        except Exception as e:
            retry_count = retry_count + 1
            time.sleep(5)
            if retry_count == 5:
                logging.exception("Exception occurred")
                label_8_status = 0
                messagebox.showerror(
                    "SQL Error", "Error extracting ED_DIAGNOSIS details\n" + str(e)
                )
                label_8_sub.configure(text="Failed (ED_DIAGNOSIS)...", fg="red")
                main_screen.update()
                df_ED_Diag_Slice_1 = pd.DataFrame(
                    columns=[
                        "facility_identifier",
                        "ed_visit_identifier",
                        "ed_diagnosis_type",
                        "ed_diagnosis_code",
                        "area_identifier",
                        "clinical_codeset",
                        "ed_diagnosis_type2",
                        "ed_diagnosis_code2",
                        "ed_diagnosis_type3",
                        "ed_diagnosis_code3",
                        "HLTH_ORG_OSP_OSP_ID",
                        "MG_AUTH_OSP_OSP_ID",
                        "SE_CBK_SK",
                        "EDDiag_ver",
                    ]
                )
                return  # stop extraction
        else:
            df_ED_Diag_Slice_1 = df_ED_Diag_Slice_1[
                [
                    "facility_identifier",
                    "ed_visit_identifier",
                    "ed_diagnosis_type",
                    "ed_diagnosis_code",
                    "area_identifier",
                    "clinical_codeset",
                    "ed_diagnosis_type2",
                    "ed_diagnosis_code2",
                    "ed_diagnosis_type3",
                    "ed_diagnosis_code3",
                    "HLTH_ORG_OSP_OSP_ID",
                    "MG_AUTH_OSP_OSP_ID",
                    "SE_CBK_SK",
                    "EDDiag_ver",
                ]
            ]
            df_ED_Diag_Slice_1 = df_ED_Diag_Slice_1.fillna("")
            df_ED_Diag_Slice_1 = df_ED_Diag_Slice_1.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            df_ED_Diag_Slice_1 = df_ED_Diag_Slice_1.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            df_ED_Diag_Slice_1 = df_ED_Diag_Slice_1.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            df_ED_Diag_Slice_1 = df_ED_Diag_Slice_1.apply(
                lambda x: x.replace(regex=r"NULL", value="")
                if x.dtype == "object"
                else x
            )
            df_ED_Diag_Slice_1 = df_ED_Diag_Slice_1.apply(
                lambda x: x.replace(regex=r"null", value="")
                if x.dtype == "object"
                else x
            )
            df_ED_Diag_Slice_1 = df_ED_Diag_Slice_1.apply(
                lambda x: x.replace(regex=r"Null", value="")
                if x.dtype == "object"
                else x
            )
            df_ED_Diag_Slice_1 = df_ED_Diag_Slice_1[
                df_ED_Diag_Slice_1["area_identifier"] == lhd_global
            ]
            df_ED_Diag_Slice_1 = df_ED_Diag_Slice_1[
                df_ED_Diag_Slice_1["facility_identifier"].isin(
                    facilities_included_list_global
                )
            ]
            # dropping duplicate values
            df_ED_Diag_Slice_1.drop_duplicates(keep="last", inplace=True)
            logging.info("df_ED_Diag_Slice_1=%s", len(df_ED_Diag_Slice_1))
            df_ED_Diag_Slice_1.to_csv(
                "./ExtractorDB/ED_Diag_Slice_1.csv",
                index=False,
                na_rep="",
                float_format=str,
                decimal=str,
                date_format=str,
            )
    # ED_Diag_Slice using Ed_Diagnosis_SCT
    # columns = facility_identifier,ed_visit_identifier,ed_diagnosis_type,ed_diagnosis_code,area_identifier,clinical_codeset
    # If    LHD = X700,X710,X720,X730,X740,X750,X760, X770,X810,X840,X850,X860 or FacilityID = C238 => These are the LHDs/Facilies that have the table in dbo_ED_DIAGNOSIS_SCT in their HIE then ED_Diag_SCT subquery
    # Access query = ED_Diag_SCT subquery
    # SELECT dbo_ED_DIAGNOSIS_SCT.facility_identifier, dbo_ED_DIAGNOSIS_SCT.ed_visit_identifier, dbo_ED_DIAGNOSIS_SCT.ed_diagnosis_type, dbo_ED_DIAGNOSIS_SCT.ed_diagnosis_code, dbo_ED_DIAGNOSIS_SCT.code_version, dbo_FACILITY.area_identifier
    label_8_sub.configure(text="In Progress (ED_DIAGNOSIS_SCT)...", fg="blue")
    main_screen.update()
    if source == "HIE":
        if (
            lhd == "X700"
            or lhd == "X701"
            or lhd == "X720"
            or lhd == "X730"
            or lhd == "X740"
            or lhd == "X750"
            or lhd == "X760"
            or lhd == "X770"
            or lhd == "X810"
            or lhd == "X840"
            or lhd == "X850"
            or lhd == "X860"
            or lhd == "X710"
        ):
            # Note: access query ED_Diag_SCT subquery excludes: dbo_ED_DIAGNOSIS.facility_identifier)<>"Q230"
            if len(facilities_excluded_list) == 0:
                query_ED_Diag_Slice_2 = (
                    """SELECT dbo.ED_DIAGNOSIS_SCT.facility_identifier, dbo.ED_DIAGNOSIS_SCT.ed_visit_identifier, dbo.ED_DIAGNOSIS_SCT.ed_diagnosis_type, dbo.ED_DIAGNOSIS_SCT.ed_diagnosis_code, dbo.FACILITY.area_identifier, dbo.ED_DIAGNOSIS_SCT.code_version as clinical_codeset,'' as ed_diagnosis_type2, '' as ed_diagnosis_code2, '' as ed_diagnosis_type3, '' as ed_diagnosis_code3, '' as HLTH_ORG_OSP_OSP_ID, '' as MG_AUTH_OSP_OSP_ID, '' as SE_CBK_SK FROM dbo.ED_DIAGNOSIS_SCT INNER JOIN dbo.FACILITY ON dbo.ED_DIAGNOSIS_SCT.facility_identifier = dbo.FACILITY.facility_identifier WHERE ((((dbo.ED_DIAGNOSIS_SCT.facility_identifier)<>"Q230") AND ((dbo.ED_DIAGNOSIS_SCT.ed_diagnosis_type)='D' OR (dbo.ED_DIAGNOSIS_SCT.ed_diagnosis_type)='d' Or (dbo.ED_DIAGNOSIS_SCT.ed_diagnosis_type) Is Null) AND ((dbo.FACILITY.area_identifier)='"""
                    + lhd
                    + """') AND ((dbo.ED_DIAGNOSIS_SCT.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.ED_DIAGNOSIS_SCT.arrival_date) >= dateadd(day, -5, CAST('"""
                    + start_date
                    + """' AS DATE )) And (dbo.ED_DIAGNOSIS_SCT.arrival_date) <= dateadd(day, 5, CAST('"""
                    + end_date
                    + """' AS DATE )))) OR (((dbo.ED_DIAGNOSIS_SCT.facility_identifier)='"""
                    + lhd
                    + """') AND ((dbo.ED_DIAGNOSIS_SCT.ed_diagnosis_type)='D' OR (dbo.ED_DIAGNOSIS_SCT.ed_diagnosis_type)='d' Or (dbo.ED_DIAGNOSIS_SCT.ed_diagnosis_type) Is Null) AND ((dbo.ED_DIAGNOSIS_SCT.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.ED_DIAGNOSIS_SCT.arrival_date) >= dateadd(day, -5, CAST('"""
                    + start_date
                    + """' AS DATE )) And (dbo.ED_DIAGNOSIS_SCT.arrival_date) <= dateadd(day, 5, CAST('"""
                    + end_date
                    + """' AS DATE )))));"""
                )
            else:
                query_ED_Diag_Slice_2 = (
                    """SELECT dbo.ED_DIAGNOSIS_SCT.facility_identifier, dbo.ED_DIAGNOSIS_SCT.ed_visit_identifier, dbo.ED_DIAGNOSIS_SCT.ed_diagnosis_type, dbo.ED_DIAGNOSIS_SCT.ed_diagnosis_code, dbo.FACILITY.area_identifier, dbo.ED_DIAGNOSIS_SCT.code_version as clinical_codeset,'' as ed_diagnosis_type2, '' as ed_diagnosis_code2, '' as ed_diagnosis_type3, '' as ed_diagnosis_code3, '' as HLTH_ORG_OSP_OSP_ID, '' as MG_AUTH_OSP_OSP_ID, '' as SE_CBK_SK FROM dbo.ED_DIAGNOSIS_SCT INNER JOIN dbo.FACILITY ON dbo.ED_DIAGNOSIS_SCT.facility_identifier = dbo.FACILITY.facility_identifier WHERE ((((dbo.ED_DIAGNOSIS_SCT.facility_identifier)<>"Q230") AND ((dbo.ED_DIAGNOSIS_SCT.ed_diagnosis_type)='D' OR (dbo.ED_DIAGNOSIS_SCT.ed_diagnosis_type)='d' Or (dbo.ED_DIAGNOSIS_SCT.ed_diagnosis_type) Is Null) AND ((dbo.FACILITY.area_identifier)='"""
                    + lhd
                    + """') AND ((dbo.ED_DIAGNOSIS_SCT.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.ED_DIAGNOSIS_SCT.arrival_date) >= dateadd(day, -5, CAST('"""
                    + start_date
                    + """' AS DATE )) And (dbo.ED_DIAGNOSIS_SCT.arrival_date) <= dateadd(day, 5, CAST('"""
                    + end_date
                    + """' AS DATE )))) OR (((dbo.ED_DIAGNOSIS_SCT.facility_identifier)='"""
                    + lhd
                    + """') AND ((dbo.ED_DIAGNOSIS_SCT.ed_diagnosis_type)='D' OR (dbo.ED_DIAGNOSIS_SCT.ed_diagnosis_type)='d' Or (dbo.ED_DIAGNOSIS_SCT.ed_diagnosis_type) Is Null) AND ((dbo.ED_DIAGNOSIS_SCT.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.ED_DIAGNOSIS_SCT.arrival_date) >= dateadd(day, -5, CAST('"""
                    + start_date
                    + """' AS DATE )) And (dbo.ED_DIAGNOSIS_SCT.arrival_date) <= dateadd(day, 5, CAST('"""
                    + end_date
                    + """' AS DATE ))))) AND dbo.FACILITY.facility_identifier NOT IN ("""
                    + facilities_excluded
                    + """);"""
                )
        # elif lhd == 'X630':
        #    if 'C238' in facilities_excluded_list:
        #    else:
        else:
            if len(facilities_excluded_list) == 0:
                query_ED_Diag_Slice_2 = (
                    """SELECT dbo.ED_DIAGNOSIS_SCT.facility_identifier, dbo.ED_DIAGNOSIS_SCT.ed_visit_identifier, dbo.ED_DIAGNOSIS_SCT.ed_diagnosis_type, dbo.ED_DIAGNOSIS_SCT.ed_diagnosis_code, dbo.FACILITY.area_identifier, dbo.ED_DIAGNOSIS_SCT.code_version as clinical_codeset,'' as ed_diagnosis_type2, '' as ed_diagnosis_code2, '' as ed_diagnosis_type3, '' as ed_diagnosis_code3, '' as HLTH_ORG_OSP_OSP_ID, '' as MG_AUTH_OSP_OSP_ID, '' as SE_CBK_SK FROM dbo.ED_DIAGNOSIS_SCT INNER JOIN dbo.FACILITY ON dbo.ED_DIAGNOSIS_SCT.facility_identifier = dbo.FACILITY.facility_identifier WHERE ((((dbo.ED_DIAGNOSIS_SCT.facility_identifier)<>"Q230") AND ((dbo.ED_DIAGNOSIS_SCT.ed_diagnosis_type)='D' OR (dbo.ED_DIAGNOSIS_SCT.ed_diagnosis_type)='d' Or (dbo.ED_DIAGNOSIS_SCT.ed_diagnosis_type) Is Null) AND ((dbo.FACILITY.area_identifier)='"""
                    + lhd
                    + """') AND ((dbo.ED_DIAGNOSIS_SCT.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.ED_DIAGNOSIS_SCT.arrival_date) >= dateadd(day, -5, CAST('"""
                    + start_date
                    + """' AS DATE )) And (dbo.ED_DIAGNOSIS_SCT.arrival_date) <= dateadd(day, 5, CAST('"""
                    + end_date
                    + """' AS DATE )))) OR (((dbo.ED_DIAGNOSIS_SCT.facility_identifier)='"""
                    + lhd
                    + """') AND ((dbo.ED_DIAGNOSIS_SCT.ed_diagnosis_type)='D' OR (dbo.ED_DIAGNOSIS_SCT.ed_diagnosis_type)='d' Or (dbo.ED_DIAGNOSIS_SCT.ed_diagnosis_type) Is Null) AND ((dbo.ED_DIAGNOSIS_SCT.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.ED_DIAGNOSIS_SCT.arrival_date) >= dateadd(day, -5, CAST('"""
                    + start_date
                    + """' AS DATE )) And (dbo.ED_DIAGNOSIS_SCT.arrival_date) <= dateadd(day, 5, CAST('"""
                    + end_date
                    + """' AS DATE )))));"""
                )
            else:
                query_ED_Diag_Slice_2 = (
                    """SELECT dbo.ED_DIAGNOSIS_SCT.facility_identifier, dbo.ED_DIAGNOSIS_SCT.ed_visit_identifier, dbo.ED_DIAGNOSIS_SCT.ed_diagnosis_type, dbo.ED_DIAGNOSIS_SCT.ed_diagnosis_code, dbo.FACILITY.area_identifier, dbo.ED_DIAGNOSIS_SCT.code_version as clinical_codeset,'' as ed_diagnosis_type2, '' as ed_diagnosis_code2, '' as ed_diagnosis_type3, '' as ed_diagnosis_code3, '' as HLTH_ORG_OSP_OSP_ID, '' as MG_AUTH_OSP_OSP_ID, '' as SE_CBK_SK FROM dbo.ED_DIAGNOSIS_SCT INNER JOIN dbo.FACILITY ON dbo.ED_DIAGNOSIS_SCT.facility_identifier = dbo.FACILITY.facility_identifier WHERE ((((dbo.ED_DIAGNOSIS_SCT.facility_identifier)<>"Q230") AND ((dbo.ED_DIAGNOSIS_SCT.ed_diagnosis_type)='D' OR (dbo.ED_DIAGNOSIS_SCT.ed_diagnosis_type)='d' Or (dbo.ED_DIAGNOSIS_SCT.ed_diagnosis_type) Is Null) AND ((dbo.FACILITY.area_identifier)='"""
                    + lhd
                    + """') AND ((dbo.ED_DIAGNOSIS_SCT.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.ED_DIAGNOSIS_SCT.arrival_date) >= dateadd(day, -5, CAST('"""
                    + start_date
                    + """' AS DATE )) And (dbo.ED_DIAGNOSIS_SCT.arrival_date) <= dateadd(day, 5, CAST('"""
                    + end_date
                    + """' AS DATE )))) OR (((dbo.ED_DIAGNOSIS_SCT.facility_identifier)='"""
                    + lhd
                    + """') AND ((dbo.ED_DIAGNOSIS_SCT.ed_diagnosis_type)='D' OR (dbo.ED_DIAGNOSIS_SCT.ed_diagnosis_type)='d' Or (dbo.ED_DIAGNOSIS_SCT.ed_diagnosis_type) Is Null) AND ((dbo.ED_DIAGNOSIS_SCT.snap_curr_indicator)='Y') AND ((dbo.FACILITY.snap_curr_indicator)='Y') AND ((dbo.ED_DIAGNOSIS_SCT.arrival_date) >= dateadd(day, -5, CAST('"""
                    + start_date
                    + """' AS DATE )) And (dbo.ED_DIAGNOSIS_SCT.arrival_date) <= dateadd(day, 5, CAST('"""
                    + end_date
                    + """' AS DATE ))))) AND dbo.FACILITY.facility_identifier NOT IN ("""
                    + facilities_excluded
                    + """);"""
                )
    elif source == "EDW":
        if (
            lhd == "X700"
            or lhd == "X701"
            or lhd == "X720"
            or lhd == "X730"
            or lhd == "X740"
            or lhd == "X750"
            or lhd == "X760"
            or lhd == "X770"
            or lhd == "X810"
            or lhd == "X840"
            or lhd == "X850"
            or lhd == "X860"
            or lhd == "X710"
        ):
            if len(facilities_included_list) > 0:
                query_ED_Diag_Slice_2 = (
                    """WITH FilteredDiag AS (SELECT SE_CBK_SK, SRV_ENC_REC_ID, SUBSTRING(DIAG_CD,charindex('|',DIAG_CD)+1,15) as DIAG_CD, DIAG_TYP_CD, DIM_DT_SE_ST_SK, DIAG_SEQ_NUM FROM CRT.v_FACT_ED_SE_DIAG WHERE DIM_DT_SE_ST_SK BETWEEN DATEADD(day, -5, '"""
                    + start_date
                    + """') AND DATEADD(day, 5, '"""
                    + end_date
                    + """') AND DIM_DT_SE_ST_SK != '1111-01-01' AND SUBSTRING(DIAG_CD, 1, 5) = '10798'),DiagWithSE AS (SELECT a.*, se.DIM_OSP_CREATED_SK FROM FilteredDiag as a LEFT JOIN CRT.v_FACT_ED_SE as se ON a.SE_CBK_SK = se.SE_CBK_SK),OSPFiltered AS (SELECT DIM_OSP_SK, OSP_HIE_FAC_ID, MG_AUTH_OSP_HIE_FAC_ID, HLTH_ORG_OSP_OSP_ID,MG_AUTH_OSP_OSP_ID, HLTH_ORG_OSP_HIE_FAC_ID,case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_ID else HLTH_ORG_OSP_OSP_ID end as OSP_ID,case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09','35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_HIE_FAC_ID else HLTH_ORG_OSP_HIE_FAC_ID end as facility_identifier FROM CRT.v_DIM_OSP WHERE MG_AUTH_OSP_HLTH_SECTOR_CD IN ('1','3') AND HLTH_ORG_OSP_HLTH_SECTOR_CD IN ('1','3') AND HLTH_ORG_OSP_HIE_FAC_ID NOT IN ('-1', '')),FinalJoin AS (SELECT d.*, o.* FROM DiagWithSE as d INNER JOIN OSPFiltered as o ON d.DIM_OSP_CREATED_SK = o.DIM_OSP_SK WHERE d.DIAG_TYP_CD IN ('DD','dd','DE','DA','de','da') and (MG_AUTH_OSP_HIE_FAC_ID = '"""
                    + lhd
                    + """' or o.facility_identifier = '"""
                    + lhd
                    + """') AND o.facility_identifier IN ("""
                    + facilities_included
                    + """)) SELECT DISTINCT facility_identifier,ISNULL(SUBSTRING(SRV_ENC_REC_ID, CHARINDEX('-', SRV_ENC_REC_ID) + 1, 10), '') AS ed_visit_identifier,MAX(CASE WHEN DIAG_SEQ_NUM = 1 THEN DIAG_TYP_CD ELSE '' END) AS ed_diagnosis_type,MAX(CASE WHEN DIAG_SEQ_NUM = 1 THEN DIAG_CD ELSE '' END) AS ed_diagnosis_code,max(case when a.DIAG_SEQ_NUM = 2 then A.DIAG_TYP_CD else '' end) as ed_diagnosis_type2,max(case when a.DIAG_SEQ_NUM = 2 then A.DIAG_CD else '' end) as ed_diagnosis_code2,max(case when a.DIAG_SEQ_NUM = 3 then A.DIAG_TYP_CD else '' end) as ed_diagnosis_type3,max(case when a.DIAG_SEQ_NUM = 3 then A.DIAG_CD else '' end) as ed_diagnosis_code3,MG_AUTH_OSP_HIE_FAC_ID as area_identifier,'SNOMEDCT' AS clinical_codeset,OSP_ID as HLTH_ORG_OSP_OSP_ID, MG_AUTH_OSP_OSP_ID, SE_CBK_SK FROM FinalJoin as a GROUP BY facility_identifier, ISNULL(SUBSTRING(SRV_ENC_REC_ID, CHARINDEX('-', SRV_ENC_REC_ID) + 1, 10), ''),MG_AUTH_OSP_HIE_FAC_ID, OSP_ID, MG_AUTH_OSP_OSP_ID, SE_CBK_SK;"""
                )
        else:
            if len(facilities_included_list) > 0:
                query_ED_Diag_Slice_2 = (
                    """WITH FilteredDiag AS (SELECT SE_CBK_SK, SRV_ENC_REC_ID, SUBSTRING(DIAG_CD,charindex('|',DIAG_CD)+1,15) as DIAG_CD, DIAG_TYP_CD, DIM_DT_SE_ST_SK, DIAG_SEQ_NUM FROM CRT.v_FACT_ED_SE_DIAG WHERE DIM_DT_SE_ST_SK BETWEEN DATEADD(day, -5, '"""
                    + start_date
                    + """') AND DATEADD(day, 5, '"""
                    + end_date
                    + """') AND DIM_DT_SE_ST_SK != '1111-01-01' AND SUBSTRING(DIAG_CD, 1, 5) = '10798'),DiagWithSE AS (SELECT a.*, se.DIM_OSP_CREATED_SK FROM FilteredDiag as a LEFT JOIN CRT.v_FACT_ED_SE as se ON a.SE_CBK_SK = se.SE_CBK_SK),OSPFiltered AS (SELECT DIM_OSP_SK, OSP_HIE_FAC_ID, MG_AUTH_OSP_HIE_FAC_ID, HLTH_ORG_OSP_OSP_ID,MG_AUTH_OSP_OSP_ID, HLTH_ORG_OSP_HIE_FAC_ID,case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_ID else HLTH_ORG_OSP_OSP_ID end as OSP_ID,case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09','35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_HIE_FAC_ID else HLTH_ORG_OSP_HIE_FAC_ID end as facility_identifier FROM CRT.v_DIM_OSP WHERE MG_AUTH_OSP_HLTH_SECTOR_CD IN ('1','3') AND HLTH_ORG_OSP_HLTH_SECTOR_CD IN ('1','3') AND HLTH_ORG_OSP_HIE_FAC_ID NOT IN ('-1', '')),FinalJoin AS (SELECT d.*, o.* FROM DiagWithSE as d INNER JOIN OSPFiltered as o ON d.DIM_OSP_CREATED_SK = o.DIM_OSP_SK WHERE d.DIAG_TYP_CD IN ('DD','dd','DE','DA','de','da') and (MG_AUTH_OSP_HIE_FAC_ID = '"""
                    + lhd
                    + """' or o.facility_identifier = '"""
                    + lhd
                    + """') AND o.facility_identifier IN ("""
                    + facilities_included
                    + """)) SELECT DISTINCT facility_identifier,ISNULL(SUBSTRING(SRV_ENC_REC_ID, CHARINDEX('-', SRV_ENC_REC_ID) + 1, 10), '') AS ed_visit_identifier,MAX(CASE WHEN DIAG_SEQ_NUM = 1 THEN DIAG_TYP_CD ELSE '' END) AS ed_diagnosis_type,MAX(CASE WHEN DIAG_SEQ_NUM = 1 THEN DIAG_CD ELSE '' END) AS ed_diagnosis_code,max(case when a.DIAG_SEQ_NUM = 2 then A.DIAG_TYP_CD else '' end) as ed_diagnosis_type2,max(case when a.DIAG_SEQ_NUM = 2 then A.DIAG_CD else '' end) as ed_diagnosis_code2,max(case when a.DIAG_SEQ_NUM = 3 then A.DIAG_TYP_CD else '' end) as ed_diagnosis_type3,max(case when a.DIAG_SEQ_NUM = 3 then A.DIAG_CD else '' end) as ed_diagnosis_code3,MG_AUTH_OSP_HIE_FAC_ID as area_identifier,'SNOMEDCT' AS clinical_codeset,OSP_ID as HLTH_ORG_OSP_OSP_ID, MG_AUTH_OSP_OSP_ID, SE_CBK_SK FROM FinalJoin as a GROUP BY facility_identifier, ISNULL(SUBSTRING(SRV_ENC_REC_ID, CHARINDEX('-', SRV_ENC_REC_ID) + 1, 10), ''),MG_AUTH_OSP_HIE_FAC_ID, OSP_ID, MG_AUTH_OSP_OSP_ID, SE_CBK_SK;"""
                )
    retry_flag = True
    retry_count = 0
    while retry_flag and retry_count < 5:
        try:
            logging.info(query_ED_Diag_Slice_2)
            df_ED_Diag_Slice_2 = pd.read_sql(query_ED_Diag_Slice_2, cnxn)
            retry_flag = False
        except Exception as e:
            retry_count = retry_count + 1
            time.sleep(5)
            if retry_count == 5:
                logging.exception("Exception occurred")
                label_8_status = 0
                messagebox.showerror(
                    "SQL Error", "Error extracting ED_DIAGNOSIS_SCT details\n" + str(e)
                )
                label_8_sub.configure(text="Failed (ED_DIAGNOSIS_SCT)...", fg="red")
                main_screen.update()
                df_ED_Diag_Slice_2 = pd.DataFrame(
                    columns=[
                        "facility_identifier",
                        "ed_visit_identifier",
                        "ed_diagnosis_type",
                        "ed_diagnosis_code",
                        "area_identifier",
                        "clinical_codeset",
                        "ed_diagnosis_type2",
                        "ed_diagnosis_code2",
                        "ed_diagnosis_type3",
                        "ed_diagnosis_code3",
                        "HLTH_ORG_OSP_OSP_ID",
                        "MG_AUTH_OSP_OSP_ID",
                        "SE_CBK_SK",
                    ]
                )
                df_ED_Diag_Slice_2["EDDiag_ver"] = df_ED_Diag_Slice_2[
                    "clinical_codeset"
                ]
                return  # stop extraction
        else:
            df_ED_Diag_Slice_2 = df_ED_Diag_Slice_2[
                [
                    "facility_identifier",
                    "ed_visit_identifier",
                    "ed_diagnosis_type",
                    "ed_diagnosis_code",
                    "area_identifier",
                    "clinical_codeset",
                    "ed_diagnosis_type2",
                    "ed_diagnosis_code2",
                    "ed_diagnosis_type3",
                    "ed_diagnosis_code3",
                    "HLTH_ORG_OSP_OSP_ID",
                    "MG_AUTH_OSP_OSP_ID",
                    "SE_CBK_SK",
                ]
            ]
            df_ED_Diag_Slice_2["EDDiag_ver"] = df_ED_Diag_Slice_2["clinical_codeset"]
            df_ED_Diag_Slice_2 = df_ED_Diag_Slice_2.fillna("")
            df_ED_Diag_Slice_2 = df_ED_Diag_Slice_2.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            df_ED_Diag_Slice_2 = df_ED_Diag_Slice_2.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            df_ED_Diag_Slice_2 = df_ED_Diag_Slice_2.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            df_ED_Diag_Slice_2 = df_ED_Diag_Slice_2.apply(
                lambda x: x.replace(regex=r"NULL", value="")
                if x.dtype == "object"
                else x
            )
            df_ED_Diag_Slice_2 = df_ED_Diag_Slice_2.apply(
                lambda x: x.replace(regex=r"null", value="")
                if x.dtype == "object"
                else x
            )
            df_ED_Diag_Slice_2 = df_ED_Diag_Slice_2.apply(
                lambda x: x.replace(regex=r"Null", value="")
                if x.dtype == "object"
                else x
            )
            df_ED_Diag_Slice_2 = df_ED_Diag_Slice_2[
                df_ED_Diag_Slice_2["area_identifier"] == lhd_global
            ]
            df_ED_Diag_Slice_2 = df_ED_Diag_Slice_2[
                df_ED_Diag_Slice_2["facility_identifier"].isin(
                    facilities_included_list_global
                )
            ]
            # dropping duplicate values
            df_ED_Diag_Slice_2.drop_duplicates(keep="last", inplace=True)
            logging.info("df_ED_Diag_Slice_2=%s", len(df_ED_Diag_Slice_2))
            df_ED_Diag_Slice_2.to_csv(
                "./ExtractorDB/ED_Diag_Slice_2.csv",
                index=False,
                na_rep="",
                float_format=str,
                decimal=str,
                date_format=str,
            )
    if len(df_ED_Diag_Slice_1) > 0 and len(df_ED_Diag_Slice_2) > 0:
        # concatenating df1 and df2 along rows
        df_ED_Diag_Slice = pd.concat([df_ED_Diag_Slice_1, df_ED_Diag_Slice_2], axis=0)
    elif len(df_ED_Diag_Slice_1) > 0 and len(df_ED_Diag_Slice_2) == 0:
        df_ED_Diag_Slice = df_ED_Diag_Slice_1.copy()
    elif len(df_ED_Diag_Slice_1) == 0 and len(df_ED_Diag_Slice_2) > 0:
        df_ED_Diag_Slice = df_ED_Diag_Slice_2.copy()
    else:
        df_ED_Diag_Slice = pd.DataFrame(
            columns=[
                "facility_identifier",
                "ed_visit_identifier",
                "ed_diagnosis_type",
                "ed_diagnosis_code",
                "area_identifier",
                "clinical_codeset",
                "ed_diagnosis_type2",
                "ed_diagnosis_code2",
                "ed_diagnosis_type3",
                "ed_diagnosis_code3",
                "HLTH_ORG_OSP_OSP_ID",
                "MG_AUTH_OSP_OSP_ID",
                "SE_CBK_SK",
                "EDDiag_ver",
            ]
        )
    # Drop duplicates
    df_ED_Diag_Slice.drop_duplicates(keep="last", inplace=True)
    df_ED_Diag_Slice = df_ED_Diag_Slice[df_ED_Diag_Slice["area_identifier"] == lhd]
    df_ED_Diag_Slice = df_ED_Diag_Slice.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    df_ED_Diag_Slice = df_ED_Diag_Slice.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    df_ED_Diag_Slice = df_ED_Diag_Slice.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    df_ED_Diag_Slice = df_ED_Diag_Slice.apply(
        lambda x: x.replace(regex=r"NULL", value="") if x.dtype == "object" else x
    )
    df_ED_Diag_Slice = df_ED_Diag_Slice.apply(
        lambda x: x.replace(regex=r"null", value="") if x.dtype == "object" else x
    )
    df_ED_Diag_Slice = df_ED_Diag_Slice.apply(
        lambda x: x.replace(regex=r"Null", value="") if x.dtype == "object" else x
    )
    # dropping duplicate values
    df_ED_Diag_Slice.drop_duplicates(keep="last", inplace=True)
    df_ED_Diag_Slice.to_csv(
        "./ExtractorDB/ED_Diag_Slice.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    logging.info("df_ED_Diag_Slice=%s", len(df_ED_Diag_Slice))
    # qry_Diag_SCT
    # Access query: qry_Diag_SCT
    # INSERT INTO SNOMED_Update ( facility_identifier, ed_visit_identifier, arrival_date, [P Diag], [D Diag] )
    # SELECT dbo_ED_DIAGNOSIS_SCT.facility_identifier, dbo_ED_DIAGNOSIS_SCT.ed_visit_identifier, dbo_ED_DIAGNOSIS_SCT.arrival_date, Max(IIf([dbo_ED_DIAGNOSIS_SCT]![ed_diagnosis_type]="P",[dbo_ED_DIAGNOSIS_SCT]![ed_diagnosis_code])) AS [P Diag], Max(IIf([dbo_ED_DIAGNOSIS_SCT]![ed_diagnosis_type]="D",[dbo_ED_DIAGNOSIS_SCT]![ed_diagnosis_code])) AS [D Diag]
    # FROM dbo_ED_DIAGNOSIS_SCT
    # WHERE (((dbo_ED_DIAGNOSIS_SCT.snap_curr_indicator)="Y"))
    # GROUP BY dbo_ED_DIAGNOSIS_SCT.facility_identifier, dbo_ED_DIAGNOSIS_SCT.ed_visit_identifier, dbo_ED_DIAGNOSIS_SCT.arrival_date
    # HAVING (((dbo_ED_DIAGNOSIS_SCT.arrival_date)>#6/20/2022#));
    # if str(roundid) in aecc_round_id_list_OLD:
    if str(roundid) in aecc_round_id_list:
        label_8_sub.configure(text="In Progress (qry_Diag_SCT)...", fg="blue")
        main_screen.update()
        if len(df_ED_Diag_Slice_2) > 1:
            snomed_Update = df_ED_Diag_Slice_2.copy()
            snomed_Update["arrival_date"] = ""
            snomed_Update["P_Diag"] = snomed_Update["ed_diagnosis_code"]
            snomed_Update["D_Diag"] = snomed_Update["ed_diagnosis_code"]
            snomed_Update = snomed_Update[
                [
                    "facility_identifier",
                    "ed_visit_identifier",
                    "arrival_date",
                    "P_Diag",
                    "D_Diag",
                ]
            ]
        else:
            snomed_Update = pd.DataFrame(
                columns=[
                    "facility_identifier",
                    "ed_visit_identifier",
                    "arrival_date",
                    "P_Diag",
                    "D_Diag",
                ]
            )
    else:
        snomed_Update = pd.DataFrame(
            columns=[
                "facility_identifier",
                "ed_visit_identifier",
                "arrival_date",
                "P_Diag",
                "D_Diag",
            ]
        )
    # dropping duplicate values
    snomed_Update.drop_duplicates(keep="last", inplace=True)
    snomed_Update.to_csv(
        "./ExtractorDB/snomed_Update.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    logging.info("snomed_Update=%s", len(snomed_Update))
    # AECC
    # Access query: qry_AECC
    # INSERT INTO AECC ( facility_identifier, ed_visit_identifier, arrival_date, aecc_end_class, aecc_version, nwau_version, nwau_final, nwau_type, nwau_base, compensable_nwau, indigenous_adj )
    # SELECT dbo_ED_NWAU_AECC.facility_identifier, "ED" & [dbo_ed_nwau]![ed_visit_identifier] AS ed_visit_identifier, dbo_ED_NWAU_AECC.arrival_date, dbo_ED_NWAU_AECC.aecc_end_class, dbo_ED_NWAU_AECC.aecc_version, dbo_ED_NWAU_AECC.nwau_version, Round([dbo_ED_NWAU]![nwau_final],4) AS nwau_final, dbo_ED_NWAU.nwau_type, Round([dbo_ED_NWAU]![nwau_base],4) AS nwau_base, Round([dbo_ED_NWAU]![compensable_nwau],4) AS compensable_nwau, Round([dbo_ED_NWAU]![indigenous_adj],4) AS indigenous_adj
    # FROM dbo_ED_NWAU INNER JOIN dbo_ED_NWAU_AECC ON (dbo_ED_NWAU_AECC.nwau_version = dbo_ED_NWAU.nwau_version) AND (dbo_ED_NWAU.ed_visit_identifier = dbo_ED_NWAU_AECC.ed_visit_identifier) AND (dbo_ED_NWAU.facility_identifier = dbo_ED_NWAU_AECC.facility_identifier)
    # WHERE (((dbo_ED_NWAU_AECC.arrival_date) Between #6/15/2022# And #6/30/2023#) AND ((dbo_ED_NWAU_AECC.nwau_version)=[Forms]![Form1]![NWAUVersion]) AND ((dbo_ED_NWAU.nwau_type)="AECC") AND ((dbo_ED_NWAU.snap_curr_indicator)="Y") AND ((dbo_ED_NWAU_AECC.snap_curr_indicator)="Y"));
    if str(roundid) in aecc_round_id_list:
        label_8_sub.configure(text="In Progress (AECC)...", fg="blue")
        main_screen.update()
        aecc = ed_nwau.copy()
        aecc["aecc_end_class"] = aecc["AECC"]
        aecc["aecc_version"] = "1.0"
        aecc["nwau_type"] = "AECC"
        aecc["ed_visit_identifier"] = (
            "ED" + aecc["ed_visit_identifier"].astype(str).str.strip()
        )
        aecc = aecc[
            [
                "facility_identifier",
                "ed_visit_identifier",
                "arrival_date",
                "aecc_end_class",
                "aecc_version",
                "nwau_version",
                "nwau_final",
                "nwau_type",
                "nwau_base",
                "compensable_nwau",
                "indigenous_adj",
                "HLTH_ORG_OSP_OSP_ID",
                "MG_AUTH_OSP_OSP_ID",
                "SE_CBK_SK",
            ]
        ]
    else:
        # aecc = pd.DataFrame(columns=['facility_identifier', 'ed_visit_identifier', 'arrival_date', 'aecc_end_class', 'aecc_version', 'nwau_version', 'nwau_final', 'nwau_type', 'nwau_base', 'compensable_nwau', 'indigenous_adj', 'HLTH_ORG_OSP_OSP_ID', 'MG_AUTH_OSP_OSP_ID', 'SE_CBK_SK', 'NWAU_DIAG_CD'])
        aecc = pd.DataFrame(
            columns=[
                "facility_identifier",
                "ed_visit_identifier",
                "arrival_date",
                "aecc_end_class",
                "aecc_version",
                "nwau_version",
                "nwau_final",
                "nwau_type",
                "nwau_base",
                "compensable_nwau",
                "indigenous_adj",
                "HLTH_ORG_OSP_OSP_ID",
                "MG_AUTH_OSP_OSP_ID",
                "SE_CBK_SK",
            ]
        )
    # dropping duplicate values
    aecc.drop_duplicates(keep="last", inplace=True)
    aecc.to_csv(
        "./ExtractorDB/aecc.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    logging.info("aecc=%s", len(aecc))
    # OutputExcludedEncounters
    # columns = facility_identifier,stay_number,episode_sequence_number,ed_identifier,SNAP_encounter,ReasonForExclusion,EncounterNumber
    # Access query = ED Exclusions
    # SELECT dbo_ED_VISIT.ed_visit_identifier, dbo_ED_VISIT.facility_identifier, IIf([dbo_ED_VISIT]![facility_identifier]="D311","D311 Contracted Hospital","Mode of Sep 99 Adminstrative Error") AS Expr1 FROM (dbo_ED_VISIT INNER JOIN dbo_FACILITY ON dbo_ED_VISIT.facility_identifier = dbo_FACILITY.facility_identifier) LEFT JOIN dbo_SLA_AREA ON dbo_ED_VISIT.area_of_usual_residence = dbo_SLA_AREA.sla_code GROUP BY dbo_ED_VISIT.ed_visit_identifier, dbo_ED_VISIT.facility_identifier, IIf([dbo_ED_VISIT]![facility_identifier]="D311","D311 Contracted Hospital","Mode of Sep 99 Adminstrative Error"), dbo_ED_VISIT.mode_of_separation, dbo_ED_VISIT.arrival_date, dbo_ED_VISIT.actual_departure_date, dbo_ED_VISIT.departure_ready_date, dbo_ED_VISIT.snap_curr_indicator, dbo_FACILITY.area_identifier, dbo_FACILITY.snap_curr_indicator, dbo_SLA_AREA.current_flag, dbo_SLA_AREA.snap_curr_indicator
    label_8_sub.configure(text="In Progress (ExcludedEncounters)...", fg="blue")
    main_screen.update()
    if source == "HIE":
        if len(facilities_excluded_list) == 0:
            query_Excluded_ED_Encounters = (
                """SELECT  dbo.ED_VISIT.facility_identifier,  'XXXXXXXX' as stay_number, 0 AS episode_sequence_number, dbo.ED_VISIT.ed_visit_identifier as ed_identifier, 'XXXX_XXXXXXXX' AS SNAP_encounter, (CASE WHEN dbo.ED_VISIT.facility_identifier = "D311" THEN "D311 Contracted Hospital" ELSE "Mode of Sep 99 Adminstrative Error" end) AS ReasonForExclusion, (TRIM(STRING(dbo.ED_VISIT.facility_identifier)) + "-E-" +  RIGHT(TRIM(STRING('00000000', dbo.ED_VISIT.ed_visit_identifier)),8)) AS EncounterNumber, '' AS EDW_Enc_Number, '' as HLTH_ORG_OSP_OSP_ID, '' as MG_AUTH_OSP_OSP_ID, '' as SE_CBK_SK, '' as CL_ID_EUID, '' AS CL_ID_IHI  FROM (dbo.ED_VISIT INNER JOIN dbo.FACILITY ON dbo.ED_VISIT.facility_identifier = dbo.FACILITY.facility_identifier) LEFT JOIN dbo.SLA_AREA ON dbo.ED_VISIT.area_of_usual_residence = dbo.SLA_AREA.sla_code GROUP BY dbo.ED_VISIT.ed_visit_identifier, (CASE WHEN dbo.ED_VISIT.facility_identifier = "D311" THEN "D311 Contracted Hospital" ELSE "Mode of Sep 99 Adminstrative Error" end), dbo.ED_VISIT.patient_postcode, dbo.ED_VISIT.area_of_usual_residence, dbo.ED_VISIT.mrn, dbo.ED_VISIT.facility_identifier, dbo.ED_VISIT.actual_departure_time, dbo.ED_VISIT.arrival_time, dbo.ED_VISIT.age, dbo.ED_VISIT.udg_weight, dbo.ED_VISIT.triage_category, dbo.ED_VISIT.mode_of_arrival, dbo.ED_VISIT.ed_visit_type, dbo.ED_VISIT.mode_of_separation, dbo.ED_VISIT.triage_time, dbo.ED_VISIT.ed_source_of_referral, dbo.ED_VISIT.indigenous_status, dbo.ED_VISIT.medicare_number, dbo.ED_VISIT.person_area_uid, dbo.ED_VISIT.snap_from_date, dbo.ED_VISIT.first_seen_clinician_time, dbo.ED_VISIT.first_seen_nurse_time, dbo.ED_VISIT.departure_ready_time, dbo.ED_VISIT.compensable_status, dbo.ED_VISIT.udg_urgency, dbo.ED_VISIT.udg_disposition, dbo.SLA_AREA.area_identifier, dbo.ED_VISIT.arrival_date, dbo.ED_VISIT.actual_departure_date, dbo.ED_VISIT.departure_ready_date, dbo.ED_VISIT.snap_curr_indicator, dbo.FACILITY.area_identifier, dbo.FACILITY.snap_curr_indicator, dbo.SLA_AREA.current_flag, dbo.SLA_AREA.snap_curr_indicator 
            HAVING (((dbo.ED_VISIT.facility_identifier)="D311") AND ((dbo.ED_VISIT.arrival_date)<=('"""
                + end_date
                + """')) AND ((dbo.ED_VISIT.actual_departure_date)>=('"""
                + start_date
                + """') And (dbo.ED_VISIT.actual_departure_date)<=('"""
                + end_date
                + """')) AND ((dbo.ED_VISIT.snap_curr_indicator)="Y") AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.FACILITY.snap_curr_indicator)="Y") AND ((dbo.SLA_AREA.current_flag)="Y" Or (dbo.SLA_AREA.current_flag) Is Null) AND ((dbo.SLA_AREA.snap_curr_indicator)="Y" Or (dbo.SLA_AREA.snap_curr_indicator) Is Null)) OR 
            (((dbo.ED_VISIT.facility_identifier)="D311") AND ((dbo.ED_VISIT.arrival_date)>=('"""
                + start_date
                + """') And (dbo.ED_VISIT.arrival_date)<=('"""
                + end_date
                + """')) AND ((dbo.ED_VISIT.actual_departure_date) Is Null Or (dbo.ED_VISIT.actual_departure_date)>=('"""
                + start_date
                + """')) AND ((dbo.ED_VISIT.departure_ready_date)>='"""
                + start_date
                + """') AND ((dbo.ED_VISIT.snap_curr_indicator)="Y") AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.FACILITY.snap_curr_indicator)="Y") AND ((dbo.SLA_AREA.current_flag)="Y" Or (dbo.SLA_AREA.current_flag) Is Null) AND ((dbo.SLA_AREA.snap_curr_indicator)="Y" Or (dbo.SLA_AREA.snap_curr_indicator) Is Null)) OR 
            (((dbo.ED_VISIT.facility_identifier)<>"Q230") AND ((dbo.ED_VISIT.mode_of_separation)="99") AND ((dbo.ED_VISIT.arrival_date)<=('"""
                + end_date
                + """')) AND ((dbo.ED_VISIT.actual_departure_date)>=('"""
                + start_date
                + """') And (dbo.ED_VISIT.actual_departure_date)<=('"""
                + end_date
                + """')) AND ((dbo.ED_VISIT.snap_curr_indicator)="Y") AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.FACILITY.snap_curr_indicator)="Y") AND ((dbo.SLA_AREA.current_flag)="Y" Or (dbo.SLA_AREA.current_flag) Is Null) AND ((dbo.SLA_AREA.snap_curr_indicator)="Y" Or (dbo.SLA_AREA.snap_curr_indicator) Is Null)) OR 
            (((dbo.ED_VISIT.facility_identifier)<>"Q230") AND ((dbo.ED_VISIT.mode_of_separation)="99") AND ((dbo.ED_VISIT.arrival_date)>=('"""
                + start_date
                + """') And (dbo.ED_VISIT.arrival_date)<=('"""
                + end_date
                + """')) AND ((dbo.ED_VISIT.actual_departure_date) Is Null Or (dbo.ED_VISIT.actual_departure_date)>=('"""
                + start_date
                + """')) AND ((dbo.ED_VISIT.departure_ready_date)>='"""
                + start_date
                + """') AND ((dbo.ED_VISIT.snap_curr_indicator)="Y") AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.FACILITY.snap_curr_indicator)="Y") AND ((dbo.SLA_AREA.current_flag)="Y" Or (dbo.SLA_AREA.current_flag) Is Null) AND ((dbo.SLA_AREA.snap_curr_indicator)="Y" Or (dbo.SLA_AREA.snap_curr_indicator) Is Null)) OR 
            (((dbo.ED_VISIT.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.ED_VISIT.mode_of_separation)="99") AND ((dbo.ED_VISIT.arrival_date)<=('"""
                + end_date
                + """')) AND ((dbo.ED_VISIT.actual_departure_date)>=('"""
                + start_date
                + """') And (dbo.ED_VISIT.actual_departure_date)<=('"""
                + end_date
                + """')) AND ((dbo.ED_VISIT.snap_curr_indicator)="Y") AND ((dbo.FACILITY.snap_curr_indicator)="Y") AND ((dbo.SLA_AREA.current_flag)="Y" Or (dbo.SLA_AREA.current_flag) Is Null) AND ((dbo.SLA_AREA.snap_curr_indicator)="Y" Or (dbo.SLA_AREA.snap_curr_indicator) Is Null)) OR 
            (((dbo.ED_VISIT.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.ED_VISIT.mode_of_separation)="99") AND ((dbo.ED_VISIT.arrival_date)>=('"""
                + start_date
                + """') And (dbo.ED_VISIT.arrival_date)<=('"""
                + end_date
                + """')) AND ((dbo.ED_VISIT.actual_departure_date) Is Null Or (dbo.ED_VISIT.actual_departure_date)>=('"""
                + start_date
                + """')) AND ((dbo.ED_VISIT.departure_ready_date)>='"""
                + start_date
                + """') AND ((dbo.ED_VISIT.snap_curr_indicator)="Y") AND ((dbo.FACILITY.snap_curr_indicator)="Y") AND ((dbo.SLA_AREA.current_flag)="Y" Or (dbo.SLA_AREA.current_flag) Is Null) AND ((dbo.SLA_AREA.snap_curr_indicator)="Y" Or (dbo.SLA_AREA.snap_curr_indicator) Is Null));"""
            )
        else:
            query_Excluded_ED_Encounters = (
                """SELECT  dbo.ED_VISIT.facility_identifier,  'XXXXXXXX' as stay_number, 0 AS episode_sequence_number, dbo.ED_VISIT.ed_visit_identifier as ed_identifier, 'XXXX_XXXXXXXX' AS SNAP_encounter, (CASE WHEN dbo.ED_VISIT.facility_identifier = "D311" THEN "D311 Contracted Hospital" ELSE "Mode of Sep 99 Adminstrative Error" end) AS ReasonForExclusion, (TRIM(STRING(dbo.ED_VISIT.facility_identifier)) + "-E-" +  RIGHT(TRIM(STRING('00000000', dbo.ED_VISIT.ed_visit_identifier)),8)) AS EncounterNumber, '' AS EDW_Enc_Number, '' as HLTH_ORG_OSP_OSP_ID, '' as MG_AUTH_OSP_OSP_ID, '' as SE_CBK_SK, '' as CL_ID_EUID, '' AS CL_ID_IHI  FROM (dbo.ED_VISIT INNER JOIN dbo.FACILITY ON dbo.ED_VISIT.facility_identifier = dbo.FACILITY.facility_identifier) LEFT JOIN dbo.SLA_AREA ON dbo.ED_VISIT.area_of_usual_residence = dbo.SLA_AREA.sla_code WHERE dbo.FACILITY.facility_identifier NOT IN ("""
                + facilities_excluded
                + """) GROUP BY dbo.ED_VISIT.ed_visit_identifier, (CASE WHEN dbo.ED_VISIT.facility_identifier = "D311" THEN "D311 Contracted Hospital" ELSE "Mode of Sep 99 Adminstrative Error" end), dbo.ED_VISIT.patient_postcode, dbo.ED_VISIT.area_of_usual_residence, dbo.ED_VISIT.mrn, dbo.ED_VISIT.facility_identifier, dbo.ED_VISIT.actual_departure_time, dbo.ED_VISIT.arrival_time, dbo.ED_VISIT.age, dbo.ED_VISIT.udg_weight, dbo.ED_VISIT.triage_category, dbo.ED_VISIT.mode_of_arrival, dbo.ED_VISIT.ed_visit_type, dbo.ED_VISIT.mode_of_separation, dbo.ED_VISIT.triage_time, dbo.ED_VISIT.ed_source_of_referral, dbo.ED_VISIT.indigenous_status, dbo.ED_VISIT.medicare_number, dbo.ED_VISIT.person_area_uid, dbo.ED_VISIT.snap_from_date, dbo.ED_VISIT.first_seen_clinician_time, dbo.ED_VISIT.first_seen_nurse_time, dbo.ED_VISIT.departure_ready_time, dbo.ED_VISIT.compensable_status, dbo.ED_VISIT.udg_urgency, dbo.ED_VISIT.udg_disposition, dbo.SLA_AREA.area_identifier, dbo.ED_VISIT.arrival_date, dbo.ED_VISIT.actual_departure_date, dbo.ED_VISIT.departure_ready_date, dbo.ED_VISIT.snap_curr_indicator, dbo.FACILITY.area_identifier, dbo.FACILITY.snap_curr_indicator, dbo.SLA_AREA.current_flag, dbo.SLA_AREA.snap_curr_indicator 
            HAVING (((dbo.ED_VISIT.facility_identifier)="D311") AND ((dbo.ED_VISIT.arrival_date)<=('"""
                + end_date
                + """')) AND ((dbo.ED_VISIT.actual_departure_date)>=('"""
                + start_date
                + """') And (dbo.ED_VISIT.actual_departure_date)<=('"""
                + end_date
                + """')) AND ((dbo.ED_VISIT.snap_curr_indicator)="Y") AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.FACILITY.snap_curr_indicator)="Y") AND ((dbo.SLA_AREA.current_flag)="Y" Or (dbo.SLA_AREA.current_flag) Is Null) AND ((dbo.SLA_AREA.snap_curr_indicator)="Y" Or (dbo.SLA_AREA.snap_curr_indicator) Is Null)) OR 
            (((dbo.ED_VISIT.facility_identifier)="D311") AND ((dbo.ED_VISIT.arrival_date)>=('"""
                + start_date
                + """') And (dbo.ED_VISIT.arrival_date)<=('"""
                + end_date
                + """')) AND ((dbo.ED_VISIT.actual_departure_date) Is Null Or (dbo.ED_VISIT.actual_departure_date)>=('"""
                + start_date
                + """')) AND ((dbo.ED_VISIT.departure_ready_date)>='"""
                + start_date
                + """') AND ((dbo.ED_VISIT.snap_curr_indicator)="Y") AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.FACILITY.snap_curr_indicator)="Y") AND ((dbo.SLA_AREA.current_flag)="Y" Or (dbo.SLA_AREA.current_flag) Is Null) AND ((dbo.SLA_AREA.snap_curr_indicator)="Y" Or (dbo.SLA_AREA.snap_curr_indicator) Is Null)) OR 
            (((dbo.ED_VISIT.facility_identifier)<>"Q230") AND ((dbo.ED_VISIT.mode_of_separation)="99") AND ((dbo.ED_VISIT.arrival_date)<=('"""
                + end_date
                + """')) AND ((dbo.ED_VISIT.actual_departure_date)>=('"""
                + start_date
                + """') And (dbo.ED_VISIT.actual_departure_date)<=('"""
                + end_date
                + """')) AND ((dbo.ED_VISIT.snap_curr_indicator)="Y") AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.FACILITY.snap_curr_indicator)="Y") AND ((dbo.SLA_AREA.current_flag)="Y" Or (dbo.SLA_AREA.current_flag) Is Null) AND ((dbo.SLA_AREA.snap_curr_indicator)="Y" Or (dbo.SLA_AREA.snap_curr_indicator) Is Null)) OR 
            (((dbo.ED_VISIT.facility_identifier)<>"Q230") AND ((dbo.ED_VISIT.mode_of_separation)="99") AND ((dbo.ED_VISIT.arrival_date)>=('"""
                + start_date
                + """') And (dbo.ED_VISIT.arrival_date)<=('"""
                + end_date
                + """')) AND ((dbo.ED_VISIT.actual_departure_date) Is Null Or (dbo.ED_VISIT.actual_departure_date)>=('"""
                + start_date
                + """')) AND ((dbo.ED_VISIT.departure_ready_date)>='"""
                + start_date
                + """') AND ((dbo.ED_VISIT.snap_curr_indicator)="Y") AND ((dbo.FACILITY.area_identifier)='"""
                + lhd
                + """') AND ((dbo.FACILITY.snap_curr_indicator)="Y") AND ((dbo.SLA_AREA.current_flag)="Y" Or (dbo.SLA_AREA.current_flag) Is Null) AND ((dbo.SLA_AREA.snap_curr_indicator)="Y" Or (dbo.SLA_AREA.snap_curr_indicator) Is Null)) OR 
            (((dbo.ED_VISIT.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.ED_VISIT.mode_of_separation)="99") AND ((dbo.ED_VISIT.arrival_date)<=('"""
                + end_date
                + """')) AND ((dbo.ED_VISIT.actual_departure_date)>=('"""
                + start_date
                + """') And (dbo.ED_VISIT.actual_departure_date)<=('"""
                + end_date
                + """')) AND ((dbo.ED_VISIT.snap_curr_indicator)="Y") AND ((dbo.FACILITY.snap_curr_indicator)="Y") AND ((dbo.SLA_AREA.current_flag)="Y" Or (dbo.SLA_AREA.current_flag) Is Null) AND ((dbo.SLA_AREA.snap_curr_indicator)="Y" Or (dbo.SLA_AREA.snap_curr_indicator) Is Null)) OR 
            (((dbo.ED_VISIT.facility_identifier)='"""
                + lhd
                + """') AND ((dbo.ED_VISIT.mode_of_separation)="99") AND ((dbo.ED_VISIT.arrival_date)>=('"""
                + start_date
                + """') And (dbo.ED_VISIT.arrival_date)<=('"""
                + end_date
                + """')) AND ((dbo.ED_VISIT.actual_departure_date) Is Null Or (dbo.ED_VISIT.actual_departure_date)>=('"""
                + start_date
                + """')) AND ((dbo.ED_VISIT.departure_ready_date)>='"""
                + start_date
                + """') AND ((dbo.ED_VISIT.snap_curr_indicator)="Y") AND ((dbo.FACILITY.snap_curr_indicator)="Y") AND ((dbo.SLA_AREA.current_flag)="Y" Or (dbo.SLA_AREA.current_flag) Is Null) AND ((dbo.SLA_AREA.snap_curr_indicator)="Y" Or (dbo.SLA_AREA.snap_curr_indicator) Is Null));"""
            )
    elif source == "EDW":
        if len(facilities_included_list) > 0:
            query_Excluded_ED_Encounters = (
                """SELECT DISTINCT C.facility_identifier, 'XXXXXXXX' as stay_number, 0 as episode_sequence_number
			,ISNULL(SUBSTRING(A.SRV_ENC_REC_ID,charindex('-',A.SRV_ENC_REC_ID)+1,10),'') as ed_identifier, 'XXXX_XXXXXXXX' as SNAP_encounter, 'Mode of Sep 99 Adminstrative Error' as ReasonForExclusion, (TRIM((C.facility_identifier)) + '-E-' +  RIGHT(CONCAT('0000000000',ISNULL(SUBSTRING(A.SRV_ENC_REC_ID,charindex('-',A.SRV_ENC_REC_ID)+1,10),'')),10)) as EncounterNumber, (TRIM((C.HLTH_ORG_OSP_OSP_ID)) + '-E-' +  RIGHT(CONCAT('0000000000',ISNULL(SUBSTRING(A.SRV_ENC_REC_ID,charindex('-',A.SRV_ENC_REC_ID)+1,10),'')),10)) AS EDW_Enc_Number,C.OSP_ID as HLTH_ORG_OSP_OSP_ID,C.MG_AUTH_OSP_OSP_ID,A.SE_CBK_SK,A.CL_ID_EUID,A.CL_ID_IHI FROM CRT.v_FACT_ED_SE_FLAT as a INNER JOIN (
			SELECT DISTINCT DIM_OSP_SK, OSP_HIE_FAC_ID,HLTH_ORG_OSP_OSP_ID, MG_AUTH_OSP_HLTH_SECTOR_CD, HLTH_ORG_OSP_HLTH_SECTOR_CD, OSP_TYP_CD,HLTH_ORG_OSP_HIE_FAC_ID, MG_AUTH_OSP_HIE_FAC_ID, MG_AUTH_OSP_OSP_ID,case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_ID else HLTH_ORG_OSP_OSP_ID end as OSP_ID,case when OSP_TYP_CD in ('35.01', '35.02', '35.03', '35.04', '35.05', '35.06', '35.09', '35.10','10.02','10.08','10.03','2.08','02.08','10.07') AND OSP_HIE_FAC_ID != '-1' AND OSP_HIE_FAC_ID != '' then OSP_HIE_FAC_ID else HLTH_ORG_OSP_HIE_FAC_ID end as facility_identifier FROM CRT.v_DIM_OSP WHERE HLTH_ORG_OSP_HIE_FAC_ID != '-1' AND HLTH_ORG_OSP_HIE_FAC_ID != '' AND ((MG_AUTH_OSP_HLTH_SECTOR_CD IN ('1','3')) and (HLTH_ORG_OSP_HLTH_SECTOR_CD IN ('1','3')))) AS C ON A.DIM_OSP_CREATED_SK = C.DIM_OSP_SK WHERE (C.Facility_identifier) IN ("""
                + facilities_included
                + """) GROUP BY OSP_TYP_CD,HLTH_ORG_OSP_HIE_FAC_ID,ISNULL(SUBSTRING(A.SRV_ENC_REC_ID,charindex('-',A.SRV_ENC_REC_ID)+1,10),''),A.CLN_POSTCODE,A.CLN_SUBURB_LOCITY,A.MRN,C.facility_identifier,A.CL_DEP_DTTM, CAST(A.CL_DEP_DTTM as time(0)), CAST(A.CL_ARR_DTTM as time(0)),A.AGE_AT_ST_YRS,A.ED_TRIAGE,A.CL_MOA_CD,A.ED_VISIT_TYP_CD,A.ED_MOS_CD,CAST(A.SB_E_FST_TRIAGE_DTTM as time(0)),A.SE_REQ_SRC_TYP_CD,A.CL_INDIGENOUS_STAT_CD
			,A.CL_ID_AUID, CAST(A.SB_E_FST_DOC_SEEN_DTTM as time(0)), CAST(A.SB_E_FST_NRS_PRAC_SN_DTTM as time(0)), CAST(A.SB_E_FST_PT_DEP_RDY_DTTM as time(0))
			, coalesce(A.FST_FIN_CLASS_CD,A.FST_BILL_CATEGORY_CD), C.MG_AUTH_OSP_HIE_FAC_ID, CAST(A.CL_ARR_DTTM as date), CAST(A.CL_DEP_DTTM as date)
			, CAST(A.SB_E_FST_PT_DEP_RDY_DTTM as date), C.MG_AUTH_OSP_HLTH_SECTOR_CD, C.HLTH_ORG_OSP_HLTH_SECTOR_CD, C.HLTH_ORG_OSP_OSP_ID,C.OSP_ID,C.MG_AUTH_OSP_OSP_ID
			,A.SE_CBK_SK,A.CL_ID_EUID,A.CL_ID_IHI HAVING (((A.ED_MOS_CD='98') AND (CAST(A.CL_ARR_DTTM AS DATE)<=('"""
                + end_date
                + """')) AND (CAST(A.CL_DEP_DTTM AS DATE)>=('"""
                + start_date
                + """') And CAST(A.CL_DEP_DTTM AS DATE)<=('"""
                + end_date
                + """')) AND (C.MG_AUTH_OSP_HIE_FAC_ID ='"""
                + lhd
                + """' OR (C.facility_identifier)='"""
                + lhd
                + """')) OR (((A.ED_MOS_CD)='98') AND (CAST(A.CL_ARR_DTTM AS DATE)>=('"""
                + start_date
                + """') And CAST(A.CL_ARR_DTTM AS DATE)<=('"""
                + end_date
                + """')) AND (A.CL_DEP_DTTM Is Null Or CAST(A.CL_DEP_DTTM AS DATE)>=('"""
                + start_date
                + """')) AND (CAST(A.SB_E_FST_PT_DEP_RDY_DTTM AS DATE)>='"""
                + start_date
                + """') AND (C.MG_AUTH_OSP_HIE_FAC_ID ='"""
                + lhd
                + """' OR (C.facility_identifier)='"""
                + lhd
                + """')));"""
            )
    retry_flag = True
    retry_count = 0
    while retry_flag and retry_count < 5:
        try:
            logging.info(query_Excluded_ED_Encounters)
            df_Excluded_ED_Encounters = pd.read_sql(query_Excluded_ED_Encounters, cnxn)
            retry_flag = False
        except Exception as e:
            retry_count = retry_count + 1
            time.sleep(5)
            if retry_count == 5:
                logging.exception("Exception occurred")
                label_8_status = 0
                messagebox.showerror(
                    "SQL Error",
                    "Error extracting Excluded ED Encounters details\n" + str(e),
                )
                label_8_sub.configure(
                    text="Failed (Excluded ED Encounters)...", fg="red"
                )
                main_screen.update()
                df_Excluded_ED_Encounters = pd.DataFrame(
                    columns=[
                        "facility_identifier",
                        "stay_number",
                        "episode_sequence_number",
                        "ed_identifier",
                        "SNAP_encounter",
                        "ReasonForExclusion",
                        "EncounterNumber",
                        "EDW_Enc_Number",
                        "HLTH_ORG_OSP_OSP_ID",
                        "MG_AUTH_OSP_OSP_ID",
                        "SE_CBK_SK",
                        "CL_ID_EUID",
                        "CL_ID_IHI",
                    ]
                )
                return  # stop extraction
        else:
            df_Excluded_ED_Encounters = df_Excluded_ED_Encounters.fillna("")
            df_Excluded_ED_Encounters = df_Excluded_ED_Encounters[
                [
                    "facility_identifier",
                    "stay_number",
                    "episode_sequence_number",
                    "ed_identifier",
                    "SNAP_encounter",
                    "ReasonForExclusion",
                    "EncounterNumber",
                    "EDW_Enc_Number",
                    "HLTH_ORG_OSP_OSP_ID",
                    "MG_AUTH_OSP_OSP_ID",
                    "SE_CBK_SK",
                    "CL_ID_EUID",
                    "CL_ID_IHI",
                ]
            ]
            df_Excluded_ED_Encounters = df_Excluded_ED_Encounters[
                df_Excluded_ED_Encounters["facility_identifier"].isin(
                    facilities_included_list_global
                )
            ]
            df_Excluded_ED_Encounters = df_Excluded_ED_Encounters.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            df_Excluded_ED_Encounters = df_Excluded_ED_Encounters.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            df_Excluded_ED_Encounters = df_Excluded_ED_Encounters.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            df_Excluded_ED_Encounters = df_Excluded_ED_Encounters.apply(
                lambda x: x.replace(regex=r"NULL", value="")
                if x.dtype == "object"
                else x
            )
            df_Excluded_ED_Encounters = df_Excluded_ED_Encounters.apply(
                lambda x: x.replace(regex=r"null", value="")
                if x.dtype == "object"
                else x
            )
            df_Excluded_ED_Encounters = df_Excluded_ED_Encounters.apply(
                lambda x: x.replace(regex=r"Null", value="")
                if x.dtype == "object"
                else x
            )
            # dropping duplicate values
            df_Excluded_ED_Encounters.drop_duplicates(keep="last", inplace=True)
            df_Excluded_ED_Encounters.to_csv(
                "./ExtractorDB/OutputExcluded_ED_Encounters.csv",
                index=False,
                na_rep="",
                float_format=str,
                decimal=str,
                date_format=str,
            )
            logging.info("df_Excluded_ED_Encounters=%s", len(df_Excluded_ED_Encounters))
    # Update Sub task status
    if label_8_status == 0:
        label_8_sub.configure(text="Failed", fg="red")
        main_screen.update()
    else:
        label_8_sub.configure(text="Completed", fg="green")
        main_screen.update()
    # label_8_res.configure(text="EdEncounterPreclean:"+str(len(tbl_ppm_ED_Encounter_preclean))+", ED_Diag_Slice:"+str(len(df_ED_Diag_Slice))+", Excluded_ED_Encounters:"+str(len(df_Excluded_ED_Encounters))+",\nsnomed_Update:"+str(len(snomed_Update))+", AECC:"+str(len(aecc)))
    main_screen.update()
    #########extract from tbl_ExcludedEncounters.csv
    df_file_ExcludedEncounters = pd.DataFrame()
    file_ExcludedEncounters = "./Costing/tbl_ExcludedEncounters.csv"
    if os.path.isfile(file_ExcludedEncounters):
        try:
            df_file_ExcludedEncounters = read_csv_file(
                file_ExcludedEncounters,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error", "Error extracting tbl_ExcludedEncounters.csv.\n" + str(e)
            )
            return  # stop extraction
        else:
            df_file_ExcludedEncounters.columns = [
                "facility_identifier",
                "stay_number",
                "episode_sequence_number",
                "ed_identifier",
                "SNAP_encounter",
                "ReasonForExclusion",
                "EncounterNumber",
            ]
            # Access query: append to tbl_excluded encounters
            # INSERT INTO tbl_ExcludedEncounters ( facility_identifier, Stay_number, episode_sequence_number, Ed_identifier, SNAP_encounter, [Reason For Exclusion] ) SELECT IIf([facility_identifier] Is Null,"XXXX",[facility_identifier]) AS Expr1, IIf([Stay_number] Is Null,"XXXXXXXX",[Stay_number]) AS Expr2, IIf([episode_sequence_number] Is Null,0,[episode_sequence_number]) AS Expr3, IIf([Ed_identifier] Is Null,"XXXXXXXXXX",[Ed_identifier]) AS Expr4, IIf([SNAP_encounter] Is Null,"XXXX_XXXXXXXX",[SNAP_encounter]) AS Expr5, [temp tbl_ExcludedEncounters].[Reason For Exclusion] FROM [temp tbl_ExcludedEncounters];
            df_file_ExcludedEncounters["facility_identifier"] = np.where(
                (df_file_ExcludedEncounters["facility_identifier"].isnull())
                | (df_file_ExcludedEncounters["facility_identifier"] == ""),
                "XXXX",
                df_file_ExcludedEncounters["facility_identifier"],
            )
            df_file_ExcludedEncounters["stay_number"] = np.where(
                (df_file_ExcludedEncounters["stay_number"].isnull())
                | (df_file_ExcludedEncounters["stay_number"] == ""),
                "XXXXXXXX",
                df_file_ExcludedEncounters["stay_number"],
            )
            df_file_ExcludedEncounters["stay_number"] = (
                df_file_ExcludedEncounters["stay_number"]
                .astype(str)
                .str.pad(8, side="left", fillchar="0")
            )
            df_file_ExcludedEncounters["episode_sequence_number"] = np.where(
                (df_file_ExcludedEncounters["episode_sequence_number"].isnull())
                | (df_file_ExcludedEncounters["episode_sequence_number"] == ""),
                "0",
                df_file_ExcludedEncounters["episode_sequence_number"],
            )
            df_file_ExcludedEncounters["ed_identifier"] = np.where(
                (df_file_ExcludedEncounters["ed_identifier"].isnull())
                | (df_file_ExcludedEncounters["ed_identifier"] == ""),
                "XXXXXXXXXX",
                df_file_ExcludedEncounters["ed_identifier"],
            )
            df_file_ExcludedEncounters["SNAP_encounter"] = np.where(
                (df_file_ExcludedEncounters["SNAP_encounter"].isnull())
                | (df_file_ExcludedEncounters["SNAP_encounter"] == ""),
                "XXXX_XXXXXXXX",
                df_file_ExcludedEncounters["SNAP_encounter"],
            )
            df_file_ExcludedEncounters = df_file_ExcludedEncounters[
                df_file_ExcludedEncounters["facility_identifier"].isin(
                    facilities_included_list
                )
            ]
            logging.info(
                "df_file_ExcludedEncounters=%s", len(df_file_ExcludedEncounters)
            )
            if len(df_file_ExcludedEncounters) == 0:
                df_file_ExcludedEncounters = pd.DataFrame(
                    columns=[
                        "facility_identifier",
                        "stay_number",
                        "episode_sequence_number",
                        "ed_identifier",
                        "SNAP_encounter",
                        "ReasonForExclusion",
                        "EncounterNumber",
                    ]
                )
            df_file_ExcludedEncounters = df_file_ExcludedEncounters.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            df_file_ExcludedEncounters = df_file_ExcludedEncounters.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            df_file_ExcludedEncounters = df_file_ExcludedEncounters.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            # dropping duplicate values
            df_file_ExcludedEncounters.drop_duplicates(keep="last", inplace=True)
            df_file_ExcludedEncounters.to_csv(
                "./ExtractorDB/imported_ExcludedEncounters.csv",
                index=False,
                na_rep="",
                float_format=str,
                decimal=str,
                date_format=str,
            )
    """
    else:
        #df_file_ExcludedEncounters = pd.DataFrame(columns=['facility_identifier', 'stay_number', 'episode_sequence_number', 'ed_identifier', 'SNAP_encounter', 'ReasonForExclusion', 'EncounterNumber'])
        messagebox.showerror("File Error","tbl_ExcludedEncounters.csv is not available in ./Costing.")
        return    
    """
    #########extract from tbl_ExcludedEncounters.txt
    file_ExcludedEncounters = "./Costing/tbl_ExcludedEncounters.txt"
    df_file_ExcludedEncounters_txt = pd.DataFrame()
    if os.path.isfile(file_ExcludedEncounters):
        try:
            df_file_ExcludedEncounters_txt = read_csv_file(
                file_ExcludedEncounters,
                encoding="unicode_escape",
                dtype=str,
                keep_default_na=False,
                na_values="",
            )
        except Exception as e:
            logging.exception("Exception occurred")
            messagebox.showerror(
                "File Error", "Error extracting tbl_ExcludedEncounters.txt.\n" + str(e)
            )
            return  # stop extraction
        else:
            df_file_ExcludedEncounters_txt.columns = [
                "facility_identifier",
                "stay_number",
                "episode_sequence_number",
                "ed_identifier",
                "SNAP_encounter",
                "ReasonForExclusion",
                "EncounterNumber",
            ]
            # Access query: append to tbl_excluded encounters
            # INSERT INTO tbl_ExcludedEncounters ( facility_identifier, Stay_number, episode_sequence_number, Ed_identifier, SNAP_encounter, [Reason For Exclusion] ) SELECT IIf([facility_identifier] Is Null,"XXXX",[facility_identifier]) AS Expr1, IIf([Stay_number] Is Null,"XXXXXXXX",[Stay_number]) AS Expr2, IIf([episode_sequence_number] Is Null,0,[episode_sequence_number]) AS Expr3, IIf([Ed_identifier] Is Null,"XXXXXXXXXX",[Ed_identifier]) AS Expr4, IIf([SNAP_encounter] Is Null,"XXXX_XXXXXXXX",[SNAP_encounter]) AS Expr5, [temp tbl_ExcludedEncounters].[Reason For Exclusion] FROM [temp tbl_ExcludedEncounters];
            df_file_ExcludedEncounters_txt["facility_identifier"] = np.where(
                (df_file_ExcludedEncounters_txt["facility_identifier"].isnull())
                | (df_file_ExcludedEncounters_txt["facility_identifier"] == ""),
                "XXXX",
                df_file_ExcludedEncounters_txt["facility_identifier"],
            )
            df_file_ExcludedEncounters_txt["stay_number"] = np.where(
                (df_file_ExcludedEncounters_txt["stay_number"].isnull())
                | (df_file_ExcludedEncounters_txt["stay_number"] == ""),
                "XXXXXXXX",
                df_file_ExcludedEncounters_txt["stay_number"],
            )
            df_file_ExcludedEncounters_txt["stay_number"] = (
                df_file_ExcludedEncounters_txt["stay_number"]
                .astype(str)
                .str.pad(8, side="left", fillchar="0")
            )
            df_file_ExcludedEncounters_txt["episode_sequence_number"] = np.where(
                (df_file_ExcludedEncounters_txt["episode_sequence_number"].isnull())
                | (df_file_ExcludedEncounters_txt["episode_sequence_number"] == ""),
                "0",
                df_file_ExcludedEncounters_txt["episode_sequence_number"],
            )
            df_file_ExcludedEncounters_txt["episode_sequence_number"] = (
                df_file_ExcludedEncounters_txt["episode_sequence_number"]
                .astype(str)
                .str.pad(3, side="left", fillchar="0")
            )
            df_file_ExcludedEncounters_txt["ed_identifier"] = np.where(
                (df_file_ExcludedEncounters_txt["ed_identifier"].isnull())
                | (df_file_ExcludedEncounters_txt["ed_identifier"] == ""),
                "XXXXXXXXXX",
                df_file_ExcludedEncounters_txt["ed_identifier"],
            )
            df_file_ExcludedEncounters_txt["SNAP_encounter"] = np.where(
                (df_file_ExcludedEncounters_txt["SNAP_encounter"].isnull())
                | (df_file_ExcludedEncounters_txt["SNAP_encounter"] == ""),
                "XXXX_XXXXXXXX",
                df_file_ExcludedEncounters_txt["SNAP_encounter"],
            )
            df_file_ExcludedEncounters_txt = df_file_ExcludedEncounters_txt[
                df_file_ExcludedEncounters_txt["facility_identifier"].isin(
                    facilities_included_list
                )
            ]
            logging.info(
                "df_file_ExcludedEncounters_txt=%s", len(df_file_ExcludedEncounters_txt)
            )
            if len(df_file_ExcludedEncounters_txt) == 0:
                df_file_ExcludedEncounters_txt = pd.DataFrame(
                    columns=[
                        "facility_identifier",
                        "stay_number",
                        "episode_sequence_number",
                        "ed_identifier",
                        "SNAP_encounter",
                        "ReasonForExclusion",
                        "EncounterNumber",
                    ]
                )
            df_file_ExcludedEncounters_txt = df_file_ExcludedEncounters_txt.applymap(
                str
            )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
            df_file_ExcludedEncounters_txt = df_file_ExcludedEncounters_txt.applymap(
                lambda x: x.strip() if isinstance(x, str) else x
            )
            df_file_ExcludedEncounters_txt = df_file_ExcludedEncounters_txt.apply(
                lambda x: x.replace(regex=r"^NaT$", value="")
                if x.dtype == "object"
                else x
            )
            # dropping duplicate values
            df_file_ExcludedEncounters_txt.drop_duplicates(keep="last", inplace=True)
            df_file_ExcludedEncounters_txt.to_csv(
                "./ExtractorDB/imported_ExcludedEncounters.txt",
                sep=",",
                index=False,
                na_rep="",
                float_format=str,
                decimal=str,
                date_format=str,
            )
    """
    else:
        #df_file_ExcludedEncounters_txt = pd.DataFrame(columns=['facility_identifier', 'stay_number', 'episode_sequence_number', 'ed_identifier', 'SNAP_encounter', 'ReasonForExclusion', 'EncounterNumber'])
        messagebox.showerror("File Error","tbl_ExcludedEncounters.txt is not available in ./Costing.")
        return 
    """
    ########### Concatenate tbl_ExcludedEncounters.csv and tbl_ExcludedEncounters.txt
    df_file_ExcludedEncounters = pd.concat(
        [df_file_ExcludedEncounters, df_file_ExcludedEncounters_txt], axis=0
    )
    ########### Concatenate Excluded Encounters
    logging.info(
        "Excluded encounters will be created with %s records from Excluded_EpisodeAts, %s records from Excluded_ED_Encounters, %s records from ExcludedEncounters in ./Costing, %s records excluded from EpisodeATS where enddate is less than startdate, and %s records excluded from EpisodeATS with invalid care type.",
        len(df_Excluded_EpisodeAts),
        len(df_Excluded_ED_Encounters),
        len(df_file_ExcludedEncounters),
        len(df_Excluded_EpisodeAts_enddate_le_startdate),
        len(df_Excluded_EpisodeAts_invalid_caretype),
    )
    tbl_ExcludedEncounters = pd.concat(
        [
            df_Excluded_EpisodeAts,
            df_Excluded_ED_Encounters,
            df_file_ExcludedEncounters,
            df_Excluded_EpisodeAts_enddate_le_startdate,
            df_Excluded_EpisodeAts_invalid_caretype,
        ],
        axis=0,
    )
    tbl_ExcludedEncounters = tbl_ExcludedEncounters.fillna("")
    # Drop duplicates
    # Check if this is correct. What if for a stay_number-episode_sequence_number combo, there are two reasons for exclusions (answer:  we remove duplicates below only if all column values are identical)
    # tbl_ExcludedEncounters.drop_duplicates(keep='last', inplace=True)
    tbl_ExcludedEncounters.sort_values(
        by=["EncounterNumber", "ReasonForExclusion"], inplace=True
    )
    tbl_ExcludedEncounters = tbl_ExcludedEncounters.drop_duplicates(
        subset=["EncounterNumber"], keep="first"
    )
    tbl_ExcludedEncounters = tbl_ExcludedEncounters[
        tbl_ExcludedEncounters["facility_identifier"].isin(facilities_included_list)
    ]
    tbl_ExcludedEncounters = tbl_ExcludedEncounters[
        [
            "facility_identifier",
            "stay_number",
            "episode_sequence_number",
            "ed_identifier",
            "SNAP_encounter",
            "ReasonForExclusion",
            "EncounterNumber",
            "EDW_Enc_Number",
            "HLTH_ORG_OSP_OSP_ID",
            "MG_AUTH_OSP_OSP_ID",
            "SE_CBK_SK",
            "CL_ID_EUID",
            "CL_ID_IHI",
        ]
    ]
    if len(tbl_ExcludedEncounters) == 0:
        tbl_ExcludedEncounters = pd.DataFrame(
            columns=[
                "facility_identifier",
                "stay_number",
                "episode_sequence_number",
                "ed_identifier",
                "SNAP_encounter",
                "ReasonForExclusion",
                "EncounterNumber",
                "EDW_Enc_Number",
                "HLTH_ORG_OSP_OSP_ID",
                "MG_AUTH_OSP_OSP_ID",
                "SE_CBK_SK",
                "CL_ID_EUID",
                "CL_ID_IHI",
            ]
        )
    tbl_ExcludedEncounters = tbl_ExcludedEncounters.sort_values(
        by=[
            "facility_identifier",
            "stay_number",
            "episode_sequence_number",
            "EncounterNumber",
        ]
    )
    tbl_ExcludedEncounters = tbl_ExcludedEncounters.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    tbl_ExcludedEncounters = tbl_ExcludedEncounters.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    tbl_ExcludedEncounters = tbl_ExcludedEncounters.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    # dropping duplicate values
    tbl_ExcludedEncounters.drop_duplicates(keep="last", inplace=True)
    tbl_ExcludedEncounters.to_csv(
        "./ExtractorDB/OutputExcludedEncounters_part1.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    logging.info("tbl_ExcludedEncounters=%s", len(tbl_ExcludedEncounters))
    # if source == "HIE":
    if (
        lhd == "X830"
        or lhd == "X840"
        or lhd == "X850"
        or lhd == "X860"
        or lhd == "X740"
        or lhd == "X170"
    ):
        """ Appends data from dbo_PATIENT_CONTACT_DETAILS when linked to tbl_dbo_stay table and excludedEncounterstbl plus tbl_dbo_episode_ats where facility_identifier in tbl_excludedencounters is null """
        # Access query = Append_to_tbl_PPM_Patient_AUID
        # INSERT INTO tbl_PPM_Patient ( PatientNumber, DateOfBirth, Gender, EthnicOrigin, mrn_for_matching ) SELECT [tbl_dbo_stay]![facility_identifier] & "-" & IIf([tbl_Patient_Contact_Details]![AUID] Is Not Null,[tbl_Patient_Contact_Details]![AUID],[tbl_dbo_stay]![mrn]) AS Expr9, tbl_dbo_stay.birth_date, tbl_dbo_stay.sex, Max(tbl_dbo_stay.country_of_birth_sacc) AS MaxOfcountry_of_birth_sacc, Trim([tbl_dbo_stay]![facility_identifier] & "-" & Right([tbl_dbo_stay]![mrn],10)) AS Expr1 FROM (tbl_dbo_episode_ats INNER JOIN (tbl_dbo_stay LEFT JOIN tbl_Patient_Contact_Details ON tbl_dbo_stay.stay_number = tbl_Patient_Contact_Details.contact_identifier) ON (tbl_dbo_episode_ats.facility_identifier = tbl_dbo_stay.facility_identifier) AND (tbl_dbo_episode_ats.stay_number = tbl_dbo_stay.stay_number)) LEFT JOIN tbl_ExcludedEncounters ON (tbl_dbo_episode_ats.facility_identifier = tbl_ExcludedEncounters.facility_identifier) AND (tbl_dbo_episode_ats.stay_number = tbl_ExcludedEncounters.Stay_number) AND (tbl_dbo_episode_ats.episode_sequence_number = tbl_ExcludedEncounters.episode_sequence_number) GROUP BY [tbl_dbo_stay]![facility_identifier] & "-" & IIf([tbl_Patient_Contact_Details]![AUID] Is Not Null,[tbl_Patient_Contact_Details]![AUID],[tbl_dbo_stay]![mrn]), tbl_dbo_stay.birth_date, tbl_dbo_stay.sex, Trim([tbl_dbo_stay]![facility_identifier] & "-" & Right([tbl_dbo_stay]![mrn],10)), tbl_ExcludedEncounters.facility_identifier, tbl_dbo_episode_ats.episode_of_care_type HAVING (((tbl_ExcludedEncounters.facility_identifier) Is Null));
        # Note: indigenous_status present in Inform8 -> Extractor.Transformations -> PatientTransformation
        tbl_dbo_stay["stay_number"] = (
            tbl_dbo_stay["stay_number"].astype(str).str.strip()
        )
        tbl_dbo_stay["stay_number"] = (
            tbl_dbo_stay["stay_number"]
            .astype(str)
            .str.pad(8, side="left", fillchar="0")
        )
        tbl_Patient_Contact_Details["contact_identifier"] = (
            tbl_Patient_Contact_Details["contact_identifier"].astype(str).str.strip()
        )
        tbl_Patient_Contact_Details["contact_identifier"] = (
            tbl_Patient_Contact_Details["contact_identifier"]
            .astype(str)
            .str.pad(8, side="left", fillchar="0")
        )
        # AQA-280 - Add AUID
        # df_1 = pd.merge(tbl_dbo_stay[['stay_number', 'facility_identifier', 'mrn', 'birth_date', 'sex', 'country_of_birth_sacc', 'indigenous_status']], tbl_Patient_Contact_Details[['contact_identifier', 'person_area_uid']], how='left', left_on = ['stay_number'], right_on = ['contact_identifier'], suffixes=('', '_drop'))
        df_1 = pd.merge(
            tbl_dbo_stay[
                [
                    "stay_number",
                    "facility_identifier",
                    "mrn",
                    "birth_date",
                    "sex",
                    "country_of_birth_sacc",
                    "indigenous_status",
                ]
            ],
            tbl_Patient_Contact_Details[
                ["contact_identifier", "person_area_uid", "AUID"]
            ],
            how="left",
            left_on=["stay_number"],
            right_on=["contact_identifier"],
            suffixes=("", "_drop"),
        )
        # 27 July 2024 - stay episode seq number - remove dup
        df_1.drop_duplicates(
            subset=[
                "stay_number",
                "facility_identifier",
                "mrn",
                "birth_date",
                "sex",
                "country_of_birth_sacc",
                "indigenous_status",
                "contact_identifier",
                "person_area_uid",
            ],
            keep="last",
            inplace=True,
        )
        df_1 = df_1.apply(
            lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
        )
        df_1 = df_1.fillna("")
        df_1["stay_number"] = df_1["stay_number"].astype(str).str.strip()
        df_1["stay_number"] = (
            df_1["stay_number"].astype(str).str.pad(8, side="left", fillchar="0")
        )
        df_1["facility_identifier"] = (
            df_1["facility_identifier"].astype(str).str.strip()
        )
        # df_1['facility_identifier'] = df_1.facility_identifier.fillna('missing')
        tbl_dbo_episode_ats_copy = tbl_dbo_episode_ats.copy()
        tbl_dbo_episode_ats_copy["stay_number"] = (
            tbl_dbo_episode_ats_copy["stay_number"].astype(str).str.strip()
        )
        tbl_dbo_episode_ats_copy["stay_number"] = (
            tbl_dbo_episode_ats_copy["stay_number"]
            .astype(str)
            .str.pad(8, side="left", fillchar="0")
        )
        tbl_dbo_episode_ats_copy["facility_identifier"] = (
            tbl_dbo_episode_ats_copy["facility_identifier"].astype(str).str.strip()
        )
        # tbl_dbo_episode_ats_copy['facility_identifier'] = tbl_dbo_episode_ats_copy.facility_identifier.fillna('missing')
        df_2 = pd.merge(
            tbl_dbo_episode_ats_copy[
                [
                    "facility_identifier",
                    "stay_number",
                    "episode_sequence_number",
                    "episode_of_care_type",
                ]
            ],
            df_1,
            how="inner",
            on=["facility_identifier", "stay_number"],
            suffixes=("", "_drop"),
        )
        df_2["stay_number"] = (
            df_2["stay_number"].astype(str).str.pad(8, side="left", fillchar="0")
        )
        df_2["episode_sequence_number"] = (
            df_2["episode_sequence_number"]
            .astype(str)
            .str.pad(3, side="left", fillchar="0")
        )
        df_2 = df_2.apply(
            lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
        )
        df_2 = df_2.fillna("")
        # CAUTION - Having tbl_ExcludedEncounters.facility_identifier Is Null means join on facility_identifier will not work
        # Therefore, fill missing facility identifiers with another value and then join. Do it on a copy of tbl_ExcludedEncounters
        # tbl_ExcludedEncounters= tbl_ExcludedEncounters.fillna("")
        # tbl_ExcludedEncounters_copy = tbl_ExcludedEncounters[pd.isna(tbl_ExcludedEncounters['facility_identifier'])]
        # tbl_ExcludedEncounters_copy['facility_identifier'] = tbl_ExcludedEncounters_copy.facility_identifier.fillna('missing')
        # df_2['facility_identifier'] = df_2.facility_identifier.fillna('missing')
        tbl_ExcludedEncounters_copy = tbl_ExcludedEncounters.copy()
        df_2["stay_number"] = df_2["stay_number"].astype(str).str.strip()
        df_2["stay_number"] = (
            df_2["stay_number"].astype(str).str.pad(8, side="left", fillchar="0")
        )
        df_2["facility_identifier"] = (
            df_2["facility_identifier"].astype(str).str.strip()
        )
        df_2["episode_sequence_number"] = (
            df_2["episode_sequence_number"].astype(str).str.strip()
        )
        df_2["episode_sequence_number"] = (
            df_2["episode_sequence_number"]
            .astype(str)
            .str.pad(3, side="left", fillchar="0")
        )
        tbl_ExcludedEncounters_copy["stay_number"] = (
            tbl_ExcludedEncounters_copy["stay_number"].astype(str).str.strip()
        )
        tbl_ExcludedEncounters_copy["stay_number"] = (
            tbl_ExcludedEncounters_copy["stay_number"]
            .astype(str)
            .str.pad(8, side="left", fillchar="0")
        )
        tbl_ExcludedEncounters_copy["facility_identifier"] = (
            tbl_ExcludedEncounters_copy["facility_identifier"].astype(str).str.strip()
        )
        tbl_ExcludedEncounters_copy["episode_sequence_number"] = (
            tbl_ExcludedEncounters_copy["episode_sequence_number"]
            .astype(str)
            .str.strip()
        )
        tbl_ExcludedEncounters_copy["episode_sequence_number"] = (
            tbl_ExcludedEncounters_copy["episode_sequence_number"]
            .astype(str)
            .str.pad(3, side="left", fillchar="0")
        )
        tbl_PPM_Patient = pd.merge(
            df_2,
            tbl_ExcludedEncounters_copy,
            how="left",
            on=["facility_identifier", "stay_number", "episode_sequence_number"],
            suffixes=("", "_drop"),
            indicator=True,
        )
        tbl_PPM_Patient = tbl_PPM_Patient.apply(
            lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
        )
        tbl_PPM_Patient = tbl_PPM_Patient[tbl_PPM_Patient["_merge"] == "left_only"]
        tbl_PPM_Patient.drop(["_merge"], axis=1, inplace=True, errors="ignore")
        # Replace 'missing' with empty string
        # tbl_PPM_Patient = tbl_PPM_Patient.facility_identifier.replace('missing','',regex = True)
        # tbl_PPM_Patient['facility_identifier'] = tbl_PPM_Patient['facility_identifier'].replace(['missing'], '')
        # tbl_PPM_Patient= tbl_PPM_Patient.fillna("")
        tbl_PPM_Patient["mrn"] = tbl_PPM_Patient["mrn"].astype(str).str.strip()
        tbl_PPM_Patient["facility_identifier"] = (
            tbl_PPM_Patient["facility_identifier"].astype(str).str.strip()
        )
        tbl_PPM_Patient["person_area_uid"] = (
            tbl_PPM_Patient["person_area_uid"].astype(str).str.strip()
        )
        tbl_PPM_Patient["PatientNumber"] = np.where(
            pd.notna(tbl_PPM_Patient["person_area_uid"])
            & (tbl_PPM_Patient["person_area_uid"] != ""),
            tbl_PPM_Patient["facility_identifier"]
            + "-"
            + tbl_PPM_Patient["person_area_uid"],
            tbl_PPM_Patient["facility_identifier"] + "-" + tbl_PPM_Patient["mrn"],
        )
        tbl_PPM_Patient["DateOfBirth"] = (
            tbl_PPM_Patient["birth_date"].astype(str).str.strip()
        )  # sometimes year will be 9999. pd.to_datetime will fail
        tbl_PPM_Patient["Gender"] = tbl_PPM_Patient["sex"].astype(str).str.strip()
        tbl_PPM_Patient["mrn_for_matching"] = (
            tbl_PPM_Patient["facility_identifier"]
            + "-"
            + tbl_PPM_Patient["mrn"].str[-10:]
        )
        tbl_PPM_Patient["Extra:IndigenousStatus"] = tbl_PPM_Patient["indigenous_status"]
        # AQA-280 - Add AUID
        tbl_PPM_Patient["AUID"] = tbl_PPM_Patient["AUID"]
        tbl_PPM_Patient = tbl_PPM_Patient[
            [
                "PatientNumber",
                "DateOfBirth",
                "Gender",
                "country_of_birth_sacc",
                "mrn_for_matching",
                "facility_identifier",
                "episode_of_care_type",
                "Extra:IndigenousStatus",
                "AUID",
            ]
        ]
        tbl_PPM_Patient = tbl_PPM_Patient[
            tbl_PPM_Patient["facility_identifier"].isin(facilities_included_list)
        ]
        # Groupby max- Ref: https://datascienceparichay.com/article/pandas-groupby-maximum/
        # tbl_PPM_Patient = tbl_PPM_Patient.groupby(['PatientNumber', 'DateOfBirth', 'Gender', 'mrn_for_matching', 'facility_identifier', 'episode_of_care_type', 'indigenous_status'])[['country_of_birth_sacc']].max()
        # AQA-280 - Add AUID
        tbl_PPM_Patient = (
            tbl_PPM_Patient.groupby(
                [
                    "PatientNumber",
                    "DateOfBirth",
                    "Gender",
                    "mrn_for_matching",
                    "facility_identifier",
                    "episode_of_care_type",
                    "Extra:IndigenousStatus",
                    "AUID",
                ],
                as_index=False,
                dropna=False,
            )
            .agg(EthnicOrigin=("country_of_birth_sacc", "max"))
            .reset_index()
        )
        # tbl_PPM_Patient.rename(columns = {'country_of_birth_sacc':'EthnicOrigin', 'indigenous_status': 'Extra:IndigenousStatus'}, inplace = True)
        # reset index after groupby Ref: https://www.geeksforgeeks.org/how-to-reset-index-after-groupby-pandas/
        # tbl_PPM_Patient = tbl_PPM_Patient.reset_index()
        tbl_PPM_Patient = tbl_PPM_Patient[
            [
                "PatientNumber",
                "Gender",
                "EthnicOrigin",
                "Extra:IndigenousStatus",
                "DateOfBirth",
                "mrn_for_matching",
                "AUID",
            ]
        ]
        tbl_PPM_Patient.sort_values(
            by=[
                "PatientNumber",
                "Gender",
                "EthnicOrigin",
                "Extra:IndigenousStatus",
                "DateOfBirth",
                "mrn_for_matching",
            ],
            inplace=True,
        )
        tbl_PPM_Patient.drop_duplicates(
            subset=[
                "PatientNumber",
                "Gender",
                "EthnicOrigin",
                "Extra:IndigenousStatus",
                "DateOfBirth",
                "mrn_for_matching",
            ],
            keep="last",
            inplace=True,
        )
        tbl_PPM_Patient = tbl_PPM_Patient.applymap(
            str
        )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
        tbl_PPM_Patient = tbl_PPM_Patient.applymap(
            lambda x: x.strip() if isinstance(x, str) else x
        )
        tbl_PPM_Patient = tbl_PPM_Patient.apply(
            lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
        )
        # tbl_PPM_Patient.to_csv('./ExtractorDB/tbl_PPM_Patient.csv', index=False, na_rep='', float_format=str, decimal=str, date_format=str)
        # print("tbl_PPM_Patient=", len(tbl_PPM_Patient))
    else:
        """Appends data from tbl_dbo_stay table linked to excludedEncounterstbl plus tbl_dbo_episode_ats where facility_identifier in tbl_excludedencounters is null. Not sure how this works being linked to ATS"""
        # Access query = Append_to_tbl_PPM_Patient - cannot see SQL view. Therefore I deleted tbl_Excluded encounters to open the below query.
        # INSERT INTO tbl_PPM_Patient ( PatientNumber, DateOfBirth, Gender, EthnicOrigin, mrn_for_matching )
        # SELECT Trim([tbl_dbo_stay]![facility_identifier] & "-" & Right([tbl_dbo_stay]![mrn],10)) AS Expr1, tbl_dbo_stay.birth_date, tbl_dbo_stay.sex, Max(tbl_dbo_stay.country_of_birth_sacc) AS MaxOfcountry_of_birth_sacc, Trim([tbl_dbo_stay]![facility_identifier] & "-" & Right([tbl_dbo_stay]![mrn],10)) AS Expr2
        # FROM tbl_dbo_stay INNER JOIN tbl_dbo_episode_ats ON (tbl_dbo_episode_ats.stay_number = tbl_dbo_stay.stay_number) AND (tbl_dbo_stay.facility_identifier = tbl_dbo_episode_ats.facility_identifier)
        # GROUP BY tbl_dbo_stay.birth_date, tbl_dbo_stay.sex, Trim([tbl_dbo_stay]![facility_identifier] & "-" & Right([tbl_dbo_stay]![mrn],10)), Trim([tbl_dbo_stay]![facility_identifier] & "-" & Right([tbl_dbo_stay]![mrn],10)), Trim(IIf([Forms]![Frm:1-ExtractSetUp]![AHS]="X800",[tbl_dbo_stay]![facility_identifier] & "-" & "000" & Right([tbl_dbo_stay]![mrn],7),[tbl_dbo_stay]![facility_identifier] & "-" & Right([tbl_dbo_stay]![mrn],10))), tbl_dbo_stay.facility_identifier
        # HAVING (((tbl_dbo_stay.facility_identifier)<>"D311" Or (tbl_dbo_stay.facility_identifier)<>"D311"));
        tbl_dbo_stay["stay_number"] = (
            tbl_dbo_stay["stay_number"].astype(str).str.strip()
        )
        tbl_dbo_stay["stay_number"] = (
            tbl_dbo_stay["stay_number"]
            .astype(str)
            .str.pad(8, side="left", fillchar="0")
        )
        tbl_dbo_stay["facility_identifier"] = (
            tbl_dbo_stay["facility_identifier"].astype(str).str.strip()
        )
        tbl_dbo_episode_ats["stay_number"] = (
            tbl_dbo_episode_ats["stay_number"].astype(str).str.strip()
        )
        tbl_dbo_episode_ats["stay_number"] = (
            tbl_dbo_episode_ats["stay_number"]
            .astype(str)
            .str.pad(8, side="left", fillchar="0")
        )
        # 27 July 2024 - stay episode seq number
        tbl_dbo_stay["episode_sequence_number"] = (
            tbl_dbo_stay["episode_sequence_number"]
            .astype(str)
            .str.pad(3, side="left", fillchar="0")
        )
        tbl_dbo_episode_ats["facility_identifier"] = (
            tbl_dbo_episode_ats["facility_identifier"].astype(str).str.strip()
        )
        # 27 July 2024 - stay episode seq number
        # df_2 = pd.merge(tbl_dbo_stay[['stay_number', 'facility_identifier', 'mrn', 'birth_date', 'sex', 'country_of_birth_sacc', 'indigenous_status']], tbl_dbo_episode_ats[['facility_identifier', 'stay_number', 'episode_sequence_number']], how='inner', on = ['facility_identifier', 'stay_number'], suffixes=('', '_drop'))
        # AQA-280 - Add AUID
        df_2 = pd.merge(
            tbl_dbo_stay[
                [
                    "stay_number",
                    "facility_identifier",
                    "mrn",
                    "birth_date",
                    "sex",
                    "country_of_birth_sacc",
                    "indigenous_status",
                    "episode_sequence_number",
                    "AUID",
                ]
            ],
            tbl_dbo_episode_ats[
                ["facility_identifier", "stay_number", "episode_sequence_number"]
            ],
            how="inner",
            on=["facility_identifier", "stay_number", "episode_sequence_number"],
            suffixes=("", "_drop"),
        )
        df_2 = df_2.apply(
            lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
        )
        tbl_ExcludedEncounters_copy = tbl_ExcludedEncounters.copy()
        df_2["stay_number"] = df_2["stay_number"].astype(str).str.strip()
        df_2["stay_number"] = (
            df_2["stay_number"].astype(str).str.pad(8, side="left", fillchar="0")
        )
        df_2["facility_identifier"] = (
            df_2["facility_identifier"].astype(str).str.strip()
        )
        df_2["episode_sequence_number"] = (
            df_2["episode_sequence_number"].astype(str).str.strip()
        )
        df_2["episode_sequence_number"] = (
            df_2["episode_sequence_number"]
            .astype(str)
            .str.pad(3, side="left", fillchar="0")
        )
        tbl_ExcludedEncounters_copy["stay_number"] = (
            tbl_ExcludedEncounters_copy["stay_number"].astype(str).str.strip()
        )
        tbl_ExcludedEncounters_copy["stay_number"] = (
            tbl_ExcludedEncounters_copy["stay_number"]
            .astype(str)
            .str.pad(8, side="left", fillchar="0")
        )
        tbl_ExcludedEncounters_copy["facility_identifier"] = (
            tbl_ExcludedEncounters_copy["facility_identifier"].astype(str).str.strip()
        )
        tbl_ExcludedEncounters_copy["episode_sequence_number"] = (
            tbl_ExcludedEncounters_copy["episode_sequence_number"]
            .astype(str)
            .str.strip()
        )
        tbl_ExcludedEncounters_copy["episode_sequence_number"] = (
            tbl_ExcludedEncounters_copy["episode_sequence_number"]
            .astype(str)
            .str.pad(3, side="left", fillchar="0")
        )
        tbl_PPM_Patient = pd.merge(
            df_2,
            tbl_ExcludedEncounters_copy,
            how="left",
            on=["facility_identifier", "stay_number", "episode_sequence_number"],
            suffixes=("", "_drop"),
            indicator=True,
        )
        tbl_PPM_Patient = tbl_PPM_Patient.apply(
            lambda x: x.replace(regex=r"^nan$", value="") if x.dtype == "object" else x
        )
        tbl_PPM_Patient = tbl_PPM_Patient[tbl_PPM_Patient["_merge"] == "left_only"]
        tbl_PPM_Patient.drop(["_merge"], axis=1, inplace=True, errors="ignore")
        tbl_PPM_Patient["mrn"] = tbl_PPM_Patient["mrn"].astype(str).str.strip()
        tbl_PPM_Patient["facility_identifier"] = (
            tbl_PPM_Patient["facility_identifier"].astype(str).str.strip()
        )
        tbl_PPM_Patient["PatientNumber"] = (
            tbl_PPM_Patient["facility_identifier"]
            + "-"
            + tbl_PPM_Patient["mrn"].str[-10:]
        )
        tbl_PPM_Patient["DateOfBirth"] = (
            tbl_PPM_Patient["birth_date"].astype(str).str.strip()
        )  # sometimes year will be 9999. pd.to_datetime will fail
        tbl_PPM_Patient["Gender"] = tbl_PPM_Patient["sex"].astype(str).str.strip()
        tbl_PPM_Patient["mrn_for_matching"] = (
            tbl_PPM_Patient["facility_identifier"]
            + "-"
            + tbl_PPM_Patient["mrn"].str[-10:]
        )
        tbl_PPM_Patient["Extra:IndigenousStatus"] = tbl_PPM_Patient["indigenous_status"]
        # AQA-280 - Add AUID
        tbl_PPM_Patient["AUID"] = tbl_PPM_Patient["AUID"]
        # AQA-280 - Add AUID
        tbl_PPM_Patient = tbl_PPM_Patient[
            [
                "PatientNumber",
                "DateOfBirth",
                "Gender",
                "country_of_birth_sacc",
                "mrn_for_matching",
                "facility_identifier",
                "Extra:IndigenousStatus",
                "AUID",
            ]
        ]
        tbl_PPM_Patient = tbl_PPM_Patient[
            tbl_PPM_Patient["facility_identifier"].isin(facilities_included_list)
        ]
        # this has not been implemented in groupby of mrn_matching: Trim(IIf([Forms]![Frm:1-ExtractSetUp]![AHS]="X800",[tbl_dbo_stay]![facility_identifier] & "-" & "000" & Right([tbl_dbo_stay]![mrn],7),[tbl_dbo_stay]![facility_identifier] & "-" & Right([tbl_dbo_stay]![mrn],10)))
        # AQA-280 - Add AUID
        tbl_PPM_Patient = (
            tbl_PPM_Patient.groupby(
                [
                    "PatientNumber",
                    "DateOfBirth",
                    "Gender",
                    "mrn_for_matching",
                    "facility_identifier",
                    "Extra:IndigenousStatus",
                    "AUID",
                ],
                as_index=False,
                dropna=False,
            )
            .agg(EthnicOrigin=("country_of_birth_sacc", "max"))
            .reset_index()
        )
        # 25 Jul 2025 RS: when you are back, just let me know if i can remove the exclusion filters on D311  or may be next week. you should not be wroking today
        # LM: Please remove it so they can see all the (still incomplete) data. So that we don't have to do anything in the future
        # Issue #16 in UAT tracker 1.16.1
        # tbl_PPM_Patient = tbl_PPM_Patient[tbl_PPM_Patient['facility_identifier'] !='D311']
        # AQA-280 - Add AUID
        tbl_PPM_Patient = tbl_PPM_Patient[
            [
                "PatientNumber",
                "Gender",
                "EthnicOrigin",
                "Extra:IndigenousStatus",
                "DateOfBirth",
                "mrn_for_matching",
                "AUID",
            ]
        ]
        tbl_PPM_Patient.sort_values(
            by=[
                "PatientNumber",
                "Gender",
                "EthnicOrigin",
                "Extra:IndigenousStatus",
                "DateOfBirth",
                "mrn_for_matching",
            ],
            inplace=True,
        )
        tbl_PPM_Patient.drop_duplicates(
            subset=[
                "PatientNumber",
                "Gender",
                "EthnicOrigin",
                "Extra:IndigenousStatus",
                "DateOfBirth",
                "mrn_for_matching",
            ],
            keep="last",
            inplace=True,
        )
        tbl_PPM_Patient = tbl_PPM_Patient.applymap(
            str
        )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
        tbl_PPM_Patient = tbl_PPM_Patient.applymap(
            lambda x: x.strip() if isinstance(x, str) else x
        )
        tbl_PPM_Patient = tbl_PPM_Patient.apply(
            lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
        )
        # tbl_PPM_Patient.to_csv('./ExtractorDB/tbl_PPM_Patient.csv', index=False, na_rep='', float_format=str, decimal=str, date_format=str)
        # print("tbl_PPM_Patient=", len(tbl_PPM_Patient))

    tbl_PPM_Patient = tbl_PPM_Patient.applymap(
        str
    )  # .apply(lambda x: x.astype(str).str.strip() if x.dtype == 'object' else x)
    tbl_PPM_Patient = tbl_PPM_Patient.applymap(
        lambda x: x.strip() if isinstance(x, str) else x
    )
    tbl_PPM_Patient = tbl_PPM_Patient.apply(
        lambda x: x.replace(regex=r"^NaT$", value="") if x.dtype == "object" else x
    )
    tbl_PPM_Patient = tbl_PPM_Patient.apply(
        lambda x: x.replace(regex=r"NULL", value="") if x.dtype == "object" else x
    )
    tbl_PPM_Patient = tbl_PPM_Patient.apply(
        lambda x: x.replace(regex=r"null", value="") if x.dtype == "object" else x
    )
    tbl_PPM_Patient = tbl_PPM_Patient.apply(
        lambda x: x.replace(regex=r"Null", value="") if x.dtype == "object" else x
    )
    # dropping duplicate values
    tbl_PPM_Patient.drop_duplicates(keep="last", inplace=True)
    ##### Join with EDW specific fields - for FUTURE##############
    ##tbl_PPM_Patient = pd.merge(tbl_PPM_Patient, XXXXXXXXXXXX[['PatientNumber', 'EDW_Pat_Number', 'CL_ID_EUID']], how='left', on = ['PatientNumber'], suffixes=('', '_drop'))
    #####################################################
    tbl_PPM_Patient.to_csv(
        "./ExtractorDB/tbl_PPM_Patient.csv",
        index=False,
        na_rep="",
        float_format=str,
        decimal=str,
        date_format=str,
    )
    logging.info("tbl_PPM_Patient=%s", len(tbl_PPM_Patient))
    # conn_staging.close()
    label_9_status, label_10_status = import_snap_amhcc_files(
        "new_extract",
        lhd,
        facilities_excluded_list,
        facilities_included_list,
        roundid,
        start_date,
        end_date,
        nwau_v,
        icd10_v,
        drg1_v,
        drg2_v,
        drg4_v,
        snap_v,
        amhcc_v,
        cost_weight_v,
        srg_drg_v,
    )
    # If all extracts are successful, then update config file.
    if (
        label_1_status == 1
        and label_2_status == 1
        and label_3_status == 1
        and label_4_status == 1
        and label_5_status == 1
        and label_6_status == 1
        and label_7_status == 1
        and label_8_status == 1
        and label_9_status == 1
        and label_10_status == 1
    ):
        logging.info("Data extraction completed without any errors.")
        ############19 Aug
        cleanup_memory(tbl_dbo_Facility)
        cleanup_memory(tbl_dbo_stay)
        cleanup_memory(tbl_Patient_Contact_Details)
        cleanup_memory(ed_nwau)
        cleanup_memory(acute_nwau)
        cleanup_memory(df_Excluded_EpisodeAts)
        cleanup_memory(df_Excluded_EpisodeAts_invalid_caretype)
        cleanup_memory(tbl_dbo_episode_ats)
        cleanup_memory(tbl_dbo_Ward_Episode)
        cleanup_memory(tbl_dbo_episode)
        cleanup_memory(tbl_dbo_episode_srg)
        cleanup_memory(tbl_transit_episode_DRG4)
        cleanup_memory(tbl_dbo_episode_DRG)
        cleanup_memory(tbl_dbo_wl_exit)
        cleanup_memory(tbl_Episode_ATS_end_date_update)
        cleanup_memory(df_Excluded_EpisodeAts_enddate_le_startdate)
        cleanup_memory(tbl_dbo_days_episode)
        cleanup_memory(df_PpmTransferAmo)
        cleanup_memory(tbl_PPM_transfer_Leave_00)
        cleanup_memory(tbl_PPM_transfer_Leave_02)
        cleanup_memory(tbl_PPM_ICD_diagnoses)
        cleanup_memory(tbl_PPM_ICD_procedures)
        cleanup_memory(tbl_ppm_ED_Patient)
        cleanup_memory(tbl_ppm_ED_Encounter_preclean)
        cleanup_memory(df_ED_Diag_Slice_1)
        cleanup_memory(df_ED_Diag_Slice_2)
        cleanup_memory(df_ED_Diag_Slice)
        cleanup_memory(df_Excluded_ED_Encounters)
        cleanup_memory(df_file_ExcludedEncounters)
        cleanup_memory(df_file_ExcludedEncounters_txt)
        cleanup_memory(df_file_ExcludedEncounters)
        cleanup_memory(df_2)
        cleanup_memory(tbl_ExcludedEncounters_copy)
        cleanup_memory(tbl_PPM_Patient)
        #################
        extract_complete(
            "new_extract",
            lhd,
            facilities_excluded_list,
            facilities_included_list,
            roundid,
            start_date,
            end_date,
            nwau_v,
            icd10_v,
            drg1_v,
            drg2_v,
            drg4_v,
            snap_v,
            amhcc_v,
            cost_weight_v,
            srg_drg_v,
        )
    else:
        logging.info("Data extraction failed due to errors.")
        messagebox.showerror("Data Extraction", "Data extraction failed due to errors.")
        # clear entry fields
        clear_entry_fields()


def fill_full_round_details(
    main_screen,
    roundid_window,
    choose_roundid,
    select_round_details,
    pick_lhd,
    start_date_pm,
    end_date_pm,
    facilities_excluded_list,
    facilities_included_list,
):
    # Ranjit 16 Aug
    global start_date, end_date
    # facilities_excluded_list = facilities_excluded_list.get()
    pick_round = choose_roundid.get()
    end_date = str(end_date_pm.get())
    start_date = str(start_date_pm.get())
    # 16 Aug
    # end_date = end_date+' '+'23:59:59'
    # end_date = end_date+' '+'00:00:00'
    # start_date=start_date+' '+'00:00:00'
    end_date = end_date[:10]
    start_date = start_date[:10]
    # print("start_date=",start_date)
    # print("end_date=",end_date)
    # destroy 'fill round details screen'
    roundid_window.destroy()
    round_details = select_round_details[pick_round]
    # print("round_details=",round_details)
    # split the selected row
    fill_details = round_details.split(",")
    # version
    global versionID  # , start_date, end_date
    versionID = str(fill_details[1])
    # print("fill_details[2]=",fill_details[2], ". fill_details[3]=",fill_details[3])
    ### START DATE, END DATE MUST BE WITHIN ROUND - START
    try:
        # round_start_date_dt = datetime.datetime.strptime(fill_details[2], "%d/%m/%Y")
        # round_start_date_date = datetime.datetime.strptime(fill_details[2], "%d/%m/%Y").date()
        round_start_date_date = datetime.datetime.strptime(
            fill_details[2][:10], "%Y-%m-%d"
        ).date()
    except ValueError as error:
        logging.exception("Exception occurred")
        messagebox.showerror("Date Error", str(error))
        choose_round_nwau(pick_lhd, facilities_excluded_list, facilities_included_list)
    try:
        # round_end_date_dt = datetime.datetime.strptime(fill_details[3], "%d/%m/%Y")
        # round_end_date_date = datetime.datetime.strptime(fill_details[3], "%d/%m/%Y").date()
        round_end_date_date = datetime.datetime.strptime(
            fill_details[3][:10], "%Y-%m-%d"
        ).date()
    except ValueError as error:
        logging.exception("Exception occurred")
        messagebox.showerror("Date Error", str(error))
        choose_round_nwau(pick_lhd, facilities_excluded_list, facilities_included_list)
    # convert stringVar to string to date
    try:
        # start_date_dt = datetime.datetime.strptime(start_date, "%d/%m/%Y")
        start_date_date = datetime.datetime.strptime(start_date, "%Y-%m-%d").date()
        end_date_date = datetime.datetime.strptime(end_date, "%Y-%m-%d").date()
        # start_date_date = datetime.datetime.strptime(start_date, "%Y-%m-%d %H:%M:%S").date()
        # end_date_date = datetime.datetime.strptime(end_date, "%Y-%m-%d %H:%M:%S").date()
    except ValueError as error:
        logging.exception("Exception occurred")
        messagebox.showerror("Date Error", str(error))
        choose_round_nwau(pick_lhd, facilities_excluded_list, facilities_included_list)
    else:
        logging.info(
            "user_start_date_date=%s, roundid_start_date=%s, user_end_date_date=%s, roundid_end_date=%s",
            start_date_date,
            round_start_date_date,
            end_date_date,
            round_end_date_date,
        )
        if (
            str(start_date_date).strip() == ""
            or str(end_date_date).strip() == ""
            or start_date_date < round_start_date_date
            or start_date_date > round_end_date_date
            or end_date_date > round_end_date_date
            or end_date_date < round_start_date_date
            or start_date_date > end_date_date
        ):
            messagebox.showerror(
                "Date Error",
                "The Start Date and End Date for "
                + pick_round
                + " has to be between "
                + fill_details[2]
                + " and "
                + fill_details[3],
            )
            choose_round_nwau(
                pick_lhd, facilities_excluded_list, facilities_included_list
            )
        ### START DATE, END DATE MUST BE WITHIN ROUND - END
        else:
            # populate fields
            roundid_field.configure(state="normal")
            roundid_field.insert(0, pick_round)
            roundid_field.configure(state="disabled")
            lhd_field.configure(state="normal")
            if len(facilities_excluded_list) > 0:
                facilities_excluded_str = ",".join(
                    str(e) for e in facilities_excluded_list
                )
                lhd_string = pick_lhd + " (excluding " + facilities_excluded_str + ")"
                lhd_field.insert(0, lhd_string)
            else:
                lhd_field.insert(0, pick_lhd)
            lhd_field.configure(state="disabled")
            start_date_field.configure(state="normal")
            # start_date_field.insert(0, fill_details[2])
            start_date_field.insert(0, start_date)
            start_date_field.configure(state="disabled")
            end_date_field.configure(state="normal")
            # end_date_field.insert(0, fill_details[3])
            end_date_field.insert(0, end_date)
            end_date_field.configure(state="disabled")
            nwau_v_field.configure(state="normal")
            nwau_v_field.insert(0, fill_details[5])
            nwau_v_field.configure(state="disabled")
            icd10_v_field.configure(state="normal")
            icd10_v_field.insert(0, fill_details[6])
            icd10_v_field.configure(state="disabled")
            drg1_v_field.configure(state="normal")
            drg1_v_field.insert(0, fill_details[7])
            drg1_v_field.configure(state="disabled")
            drg2_v_field.configure(state="normal")
            drg2_v_field.insert(0, fill_details[8])
            drg2_v_field.configure(state="disabled")
            drg4_v_field.configure(state="normal")
            drg4_v_field.insert(0, fill_details[13])
            drg4_v_field.configure(state="disabled")
            snap_v_field.configure(state="normal")
            snap_v_field.insert(0, fill_details[10])
            snap_v_field.configure(state="disabled")
            amhcc_v_field.configure(state="normal")
            amhcc_v_field.insert(0, fill_details[9])
            amhcc_v_field.configure(state="disabled")
            cost_weight_v_field.configure(state="normal")
            cost_weight_v_field.insert(0, fill_details[11])
            cost_weight_v_field.configure(state="disabled")
            srg_drg_v_field.configure(state="normal")
            srg_drg_v_field.insert(0, fill_details[12])
            srg_drg_v_field.configure(state="disabled")
            # Remove square brackets from list using str() + list slicing
            facilities_excluded = str(facilities_excluded_list)[1:-1]
            facilities_included = str(facilities_included_list)[1:-1]
            # call to start extraction iff
            #   1. the lhd, round, excluded facilities, dates and nwau of this run are different from saved details.
            #   2. previous run files exist
            prev_run_files_list = [
                "OutputFacility.csv",
                "OutputStay.csv",
                "OutputEdNwau.csv",
                "OutputAcuteNwau.csv",
                "OutputEpisodeAts.csv",
                "OutputWardEpisode.csv",
                "OutputEpisode.csv",
                "OutputEpisodeSrg.csv",
                "tbl_transit_episode_DRG4.csv",
                "OutputEpisodeDrg.csv",
                "Excluded_EpisodeAts_enddate_less_startdate.csv",
                "OutputWlExit.csv",
                "OutputDaysEpisode.csv",
                "tbl_PPM_transfer_Leave00.csv",
                "tbl_PPM_transfer_Leave02.csv",
                "PpmIcdDiagnoses.csv",
                "PpmIcdProcedures.csv",
                "PpmEdPatient.csv",
                "PpmEdEncounterPreclean.csv",
                "ED_Diag_Slice.csv",
                "OutputExcluded_ED_Encounters.csv",
                "OutputExcludedEncounters.csv",
                "tbl_PPM_Patient.csv",
            ]
            prev_run_files_exists = 1
            for index, files in enumerate(prev_run_files_list):
                file_path = "./ExtractorDB/" + files
                if os.path.isfile(file_path):
                    continue
                else:
                    prev_run_files_exists = 0  # prev_run_files_exists+1
            """
            if (pick_lhd == 'X830' or pick_lhd == 'X840' or pick_lhd == 'X850' or pick_lhd == 'X860' or lhd_global == 'X740'):
                if os.path.isfile("./ExtractorDB/OutputPatient.csv"):
                    prev_run_files_exists=prev_run_files_exists+1
            else:
                if os.path.isfile("./ExtractorDB/Patient_contact_details.csv"):
                    prev_run_files_exists=prev_run_files_exists+1   
            """
            # print("From config. lhd=",config['previous_exractor_run']['prev_lhd'],". excl. facilites=",config['previous_exractor_run']['prev_excluded_facilities'],". roundid=",config['previous_exractor_run']['prev_roundid'],". start_date=",config['previous_exractor_run']['prev_start_dt'],".\nend_date=",config['previous_exractor_run']['prev_end_dt'],". nwau_v=",config['previous_exractor_run']['prev_nwau'],".prev_run_files_exists=",prev_run_files_exists)
            # check if any files from previous run exist in ./ExtractorDB
            directory_path = "./ExtractorDB/"
            no_of_files = len(os.listdir(directory_path))
            # 16 Aug
            """
            if (
            pick_lhd == config['previous_exractor_run']['prev_lhd']
            and str(facilities_excluded_list) == str(config['previous_exractor_run']['prev_excluded_facilities'])
            and pick_round == config['previous_exractor_run']['prev_roundid']
            and str(start_date_date) == config['previous_exractor_run']['prev_start_dt']
            and str(end_date_date) == config['previous_exractor_run']['prev_end_dt']
            and fill_details[5] == config['previous_exractor_run']['prev_nwau']
            and prev_run_files_exists == 1
            and no_of_files > 0
            ): 
            """
            if (
                pick_lhd == config["previous_exractor_run"]["prev_lhd"]
                and str(facilities_excluded_list)
                == str(config["previous_exractor_run"]["prev_excluded_facilities"])
                and str(facilities_included_list)
                == str(config["previous_exractor_run"]["prev_included_facilities"])
                and pick_round == config["previous_exractor_run"]["prev_roundid"]
                and str(start_date) == config["previous_exractor_run"]["prev_start_dt"]
                and str(end_date) == config["previous_exractor_run"]["prev_end_dt"]
                and fill_details[5] == config["previous_exractor_run"]["prev_nwau"]
                and prev_run_files_exists == 1
                and no_of_files > 0
            ):
                prev_run_message = (
                    "Files for "
                    + pick_lhd
                    + " excluding facilities "
                    + str(facilities_excluded_list)
                    + ",\nround="
                    + pick_round
                    + ", start date="
                    + str(start_date)
                    + ", end date="
                    + str(end_date)
                    + ", NWAU="
                    + fill_details[5]
                    + " already exists.\nDo you wish to use the previously extracted files?"
                )
                extract_again_flag = messagebox.askyesno(
                    title="Files extracted", message=prev_run_message
                )
                if extract_again_flag == False:
                    # clear_output_dir('./temp_transform')
                    logging.info(
                        "Even though the user was given the option to use the previously extracted files, they opted to perform fresh extraction."
                    )
                    # 16 Aug
                    # start_extraction(pick_lhd, facilities_excluded, facilities_excluded_list, pick_round, str(start_date_date), str(end_date_date), fill_details[5], fill_details[6],fill_details[7], fill_details[8], fill_details[13], fill_details[10], fill_details[9], fill_details[11], fill_details[12])
                    start_extraction(
                        pick_lhd,
                        facilities_excluded,
                        facilities_excluded_list,
                        facilities_included,
                        facilities_included_list,
                        pick_round,
                        str(start_date),
                        str(end_date),
                        fill_details[5],
                        fill_details[6],
                        fill_details[7],
                        fill_details[8],
                        fill_details[13],
                        fill_details[10],
                        fill_details[9],
                        fill_details[11],
                        fill_details[12],
                    )
                else:
                    logging.info(
                        "The user selected the option to use previously extracted files for this run."
                    )
                    messagebox.showinfo(
                        "Files extracted",
                        "Previously extracted files for lhd = "
                        + pick_lhd
                        + " will be used for this run. \nPlease wait ...",
                        parent=main_screen,
                    )
                    # convert data in csv files to dataframes.
                    # Check if all csv files are read.
                    global \
                        tbl_dbo_Facility, \
                        tbl_dbo_stay, \
                        tbl_Patient_Contact_Details, \
                        tbl_dbo_episode_ats, \
                        tbl_dbo_Ward_Episode, \
                        tbl_dbo_episode, \
                        tbl_dbo_episode_srg, \
                        tbl_dbo_episode_DRG, \
                        tbl_dbo_wl_exit, \
                        ed_nwau, \
                        acute_nwau, \
                        tbl_dbo_days_episode, \
                        df_PpmTransferAmo, \
                        tbl_PPM_transfer_Leave_00, \
                        tbl_PPM_transfer_Leave02, \
                        tbl_PPM_ICD_diagnoses, \
                        tbl_PPM_ICD_procedures, \
                        tbl_ppm_ED_Patient, \
                        tbl_ppm_Patient, \
                        tbl_ppm_Encounter, \
                        tbl_ppm_ED_Encounter_preclean, \
                        df_ED_Diag_Slice, \
                        df_ExcludedEncounters, \
                        snapApp_CostingExtract, \
                        df_AMHCC_extract, \
                        df_SNAPRec, \
                        snap_NWAU, \
                        df_ICU_RoleDelin, \
                        df_PLA_Mapping_00, \
                        df_PLA_AMHCC, \
                        df_Class_Descriptions, \
                        df_SpecialtyPortalValues, \
                        df_MDC, \
                        pla_Role_Table, \
                        criticalcaregroup, \
                        specialtyPortalMapping, \
                        tbl_EDRoleDelin, \
                        tbl_ExcludedEncounters
                    # display extraction is complete and start transformations
                    extract_complete(
                        "prev_extract",
                        pick_lhd,
                        facilities_excluded_list,
                        facilities_included_list,
                        pick_round,
                        str(start_date),
                        str(end_date),
                        fill_details[5],
                        fill_details[6],
                        fill_details[7],
                        fill_details[8],
                        fill_details[13],
                        fill_details[10],
                        fill_details[9],
                        fill_details[11],
                        fill_details[12],
                    )
            else:
                logging.info(
                    "As the round details of the previous run is different from the present run, there will be a fresh extraction."
                )
                # clear_output_dir('./temp_transform')
                # 16 Aug
                # start_extraction(pick_lhd, facilities_excluded, facilities_excluded_list, pick_round, str(start_date_date), str(end_date_date), fill_details[5], fill_details[6], fill_details[7], fill_details[8], fill_details[13], fill_details[10], fill_details[9], fill_details[11], fill_details[12])
                start_extraction(
                    pick_lhd,
                    facilities_excluded,
                    facilities_excluded_list,
                    facilities_included,
                    facilities_included_list,
                    pick_round,
                    str(start_date),
                    str(end_date),
                    fill_details[5],
                    fill_details[6],
                    fill_details[7],
                    fill_details[8],
                    fill_details[13],
                    fill_details[10],
                    fill_details[9],
                    fill_details[11],
                    fill_details[12],
                )


def choose_round_nwau(pick_lhd, facilities_excluded_list, facilities_included_list):
    roundid_window = Toplevel(main_screen)
    # roundid_window.attributes('-topmost', 'true')
    roundid_window.geometry("%dx%d+%d+%d" % (500, 400, center_x1, center_y1))
    roundid_window.configure(bg="white")
    roundid_window.title("Start and End Date + NWAU Version")
    # Prevent window x and y to be rezizeable
    roundid_window.resizable(False, False)
    Label(
        roundid_window,
        text="Choose Round from drop down",
        font=("Times New Roman", 12),
        bg="white",
    ).place(x=75, y=25)
    # Combo box data from csv. Ref: https://www.plus2net.com/python/tkinter-Combobox-mysql.php
    round_details_file = open(".\costing\RoundDetails.csv", "r")
    headings = next(round_details_file)  # remove header row
    round_details_data_nl = [r for r in round_details_file]
    # Removing newline character from string
    round_details_data = []
    for sub in round_details_data_nl:
        round_details_data.append(sub.replace("\n", ""))
    round_id_list = []  # list to hold only round ids
    round_id_dict = {}  # dict to hold all details of the selected roundid
    for row in round_details_data:
        ## split each row on comma
        round_details = row.split(",")
        round_id_dict[round_details[1]] = row
        round_id_list.append(round_details[1])  # name as list

    def fill_mini_round_details(*args):  # *args is used to pass any number of arguments
        round_id = roundid_options.get()
        round_details = round_id_dict[round_id]
        # split the selected row
        fill_details = round_details.split(",")
        # fill start, end and nwau
        Label(
            roundid_window,
            text="Start Date (yyyy-mm-dd):",
            font=("Times New Roman", 12),
            bg="white",
        ).place(x=75, y=100)
        global start_date, end_date
        start_date = StringVar(roundid_window, value=fill_details[2])
        start_date_field = Entry(roundid_window, text=start_date)
        start_date_field.place(x=75, y=125)
        start_date_field.configure(state="normal")
        Label(
            roundid_window,
            text="End Date (yyyy-mm-dd):",
            font=("Times New Roman", 12),
            bg="white",
        ).place(x=75, y=175)
        # global end_date
        end_date = StringVar(roundid_window, value=fill_details[3])
        end_date_field = Entry(roundid_window, text=end_date)
        end_date_field.place(x=75, y=200)
        end_date_field.configure(state="normal")
        Label(
            roundid_window,
            text="NWAU Version:",
            font=("Times New Roman", 12),
            bg="white",
        ).place(x=75, y=250)
        nwau_v_field = Entry(roundid_window, text="")
        nwau_v_field.place(x=75, y=275)
        nwau_v_field.configure(state="normal")
        nwau_v_field.insert(0, fill_details[5])
        nwau_v_field.configure(state="disabled")

    roundid_options = StringVar(roundid_window)
    roundid_list_box = ttk.Combobox(
        roundid_window, values=round_id_list, textvariable=roundid_options
    ).place(x=75, y=50)
    roundid_options.trace("w", fill_mini_round_details)  # Call the function on change
    # start extracting button (on click, call fill_full_round_details
    start_extract_button = Button(
        roundid_window,
        text="Start extracting",
        command=lambda: fill_full_round_details(
            main_screen,
            roundid_window,
            roundid_options,
            round_id_dict,
            pick_lhd,
            start_date,
            end_date,
            facilities_excluded_list,
            facilities_included_list,
        ),
    ).place(x=125, y=350)
    round_details_file.close()  # close the file pointer


"""   
def destroy_lhd_window(main_screen, lhd_window, choose_lhd, facilities_excluded_list):
    #pick_lhd = choose_lhd.get()
    #print("facilities_excluded_list=",facilities_excluded_list)
    lhd_window.destroy()
    choose_round_nwau(choose_lhd, facilities_excluded_list)
"""


def destroy_excl_fac_window(excl_fac_window, lhd, excl_facility_box, facility_list):
    # pick_lhd = choose_lhd.get()
    # print("facilities_excluded_list=",facilities_excluded_list)
    global facilities_excluded_list
    facilities_excluded_list = []
    if len(facility_list) > 0:
        for index in excl_facility_box.curselection():
            facilities_excluded_list.append(str(excl_facility_box.get(index)))
    ###############################
    global facilities_included_list
    facilities_included_list = []
    facilities_included_list = [
        ele for ele in facility_list if ele not in facilities_excluded_list
    ]
    ###############################
    excl_fac_window.destroy()
    choose_round_nwau(lhd, facilities_excluded_list, facilities_included_list)


"""
def fac_listbox_used(event):
    # Ref: https://stackoverflow.com/a/67592924
    print("inside fac_listbox_used(), event=",event)
    for index in excl_facility_box.curselection():
        print(excl_facility_box.get(index)) ## Get current selection from listbox
"""


def lhd_selection_event(event):
    lhd = event
    # show only if user selected an LHD from drop down
    if lhd != "":
        logging.info("User selected LHD = %s", str(lhd))
        ########################
        messagebox.showinfo(
            "Verify facilities",
            "Please click OK ONLY after verifying (and correcting if required) the list of DNR reporting facilities in /dist/extractor/Costing/lhd_facility.csv.",
        )
        ########################
        lhd_window.destroy()
        #  Exclude facilities
        if source == "HIE":
            query_fetch_fac_list = (
                """SELECT dbo.FACILITY.facility_identifier 
            FROM dbo.FACILITY WHERE dbo.FACILITY.area_identifier = '"""
                + str(lhd)
                + """' and dbo.FACILITY.recognised_ph_flag='Y'
            ORDER BY dbo.FACILITY.facility_identifier"""
            )
        elif source == "EDW":
            # query_fetch_fac_list="""SELECT DISTINCT OSP_HIE_FAC_ID
            # FROM CRT.v_DIM_FST_RSP_OSP WHERE MG_AUTH_OSP_HIE_FAC_ID = '"""+str(lhd)+"""' and OSP_HIE_FAC_ID != '-1'
            # AND DIM_CURR_IND_FG = 1 AND OSP_HIE_FAC_ID is not null AND OSP_HIE_FAC_ID != '' AND MG_AUTH_OSP_HLTH_SECTOR = 'Public'
            # AND HLTH_ORG_OSP_HLTH_SECTOR = 'Public'
            # ORDER BY OSP_HIE_FAC_ID"""
            query_fetch_fac_list = (
                """SELECT DISTINCT OSP_HIE_FAC_ID 
            FROM CRT.v_DIM_OSP WHERE (MG_AUTH_OSP_HIE_FAC_ID ='"""
                + str(lhd)
                + """' OR OSP_HIE_FAC_ID = '"""
                + str(lhd)
                + """') 
            AND OSP_HIE_FAC_ID != ''
            ORDER BY OSP_HIE_FAC_ID"""
            )
        if source == "HIE":
            # execute query and fetch results
            fac_data = cursor.execute(query_fetch_fac_list)
            # create list of lhds from query results
            facility_list = [r for (r,) in fac_data]
        elif source == "EDW":
            ##################################
            file_path = "./Costing/lhd_facility_list.csv"
            if os.path.isfile(file_path):
                try:
                    df_facilities = read_csv_file(
                        file_path,
                        encoding="unicode_escape",
                        dtype=str,
                        keep_default_na=False,
                        na_values="",
                    )
                except Exception as e:
                    messagebox.showerror("showerror", str(e))
                    return
                else:
                    if len(df_facilities) > 0:
                        df_fil_facilities = df_facilities[
                            df_facilities["area_identifier"] == str(lhd)
                        ]
                        facility_list = df_fil_facilities[
                            "facility_identifier"
                        ].tolist()
            else:
                messagebox.showerror("showerror", "lhd_facility_list.csv not found.")
            ##################################
        if len(facility_list) > 0:
            # window to select odbc connection
            excl_fac_window = Toplevel(main_screen)
            # excl_fac_window.attributes('-topmost', 'true')
            excl_fac_window.geometry("%dx%d+%d+%d" % (500, 400, center_x1, center_y1))
            excl_fac_window.configure(bg="white")
            excl_fac_window.title("Exclude Facilities")
            # Prevent window x and y to be rezizeable
            excl_fac_window.resizable(False, False)
            Label(
                excl_fac_window,
                text="OPTIONAL\nSelect facilities to exclude under " + lhd,
                font=("Times New Roman", 12),
                bg="white",
            ).place(x=75, y=50)
            excl_facility_box = Listbox(
                excl_fac_window,
                width=40,
                height=5,
                selectmode="multiple",
                selectbackground="blue",
            )
            excl_facility_box.place(x=75, y=100)
            # Inserting the listbox items after end
            for fac in facility_list:
                excl_facility_box.insert(END, fac)
            """
            global facilities_excluded_list  
            facilities_excluded_list = []
            def fac_listbox_used(event):
                for index in excl_facility_box.curselection():
                    facilities_excluded_list.append(str(excl_facility_box.get(index)))
            # Ref: https://stackoverflow.com/a/67592924
            excl_facility_box.bind("<<ListboxSelect>>", fac_listbox_used)
            """
            exc_fac_select_button = Button(
                excl_fac_window,
                text="Proceed",
                command=lambda: destroy_excl_fac_window(
                    excl_fac_window, str(lhd), excl_facility_box, facility_list
                ),
            )
            exc_fac_select_button.place(x=100, y=200)
            """
            exc_fac_cancel_button = Button(excl_fac_window, text='Skip', command=lambda:destroy_excl_fac_window(excl_fac_window, str(lhd), excl_facility_box, facility_list))
            exc_fac_cancel_button.place(x=150,y= 200)
            """
        else:
            choose_round_nwau(str(lhd), [])


def select_lhd(main_screen, cursor, source):
    messagebox.showinfo("Querying", "Please wait for LHDs to load.")
    # window to choose LHD
    global lhd_window
    # Fetch list of LHDs from query
    # Ref: https://www.plus2net.com/python/tkinter-OptionMenu-proj3-mysql.php
    # Create OptionMenu from query results
    # Ref: https://www.plus2net.com/python/tkinter-OptionMenu-proj3-mysql.php
    if source == "HIE":
        query_fetch_lhd_list = """SELECT dbo.FACILITY.area_identifier 
        FROM dbo.STAY INNER JOIN dbo.FACILITY ON dbo.FACILITY.facility_identifier = dbo.STAY.facility_identifier 
        WHERE dbo.FACILITY.snap_curr_indicator = 'Y' 
        GROUP BY dbo.FACILITY.area_identifier ORDER BY dbo.FACILITY.area_identifier"""
    elif source == "EDW":
        query_fetch_lhd_list = """SELECT DISTINCT MG_AUTH_OSP_HIE_FAC_ID FROM CRT.v_DIM_FST_RSP_OSP WHERE OSP_HIE_FAC_ID != '-1' AND DIM_CURR_IND_FG = 1 AND MG_AUTH_OSP_HIE_FAC_ID !='-1' and 
        MG_AUTH_OSP_HIE_FAC_ID is not null AND MG_AUTH_OSP_HIE_FAC_ID != '' and ((MG_AUTH_OSP_HLTH_SECTOR_CD IN ('1','3')) and (HLTH_ORG_OSP_HLTH_SECTOR_CD IN ('1','3'))) order by MG_AUTH_OSP_HIE_FAC_ID;"""
    # execute query and fetch results
    lhd_data = cursor.execute(query_fetch_lhd_list)
    # Instead of showing a list of LHDs, pick a single LHD from file. Comment above code and uncomment below line
    # lhd_list = [config['pick_lhd']['lhd']]
    # create list of lhds from query results
    lhd_list = [r for (r,) in lhd_data]
    logging.info("List of lhds = %s", str(lhd_list))
    if len(lhd_list) == 0:
        messagebox.showinfo(
            "No LHD",
            "LHD could not be fetched from the database at this point. Please try again after some time.",
        )
        logging.info(
            "LHD could not be fetched from the database at this point. Please try again after some time."
        )
    else:
        lhd_window = Toplevel(main_screen)
        # lhd_window.attributes('-topmost', 'true')
        # lhd_window.geometry("400x300")
        lhd_window.geometry("%dx%d+%d+%d" % (500, 400, center_x1, center_y1))
        lhd_window.configure(bg="white")
        lhd_window.title("Select your LHD")
        # Prevent window x and y to be rezizeable
        lhd_window.resizable(False, False)
        Label(
            lhd_window, text="Select the LHD", font=("Times New Roman", 12), bg="white"
        ).place(x=75, y=50)
        #####################
        # Fetch list of LHDs from query
        # Ref: https://www.plus2net.com/python/tkinter-OptionMenu-proj3-mysql.php
        # Create OptionMenu from query results
        # Ref: https://www.plus2net.com/python/tkinter-OptionMenu-proj3-mysql.php
        # if source == 'HIE':
        # query_fetch_lhd_list="""SELECT dbo.FACILITY.area_identifier
        # FROM dbo.STAY INNER JOIN dbo.FACILITY ON dbo.FACILITY.facility_identifier = dbo.STAY.facility_identifier
        # WHERE dbo.FACILITY.snap_curr_indicator = 'Y'
        # GROUP BY dbo.FACILITY.area_identifier ORDER BY dbo.FACILITY.area_identifier"""
        # execute query and fetch results
        # lhd_data=cursor.execute(query_fetch_lhd_list)
        # Instead of showing a list of LHDs, pick a single LHD from file. Comment above code and uncomment below line
        # lhd_list = [config['pick_lhd']['lhd']]
        # create list of lhds from query results
        # lhd_list = [r for r, in lhd_data]
        # if len(lhd_list) ==0:
        #    messagebox.showinfo('No LHD','LHD could not be fetched from the database at this point. Please try again after some time.')
        #    lhd_window.destroy()
        # else:
        #####################
        # create a StringVar() and set the default value for the optionMenu.
        lhd_options = StringVar(lhd_window)
        lhd_options.set("")
        # Set the optionMenu and add the option values
        lhd_list_menu = OptionMenu(
            lhd_window, lhd_options, *lhd_list, command=lhd_selection_event
        )
        lhd_list_menu.place(x=75, y=75)


def check_table_access(main_screen, odbc_window, cursor, source):
    logging.info("Checking if the user has access to tables in %s", source)
    odbc_window.destroy()
    table_access_window = Toplevel(main_screen)
    # table_access_window.attributes('-topmost', 'true')
    table_access_window.geometry("%dx%d+%d+%d" % (500, 500, center_x1, center_y1))
    table_access_window.configure(bg="white")
    table_access_window.title("Permission denied")
    table_access_window.resizable(False, False)
    Label(
        table_access_window,
        text="Permission denied to below "
        + source
        + " tables. \n Please contact your manager for access.",
        font=("Times New Roman", 12),
        bg="white",
    ).place(x=100, y=25)
    # Ranjit: Check whether VIEWS should be considered, if tables are not accessible?
    if source == "HIE":
        table_list = [
            "dbo.DAYS_EPISODE",
            "dbo.DIAGNOSIS",
            "dbo.ED_DIAGNOSIS",
            "dbo.ED_DIAGNOSIS_SCT",
            "dbo.ED_NWAU",
            "dbo.EPISODE_ATS",
            "dbo.EPISODE_DRG",
            "dbo.EPISODE_NWAU",
            "dbo.EPISODE_SRG",
            "dbo.FACILITY",
            "dbo.PRACTICE",
            "dbo.SLA_AREA",
            "dbo.STAY",
            "dbo.WARD_EPISODE",
            "dbo.WL_EXIT",
            "dbo.PATIENT_CONTACT_DETAILS",
            "dbo.AMO_EPISODE",
            "dbo.AN_DRG",
            "dbo.BED",
            "dbo.BED_TYPE",
            "dbo.COUNTRY_OF_BIRTH",
            "dbo.CLINICAL_CODESET",
            "dbo.COUNTRY_SACC",
            "dbo.ED_VISIT EPISODE",
            "dbo.HIRD_REFERENCE",
            "dbo.LOCATION",
            "dbo.MEDPROC",
            "dbo.MORBIDITY_CODE",
            "dbo.PATIENT",
            "dbo.SERVICE_UNIT",
            "dbo.SNOMED_CT_CODE",
            "dbo.SPECIALTY",
            "dbo.WARD",
        ]
    else:
        table_list = ["CRT.v_DIM_WAU_VER"]
    all_table_access = 1
    ht = 3
    for index, table in enumerate(table_list):
        try:
            cursor.execute("SELECT count(1) FROM " + table)
        except pyodbc.Error as ex:
            logging.exception("Exception occurred")
            all_table_access = 0
            Label(
                table_access_window,
                text=table,
                font=("Times New Roman", 10),
                bg="white",
            ).place(x=75, y=30 * ht)
            Label(
                table_access_window,
                text="...No",
                font=("Times New Roman", 10),
                bg="white",
                fg="red",
            ).place(x=300, y=30 * ht)
            ht = ht + 1
        else:
            logging.info("User has access to %s", table)
    if all_table_access == 1:
        # Button(table_access_window, text='Proceed', state=NORMAL, command=lambda:select_lhd(main_screen, cursor, source)).place(x=225, y=450)
        table_access_window.destroy()
        select_lhd(main_screen, cursor, source)
    else:
        Button(
            table_access_window,
            text="Cancel",
            state=NORMAL,
            command=table_access_window.destroy,
        ).place(x=225, y=450)


def validateLogin_HIE(
    main_screen, login_window, username, password, selected_driver, source
):
    # This function is not used for DSN login
    server = "htu055.htech.health.nsw.gov.au,6600"  # HIE
    database = "HSPREP"  # HIE
    connection_string = (
        "Driver={"
        + selected_driver
        + "};NA="
        + server
        + ";DB="
        + database
        + ";UID="
        + str(username.get())
        + ";PWD="
        + str(password.get())
    )  # HIE
    logging.info("connection_string= %s.", connection_string)
    login_window.destroy()
    global cnxn
    global cursor
    # Ref: https://stackoverflow.com/a/42143703
    try:
        cnxn = pyodbc.connect(connection_string)
    except Exception as ex:  # pyodbc.Error as ex: # for HIE
        logging.exception("Exception occurred")
        # Ref: https://stackoverflow.com/a/61000557
        # sqlstate = ex.args[1]
        # sqlstate = sqlstate.split(".")
        # messagebox.showerror("Error","This ODBC connection is not configured correctly.\nPlease review its configuration or select a new connection.\n\nDetails:"+sqlstate[-2])
        messagebox.showerror(
            "Error",
            "This ODBC connection is not configured correctly.\nPlease review its configuration or select a new connection.\n\nDetails:"
            + str(ex),
        )
    else:
        cursor = cnxn.cursor()
        logging.info("Login to HIE is successful")
        messagebox.showinfo("Login Success", "Login to HIE is successful.")
        # ## Place to check access to dbo tables
        messagebox.showinfo("Login Success", "Please wait for LHDs to load.")
        select_lhd(main_screen, cursor, source)


def connect_odbc_HIE(main_screen, odbc_window, selected_driver, source):
    selected_driver = selected_driver.get()
    odbc_window.destroy()
    # if not using DSN but driver list, then use the below commented algorithm
    connection_string = "DSN=" + selected_driver + ";"  # HIE  using DSN
    global cnxn
    global cursor
    try:
        cnxn = pyodbc.connect(connection_string)
    except Exception as ex:  # pyodbc.Error as ex: # for HIE
        logging.exception("Exception occurred")
        # Ref: https://stackoverflow.com/a/61000557
        # sqlstate = ex.args[1]
        # sqlstate = sqlstate.split(".")
        # messagebox.showerror("Error","This ODBC connection is not configured correctly.\nPlease review its configuration or select a new connection.\n\nDetails:"+sqlstate[-2])
        messagebox.showerror(
            "Error",
            "This ODBC connection is not configured correctly.\nPlease review its configuration or select a new connection.\n\nDetails:"
            + str(ex),
        )
    else:
        cursor = cnxn.cursor()
        query_fetch_lhd_list = (
            """SELECT dbo.FACILITY.area_identifier FROM dbo.FACILITY;"""
        )
        try:
            lhd_data = cursor.execute(query_fetch_lhd_list)
        except Exception as ex1:
            logging.info("Error in testing HIE connection.")
            messagebox.showerror(
                "Error", "Error in testing HIE connection.\nDetails:" + str(ex1)
            )
        else:
            lhd_list = [r for (r,) in lhd_data]
            if len(lhd_list) > 0:
                logging.info("Login to HIE is successful")
                messagebox.showinfo(
                    "Login Success",
                    "Login to HIE (Server=htu055.htech.health.nsw.gov.au, Database=HSPREP) is successful.",
                )
                check_table_access(main_screen, odbc_window, cursor, source)
            else:
                logging.info(
                    "Login to HIE is successful. However, no lhds were returned."
                )
                messagebox.showerror(
                    "Error", "Error in testing HIE connection. No LHDs returned."
                )


def connect_odbc_EDW(main_screen, odbc_window, selected_driver, source):
    selected_driver = selected_driver.get()
    # connection_string = 'DRIVER={'+selected_driver+'};SERVER=AZMHEDW-P01UDM.NSWHEALTH.NET,1433;DATABASE=LRS_MOH' # EDW  using Driver
    connection_string = "DSN=" + selected_driver + ";"  # EDW  using DSN
    odbc_window.destroy()
    global cnxn
    global cursor
    # Ref: https://stackoverflow.com/a/42143703
    try:
        cnxn = pyodbc.connect(connection_string)
    except Exception as ex:  # pyodbc.Error as ex: # for EDW
        logging.exception("Exception occurred")
        # Ref: https://stackoverflow.com/a/61000557
        # sqlstate = ex.args[1]
        # sqlstate = sqlstate.split(".")
        # messagebox.showerror("Error","This ODBC connection to EDW is not configured correctly.\nPlease review its configuration or select a new connection.\n\nDetails:"\
        # +sqlstate[-2]+"\n1. Check if SQL Driver is installed\n2. Check if you have access to the server (hosting EDW) with your windows credentials")
        messagebox.showerror(
            "Error",
            "This ODBC connection is not configured correctly.\nPlease review its configuration or select a new connection.\n\nDetails:"
            + str(ex),
        )
    else:
        cursor = cnxn.cursor()
        query_fetch_lhd_list = """select DISTINCT MG_AUTH_OSP_HIE_FAC_ID from CRT.v_DIM_FST_RSP_OSP where MG_AUTH_OSP_HIE_FAC_ID is not null AND MG_AUTH_OSP_HIE_FAC_ID != '' order by MG_AUTH_OSP_HIE_FAC_ID;"""
        try:
            lhd_data = cursor.execute(query_fetch_lhd_list)
        except Exception as ex2:
            logging.info("Error in testing EDW connection.")
            logging.info(str(ex2))
            messagebox.showerror(
                "Error", "Error in testing EDW connection.\nDetails:" + str(ex2)
            )
        else:
            lhd_list = [r for (r,) in lhd_data]
            if len(lhd_list) > 0:
                logging.info("Login to EDW is successful")
                messagebox.showinfo(
                    "Login Success",
                    "Login to EDW is successful.\nIf you want to see the Server and Database details for the chosen DSN, please open ODBC Administrator (C:\Windows\System32\odbcad32.exe).",
                )
                check_table_access(main_screen, odbc_window, cursor, source)
            else:
                logging.info(
                    "Login to EDW is successful. However, no lhds were returned."
                )
                messagebox.showerror(
                    "Error", "Error in testing EDW connection. No LHDs returned."
                )


def select_odbc(main_screen, source_window, source_options):
    global source
    source = source_options.get()
    logging.info("User selected%s as source", source)
    source_window.destroy()
    if len(drivers_list) > 0:
        # window to select odbc connection
        odbc_window = Toplevel(main_screen)
        # odbc_window.attributes('-topmost', 'true')
        # odbc_window.geometry("400x250")
        odbc_window.geometry("%dx%d+%d+%d" % (500, 400, center_x1, center_y1))
        odbc_window.configure(bg="white")
        odbc_window.title("Connection Select Window ")
        # Prevent window x and y to be rezizeable
        odbc_window.resizable(False, False)
        Label(
            odbc_window,
            text="Select an ODBC Connection",
            font=("Times New Roman", 12),
            bg="white",
        ).place(x=75, y=50)
        # display list of odbc connection
        odbc_options = StringVar(odbc_window)
        odbc_options.set("")
        if source == "HIE":
            # Disable Select button based on null odbc connection
            # Option 1: use driver to connect
            odbc_select_button = Button(
                odbc_window,
                text="Select",
                state=DISABLED,
                command=lambda: connect_odbc_HIE(
                    main_screen, odbc_window, odbc_options, "HIE"
                ),
            )  # for HIE
        else:
            odbc_select_button = Button(
                odbc_window,
                text="Select",
                state=DISABLED,
                command=lambda: connect_odbc_EDW(
                    main_screen, odbc_window, odbc_options, "EDW"
                ),
            )  # for EDW
        odbc_select_button.place(x=125, y=200)
        # Show odbc option menu
        odbc_menu = OptionMenu(
            odbc_window,
            odbc_options,
            *drivers_list,
            command=lambda _: changeState(odbc_select_button, odbc_options),
        ).place(x=75, y=75)
    else:
        logging.info(
            "ERROR: User does not have any 64 bit drivers installed in this machine"
        )
        messagebox.showerror(
            "Error",
            "You do not have any 64 bit drivers installed in this machine. Please install 64bit driver to proceed.",
        )


def select_source(file_exist_window):
    if len(os.listdir("./Output/")) > 0:
        if messagebox.askyesno(
            "Delete files",
            "This will delete all output files from \ Output\ directory, generated from the previous run.\nDo you wish to proceed?",
        ):
            clear_output_dir("./Output")
            """
            if messagebox.askyesno("Delete files", "This will delete all output files from \Output\ directory, generated from the previous run.\nDo you wish to proceed?"):
                clear_output_dir('./Output')
            """
            file_exist_window.destroy()
            # Choose HIE or EDW screen
            source_window = Toplevel(main_screen)
            # source_window.attributes('-topmost', 'true')
            source_window.geometry("%dx%d+%d+%d" % (300, 300, center_x1, center_y1))
            source_window.configure(bg="white")
            source_window.title("Select Source")
            source_window.resizable(False, False)
            Label(
                source_window,
                text="Select source",
                font=("Times New Roman", 12),
                bg="white",
            ).place(x=75, y=50)
            source_options = StringVar(source_window)
            source_options.set("")
            source_select_button = Button(
                source_window,
                text="Select",
                command=lambda: select_odbc(main_screen, source_window, source_options),
            )
            source_select_button.place(x=125, y=150)
            # Show source option menu
            source_menu = OptionMenu(source_window, source_options, *source_list).place(
                x=75, y=75
            )
        else:
            file_exist_window.destroy()
    else:
        file_exist_window.destroy()
        # Choose HIE or EDW screen
        source_window = Toplevel(main_screen)
        # source_window.attributes('-topmost', 'true')
        source_window.geometry("%dx%d+%d+%d" % (300, 300, center_x1, center_y1))
        source_window.configure(bg="white")
        source_window.title("Select Source")
        source_window.resizable(False, False)
        Label(
            source_window,
            text="Select source",
            font=("Times New Roman", 12),
            bg="white",
        ).place(x=75, y=50)
        source_options = StringVar(source_window)
        source_options.set("")
        source_select_button = Button(
            source_window,
            text="Select",
            command=lambda: select_odbc(main_screen, source_window, source_options),
        )
        source_select_button.place(x=125, y=150)
        # Show source option menu
        source_menu = OptionMenu(source_window, source_options, *source_list).place(
            x=75, y=75
        )


def check_if_col_exist(files, df_check, col_list):
    # Check for multiple columns all exist Using set.issubset
    # if set(col_list).issubset(df_check.columns):
    mandatory_col = sorted(col_list)
    if (
        (files == "EDRoleDelin.csv")
        or (files == "SpecialityPortalMapping.csv")
        or (files == "PLA_Role_Table.csv")
        or (files == "CriticalCareGroup.csv")
    ):
        updated_col = [
            "HLTH_ORG_OSP_OSP_ID",
            "MG_AUTH_OSP_OSP_ID",
            "SE_CBK_SK",
        ] + mandatory_col
    elif files == "Tbl_PPM_transfer_AMO.csv":
        updated_col = [
            "HLTH_ORG_OSP_OSP_ID",
            "MG_AUTH_OSP_OSP_ID",
            "SE_CBK_SK",
            "DIM_RSP_ISP_SK",
        ] + mandatory_col
    else:
        updated_col = mandatory_col
    updated_col_sorted = sorted(updated_col)
    file_col = sorted(df_check.columns.values.tolist())
    # print(col_list.sort(),df_check.columns.values.tolist().sort())
    # if col_list.sort()==df_check.columns.values.tolist().sort():
    if (mandatory_col == file_col) or (updated_col_sorted == file_col):
        all_col_present = 1
    else:
        all_col_present = 0
        logging.info("mandatory columns -> %s ", mandatory_col)
        logging.info("updated_col columns -> %s ", updated_col)
        logging.info("columns in file -> %s ", file_col)
    # if all_col_present == 0:
    #    print("set(col_list)=",set(col_list),"\nset(df_check.columns.values.tolist())=",set(df_check.columns.values.tolist()),"\nall_col_present=",all_col_present)
    return all_col_present, updated_col_sorted


def check_initial_files_exist(main_screen):
    #################CHECK IF we need to reload snap data from SNAP app ################################
    # Access query: qry SNAP Encounters Imported
    """SELECT Count(snapApp_CostingExtract.EncounterNumber) AS SNAPEncountersImported, snapApp_CostingExtract.[Grouped Status]
    FROM snapApp_CostingExtract
    WHERE (((snapApp_CostingExtract.FacilityCode) Is Not Null))
    GROUP BY snapApp_CostingExtract.[Grouped Status]
    HAVING (((snapApp_CostingExtract.[Grouped Status])="Grouped"));"""

    # Access query: SNAPREC01
    """SELECT SNAPREC.LHD, SNAPREC.[Grouped Status], Sum(SNAPREC.[In Scope Episodes/Phases]) AS [In Scope Episodes/Phases]
    FROM SNAPREC
    GROUP BY SNAPREC.LHD, SNAPREC.[Grouped Status]
    HAVING (((SNAPREC.[Grouped Status])="Grouped"));"""

    # Access query: qry SNAP Reconciliation
    """SELECT [SNAPREC 01].LHD, [SNAPREC 01].[Grouped Status], [SNAPREC 01].[In Scope Episodes/Phases], [qry SNAP Encounters Imported].SNAPEncountersImported, Nz([SNAPEncountersImported])-Nz([In Scope Episodes/Phases]) AS Variance
    FROM [qry SNAP Encounters Imported], [SNAPREC 01]
    WHERE ((([SNAPREC 01].[Grouped Status])="Grouped"));"""
    # 21 Jan 2025 - COMMENTED bcos now we have one big file. will do it later release
    """
    if os.path.isfile("./Costing/SNAP_CostingExtract.xls") & os.path.isfile("./Costing/SNAPRec.xls"):
        # Access query: qry SNAP Encounters Imported
        df_qry_SNAP_Encounters_Imported = pd.read_excel("./Costing/SNAP_CostingExtract.xls", keep_default_na=False)
        df_qry_SNAP_Encounters_Imported = df_qry_SNAP_Encounters_Imported[['EncounterNumber', 'Grouped Status']][(((pd.notna(df_qry_SNAP_Encounters_Imported['FacilityCode'])) & (df_qry_SNAP_Encounters_Imported['FacilityCode']!='')) | \
        (df_qry_SNAP_Encounters_Imported['FacilityCode']!='')) & (df_qry_SNAP_Encounters_Imported['Grouped Status'] == 'Grouped')] 
        df_qry_SNAP_Encounters_Imported = df_qry_SNAP_Encounters_Imported.groupby(['Grouped Status'], as_index=False, dropna=False).agg(SNAPEncountersImported=("EncounterNumber", "count")).reset_index()
        df_qry_SNAP_Encounters_Imported = df_qry_SNAP_Encounters_Imported[['SNAPEncountersImported', 'Grouped Status']]
        # Access query: SNAPREC01
        df_SNAPREC01 = pd.read_excel("./Costing/SNAPRec.xls", keep_default_na=False)
        df_SNAPREC01 = df_SNAPREC01[['Grouped Status', 'In Scope Episodes/Phases']][(df_SNAPREC01['Grouped Status'] == 'Grouped')]
        df_SNAPREC01 = df_SNAPREC01.groupby(['Grouped Status'], as_index=False, dropna=False).agg(inscope=("In Scope Episodes/Phases", "sum")).reset_index()
        df_SNAPREC01 = df_SNAPREC01[['Grouped Status', 'inscope']]
        df_SNAPREC01.rename(columns = {'inscope':'In Scope Episodes/Phases'}, inplace = True)
        # Access query: qry SNAP Reconciliation 
        df_qry_SNAP_Reconciliation = pd.merge(df_qry_SNAP_Encounters_Imported, df_SNAPREC01, how='inner', on=['Grouped Status'], suffixes=('', '_drop'))
        df_qry_SNAP_Reconciliation = df_qry_SNAP_Reconciliation.apply(lambda x: x.replace(regex=r'^nan$', value='') if x.dtype == 'object' else x)
        df_qry_SNAP_Reconciliation['Variance'] = df_qry_SNAP_Reconciliation['SNAPEncountersImported'] - df_qry_SNAP_Reconciliation['In Scope Episodes/Phases']
        #df_qry_SNAP_Reconciliation = df_qry_SNAP_Reconciliation[['LHD', 'Grouped Status', 'In Scope Episodes/Phases', 'SNAPEncountersImported', 'Variance']]
        df_qry_SNAP_Reconciliation = df_qry_SNAP_Reconciliation[['Variance']]

        
        data_list = df_qry_SNAP_Reconciliation.values.tolist()
        if len(df_qry_SNAP_Reconciliation[(df_qry_SNAP_Reconciliation['Variance']!=0)])>0:
            logging.info('The variance between the SNAP Costing Extract File and the SNAP Report is > 0. Please check the SNAP_App to ensure you have loaded all the encounters.')
            text_entry = "Please check the SNAP_App to ensure you have loaded all the encounters.\nThe variance between the SNAP Costing Extract File and the SNAP Report is greater than 0. "
            messagebox.showinfo("SNAP Variance", text_entry) 
        else:
            logging.info('The variance between the SNAP Costing Extract File and the SNAP Report is = 0')
            text_entry="The variance between the SNAP Costing Extract File and the SNAP Report = 0"
            messagebox.showinfo("SNAP Variance", text_entry) 
    """
    ###################
    logging.info("Checking if mandatory files exist")
    file_exist_window = Toplevel(main_screen)
    # file_exist_window.attributes('-topmost', 'true')
    file_exist_window.geometry("%dx%d+%d+%d" % (700, 500, center_x1, center_y1))
    file_exist_window.configure(bg="white")
    file_exist_window.title("Check if files exist")
    file_exist_window.resizable(False, False)
    # check if tbl_ExcludedEncounters.CSV is mandatory.
    # Ranjit: Check if all these files are required to be mandatory and non-empty
    Label(
        file_exist_window,
        text="Missing or Empty files in ./Costing folder",
        font=("Times New Roman", 12),
        bg="white",
    ).place(x=200, y=25)
    files_list = [
        "Class_Descriptions.csv",
        "CriticalCareGroup.csv",
        "DRGStandardWeights.csv",
        "EDRoleDelin.csv",
        "ICU_RoleDelin.csv",
        "PLA_AMHCC.csv",
        "PLA_Mapping_00.csv",
        "PLA_Role_Table.csv",
        "RoundDetails.csv",
        "SNAPStandardWeights.csv",
        "SpecialityPortalMapping.csv",
        "SpecialtyPortal.txt",
        "tbl_ExcludedEncounters.csv",
        "Tbl_PPM_transfer_AMO.csv",
    ]
    # all_files_exists = 0
    all_files_exists = 1
    ht = 3
    for index, files in enumerate(files_list):
        file_path = "./Costing/" + files
        logging.info("File=%s", file_path)
        # ht = (index+1)*25
        # Label(file_exist_window, text=files, font=("Times New Roman", 10), bg='white').place(x=75,y= 25+ht)
        if os.path.isfile(file_path):
            # Label(file_exist_window, text="...EXISTS", font=("Times New Roman", 10), bg='white', fg='green').place(x=300,y=25+ht)
            # all_files_exists=all_files_exists+1
            logging.info("File=%s EXISTS", file_path)
            try:
                df_check = read_csv_file(
                    file_path,
                    encoding="unicode_escape",
                    dtype=str,
                    keep_default_na=False,
                    na_values="",
                )
            except pd.errors.EmptyDataError:
                logging.exception("Exception occurred")
                # File is present with no header, i.e. 0 KB file
                all_files_exists = 0
                Label(
                    file_exist_window,
                    text=files,
                    font=("Times New Roman", 10),
                    bg="white",
                ).place(x=75, y=30 * ht)
                Label(
                    file_exist_window,
                    text="...EMPTY FILE",
                    font=("Times New Roman", 10),
                    bg="white",
                    fg="red",
                ).place(x=300, y=30 * ht)
                ht = ht + 1
            else:
                if len(df_check) > 1:
                    if files == "Class_Descriptions.csv":
                        all_col_present, col_list = check_if_col_exist(
                            files, df_check, ["Code", "Description", "Version"]
                        )
                    elif files == "CriticalCareGroup.csv":
                        all_col_present, col_list = check_if_col_exist(
                            files,
                            df_check,
                            [
                                "facility_identifier",
                                "ward_identifier",
                                "ward_name",
                                "unit_type",
                                "NSW_Role_Delineation",
                                "College_Intensive_Care_Medicine_Role_Delineation",
                                "CritGroup",
                                "area_identifier",
                                "PPMWardUnit",
                            ],
                        )
                    elif files == "DRGStandardWeights.csv":
                        # print("DRGStandardWeights=", df_check.columns.values.tolist())
                        all_col_present, col_list = check_if_col_exist(
                            files,
                            df_check,
                            [
                                "CLINLABUC",
                                "PROSPUBUC",
                                "SUPPLYUC",
                                "MRIC",
                                "SPTHERUC",
                                "DRG_VERSION",
                                "ANGIOC",
                                "ORPUBXMC",
                                "ALLIEDUC",
                                "CTC",
                                "SUPPLYC",
                                "DRG_CODE",
                                "OTUC",
                                "snapallied",
                                "PHARMSTR",
                                "snapother",
                                "INTERRADC",
                                "RADC",
                                "NUCMEDC",
                                "snapsupply",
                                "ICU",
                                "SPTHERC",
                                "ORPUBC",
                                "ULTSNDC",
                                "HITHNURSE",
                                "NURSEUC",
                                "SOCIALWC",
                                "HITHALLIED",
                                "snapnurse",
                                "NURSEUC_SA",
                                "SOCIALWUC",
                                "PHYSIOC",
                                "NUTRDIETC",
                                "GENRADC",
                                "OTC",
                                "PharmUC",
                                "snappath",
                                "ALLIEDC",
                                "ONE",
                                "ORPUBUC",
                                "GENRADUC",
                                "snapimag",
                                "NUTRDIETUC",
                                "HITHMSS",
                                "CCU",
                                "CLINLABC",
                                "PROSPUBC",
                                "PHYSIOUC",
                                "CritUC",
                                "HITHDRUGS",
                                "NICU",
                                "snapdrugs",
                            ],
                        )
                        # print(df_check.columns)
                    elif files == "EDRoleDelin.csv":
                        all_col_present, col_list = check_if_col_exist(
                            files,
                            df_check,
                            [
                                "facility_identifier",
                                "facility_name",
                                "EmergRoleDelin",
                                "area_identifier",
                            ],
                        )
                    elif files == "ICU_RoleDelin.csv":
                        all_col_present, col_list = check_if_col_exist(
                            files,
                            df_check,
                            [
                                "Hospital",
                                "NSW Role Delineation",
                                "College Intensive Care Medicine Role Delineation",
                                "CICM Role Delineation Self Reported",
                            ],
                        )
                    elif files == "PLA_AMHCC.csv":
                        # print("PLA_AMHCC=", df_check.columns.values.tolist())
                        # print(df_check.columns)
                        all_col_present, col_list = check_if_col_exist(
                            files,
                            df_check,
                            ["PLACode", "ClassDescription", "ClassCode"],
                        )
                    elif files == "PLA_Mapping_00.csv":
                        all_col_present, col_list = check_if_col_exist(
                            files,
                            df_check,
                            [
                                "episode_of_care_type",
                                "spec Role",
                                "Ward Role",
                                "PLA",
                                "PsychDays",
                                "HospRole",
                            ],
                        )
                    elif files == "PLA_Role_Table.csv":
                        all_col_present, col_list = check_if_col_exist(
                            files,
                            df_check,
                            ["Role", "RoleType", "HospID", "Ward", "Speciality", "LHD"],
                        )
                    elif files == "RoundDetails.csv":
                        all_col_present, col_list = check_if_col_exist(
                            files,
                            df_check,
                            [
                                "RoundID",
                                "RoundVersion",
                                "StartDate",
                                "EndDate",
                                "RoundVersionDisplay",
                                "NWAUVersion",
                                "ICDVersion",
                                "DRG1Version",
                                "DRG2Version",
                                "AMHCCVersion",
                                "SNAPVersion",
                                "CostWeightVersion",
                                "SRG_DRGVersion",
                                "DRG4Version",
                            ],
                        )
                    elif files == "SNAPStandardWeights.csv":
                        all_col_present, col_list = check_if_col_exist(
                            files,
                            df_check,
                            [
                                "DRG_VERSION",
                                "DRG_CODE",
                                "AvgOfsnapallied",
                                "AvgOfsnappath",
                                "AvgOfsnapimag",
                                "AvgOfsnapnurse",
                                "AvgOfsnapdrugs",
                                "AvgOfsnapsupply",
                                "AvgOfsnapother",
                            ],
                        )
                    elif files == "SpecialityPortalMapping.csv":
                        all_col_present, col_list = check_if_col_exist(
                            files,
                            df_check,
                            [
                                "area_identifier",
                                "Hospital",
                                "Clinic",
                                "SpecialityPortal",
                            ],
                        )
                    elif files == "SpecialtyPortal.txt":
                        all_col_present, col_list = check_if_col_exist(
                            files, df_check, ["Value"]
                        )
                    elif files == "tbl_ExcludedEncounters.txt":
                        all_col_present, col_list = check_if_col_exist(
                            files,
                            df_check,
                            [
                                "facility_identifier",
                                "Stay_number",
                                "episode_sequence_number",
                                "Ed_identifier",
                                "SNAP_encounter",
                                "Reason For Exclusion",
                                "EncounterNumber",
                            ],
                        )
                    elif files == "tbl_ExcludedEncounters.csv":
                        all_col_present, col_list = check_if_col_exist(
                            files,
                            df_check,
                            [
                                "facility_identifier",
                                "stay_number",
                                "episode_sequence_number",
                                "ed_identifier",
                                "SNAP_encounter",
                                "ReasonForExclusion",
                                "EncounterNumber",
                            ],
                        )
                    elif files == "Tbl_PPM_transfer_AMO.csv":
                        # print("amo=", df_check.columns.values.tolist())
                        # print(df_check.columns)
                        all_col_present, col_list = check_if_col_exist(
                            files,
                            df_check,
                            [
                                "LHD",
                                "clinician_name",
                                "facility_identifier",
                                "Consultant_Status",
                                "mo_code",
                                "Code",
                            ],
                        )  # exclude consultant_status
                    # If all cols are present, then it is a pass
                    if all_col_present:
                        logging.info(
                            "In file=%s, these columns exist -> %s ", files, col_list
                        )
                        continue
                    else:
                        # if all columns are not present, use the same flag 'all_files_exists'
                        logging.info(
                            "File=%s all required columns are not present", files
                        )
                        all_files_exists = 0
                        Label(
                            file_exist_window,
                            text=files,
                            font=("Times New Roman", 10),
                            bg="white",
                        ).place(x=75, y=30 * ht)
                        Label(
                            file_exist_window,
                            text="...NOT ALL REQUIRED COLUMNS PRESENT",
                            font=("Times New Roman", 10),
                            bg="white",
                            fg="red",
                        ).place(x=300, y=30 * ht)
                        ht = ht + 1
                else:
                    # File is present with only header
                    # comment if files can be empty
                    # all_files_exists = 0
                    logging.info("File=%s exists, but it is empty", file_path)
                    Label(
                        file_exist_window,
                        text=files,
                        font=("Times New Roman", 10),
                        bg="white",
                    ).place(x=75, y=30 * ht)
                    Label(
                        file_exist_window,
                        text="...NO DATA",
                        font=("Times New Roman", 10),
                        bg="white",
                        fg="blue",
                    ).place(x=300, y=30 * ht)
                    ht = ht + 1
        else:
            logging.info("File=%s does NOT EXIST", file_path)
            all_files_exists = 0
            Label(
                file_exist_window, text=files, font=("Times New Roman", 10), bg="white"
            ).place(x=75, y=30 * ht)
            Label(
                file_exist_window,
                text="...NOT FOUND",
                font=("Times New Roman", 10),
                bg="white",
                fg="red",
            ).place(x=300, y=30 * ht)
            ht = ht + 1
    ### Check optional file list
    optional_files_list = [
        "SNAP_CostingExtract.xlsx",
        "SNAP_NWAU.xlsx",
        "SNAPRec.xls",
        "SNAPStandardWeights.csv",
        "AMHCC_Extract.csv",
    ]
    for index, opt_files in enumerate(optional_files_list):
        opt_file_path = "./Costing/" + opt_files
        if os.path.isfile(opt_file_path):
            try:
                if (
                    opt_files == "SNAPStandardWeights.csv"
                    or opt_files == "AMHCC_Extract.csv"
                ):
                    df_check = read_csv_file(
                        opt_file_path,
                        encoding="unicode_escape",
                        dtype=str,
                        keep_default_na=False,
                        na_values="",
                    )
                else:
                    df_check = pd.read_excel(opt_file_path, keep_default_na=False)
            except pd.errors.EmptyDataError:
                logging.exception("Exception occurred")
                # File is present with no header, i.e. 0 KB file
                Label(
                    file_exist_window,
                    text=opt_files,
                    font=("Times New Roman", 10),
                    bg="white",
                ).place(x=75, y=30 * ht)
                Label(
                    file_exist_window,
                    text="...EMPTY OPTIONAL FILE",
                    font=("Times New Roman", 10),
                    bg="white",
                    fg="blue",
                ).place(x=300, y=30 * ht)
                ht = ht + 1
            else:
                if len(df_check) == 0:
                    logging.info("File=%s exists, but it is empty", opt_file_path)
                    Label(
                        file_exist_window,
                        text=opt_files,
                        font=("Times New Roman", 10),
                        bg="white",
                    ).place(x=75, y=30 * ht)
                    Label(
                        file_exist_window,
                        text="...EMPTY OPTIONAL FILE",
                        font=("Times New Roman", 10),
                        bg="white",
                        fg="blue",
                    ).place(x=300, y=30 * ht)
                    ht = ht + 1
        else:
            logging.info("File=%s does not exist", opt_file_path)
            Label(
                file_exist_window,
                text=opt_files,
                font=("Times New Roman", 10),
                bg="white",
            ).place(x=75, y=30 * ht)
            Label(
                file_exist_window,
                text="...NOT FOUND (OPTIONAL)",
                font=("Times New Roman", 10),
                bg="white",
                fg="blue",
            ).place(x=300, y=30 * ht)
            ht = ht + 1
    """    
    Label(file_exist_window, text="Variance b/w SNAP Costing Extract and SNAP Rec= ", font=("Times New Roman", 10), bg='white').place(x=75,y= 30*ht)
    if len(df_qry_SNAP_Reconciliation[(df_qry_SNAP_Reconciliation['Variance']!=0)])>0:
        logging.info('The SNAP files were successfully imported from .\costing. The variance between the SNAP Costing Extract File and the SNAP Report is %s. Please check the SNAP_App to ensure you have loaded all the encounters.',len(df_qry_SNAP_Reconciliation[(df_qry_SNAP_Reconciliation['Variance']!=0)]))
        Label(file_exist_window, text=str(len(df_qry_SNAP_Reconciliation[(df_qry_SNAP_Reconciliation['Variance']!=0)])+". \nCheck the SNAP_App to ensure you have loaded all encounters"), \
        font=("Times New Roman", 10), bg='white', fg='red').place(x=300,y=30*ht)
    else:
        logging.info('The SNAP files were successfully imported from .\costing. The variance between the SNAP Costing Extract File and the SNAP Report is %s.',len(df_qry_SNAP_Reconciliation[(df_qry_SNAP_Reconciliation['Variance']!=0)]))
        Label(file_exist_window, text=str(len(df_qry_SNAP_Reconciliation[(df_qry_SNAP_Reconciliation['Variance']!=0)])), font=("Times New Roman", 10), bg='white', fg='green').place(x=300,y=30*ht)
    ht = ht+1
    """
    ###################
    if all_files_exists == 1:
        Label(
            file_exist_window,
            text="There are no missing or empty mandatory files. ",
            font=("Times New Roman", 10),
            bg="white",
            fg="green",
        ).place(x=200, y=30 * ht)
        logging.info("All the required files exist and are not empty")
        Button(
            file_exist_window,
            text="Proceed",
            state=NORMAL,
            command=lambda: select_source(file_exist_window),
        ).place(x=225, y=450)
        # Button(file_exist_window, text='Cancel', state=NORMAL, command=file_exist_window.destroy).place(x=225, y=450)
        # file_exist_window.destroy()
        # To prevent file open errors during export, clear all files if the .\Output\ directory is not empty
        """
        if messagebox.askyesno("Delete files", "This will delete all output files from \Output\ directory, generated from the previous run.\nDo you wish to proceed?"):
            clear_output_dir('./Output')            
            select_source(file_exist_window)
            #Button(file_exist_window, text='Proceed', state=NORMAL, command=lambda:select_source(file_exist_window)).place(x=225, y=450)
        else:
            if file_exist_window.winfo_exists():
                file_exist_window.destroy()  
        """
        Button(
            file_exist_window,
            text="Cancel",
            state=NORMAL,
            command=file_exist_window.destroy,
        ).place(x=300, y=450)
        # Added below 2 steps - Jeanette display only if any file is missing
        file_exist_window.destroy()
        select_source(file_exist_window)
    else:
        logging.info("Some of the required files do not exist/ are empty")
        if messagebox.askyesno(
            "Continue?",
            "Some of the required files does not exist/ are empty.\nContinuing the extract will error out at a later point.\nDo you still want to proceed with the extraction?",
        ):
            logging.info("The user still attempted to proceed with the extraction")
            Button(
                file_exist_window,
                text="Proceed",
                state=NORMAL,
                command=lambda: select_source(file_exist_window),
            ).place(x=225, y=450)
            # file_exist_window.destroy()
            # To prevent file open errors during export, clear all files if the .\Output\ directory is not empty
            """
            if messagebox.askyesno("Delete files", "This will delete all output files from \Output\ directory, generated from the previous run.\nDo you wish to proceed?"):
                clear_output_dir('./Output')            
                select_source(file_exist_window)
                #Button(file_exist_window, text='Proceed', state=NORMAL, command=lambda:select_source(file_exist_window)).place(x=225, y=450)
            else:
                if file_exist_window.winfo_exists():
                    file_exist_window.destroy()
            """
            Button(
                file_exist_window,
                text="Cancel",
                state=NORMAL,
                command=file_exist_window.destroy,
            ).place(x=300, y=450)
        else:
            if file_exist_window.winfo_exists():
                file_exist_window.destroy()


def run_task(
    main_screen,
    label_1,
    label_2,
    label_3,
    label_4,
    label_5,
    label_6,
    label_7,
    label_8,
    label_9,
    label_10,
    button_task,
    task,
):
    if task == "extract":
        button_export["state"] = DISABLED
        label_1_sub.configure(text="")
        label_1_res.configure(text="")
        label_2_sub.configure(text="")
        label_2_res.configure(text="")
        label_3_sub.configure(text="")
        label_3_res.configure(text="")
        label_4_sub.configure(text="")
        label_4_res.configure(text="")
        label_5_sub.configure(text="")
        label_5_res.configure(text="")
        label_6_sub.configure(text="")
        label_6_res.configure(text="")
        label_7_sub.configure(text="")
        label_7_res.configure(text="")
        label_8_sub.configure(text="")
        label_8_res.configure(text="")
        label_9_sub.configure(text="")
        label_9_res.configure(text="")
        label_10_sub.configure(text="")
        label_10_res.configure(text="")
        # destroy transform buttons
        if button_critical_care.winfo_exists():
            button_critical_care.place_forget()
        if button_EDRoleDelin.winfo_exists():
            button_EDRoleDelin.place_forget()
        if button_Specialtyportalmapping.winfo_exists():
            button_Specialtyportalmapping.place_forget()
        if button_SubProgramRole.winfo_exists():
            button_SubProgramRole.place_forget()
        if button_amo_payment.winfo_exists():
            button_amo_payment.place_forget()
        label_1.configure(text="Extract Patient Data")
        label_2.configure(text="Extract NWAU Data")
        label_3.configure(text="Extract Encounter IP Data")
        label_4.configure(text="Extract Transfer Data")
        label_5.configure(text="Extract Diagnosis Data")
        label_6.configure(text="Extract Procedure Data")
        label_7.configure(text="Extract ED Patient Data")
        label_8.configure(text="Extract ED Encounter Data")
        label_9.configure(text="Import SNAP Data")
        label_10.configure(text="Import AMHCC Data")
        # check if mandatory files exists
        check_initial_files_exist(main_screen)
    elif task == "transform":
        button_transform["state"] = DISABLED
        # clear extract labels
        label_1_sub.configure(text="")
        label_1_res.configure(text="")
        label_2_sub.configure(text="")
        label_2_res.configure(text="")
        label_3_sub.configure(text="")
        label_3_res.configure(text="")
        label_4_sub.configure(text="")
        label_4_res.configure(text="")
        label_5_sub.configure(text="")
        label_5_res.configure(text="")
        label_6_sub.configure(text="")
        label_6_res.configure(text="")
        label_7_sub.configure(text="")
        label_7_res.configure(text="")
        label_8_sub.configure(text="")
        label_8_res.configure(text="")
        label_9_sub.configure(text="")
        label_9_res.configure(text="")
        label_10_sub.configure(text="")
        label_10_res.configure(text="")
        # re PLACE the labels
        label_1.place(in_=left_frame, relx=0.10, rely=0.08, anchor=W)
        label_2.place(in_=left_frame, relx=0.10, rely=0.20, anchor=W)
        label_3.place(in_=left_frame, relx=0.10, rely=0.32, anchor=W)
        label_4.place(in_=left_frame, relx=0.10, rely=0.44, anchor=W)
        label_5.place(in_=left_frame, relx=0.10, rely=0.56, anchor=W)
        label_6.place(in_=left_frame, relx=0.10, rely=0.68, anchor=W)
        label_7.place(in_=left_frame, relx=0.10, rely=0.80, anchor=W)
        label_8.place(in_=left_frame, relx=0.10, rely=0.92, anchor=W)
        label_9.place(in_=left_frame, relx=0.10, rely=0.94, anchor=W)
        label_10.place(in_=left_frame, relx=0.10, rely=0.96, anchor=W)
        # add transform labels
        # label_1.configure(text= "Execute Transformations") # Ranjit
        label_1.configure(text="Update AMO Payment Status")
        label_2.configure(text="Map to State Standard Specialty")
        label_3.configure(text="Check Key Location Map")
        label_4.configure(text="ED Role Delineation")
        label_5.configure(text="Check Ward Roles for SubProgram Assignment")
        label_6.configure(text="")
        # label_6.configure(text= "Finalise Transformations") # Ranjit
        label_7.configure(text="")
        label_8.configure(text="")
        label_9.configure(text="")
        label_10.configure(text="")
        # add buttons @ positions y = 0.08 0.20 0.32 0.44 0.56 0.76
        # button_amo_payment=Button(left_frame, text="Review table", fg='black', font=("Times New Roman", 10), command=lambda:transform_amo_payment())
        button_amo_payment.place(relx=0.80, rely=0.08, anchor=CENTER)
        # button_Specialtyportalmapping=Button(left_frame, text="Review table", fg='black', font=("Times New Roman", 10), command=lambda:transform_Specialtyportalmapping())
        button_Specialtyportalmapping.place(relx=0.80, rely=0.20, anchor=CENTER)
        # button_critical_care=Button(left_frame, text="Review table", fg='black', font=("Times New Roman", 10), command=lambda:transform_critical_care())
        button_critical_care.place(relx=0.80, rely=0.32, anchor=CENTER)
        # button_EDRoleDelin=Button(left_frame, text="Review table", fg='black', font=("Times New Roman", 10), command=lambda:transform_EDRoleDelin())
        button_EDRoleDelin.place(relx=0.80, rely=0.44, anchor=CENTER)
        # button_SubProgramRole=Button(left_frame, text="Review table", fg='black', font=("Times New Roman", 10), command=lambda:transform_SubProgramRole())
        button_SubProgramRole.place(relx=0.80, rely=0.56, anchor=CENTER)
        # transformation complete
        button_transform_complete.place(relx=0.50, rely=0.76, anchor=CENTER)
        # change button color for mapping tables
        ########################################
        file_PpmTransferAmo = "./ExtractorDB/Tbl_PPM_transfer_AMO.csv"
        if os.path.isfile(file_PpmTransferAmo):
            try:
                df_file_PpmTransferAmo = read_csv_file(
                    file_PpmTransferAmo,
                    encoding="unicode_escape",
                    dtype=str,
                    keep_default_na=False,
                    na_values="",
                )
            except Exception as e:
                logging.exception("Exception occurred")
                messagebox.showerror(
                    "File Error", "Error extracting Tbl_PPM_transfer_AMO.\n" + str(e)
                )
            else:
                if (
                    df_file_PpmTransferAmo.Consultant_Status.isnull().sum() > 0
                    or df_file_PpmTransferAmo.Consultant_Status.isna().sum() > 0
                    or len(
                        df_file_PpmTransferAmo[
                            df_file_PpmTransferAmo["Consultant_Status"] == ""
                        ]
                    )
                    > 0
                ):
                    button_amo_payment.config(bg="yellow")
                else:
                    button_amo_payment.config(bg="#f0f0f0")
        else:
            button_amo_payment.config(bg="#f0f0f0")
        file_SpecialtyPortalMapping = "./ExtractorDB/SpecialityPortalMapping.csv"
        if os.path.isfile(file_SpecialtyPortalMapping):
            try:
                df_file_SpecialtyPortalMapping = read_csv_file(
                    file_SpecialtyPortalMapping,
                    encoding="unicode_escape",
                    dtype=str,
                    keep_default_na=False,
                    na_values="",
                )
            except Exception as e:
                logging.exception("Exception occurred")
                messagebox.showerror(
                    "File Error", "Error extracting SpecialtyPortalMapping.\n" + str(e)
                )
            else:
                if (
                    df_file_SpecialtyPortalMapping.SpecialityPortal.isnull().sum() > 0
                    or df_file_SpecialtyPortalMapping.SpecialityPortal.isna().sum() > 0
                    or len(
                        df_file_SpecialtyPortalMapping[
                            df_file_SpecialtyPortalMapping["SpecialityPortal"] == ""
                        ]
                    )
                    > 0
                ):
                    button_Specialtyportalmapping.config(bg="yellow")
                else:
                    button_Specialtyportalmapping.config(bg="#f0f0f0")
        else:
            button_Specialtyportalmapping.config(bg="#f0f0f0")
        ########################################
        main_screen.update()
    elif task == "reconciliation":
        label_1_sub.configure(text="")
        label_1_res.configure(text="")
        label_2_sub.configure(text="")
        label_2_res.configure(text="")
        label_3_sub.configure(text="")
        label_3_res.configure(text="")
        label_4_sub.configure(text="")
        label_4_res.configure(text="")
        label_5_sub.configure(text="")
        label_5_res.configure(text="")
        label_6_sub.configure(text="")
        label_6_res.configure(text="")
        label_7_sub.configure(text="")
        label_7_res.configure(text="")
        label_8_sub.configure(text="")
        label_8_res.configure(text="")
        label_9_sub.configure(text="")
        label_9_res.configure(text="")
        label_10_sub.configure(text="")
        label_10_res.configure(text="")
        label_1.configure(text="")
        label_2.configure(text="")
        label_3.configure(text="")
        label_4.configure(text="")
        label_5.configure(text="")
        label_6.configure(text="")
        label_7.configure(text="")
        label_8.configure(text="")
        label_9.configure(text="")
        label_10.configure(text="")
        # destroy transform buttons
        if button_critical_care.winfo_exists():
            button_critical_care.place_forget()
        if button_EDRoleDelin.winfo_exists():
            button_EDRoleDelin.place_forget()
        if button_Specialtyportalmapping.winfo_exists():
            button_Specialtyportalmapping.place_forget()
        if button_SubProgramRole.winfo_exists():
            button_SubProgramRole.place_forget()
        if button_amo_payment.winfo_exists():
            button_amo_payment.place_forget()
        if button_transform_complete.winfo_exists():
            button_transform_complete.place_forget()
        main_screen.update()
    elif task == "qc_check":
        label_1_sub.configure(text="")
        label_1_res.configure(text="")
        label_2_sub.configure(text="")
        label_2_res.configure(text="")
        label_3_sub.configure(text="")
        label_3_res.configure(text="")
        label_4_sub.configure(text="")
        label_4_res.configure(text="")
        label_5_sub.configure(text="")
        label_5_res.configure(text="")
        label_6_sub.configure(text="")
        label_6_res.configure(text="")
        label_7_sub.configure(text="")
        label_7_res.configure(text="")
        label_8_sub.configure(text="")
        label_8_res.configure(text="")
        label_9_sub.configure(text="")
        label_9_res.configure(text="")
        label_10_sub.configure(text="")
        label_10_res.configure(text="")
        label_1.configure(text="")
        label_2.configure(text="")
        label_3.configure(text="")
        label_4.configure(text="")
        label_5.configure(text="")
        label_6.configure(text="")
        label_7.configure(text="")
        label_8.configure(text="")
        label_9.configure(text="")
        label_10.configure(text="")
        # destroy transform buttons
        if button_critical_care.winfo_exists():
            button_critical_care.place_forget()
        if button_EDRoleDelin.winfo_exists():
            button_EDRoleDelin.place_forget()
        if button_Specialtyportalmapping.winfo_exists():
            button_Specialtyportalmapping.place_forget()
        if button_SubProgramRole.winfo_exists():
            button_SubProgramRole.place_forget()
        if button_amo_payment.winfo_exists():
            button_amo_payment.place_forget()
        if button_transform_complete.winfo_exists():
            button_transform_complete.place_forget()
        main_screen.update()
    # task == 'export':
    else:
        button_export["state"] = DISABLED
        # clear transform labels
        label_1_sub.configure(text="")
        label_1_res.configure(text="")
        label_2_sub.configure(text="")
        label_2_res.configure(text="")
        label_3_sub.configure(text="")
        label_3_res.configure(text="")
        label_4_sub.configure(text="")
        label_4_res.configure(text="")
        label_5_sub.configure(text="")
        label_5_res.configure(text="")
        label_6_sub.configure(text="")
        label_6_res.configure(text="")
        label_7_sub.configure(text="")
        label_7_res.configure(text="")
        label_8_sub.configure(text="")
        label_8_res.configure(text="")
        label_9_sub.configure(text="")
        label_9_res.configure(text="")
        label_10_sub.configure(text="")
        label_10_res.configure(text="")
        # destroy transform buttons
        if button_critical_care.winfo_exists():
            button_critical_care.place_forget()
        if button_EDRoleDelin.winfo_exists():
            button_EDRoleDelin.place_forget()
        if button_Specialtyportalmapping.winfo_exists():
            button_Specialtyportalmapping.place_forget()
        if button_SubProgramRole.winfo_exists():
            button_SubProgramRole.place_forget()
        if button_amo_payment.winfo_exists():
            button_amo_payment.place_forget()
        if button_transform_complete.winfo_exists():
            button_transform_complete.place_forget()
        # destroy if any existing reconciliation buttons
        if button_reconciliation_ip.winfo_exists():
            button_reconciliation_ip.place_forget()
        if button_reconciliation_ed.winfo_exists():
            button_reconciliation_ed.place_forget()
        # destroy if any existing QC button
        if button_QCcheck.winfo_exists():
            button_QCcheck.place_forget()
        # re PLACE the labels
        label_1.place(in_=left_frame, relx=0.10, rely=0.08, anchor=W)
        label_2.place(in_=left_frame, relx=0.10, rely=0.14, anchor=W)
        label_3.place(in_=left_frame, relx=0.10, rely=0.20, anchor=W)
        label_4.place(in_=left_frame, relx=0.10, rely=0.26, anchor=W)
        label_5.place(in_=left_frame, relx=0.10, rely=0.32, anchor=W)
        label_6.place(in_=left_frame, relx=0.10, rely=0.38, anchor=W)
        label_7.place(in_=left_frame, relx=0.10, rely=0.44, anchor=W)
        label_8.place(in_=left_frame, relx=0.10, rely=0.50, anchor=W)
        label_9.place(in_=left_frame, relx=0.10, rely=0.60, anchor=W)
        label_10.place(in_=left_frame, relx=0.10, rely=0.66, anchor=W)
        # add export labels
        label_1.configure(text="Export Patient Data")
        label_2.configure(text="Export Encounter IP Data")
        label_3.configure(text="Export Diagnosis Data")
        label_4.configure(text="Export Procedure Data")
        label_5.configure(text="Export Transfer Data")
        label_6.configure(text="Export ED Encounter Data")
        label_7.configure(text="Export ED Patient Data")
        # Kylie informed that DRG Weight maker is not required anymore
        # label_8.configure(text= "Execute DRG Weight Maker")
        label_8.configure(text="")
        label_9.configure(text="Execute Final Steps")
        label_10.configure(text="")
        # re PLACE the progress labels
        label_1_sub.place(in_=left_frame, relx=0.50, rely=0.08, anchor=W)
        label_2_sub.place(in_=left_frame, relx=0.50, rely=0.14, anchor=W)
        label_3_sub.place(in_=left_frame, relx=0.50, rely=0.20, anchor=W)
        label_4_sub.place(in_=left_frame, relx=0.50, rely=0.26, anchor=W)
        label_5_sub.place(in_=left_frame, relx=0.50, rely=0.32, anchor=W)
        label_6_sub.place(in_=left_frame, relx=0.50, rely=0.38, anchor=W)
        label_7_sub.place(in_=left_frame, relx=0.50, rely=0.44, anchor=W)
        label_8_sub.place(in_=left_frame, relx=0.50, rely=0.50, anchor=W)
        label_9_sub.place(in_=left_frame, relx=0.50, rely=0.60, anchor=W)
        main_screen.update()
        directory_path = "./Output/"
        no_of_files = len(os.listdir(directory_path))
        if no_of_files == 0:
            messagebox.showinfo(
                "Omen",
                "There are no files in the Output folder to export.\nCosting Extractor will now close.",
            )
            button_export["state"] = DISABLED
            main_screen.destroy()
            logging.info("There are no files in the Output folder to export.")
        else:
            messagebox.showinfo(
                "Export Data",
                "Starting Exporting of Data.\nPlease don't open any files from Output or Extractor folder until Export completes.\nAfter the export completes successfully, the files will be visible in ./Output folder.\nIf export fails at any point, you will have to rectify the error and restart the export.",
            )
            export_data()


def open_user_guide():
    file_to_open = "Instructions.pdf"
    os.startfile(os.path.abspath(file_to_open))


def send_outlook_email():
    # Ref: https://github.com/cydalytics/Python_Outlook_Email_Deliver/blob/main/Use%20Python%20to%20Send%20Outlook%20Email.ipynb
    # https://stackoverflow.com/a/17887528
    # Open the Outlook
    outlook = win32.Dispatch("outlook.application")
    # Create the email
    mail = outlook.CreateItem(0)
    # Set the email subject
    mail.Subject = "EDW Costing extractor v1.17 - issue"
    # Set the receiver email
    mail.To = "HSSG-DNRSubmissions@health.nsw.gov.au"
    # mail CC
    mail.CC = "Ranjit.Sukumaran@health.nsw.gov.au;"
    # Write the email content
    mail.HTMLBody = r"""
    Hi ABM,<br><br>
    ##Please provide below information about the bug/enhancement/feedback :##<br><br>
    For more details, please check the attached log file.<br><br>
    Best regards,<br>
    """
    # Add the attachment
    mail.Attachments.Add(os.getcwd() + "\\python_costing_extractor_log.log")
    # Send the email
    # mail.Send()
    mail.Display(True)


def about_us(main_screen):
    about_us_win = Toplevel(main_screen)
    about_us_win.geometry("%dx%d+%d+%d" % (200, 200, center_x1, center_y1))
    about_us_win.configure(bg="white")
    about_us_win.title("About Us")
    about_us_win.resizable(False, False)
    about_us_label = Label(
        about_us_win,
        text="ABM\n\n1 Reserve Road,\nSt Leonards,\nNew South Wales 2065",
        font=("Times New Roman", 12),
        background="white",
    ).grid(column=10, row=20)
    about_us_win.mainloop()


def condition_of_access(main_screen):
    # Ref: https://www.geeksforgeeks.org/python-tkinter-scrolledtext-widget/
    # Creating tkinter main window
    win = Toplevel(main_screen)
    win.geometry("%dx%d+%d+%d" % (500, 500, center_x1, center_y1))
    win.configure(bg="white")
    win.title("Conditions of Access")
    win.resizable(False, False)
    Label(
        win,
        text="Conditions of Access\nto the PPM Patient Extraction Tool",
        font=("Times New Roman", 15),
        background="white",
    ).grid(column=0, row=0)
    # Creating scrolled text
    # area widget
    text_area = st.ScrolledText(win, width=55, height=20, font=("Times New Roman", 12))
    text_area.grid(column=0, pady=10, padx=20)
    # Inserting Text which is read only
    text_area.insert(
        INSERT,
        """The conditions of access set out below need to be read in conjunction with the NSW Heath Department Policy Directive PD2015_035- Code of Conduct NSW Health. Non-compliance with the conditions of access could lead to withdrawal of privileges and disciplinary action. 
    1. Access to the facility is via user passwords. The user is responsible at all times for the proper use of the password and for all access under the password, which should be changed regularly to prevent misuse. It is a violation of conditions of use to use another's password or allow yours to be used by others.
    2. Computer records are maintained for all usage of passwords to access sites. Access to any user may be limited or denied at the Director-General's discretion.
    3. I understand that by accessing this database, I may have access to confidential data or information collected for purposes of client/patient care, financial, full-time equivalent or for administrative, statistical or other purposes. Such confidential information may include among other things the identity of, and personal and health information about individual persons.
    4. I undertake not to knowingly access any personal health, financial or FTE information unless such information is essential for me to properly and efficiently perform my duties. I undertake to preserve the confidentiality of this information and understand that a breach of this undertaking will result in disciplinary action. I acknowledge my statutory duty under Section 22 of the Health Administration Act 1982 as well as under the NSW Health Code of conduct, in relation to the disclosure of information. In order to fulfil this undertaking, I will not divulge any identifying, personal or health information regarding individual persons, financial or FTE, except to authorised staff of the Department of Health or LHD/SHN who require such information to carry out the functions of their Department.
    5. I also undertake to follow other information privacy and security procedures as stipulated by the Director-General, in relation to any personal health information that I access in the course of my duties. In order to fulfil this undertaking I will ensure that, so far as within, my control, such information, whether in the form of paper documents, computerised data or in any other form, cannot be views by unauthorised persons and that the information is stored in a secure and orderly manner which prevents unauthorised access.
    6.I further undertake to inform my supervisor immediately if I become aware of any breach of privacy or security relating to the information that I access in the course of my duties.""",
    )
    # Making the text read only
    text_area.configure(state="disabled")
    win.mainloop()


##############################################
# destroy splash window
splash_screen.after(3000, lambda: splash_screen.destroy())
# Execute tkinter
main_screen = Tk()
# SET POSITION AND SIZE OF THE WINDOW
main_screen.geometry("1300x700")
# Ref: https://www.pythontutorial.net/tkinter/tkinter-window/
global root_width, root_height
root_width = 1300
root_height = 750
# get the screen dimension
screen_width1 = main_screen.winfo_screenwidth()
screen_height1 = main_screen.winfo_screenheight()
# find the center point
global center_x1, center_y1
center_x1 = int(screen_width1 / 2 - root_width / 2)
center_y1 = int(screen_height1 / 2 - root_height / 2)
# set the position of the window to the center of the screen
# main_screen.geometry(f'{root_width}x{root_height}+{center_x1}+{center_y1}')
main_screen.geometry("%dx%d+%d+%d" % (root_width, root_height, center_x1, center_y1))
# set window color
main_screen.configure(bg="white")
# SET WINDOW TITLE
main_screen.title("Data Extraction Utility for PPM3 v1.17")
# add label widget
label_heading = Label(
    main_screen,
    text="Data Extraction Utility for PPM3",
    fg="black",
    font=("Times New Roman", 20),
    justify=CENTER,
    bg="white",
)
label_heading.place(x=300, y=25)
# Create left frame
left_frame = Frame(
    main_screen,
    width=575,
    height=600,
    bg="white",
    highlightbackground="grey",
    highlightthickness=2,
)
left_frame.place(x=250, y=75)
# Create right frame
right_frame = Frame(
    main_screen,
    width=400,
    height=600,
    bg="white",
    highlightbackground="grey",
    highlightthickness=2,
)
right_frame.place(x=850, y=75)
# add labels for extract task
label_1 = Label(
    main_screen, text="Extract Patient Data", font=("Times New Roman", 12), bg="white"
)
label_1.place(in_=left_frame, relx=0.10, rely=0.08, anchor=W)
label_2 = Label(
    main_screen, text="Extract NWAU Data", font=("Times New Roman", 12), bg="white"
)
# label_2.place(in_=left_frame,  relx=0.10, rely=0.16,  anchor=W)
label_2.place(in_=left_frame, relx=0.10, rely=0.14, anchor=W)
label_3 = Label(
    main_screen,
    text="Extract Encounter IP Data",
    font=("Times New Roman", 12),
    bg="white",
)
# label_3.place(in_=left_frame,  relx=0.10, rely=0.24,  anchor=W)
label_3.place(in_=left_frame, relx=0.10, rely=0.20, anchor=W)
label_4 = Label(
    main_screen, text="Extract Transfer Data", font=("Times New Roman", 12), bg="white"
)
# label_4.place(in_=left_frame,  relx=0.10, rely=0.34,  anchor=W)
label_4.place(in_=left_frame, relx=0.10, rely=0.26, anchor=W)
label_5 = Label(
    main_screen, text="Extract Diagnosis Data", font=("Times New Roman", 12), bg="white"
)
# label_5.place(in_=left_frame,  relx=0.10, rely=0.44,  anchor=W)
label_5.place(in_=left_frame, relx=0.10, rely=0.32, anchor=W)
label_6 = Label(
    main_screen, text="Extract Procedure Data", font=("Times New Roman", 12), bg="white"
)
# label_6.place(in_=left_frame,  relx=0.10, rely=0.52,  anchor=W)
label_6.place(in_=left_frame, relx=0.10, rely=0.38, anchor=W)
label_7 = Label(
    main_screen,
    text="Extract ED Patient Data",
    font=("Times New Roman", 12),
    bg="white",
)
# label_7.place(in_=left_frame,  relx=0.10, rely=0.60,  anchor=W)
label_7.place(in_=left_frame, relx=0.10, rely=0.44, anchor=W)
label_8 = Label(
    main_screen,
    text="Extract ED Encounter Data",
    font=("Times New Roman", 12),
    bg="white",
)
# label_8.place(in_=left_frame,  relx=0.10, rely=0.68,  anchor=W)
label_8.place(in_=left_frame, relx=0.10, rely=0.50, anchor=W)
label_9 = Label(
    main_screen, text="Import SNAP Data", font=("Times New Roman", 12), bg="white"
)
# label_9.place(in_=left_frame,  relx=0.10, rely=0.76,  anchor=W)
label_9.place(in_=left_frame, relx=0.10, rely=0.56, anchor=W)
label_10 = Label(
    main_screen, text="Import AMHCC Data", font=("Times New Roman", 12), bg="white"
)
# label_10.place(in_=left_frame,  relx=0.10, rely=0.92,  anchor=W)
label_10.place(in_=left_frame, relx=0.10, rely=0.62, anchor=W)
# add labels for Progress status in extract task
label_1_sub = Label(main_screen, text="", font=("Times New Roman", 12), bg="white")
# label_1_sub.place(in_=left_frame,  relx=0.50, rely=0.08,  anchor=W)
label_1_sub.place(in_=left_frame, relx=0.50, rely=0.08, anchor=W)
label_2_sub = Label(main_screen, text="", font=("Times New Roman", 12), bg="white")
# label_2_sub.place(in_=left_frame,  relx=0.50, rely=0.16,  anchor=W)
label_2_sub.place(in_=left_frame, relx=0.50, rely=0.14, anchor=W)
label_3_sub = Label(main_screen, text="", font=("Times New Roman", 12), bg="white")
# label_3_sub.place(in_=left_frame,  relx=0.50, rely=0.24,  anchor=W)
label_3_sub.place(in_=left_frame, relx=0.50, rely=0.20, anchor=W)
label_4_sub = Label(main_screen, text="", font=("Times New Roman", 12), bg="white")
# label_4_sub.place(in_=left_frame,  relx=0.50, rely=0.34,  anchor=W)
label_4_sub.place(in_=left_frame, relx=0.50, rely=0.26, anchor=W)
label_5_sub = Label(main_screen, text="", font=("Times New Roman", 12), bg="white")
# label_5_sub.place(in_=left_frame,  relx=0.50, rely=0.44,  anchor=W)
label_5_sub.place(in_=left_frame, relx=0.50, rely=0.32, anchor=W)
label_6_sub = Label(main_screen, text="", font=("Times New Roman", 12), bg="white")
# label_6_sub.place(in_=left_frame,  relx=0.50, rely=0.52,  anchor=W)
label_6_sub.place(in_=left_frame, relx=0.50, rely=0.38, anchor=W)
label_7_sub = Label(main_screen, text="", font=("Times New Roman", 12), bg="white")
# label_7_sub.place(in_=left_frame,  relx=0.50, rely=0.60,  anchor=W)
label_7_sub.place(in_=left_frame, relx=0.50, rely=0.44, anchor=W)
label_8_sub = Label(main_screen, text="", font=("Times New Roman", 12), bg="white")
# label_8_sub.place(in_=left_frame,  relx=0.50, rely=0.68,  anchor=W)
label_8_sub.place(in_=left_frame, relx=0.50, rely=0.50, anchor=W)
label_9_sub = Label(main_screen, text="", font=("Times New Roman", 12), bg="white")
# label_9_sub.place(in_=left_frame,  relx=0.50, rely=0.76,  anchor=W)
label_9_sub.place(in_=left_frame, relx=0.50, rely=0.56, anchor=W)
label_10_sub = Label(main_screen, text="", font=("Times New Roman", 12), bg="white")
# label_10_sub.place(in_=left_frame,  relx=0.50, rely=0.92,  anchor=W)
label_10_sub.place(in_=left_frame, relx=0.50, rely=0.62, anchor=W)
# add labels for results in extract task
label_1_res = Label(
    main_screen, text="", font=("Times New Roman", 8), bg="white", justify=LEFT
)
label_1_res.place(in_=left_frame, relx=0.15, rely=0.12, anchor=W)
label_2_res = Label(
    main_screen, text="", font=("Times New Roman", 8), bg="white", justify=LEFT
)
label_2_res.place(in_=left_frame, relx=0.15, rely=0.20, anchor=W)
label_3_res = Label(
    main_screen, text="", font=("Times New Roman", 8), bg="white", justify=LEFT
)
label_3_res.place(in_=left_frame, relx=0.15, rely=0.30, anchor=W)
label_4_res = Label(
    main_screen, text="", font=("Times New Roman", 8), bg="white", justify=LEFT
)
label_4_res.place(in_=left_frame, relx=0.15, rely=0.40, anchor=W)
label_5_res = Label(
    main_screen, text="", font=("Times New Roman", 8), bg="white", justify=LEFT
)
label_5_res.place(in_=left_frame, relx=0.15, rely=0.48, anchor=W)
label_6_res = Label(
    main_screen, text="", font=("Times New Roman", 8), bg="white", justify=LEFT
)
label_6_res.place(in_=left_frame, relx=0.15, rely=0.56, anchor=W)
label_7_res = Label(
    main_screen, text="", font=("Times New Roman", 8), bg="white", justify=LEFT
)
label_7_res.place(in_=left_frame, relx=0.15, rely=0.64, anchor=W)
label_8_res = Label(
    main_screen, text="", font=("Times New Roman", 8), bg="white", justify=LEFT
)
label_8_res.place(in_=left_frame, relx=0.15, rely=0.72, anchor=W)
label_9_res = Label(
    main_screen, text="", font=("Times New Roman", 8), bg="white", justify=LEFT
)
label_9_res.place(in_=left_frame, relx=0.15, rely=0.84, anchor=W)
label_10_res = Label(
    main_screen, text="", font=("Times New Roman", 8), bg="white", justify=LEFT
)
label_10_res.place(in_=left_frame, relx=0.15, rely=0.96, anchor=W)
# Add buttons to left
# EXTRACT
button_extract = Button(
    main_screen,
    text="Start Extractions",
    fg="black",
    font=("Times New Roman", 10),
    width=25,
    state=NORMAL,
    command=lambda: run_task(
        main_screen,
        label_1,
        label_2,
        label_3,
        label_4,
        label_5,
        label_6,
        label_7,
        label_8,
        label_9,
        label_10,
        button_extract,
        "extract",
    ),
)
button_extract.place(x=25, y=100)
# TRANSFORM
button_transform = Button(
    main_screen,
    text="Run Transformations",
    fg="black",
    font=("Times New Roman", 10),
    width=25,
    state=DISABLED,
    command=lambda: run_task(
        main_screen,
        label_1,
        label_2,
        label_3,
        label_4,
        label_5,
        label_6,
        label_7,
        label_8,
        label_9,
        label_10,
        button_transform,
        "transform",
    ),
)
button_transform.place(x=25, y=150)
# EXPORT
# check if any files from previous run exist in ./ExtractorDB
directory_path = "./ExtractorDB/"
no_of_files = len(os.listdir(directory_path))
if no_of_files > 0:
    button_export = Button(
        main_screen,
        text="Export Data",
        fg="black",
        font=("Times New Roman", 10),
        width=25,
        state=ACTIVE,
        command=lambda: run_task(
            main_screen,
            label_1,
            label_2,
            label_3,
            label_4,
            label_5,
            label_6,
            label_7,
            label_8,
            label_9,
            label_10,
            button_export,
            "export",
        ),
    )
    button_export.place(x=25, y=200)
else:
    button_export = Button(
        main_screen,
        text="Export Data",
        fg="black",
        font=("Times New Roman", 10),
        width=25,
        state=DISABLED,
        command=lambda: run_task(
            main_screen,
            label_1,
            label_2,
            label_3,
            label_4,
            label_5,
            label_6,
            label_7,
            label_8,
            label_9,
            label_10,
            button_export,
            "export",
        ),
    )
    button_export.place(x=25, y=200)
####################RECONCILIATION-EXTRA #############
# Reconciliation
button_ed_recon = Button(
    main_screen,
    text="ED Reconciliation Report",
    fg="black",
    font=("Times New Roman", 10),
    width=25,
    state=DISABLED,
    command=lambda: os.startfile(os.path.abspath("Output/ReconcileEdPatientData.csv")),
)
# button_ed_recon.place(x = 25, y = 250)
button_ip_recon = Button(
    main_screen,
    text="IP Reconciliation Report",
    fg="black",
    font=("Times New Roman", 10),
    width=25,
    state=DISABLED,
    command=lambda: os.startfile(os.path.abspath("Output/ReconcileInpatientData.csv")),
)
# button_ip_recon.place(x = 25, y = 300)
# OMEN
button_omen = Button(
    main_screen,
    text="OMEN",
    fg="black",
    font=("Times New Roman", 10),
    width=25,
    state=NORMAL,
    command=lambda: run_omen(),
)
button_omen.place(x=25, y=350)
# Additional buttons
# Conditions of Access
button_access = Button(
    main_screen,
    text="Conditions of Access",
    fg="black",
    font=("Times New Roman", 10),
    width=25,
    state=NORMAL,
    command=lambda: condition_of_access(main_screen),
)
button_access.place(x=25, y=400)
# HELP
button_help = Button(
    main_screen,
    text="Help",
    fg="black",
    font=("Times New Roman", 10),
    width=25,
    state=NORMAL,
    command=lambda: open_user_guide(),
)
button_help.place(x=25, y=450)
# CONTACT
button_contact = Button(
    main_screen,
    text="Contact Us",
    fg="black",
    font=("Times New Roman", 10),
    width=25,
    state=NORMAL,
    command=lambda: send_outlook_email(),
)
button_contact.place(x=25, y=500)
# ABOUT
###################################
# Create text fields in right frame
Label(main_screen, text="Round ID:", font=("Times New Roman", 12), bg="white").place(
    in_=right_frame, rely=0.04, anchor=W
)
roundid_field = Entry(main_screen, text="")
roundid_field.place(in_=right_frame, relx=0.50, rely=0.04, anchor=W)
Label(main_screen, text="LHD:", font=("Times New Roman", 12), bg="white").place(
    in_=right_frame, rely=0.1, anchor=W
)
lhd_field = Entry(main_screen, text="", width=30)
lhd_field.place(in_=right_frame, relx=0.50, rely=0.1, anchor=W)
Label(
    main_screen,
    text="Start Date (yyyy-mm-dd):",
    font=("Times New Roman", 12),
    bg="white",
).place(in_=right_frame, rely=0.16, anchor=W)
start_date_field = Entry(main_screen, text="")
start_date_field.place(in_=right_frame, relx=0.50, rely=0.16, anchor=W)
Label(
    main_screen, text="End Date (yyyy-mm-dd):", font=("Times New Roman", 12), bg="white"
).place(in_=right_frame, rely=0.24, anchor=W)
end_date_field = Entry(main_screen, text="")
end_date_field.place(in_=right_frame, relx=0.50, rely=0.24, anchor=W)
Label(
    main_screen, text="NWAU Version:", font=("Times New Roman", 12), bg="white"
).place(in_=right_frame, rely=0.32, anchor=W)
nwau_v_field = Entry(main_screen, text="")
nwau_v_field.place(in_=right_frame, relx=0.50, rely=0.32, anchor=W)
Label(
    main_screen, text="ICD10 Version:", font=("Times New Roman", 12), bg="white"
).place(in_=right_frame, rely=0.40, anchor=W)
icd10_v_field = Entry(main_screen, text="")
icd10_v_field.place(in_=right_frame, relx=0.50, rely=0.40, anchor=W)
Label(
    main_screen, text="DRG1 Version:", font=("Times New Roman", 12), bg="white"
).place(in_=right_frame, rely=0.48, anchor=W)
drg1_v_field = Entry(main_screen, text="")
drg1_v_field.place(in_=right_frame, relx=0.50, rely=0.48, anchor=W)
Label(
    main_screen, text="DRG2 Version:", font=("Times New Roman", 12), bg="white"
).place(in_=right_frame, rely=0.56, anchor=W)
drg2_v_field = Entry(main_screen, text="")
drg2_v_field.place(in_=right_frame, relx=0.50, rely=0.56, anchor=W)
Label(
    main_screen, text="DRG4 Version:", font=("Times New Roman", 12), bg="white"
).place(in_=right_frame, rely=0.64, anchor=W)
drg4_v_field = Entry(main_screen, text="")
drg4_v_field.place(in_=right_frame, relx=0.50, rely=0.64, anchor=W)
Label(
    main_screen, text="SNAP Version:", font=("Times New Roman", 12), bg="white"
).place(in_=right_frame, rely=0.72, anchor=W)
snap_v_field = Entry(main_screen, text="")
snap_v_field.place(in_=right_frame, relx=0.50, rely=0.72, anchor=W)
Label(
    main_screen, text="AMHCC Version:", font=("Times New Roman", 12), bg="white"
).place(in_=right_frame, rely=0.80, anchor=W)
amhcc_v_field = Entry(main_screen, text="")
amhcc_v_field.place(in_=right_frame, relx=0.50, rely=0.80, anchor=W)
Label(
    main_screen, text="Cost Weight Version:", font=("Times New Roman", 12), bg="white"
).place(in_=right_frame, rely=0.88, anchor=W)
cost_weight_v_field = Entry(main_screen, text="")
cost_weight_v_field.place(in_=right_frame, relx=0.50, rely=0.88, anchor=W)
Label(
    main_screen, text="SRG/DRG Version:", font=("Times New Roman", 12), bg="white"
).place(in_=right_frame, rely=0.96, anchor=W)
srg_drg_v_field = Entry(main_screen, text="")
srg_drg_v_field.place(in_=right_frame, relx=0.50, rely=0.96, anchor=W)
# define transform buttons
button_critical_care = Button(
    left_frame,
    text="Review table",
    fg="black",
    font=("Times New Roman", 10),
    command=lambda: fn_display_data_in_window("transform", "CriticalCareGroup"),
)
button_EDRoleDelin = Button(
    left_frame,
    text="Review table",
    fg="black",
    font=("Times New Roman", 10),
    command=lambda: fn_display_data_in_window("transform", "EDRoleDelin"),
)
button_SubProgramRole = Button(
    left_frame,
    text="Review table",
    fg="black",
    font=("Times New Roman", 10),
    command=lambda: fn_display_data_in_window("transform", "PLA_Role_Table"),
)
button_transform_complete = Button(
    left_frame,
    width=20,
    text="Finalise transformations",
    command=lambda: transform_complete(),
)
# button_Specialtyportalmapping=Button(left_frame, text="Review table", fg='black', font=("Times New Roman", 10), command=lambda:fn_display_data_in_window('transform', 'SpecialityPortalMapping'))
# button_amo_payment=Button(left_frame, text="Review table", fg='black', font=("Times New Roman", 10), command=lambda:fn_display_data_in_window('transform', 'Tbl_PPM_transfer_AMO'))
###################################################################
file_PpmTransferAmo = "./ExtractorDB/Tbl_PPM_transfer_AMO.csv"
if os.path.isfile(file_PpmTransferAmo):
    try:
        df_file_PpmTransferAmo = read_csv_file(
            file_PpmTransferAmo,
            encoding="unicode_escape",
            dtype=str,
            keep_default_na=False,
            na_values="",
        )
    except Exception as e:
        logging.exception("Exception occurred")
        messagebox.showerror(
            "File Error", "Error extracting Tbl_PPM_transfer_AMO.\n" + str(e)
        )
    else:
        if (
            df_file_PpmTransferAmo.Consultant_Status.isnull().sum() > 0
            or df_file_PpmTransferAmo.Consultant_Status.isna().sum() > 0
            or len(
                df_file_PpmTransferAmo[
                    df_file_PpmTransferAmo["Consultant_Status"] == ""
                ]
            )
            > 0
        ):
            button_amo_payment = Button(
                left_frame,
                text="Review table",
                fg="black",
                bg="yellow",
                font=("Times New Roman", 10),
                command=lambda: fn_display_data_in_window(
                    "transform", "Tbl_PPM_transfer_AMO"
                ),
            )
        else:
            button_amo_payment = Button(
                left_frame,
                text="Review table",
                fg="black",
                font=("Times New Roman", 10),
                command=lambda: fn_display_data_in_window(
                    "transform", "Tbl_PPM_transfer_AMO"
                ),
            )
else:
    button_amo_payment = Button(
        left_frame,
        text="Review table",
        fg="black",
        font=("Times New Roman", 10),
        command=lambda: fn_display_data_in_window("transform", "Tbl_PPM_transfer_AMO"),
    )
file_SpecialtyPortalMapping = "./ExtractorDB/SpecialityPortalMapping.csv"
if os.path.isfile(file_SpecialtyPortalMapping):
    try:
        df_file_SpecialtyPortalMapping = read_csv_file(
            file_SpecialtyPortalMapping,
            encoding="unicode_escape",
            dtype=str,
            keep_default_na=False,
            na_values="",
        )
    except Exception as e:
        logging.exception("Exception occurred")
        messagebox.showerror(
            "File Error", "Error extracting SpecialtyPortalMapping.\n" + str(e)
        )
    else:
        if (
            df_file_SpecialtyPortalMapping.SpecialityPortal.isnull().sum() > 0
            or df_file_SpecialtyPortalMapping.SpecialityPortal.isna().sum() > 0
            or len(
                df_file_SpecialtyPortalMapping[
                    df_file_SpecialtyPortalMapping["SpecialityPortal"] == ""
                ]
            )
            > 0
        ):
            button_Specialtyportalmapping = Button(
                left_frame,
                text="Review table",
                fg="black",
                bg="yellow",
                font=("Times New Roman", 10),
                command=lambda: fn_display_data_in_window(
                    "transform", "SpecialityPortalMapping"
                ),
            )
        else:
            button_Specialtyportalmapping = Button(
                left_frame,
                text="Review table",
                fg="black",
                font=("Times New Roman", 10),
                command=lambda: fn_display_data_in_window(
                    "transform", "SpecialityPortalMapping"
                ),
            )
else:
    button_Specialtyportalmapping = Button(
        left_frame,
        text="Review table",
        fg="black",
        font=("Times New Roman", 10),
        command=lambda: fn_display_data_in_window(
            "transform", "SpecialityPortalMapping"
        ),
    )
###################################################################
# define qc and reconciliation buttons
button_reconciliation_ip = Button(
    left_frame,
    text="Reconciliation Report: Inpatient Data",
    fg="black",
    font=("Times New Roman", 10),
    command=lambda: display_reconciliation("ip"),
)
button_reconciliation_ed = Button(
    left_frame,
    text="Reconciliation Report: ED Data",
    fg="black",
    font=("Times New Roman", 10),
    command=lambda: display_reconciliation("ed"),
)
button_QCcheck = Button(
    left_frame,
    text="Quality Checks",
    fg="black",
    font=("Times New Roman", 10),
    command=lambda: show_qc_window(),
)
# Prevent window x and y to be rezizeable
main_screen.resizable(False, False)
#############################################
# Execute tkinter
mainloop()
